{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_papers = pd.read_parquet('./data/industry_really_complete.parquet')\n",
    "academic_papers = pd.read_parquet('./data/academic_really_complete.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract_claims</th>\n",
       "      <th>conclusion_claims</th>\n",
       "      <th>main_author</th>\n",
       "      <th>institution</th>\n",
       "      <th>year</th>\n",
       "      <th>institution_type</th>\n",
       "      <th>text</th>\n",
       "      <th>abstract</th>\n",
       "      <th>conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011.00890</td>\n",
       "      <td>Emergent Communication Pretraining for Few-Sho...</td>\n",
       "      <td>[Nevertheless, most of the world's languages l...</td>\n",
       "      <td>[In theory, it makes this paradigm applicable ...</td>\n",
       "      <td>Yaoyiran Li</td>\n",
       "      <td>Language Science (South Korea)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>While state-of-the-art models that rely upon m...</td>\n",
       "      <td>and Future Work We have demonstrated that an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2209.15236</td>\n",
       "      <td>Language-Family Adapters for Multilingual Neur...</td>\n",
       "      <td>[In machine translation, multilingual pretrain...</td>\n",
       "      <td>[We have presented a novel approach for fine-t...</td>\n",
       "      <td>Alexandra Chronopoulou</td>\n",
       "      <td>Microsoft (Germany)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Massively multilingual models pretrained on ab...</td>\n",
       "      <td>We have presented a novel approach for fine-tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1910.13299</td>\n",
       "      <td>Findings of the Third Workshop on Neural Gener...</td>\n",
       "      <td>[This document describes the findings of the T...</td>\n",
       "      <td>[This paper summarized the results of the Thir...</td>\n",
       "      <td>Hiroaki Hayashi</td>\n",
       "      <td>Google (United States)</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>This document describes the findings of the Th...</td>\n",
       "      <td>This paper summarized the results of the Third...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2104.08677</td>\n",
       "      <td>From Fully Trained to Fully Random Embeddings:...</td>\n",
       "      <td>[We also show how incorporating only a limited...</td>\n",
       "      <td>[Our work points towards the need of rethinkin...</td>\n",
       "      <td>Krtin Kumar</td>\n",
       "      <td>Thomson Reuters (Canada)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Embedding matrices are key components in neura...</td>\n",
       "      <td>Our work points towards the need of rethinking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1703.04908</td>\n",
       "      <td>Emergence of Grounded Compositional Language i...</td>\n",
       "      <td>[By capturing statistical patterns in large co...</td>\n",
       "      <td>[This abstract language is formed without any ...</td>\n",
       "      <td>Igor Mordatch</td>\n",
       "      <td>OpenAI (United States)</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>By capturing statistical patterns in large cor...</td>\n",
       "      <td>We have presented a multi-agent environment an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1610.08613</td>\n",
       "      <td>Can Active Memory Replace Attention?</td>\n",
       "      <td>[Several mechanisms to focus attention of a ne...</td>\n",
       "      <td>[To better understand the main shortcoming of ...</td>\n",
       "      <td>Łukasz Kaiser</td>\n",
       "      <td>Google (United States)</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Several mechanisms to focus attention of a neu...</td>\n",
       "      <td>To better understand the main shortcoming of p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1411.4555</td>\n",
       "      <td>Show and Tell: A Neural Image Caption Generator</td>\n",
       "      <td>[The model is trained to maximize the likeliho...</td>\n",
       "      <td>[The model is trained to maximize the likeliho...</td>\n",
       "      <td>Oriol Vinyals</td>\n",
       "      <td>Google (United States)</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Automatically describing the content of an ima...</td>\n",
       "      <td>We have presented NIC, an end-to-end neural ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2205.01398</td>\n",
       "      <td>Neural language models for network configurati...</td>\n",
       "      <td>[Boosted by deep learning, natural language pr...</td>\n",
       "      <td>[and recommendations In this paper, we overvie...</td>\n",
       "      <td>Zied Ben Houidi</td>\n",
       "      <td>Huawei Technologies (France)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Boosted by deep learning, natural language pro...</td>\n",
       "      <td>and recommendations In this paper, we overview...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1909.05362</td>\n",
       "      <td>Problems with automating translation of movie/...</td>\n",
       "      <td>[We present 27 problems encountered in automat...</td>\n",
       "      <td>[In this work, we explained 27 problems in aut...</td>\n",
       "      <td>Prabhakar Gupta</td>\n",
       "      <td>Amazon (Germany)</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>We present 27 problems encountered in automati...</td>\n",
       "      <td>In this work, we explained 27 problems in auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2201.04843</td>\n",
       "      <td>Multi-task Pre-training Language Model for Sem...</td>\n",
       "      <td>[Semantic networks, such as the knowledge grap...</td>\n",
       "      <td>[and Future Work We present a multi-task pre-t...</td>\n",
       "      <td>Da Li</td>\n",
       "      <td>Tencent (China)</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Semantic networks, such as the knowledge graph...</td>\n",
       "      <td>and Future Work We present a multi-task pre-tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1808.05505</td>\n",
       "      <td>Paraphrase Thought: Sentence Embedding Module ...</td>\n",
       "      <td>[Sentence embedding is an important research t...</td>\n",
       "      <td>[Sentence embedding is one of the most importa...</td>\n",
       "      <td>Myeongjun Jang</td>\n",
       "      <td>SK Group (South Korea)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Sentence embedding is an important research to...</td>\n",
       "      <td>Sentence embedding is one of the most importan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1503.02427</td>\n",
       "      <td>Syntax-based Deep Matching of Short Texts</td>\n",
       "      <td>[Many tasks in natural language processing, ra...</td>\n",
       "      <td>[We propose a generic model for matching two s...</td>\n",
       "      <td>Mingxuan Wang</td>\n",
       "      <td>Chinese Academy of Sciences</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Many tasks in natural language processing, ran...</td>\n",
       "      <td>We propose a generic model for matching two sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1909.11556</td>\n",
       "      <td>Reducing Transformer Depth on Demand with Stru...</td>\n",
       "      <td>[Overparameterized transformer networks have o...</td>\n",
       "      <td>[Structured dropout regularizes neural network...</td>\n",
       "      <td>Angela Fan</td>\n",
       "      <td>Meta (Israel)</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Overparameterized transformer networks have ob...</td>\n",
       "      <td>Structured dropout regularizes neural networks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2203.06462</td>\n",
       "      <td>Low-Rank Softmax Can Have Unargmaxable Classes...</td>\n",
       "      <td>[Classifiers in natural language processing (N...</td>\n",
       "      <td>[ and Future Work In this work we discretised ...</td>\n",
       "      <td>Andreas Grivas</td>\n",
       "      <td>Language Science (South Korea)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Classifiers in natural language processing (NL...</td>\n",
       "      <td>and Future Work In this work we discretised t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001.10238</td>\n",
       "      <td>Controlling generative models with continuous ...</td>\n",
       "      <td>[Recent deep generative models are able to pro...</td>\n",
       "      <td>[ Generative models are increasingly more powe...</td>\n",
       "      <td>Antoine Plumerault</td>\n",
       "      <td>Integra (United States)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Recent deep generative models are able to prov...</td>\n",
       "      <td>Generative models are increasingly more power...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cmp-lg/9505042</td>\n",
       "      <td>Robust Parsing Based on Discourse Information:...</td>\n",
       "      <td>[In a consistent text, many words and phrases ...</td>\n",
       "      <td>[We have proposed a method for completing part...</td>\n",
       "      <td>Tetsuya Nasukawa</td>\n",
       "      <td>IBM Research - Tokyo</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>In a consistent text, many words and phrases a...</td>\n",
       "      <td>We have proposed a method for completing parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012.01303</td>\n",
       "      <td>Complex Coordinate-Based Meta-Analysis with Pr...</td>\n",
       "      <td>[With the growing number of published function...</td>\n",
       "      <td>[This work is a step towards incorporating com...</td>\n",
       "      <td>Valentin Iovene</td>\n",
       "      <td>CEA Paris-Saclay</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>With the growing number of published functiona...</td>\n",
       "      <td>This work is a step towards incorporating comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2204.13353</td>\n",
       "      <td>Attention Mechanism with Energy-Friendly Opera...</td>\n",
       "      <td>[Attention mechanism has become the dominant m...</td>\n",
       "      <td>[We visualize the averaged attention values ov...</td>\n",
       "      <td>Yu Wan</td>\n",
       "      <td>Alibaba Group (United States)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Attention mechanism has become the dominant mo...</td>\n",
       "      <td>We visualize the averaged attention values ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1911.12864</td>\n",
       "      <td>Self-attention with Functional Time Representa...</td>\n",
       "      <td>[Sequential modelling with self-attention has ...</td>\n",
       "      <td>[mplementation The reference code for our impl...</td>\n",
       "      <td>Da Xu</td>\n",
       "      <td>Walmart (United States)</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Sequential modelling with self-attention has a...</td>\n",
       "      <td>mplementation The reference code for our imple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2204.00471</td>\n",
       "      <td>Uncertainty Determines the Adequacy of the Mod...</td>\n",
       "      <td>[In many natural language processing (NLP) tas...</td>\n",
       "      <td>[We identified a major culprit behind various ...</td>\n",
       "      <td>Felix Stahlberg</td>\n",
       "      <td>Google (United States)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>In many natural language processing (NLP) task...</td>\n",
       "      <td>We identified a major culprit behind various i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1910.06762</td>\n",
       "      <td>T-GSA: Transformer with Gaussian-weighted self...</td>\n",
       "      <td>[Transformer neural networks (TNN) demonstrate...</td>\n",
       "      <td>[We proposed a Transformer architecture with G...</td>\n",
       "      <td>Jaeyoung Kim</td>\n",
       "      <td>Samsung (South Korea)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Transformer neural networks (TNN) demonstrated...</td>\n",
       "      <td>We proposed a Transformer architecture with Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2202.12934</td>\n",
       "      <td>Accelerating Neural Architecture Exploration A...</td>\n",
       "      <td>[Neural architecture search (NAS), the study o...</td>\n",
       "      <td>[The goal of the work was to demonstrate how G...</td>\n",
       "      <td>Daniel Cummings</td>\n",
       "      <td>Intel (United Kingdom)</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Neural architecture search (NAS), the study of...</td>\n",
       "      <td>The goal of the work was to demonstrate how GA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1907.12461</td>\n",
       "      <td>Leveraging Pre-trained Checkpoints for Sequenc...</td>\n",
       "      <td>[Unsupervised pre-training of large neural mod...</td>\n",
       "      <td>[We performed an extensive study on leveraging...</td>\n",
       "      <td>Sascha Rothe</td>\n",
       "      <td>Google (Switzerland)</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Unsupervised pre-training of large neural mode...</td>\n",
       "      <td>We performed an extensive study on leveraging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2108.11703</td>\n",
       "      <td>Data Augmentation for Low-Resource Named Entit...</td>\n",
       "      <td>[The state of art natural language processing ...</td>\n",
       "      <td>[In this paper, we adapt backtranslation to th...</td>\n",
       "      <td>Usama Yaseen</td>\n",
       "      <td>Siemens (Germany)</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>The state of art natural language processing s...</td>\n",
       "      <td>In this paper, we adapt backtranslation to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1609.06647</td>\n",
       "      <td>Show and Tell: Lessons learned from the 2015 M...</td>\n",
       "      <td>[The model is trained to maximize the likeliho...</td>\n",
       "      <td>[The model is trained to maximize the likeliho...</td>\n",
       "      <td>Oriol Vinyals</td>\n",
       "      <td>Google (United States)</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Industry</td>\n",
       "      <td>None</td>\n",
       "      <td>Automatically describing the content of an ima...</td>\n",
       "      <td>We have presented NIC, an end-to-end neural ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                              title  \\\n",
       "0       2011.00890  Emergent Communication Pretraining for Few-Sho...   \n",
       "1       2209.15236  Language-Family Adapters for Multilingual Neur...   \n",
       "2       1910.13299  Findings of the Third Workshop on Neural Gener...   \n",
       "3       2104.08677  From Fully Trained to Fully Random Embeddings:...   \n",
       "4       1703.04908  Emergence of Grounded Compositional Language i...   \n",
       "5       1610.08613               Can Active Memory Replace Attention?   \n",
       "6        1411.4555    Show and Tell: A Neural Image Caption Generator   \n",
       "7       2205.01398  Neural language models for network configurati...   \n",
       "8       1909.05362  Problems with automating translation of movie/...   \n",
       "9       2201.04843  Multi-task Pre-training Language Model for Sem...   \n",
       "10      1808.05505  Paraphrase Thought: Sentence Embedding Module ...   \n",
       "11      1503.02427          Syntax-based Deep Matching of Short Texts   \n",
       "12      1909.11556  Reducing Transformer Depth on Demand with Stru...   \n",
       "13      2203.06462  Low-Rank Softmax Can Have Unargmaxable Classes...   \n",
       "14      2001.10238  Controlling generative models with continuous ...   \n",
       "15  cmp-lg/9505042  Robust Parsing Based on Discourse Information:...   \n",
       "16      2012.01303  Complex Coordinate-Based Meta-Analysis with Pr...   \n",
       "17      2204.13353  Attention Mechanism with Energy-Friendly Opera...   \n",
       "18      1911.12864  Self-attention with Functional Time Representa...   \n",
       "19      2204.00471  Uncertainty Determines the Adequacy of the Mod...   \n",
       "20      1910.06762  T-GSA: Transformer with Gaussian-weighted self...   \n",
       "21      2202.12934  Accelerating Neural Architecture Exploration A...   \n",
       "22      1907.12461  Leveraging Pre-trained Checkpoints for Sequenc...   \n",
       "23      2108.11703  Data Augmentation for Low-Resource Named Entit...   \n",
       "24      1609.06647  Show and Tell: Lessons learned from the 2015 M...   \n",
       "\n",
       "                                      abstract_claims  \\\n",
       "0   [Nevertheless, most of the world's languages l...   \n",
       "1   [In machine translation, multilingual pretrain...   \n",
       "2   [This document describes the findings of the T...   \n",
       "3   [We also show how incorporating only a limited...   \n",
       "4   [By capturing statistical patterns in large co...   \n",
       "5   [Several mechanisms to focus attention of a ne...   \n",
       "6   [The model is trained to maximize the likeliho...   \n",
       "7   [Boosted by deep learning, natural language pr...   \n",
       "8   [We present 27 problems encountered in automat...   \n",
       "9   [Semantic networks, such as the knowledge grap...   \n",
       "10  [Sentence embedding is an important research t...   \n",
       "11  [Many tasks in natural language processing, ra...   \n",
       "12  [Overparameterized transformer networks have o...   \n",
       "13  [Classifiers in natural language processing (N...   \n",
       "14  [Recent deep generative models are able to pro...   \n",
       "15  [In a consistent text, many words and phrases ...   \n",
       "16  [With the growing number of published function...   \n",
       "17  [Attention mechanism has become the dominant m...   \n",
       "18  [Sequential modelling with self-attention has ...   \n",
       "19  [In many natural language processing (NLP) tas...   \n",
       "20  [Transformer neural networks (TNN) demonstrate...   \n",
       "21  [Neural architecture search (NAS), the study o...   \n",
       "22  [Unsupervised pre-training of large neural mod...   \n",
       "23  [The state of art natural language processing ...   \n",
       "24  [The model is trained to maximize the likeliho...   \n",
       "\n",
       "                                    conclusion_claims             main_author  \\\n",
       "0   [In theory, it makes this paradigm applicable ...             Yaoyiran Li   \n",
       "1   [We have presented a novel approach for fine-t...  Alexandra Chronopoulou   \n",
       "2   [This paper summarized the results of the Thir...         Hiroaki Hayashi   \n",
       "3   [Our work points towards the need of rethinkin...             Krtin Kumar   \n",
       "4   [This abstract language is formed without any ...           Igor Mordatch   \n",
       "5   [To better understand the main shortcoming of ...           Łukasz Kaiser   \n",
       "6   [The model is trained to maximize the likeliho...           Oriol Vinyals   \n",
       "7   [and recommendations In this paper, we overvie...         Zied Ben Houidi   \n",
       "8   [In this work, we explained 27 problems in aut...         Prabhakar Gupta   \n",
       "9   [and Future Work We present a multi-task pre-t...                   Da Li   \n",
       "10  [Sentence embedding is one of the most importa...          Myeongjun Jang   \n",
       "11  [We propose a generic model for matching two s...           Mingxuan Wang   \n",
       "12  [Structured dropout regularizes neural network...              Angela Fan   \n",
       "13  [ and Future Work In this work we discretised ...          Andreas Grivas   \n",
       "14  [ Generative models are increasingly more powe...      Antoine Plumerault   \n",
       "15  [We have proposed a method for completing part...        Tetsuya Nasukawa   \n",
       "16  [This work is a step towards incorporating com...         Valentin Iovene   \n",
       "17  [We visualize the averaged attention values ov...                  Yu Wan   \n",
       "18  [mplementation The reference code for our impl...                   Da Xu   \n",
       "19  [We identified a major culprit behind various ...         Felix Stahlberg   \n",
       "20  [We proposed a Transformer architecture with G...            Jaeyoung Kim   \n",
       "21  [The goal of the work was to demonstrate how G...         Daniel Cummings   \n",
       "22  [We performed an extensive study on leveraging...            Sascha Rothe   \n",
       "23  [In this paper, we adapt backtranslation to th...            Usama Yaseen   \n",
       "24  [The model is trained to maximize the likeliho...           Oriol Vinyals   \n",
       "\n",
       "                       institution    year institution_type  text  \\\n",
       "0   Language Science (South Korea)  2020.0         Industry  None   \n",
       "1              Microsoft (Germany)  2023.0         Industry  None   \n",
       "2           Google (United States)  2019.0         Industry  None   \n",
       "3         Thomson Reuters (Canada)  2022.0         Industry  None   \n",
       "4           OpenAI (United States)  2018.0         Industry  None   \n",
       "5           Google (United States)  2016.0         Industry  None   \n",
       "6           Google (United States)  2015.0         Industry  None   \n",
       "7     Huawei Technologies (France)  2022.0         Industry  None   \n",
       "8                 Amazon (Germany)  2019.0         Industry  None   \n",
       "9                  Tencent (China)  2023.0         Industry  None   \n",
       "10          SK Group (South Korea)  2020.0         Industry  None   \n",
       "11     Chinese Academy of Sciences  2015.0         Industry  None   \n",
       "12                   Meta (Israel)  2019.0         Industry  None   \n",
       "13  Language Science (South Korea)  2022.0         Industry  None   \n",
       "14         Integra (United States)  2020.0         Industry  None   \n",
       "15            IBM Research - Tokyo  1995.0         Industry  None   \n",
       "16                CEA Paris-Saclay  2021.0         Industry  None   \n",
       "17   Alibaba Group (United States)  2022.0         Industry  None   \n",
       "18         Walmart (United States)  2019.0         Industry  None   \n",
       "19          Google (United States)  2022.0         Industry  None   \n",
       "20           Samsung (South Korea)  2020.0         Industry  None   \n",
       "21          Intel (United Kingdom)  2022.0         Industry  None   \n",
       "22            Google (Switzerland)  2020.0         Industry  None   \n",
       "23               Siemens (Germany)  2021.0         Industry  None   \n",
       "24          Google (United States)  2016.0         Industry  None   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   While state-of-the-art models that rely upon m...   \n",
       "1   Massively multilingual models pretrained on ab...   \n",
       "2   This document describes the findings of the Th...   \n",
       "3   Embedding matrices are key components in neura...   \n",
       "4   By capturing statistical patterns in large cor...   \n",
       "5   Several mechanisms to focus attention of a neu...   \n",
       "6   Automatically describing the content of an ima...   \n",
       "7   Boosted by deep learning, natural language pro...   \n",
       "8   We present 27 problems encountered in automati...   \n",
       "9   Semantic networks, such as the knowledge graph...   \n",
       "10  Sentence embedding is an important research to...   \n",
       "11  Many tasks in natural language processing, ran...   \n",
       "12  Overparameterized transformer networks have ob...   \n",
       "13  Classifiers in natural language processing (NL...   \n",
       "14  Recent deep generative models are able to prov...   \n",
       "15  In a consistent text, many words and phrases a...   \n",
       "16  With the growing number of published functiona...   \n",
       "17  Attention mechanism has become the dominant mo...   \n",
       "18  Sequential modelling with self-attention has a...   \n",
       "19  In many natural language processing (NLP) task...   \n",
       "20  Transformer neural networks (TNN) demonstrated...   \n",
       "21  Neural architecture search (NAS), the study of...   \n",
       "22  Unsupervised pre-training of large neural mode...   \n",
       "23  The state of art natural language processing s...   \n",
       "24  Automatically describing the content of an ima...   \n",
       "\n",
       "                                           conclusion  \n",
       "0   and Future Work We have demonstrated that an e...  \n",
       "1   We have presented a novel approach for fine-tu...  \n",
       "2   This paper summarized the results of the Third...  \n",
       "3   Our work points towards the need of rethinking...  \n",
       "4   We have presented a multi-agent environment an...  \n",
       "5   To better understand the main shortcoming of p...  \n",
       "6   We have presented NIC, an end-to-end neural ne...  \n",
       "7   and recommendations In this paper, we overview...  \n",
       "8   In this work, we explained 27 problems in auto...  \n",
       "9   and Future Work We present a multi-task pre-tr...  \n",
       "10  Sentence embedding is one of the most importan...  \n",
       "11  We propose a generic model for matching two sh...  \n",
       "12  Structured dropout regularizes neural networks...  \n",
       "13   and Future Work In this work we discretised t...  \n",
       "14   Generative models are increasingly more power...  \n",
       "15  We have proposed a method for completing parti...  \n",
       "16  This work is a step towards incorporating comp...  \n",
       "17  We visualize the averaged attention values ove...  \n",
       "18  mplementation The reference code for our imple...  \n",
       "19  We identified a major culprit behind various i...  \n",
       "20  We proposed a Transformer architecture with Ga...  \n",
       "21  The goal of the work was to demonstrate how GA...  \n",
       "22  We performed an extensive study on leveraging ...  \n",
       "23  In this paper, we adapt backtranslation to the...  \n",
       "24  We have presented NIC, an end-to-end neural ne...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer_industry = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model_industry = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a1b3f8a48f4c8c9e1363da6b7fdf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "2011.00890",
           "Nevertheless, most of the world's languages lack such resources"
          ],
          [
           "2011.00890",
           "Hence, we investigate a more radical form of unsupervised knowledge transfer in the absence of linguistic data"
          ],
          [
           "2011.00890",
           "In particular, for the first time we pretrain neural networks via emergent communication from referential games"
          ],
          [
           "2011.00890",
           "On the other hand, this also provides an extrinsic evaluation protocol to probe the properties of emergent languages ex vitro"
          ],
          [
           "2011.00890",
           "Intuitively, the closer they are to natural languages, the higher the gains from pretraining on them should be"
          ],
          [
           "2011.00890",
           "For instance, in this work we measure the influence of communication success and maximum sequence length on downstream performances"
          ],
          [
           "2011.00890",
           "Finally, we introduce a customised adapter layer and annealing strategies for the regulariser of maximum-a-posteriori inference during fine-tuning"
          ],
          [
           "2011.00890",
           "These turn out to be crucial to facilitate knowledge transfer and prevent catastrophic forgetting"
          ],
          [
           "2209.15236",
           "In machine translation, multilingual pretrained models are often fine-tuned on parallel data from one or multiple language pairs"
          ],
          [
           "2209.15236",
           "Multilingual fine-tuning improves performance on medium- and low-resource languages but requires modifying the entire model and can be prohibitively expensive"
          ],
          [
           "2209.15236",
           "Training a new set of adapters on each language pair or training a single set of adapters on all language pairs while keeping the pretrained model's parameters frozen has been proposed as a parameter-efficient alternative"
          ],
          [
           "2209.15236",
           "However, the former do not permit any sharing between languages, while the latter share parameters for all languages and have to deal with negative interference"
          ],
          [
           "2209.15236",
           "In this paper, we propose training language-family adapters on top of a pretrained multilingual model to facilitate cross-lingual transfer"
          ],
          [
           "2209.15236",
           "Our model consistently outperforms other adapter-based approaches"
          ],
          [
           "1910.13299",
           "This document describes the findings of the Third Workshop on Neural Generation and Translation, held in concert with the annual conference of the Empirical Methods in Natural Language Processing (EMNLP 2019)"
          ],
          [
           "1910.13299",
           "First, we summarize the research trends of papers presented in the proceedings"
          ],
          [
           "2104.08677",
           "We also show how incorporating only a limited amount of task-specific knowledge from fully-trained embeddings can boost the performance NMT systems"
          ],
          [
           "2104.08677",
           "Working with such structures means a minimal memory requirement as there is no longer need to store large embedding tables, which is a significant gain in industrial and on-device settings"
          ],
          [
           "2104.08677",
           "Despite having a considerably smaller architecture, our models in some cases are even able to outperform state-of-the-art baselines."
          ],
          [
           "1703.04908",
           "By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis"
          ],
          [
           "1703.04908",
           "However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient"
          ],
          [
           "1703.04908",
           "In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations"
          ],
          [
           "1703.04908",
           "We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable."
          ],
          [
           "1610.08613",
           "Several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years"
          ],
          [
           "1610.08613",
           "Attention has improved image classification, image captioning, speech recognition, generative models, and learning algorithmic tasks, but it had probably the largest impact on neural machine translation"
          ],
          [
           "1610.08613",
           "Such mechanism, which we call active memory, improved over attention in algorithmic tasks, image processing, and in generative modelling"
          ],
          [
           "1610.08613",
           "So far, however, active memory has not improved over attention for most natural language processing tasks, in particular for machine translation"
          ],
          [
           "1610.08613",
           "We investigate this model and explain why previous active memory models did not succeed"
          ],
          [
           "1610.08613",
           "Finally, we discuss when active memory brings most benefits and where attention can be a better choice."
          ],
          [
           "1411.4555",
           "The model is trained to maximize the likelihood of the target description sentence given the training image"
          ],
          [
           "1411.4555",
           "Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions"
          ],
          [
           "1411.4555",
           "Our model is often quite accurate, which we verify both qualitatively and quantitatively"
          ],
          [
           "1411.4555",
           "For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69"
          ],
          [
           "1411.4555",
           "We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28"
          ],
          [
           "1411.4555",
           "Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art."
          ],
          [
           "2205.01398",
           "Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (e.g"
          ],
          [
           "2205.01398",
           "word2vec) as well as novel architectures (e.g"
          ],
          [
           "2205.01398",
           "transformers)"
          ],
          [
           "2205.01398",
           "This success quickly invited researchers to explore the use of NLP techniques to other fields, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code synthesis, code repair, cross language translation etc.)"
          ],
          [
           "2205.01398",
           "By extension, NLP has potential for application to network configuration languages as well, for instance considering tasks such as network configuration verification, synthesis, and cross-vendor translation"
          ],
          [
           "2205.01398",
           "In this paper, we survey recent advances in deep learning applied to programming languages, for the purpose of code verification, synthesis and translation: in particularly, we review their training requirements and expected performance, and qualitatively assess whether similar techniques can benefit corresponding use-cases in networking."
          ],
          [
           "1909.05362",
           "We present 27 problems encountered in automating the translation of movie/TV show subtitles"
          ],
          [
           "1909.05362",
           "We categorize each problem in one of the three categories viz"
          ],
          [
           "1909.05362",
           "problems directly related to textual translation, problems related to subtitle creation guidelines, and problems due to adaptability of machine translation (MT) engines"
          ],
          [
           "1909.05362",
           "We also present the findings of a translation quality evaluation experiment where we share the frequency of 16 key problems"
          ],
          [
           "2201.04843",
           "Semantic networks, such as the knowledge graph, can represent the knowledge leveraging the graph structure"
          ],
          [
           "2201.04843",
           "Although the knowledge graph shows promising values in natural language processing, it suffers from incompleteness"
          ],
          [
           "2201.04843",
           "This paper focuses on knowledge graph completion by predicting linkage between entities, which is a fundamental yet critical task"
          ],
          [
           "2201.04843",
           "Semantic matching is a potential solution as it can deal with unseen entities, which the translational distance based methods struggle with"
          ],
          [
           "2201.04843",
           "However, to achieve competitive performance as translational distance based methods, semantic matching based methods require large-scale datasets for the training purpose, which are typically unavailable in practical settings"
          ],
          [
           "2201.04843",
           "Therefore, we employ the language model and introduce a novel knowledge graph architecture named LP-BERT, which contains two main stages: multi-task pre-training and knowledge graph fine-tuning"
          ],
          [
           "2201.04843",
           "In the pre-training phase, three tasks are taken to drive the model to learn the relationship from triples by predicting either entities or relations"
          ],
          [
           "2201.04843",
           "While in the fine-tuning phase, inspired by contrastive learning, we design a triple-style negative sampling in a batch, which greatly increases the proportion of negative sampling while keeping the training time almost unchanged"
          ],
          [
           "2201.04843",
           "Furthermore, we propose a new data augmentation method utilizing the inverse relationship of triples to improve the performance and robustness of the model"
          ],
          [
           "2201.04843",
           "To demonstrate the effectiveness of our method, we conduct extensive experiments on three widely-used datasets, WN18RR, FB15k-237, and UMLS"
          ],
          [
           "2201.04843",
           "Significantly, Hits@10 indicator is improved by 5% from previous state-of-the-art result on the WN18RR dataset while reaching 100% on the UMLS dataset."
          ],
          [
           "1808.05505",
           "Sentence embedding is an important research topic in natural language processing"
          ],
          [
           "1808.05505",
           "Thus far, various sentence embedding models have been proposed, and their feasibility has been demonstrated through good performances on tasks following embedding, such as sentiment analysis and sentence classification"
          ],
          [
           "1808.05505",
           "In this paper, inspired by human language recognition, we propose the following concept of semantic coherence, which should be satisfied for a good sentence embedding method: similar sentences should be located close to each other in the embedding space"
          ],
          [
           "1808.05505",
           "Then, we propose the Paraphrase-Thought (P-thought) model to pursue semantic coherence as much as possible"
          ],
          [
           "1503.02427",
           "Many tasks in natural language processing, ranging from machine translation to question answering, can be reduced to the problem of matching two sentences or more generally two short texts"
          ],
          [
           "1503.02427",
           "We propose a new approach to the problem, called Deep Match Tree (DeepMatch$_{tree}$), under a general setting"
          ],
          [
           "1909.11556",
           "Overparameterized transformer networks have obtained state of the art results in various natural language processing tasks, such as machine translation, language modeling, and question answering"
          ],
          [
           "1909.11556",
           "These models contain hundreds of millions of parameters, necessitating a large amount of computation and making them prone to overfitting"
          ],
          [
           "1909.11556",
           "In this work, we explore LayerDrop, a form of structured dropout, which has a regularization effect during training and allows for efficient pruning at inference time"
          ],
          [
           "1909.11556",
           "We demonstrate the effectiveness of our approach by improving the state of the art on machine translation, language modeling, summarization, question answering, and language understanding benchmarks"
          ],
          [
           "2203.06462",
           "Classifiers in natural language processing (NLP) often have a large number of output classes"
          ],
          [
           "2203.06462",
           "For example, neural language models (LMs) and machine translation (MT) models both predict tokens from a vocabulary of thousands"
          ],
          [
           "2203.06462",
           "The Softmax output layer of these models typically receives as input a dense feature representation, which has much lower dimensionality than the output"
          ],
          [
           "2203.06462",
           "In theory, the result is some words may be impossible to be predicted via argmax, irrespective of input features, and empirically, there is evidence this happens in small language models"
          ],
          [
           "2203.06462",
           "In this paper we ask whether it can happen in practical large language models and translation models"
          ],
          [
           "2203.06462",
           "To do so, we develop algorithms to detect such \\emph{unargmaxable} tokens in public models"
          ],
          [
           "2001.10238",
           "Recent deep generative models are able to provide photo-realistic images as well as visual or textual content embeddings useful to address various tasks of computer vision and natural language processing"
          ],
          [
           "2001.10238",
           "Their usefulness is nevertheless often limited by the lack of control over the generative process or the poor understanding of the learned representation"
          ],
          [
           "2001.10238",
           "To overcome these major issues, very recent work has shown the interest of studying the semantics of the latent space of generative models"
          ],
          [
           "2001.10238",
           "Our method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations of the generated image, such as translation, zoom or color variations"
          ],
          [
           "cmp-lg/9505042",
           "In a consistent text, many words and phrases are repeatedly used in more than one sentence"
          ],
          [
           "cmp-lg/9505042",
           "When an identical phrase (a set of consecutive words) is repeated in different sentences, the constituent words of those sentences tend to be associated in identical modification patterns with identical parts of speech and identical modifiee-modifier relationships"
          ],
          [
           "cmp-lg/9505042",
           "Thus, when a syntactic parser cannot parse a sentence as a unified structure, parts of speech and modifiee-modifier relationships among morphologically identical words in complete parses of other sentences within the same text provide useful information for obtaining partial parses of the sentence"
          ],
          [
           "cmp-lg/9505042",
           "In this paper, we describe a method for completing partial parses by maintaining consistency among morphologically identical words within the same text as regards their part of speech and their modifiee-modifier relationship"
          ],
          [
           "2012.01303",
           "With the growing number of published functional magnetic resonance imaging (fMRI) studies, meta-analysis databases and models have become an integral part of brain mapping research"
          ],
          [
           "2012.01303",
           "Coordinate-based meta-analysis (CBMA) databases are built by automatically extracting both coordinates of reported peak activations and term associations using natural language processing (NLP) techniques"
          ],
          [
           "2012.01303",
           "Solving term-based queries on these databases make it possible to obtain statistical maps of the brain related to specific cognitive processes"
          ],
          [
           "2012.01303",
           "When solving richer queries, too few studies from the database contribute to the statistical estimations"
          ],
          [
           "2012.01303",
           "We design a probabilistic domain-specific language (DSL) standing on Datalog and one of its probabilistic extensions, CP-Logic, for expressing and solving rich logic-based queries"
          ],
          [
           "2012.01303",
           "We encode a CBMA database into a probabilistic program"
          ],
          [
           "2012.01303",
           "We explain how recent lifted query processing algorithms make it possible to scale to the size of large neuroimaging data, where state of the art knowledge compilation (KC) techniques fail to solve queries fast enough for practical applications"
          ],
          [
           "2012.01303",
           "Finally, we introduce a method for relating studies to terms probabilistically, leading to better solutions for conjunctive queries on smaller databases"
          ],
          [
           "2204.13353",
           "Attention mechanism has become the dominant module in natural language processing models"
          ],
          [
           "2204.13353",
           "It is computationally intensive and depends on massive power-hungry multiplications"
          ],
          [
           "2204.13353",
           "In this paper, we rethink variants of attention mechanism from the energy consumption aspects"
          ],
          [
           "2204.13353",
           "Code is available at: https://github.com/NLP2CT/E-Att."
          ],
          [
           "1911.12864",
           "Sequential modelling with self-attention has achieved cutting edge performances in natural language processing"
          ],
          [
           "1911.12864",
           "With advantages in model flexibility, computation complexity and interpretability, self-attention is gradually becoming a key component in event sequence models"
          ],
          [
           "1911.12864",
           "However, like most other sequence models, self-attention does not account for the time span between events and thus captures sequential signals rather than temporal patterns"
          ],
          [
           "1911.12864",
           "Without relying on recurrent network structures, self-attention recognizes event orderings via positional encoding"
          ],
          [
           "1911.12864",
           "By constructing the associated translation-invariant time kernel function, we reveal the functional forms of the feature map under classic functional function analysis results, namely Bochner's Theorem and Mercer's Theorem"
          ],
          [
           "1911.12864",
           "We propose several models to learn the functional time representation and the interactions with event representation"
          ],
          [
           "1911.12864",
           "These methods are evaluated on real-world datasets under various continuous-time event sequence prediction tasks"
          ],
          [
           "2204.00471",
           "In many natural language processing (NLP) tasks the same input (e.g"
          ],
          [
           "2204.00471",
           "source sentence) can have multiple possible outputs (e.g"
          ],
          [
           "2204.00471",
           "translations)"
          ],
          [
           "2204.00471",
           "To analyze how this ambiguity (also known as intrinsic uncertainty) shapes the distribution learned by neural sequence models we measure sentence-level uncertainty by computing the degree of overlap between references in multi-reference test sets from two different NLP tasks: machine translation (MT) and grammatical error correction (GEC)"
          ],
          [
           "2204.00471",
           "At both the sentence- and the task-level, intrinsic uncertainty has major implications for various aspects of search such as the inductive biases in beam search and the complexity of exact search"
          ],
          [
           "1910.06762",
           "Transformer neural networks (TNN) demonstrated state-of-art performance on many natural language processing (NLP) tasks, replacing recurrent neural networks (RNNs), such as LSTMs or GRUs"
          ],
          [
           "1910.06762",
           "However, TNNs did not perform well in speech enhancement, whose contextual nature is different than NLP tasks, like machine translation"
          ],
          [
           "1910.06762",
           "In this paper, we propose a Transformer with Gaussian-weighted self-attention (T-GSA), whose attention weights are attenuated according to the distance between target and context symbols"
          ],
          [
           "2202.12934",
           "Neural architecture search (NAS), the study of automating the discovery of optimal deep neural network architectures for tasks in domains such as computer vision and natural language processing, has seen rapid growth in the machine learning research community"
          ],
          [
           "2202.12934",
           "While there have been many recent advancements in NAS, there is still a significant focus on reducing the computational cost incurred when validating discovered architectures by making search more efficient"
          ],
          [
           "2202.12934",
           "Evolutionary algorithms, specifically genetic algorithms, have a history of usage in NAS and continue to gain popularity versus other optimization approaches as a highly efficient way to explore the architecture objective space"
          ],
          [
           "2202.12934",
           "Most NAS research efforts have centered around computer vision tasks and only recently have other modalities, such as the rapidly growing field of natural language processing, been investigated in depth"
          ],
          [
           "1907.12461",
           "Unsupervised pre-training of large neural models has recently revolutionized Natural Language Processing"
          ],
          [
           "1907.12461",
           "By warm-starting from the publicly released checkpoints, NLP practitioners have pushed the state-of-the-art on multiple benchmarks while saving significant amounts of compute time"
          ],
          [
           "1907.12461",
           "So far the focus has been mainly on the Natural Language Understanding tasks"
          ],
          [
           "1907.12461",
           "In this paper, we demonstrate the efficacy of pre-trained checkpoints for Sequence Generation"
          ],
          [
           "2108.11703",
           "The state of art natural language processing systems relies on sizable training datasets to achieve high performance"
          ],
          [
           "2108.11703",
           "Lack of such datasets in the specialized low resource domains lead to suboptimal performance"
          ],
          [
           "2108.11703",
           "In this work, we adapt backtranslation to generate high quality and linguistically diverse synthetic data for low-resource named entity recognition"
          ],
          [
           "2108.11703",
           "We perform experiments on two datasets from the materials science (MaSciP) and biomedical domains (S800)"
          ],
          [
           "1609.06647",
           "The model is trained to maximize the likelihood of the target description sentence given the training image"
          ],
          [
           "1609.06647",
           "Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions"
          ],
          [
           "1609.06647",
           "Our model is often quite accurate, which we verify both qualitatively and quantitatively"
          ],
          [
           "1609.06647",
           "Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset"
          ],
          [
           "1609.06647",
           "We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research, and provide an open source implementation in TensorFlow."
          ]
         ],
         "hovertemplate": "type=Industry<br>x=%{x}<br>y=%{y}<br>article_id=%{customdata[0]}<br>claim=%{customdata[1]}<extra></extra>",
         "legendgroup": "Industry",
         "marker": {
          "color": "#FF6B6B",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Industry",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -11.569607734680176,
          0.7342629432678223,
          -4.751854419708252,
          -8.500773429870605,
          -7.819395542144775,
          -20.991130828857422,
          -15.384858131408691,
          -10.529308319091797,
          -7.690721035003662,
          -11.282265663146973,
          -9.241677284240723,
          -6.326479911804199,
          -8.515649795532227,
          -17.821378707885742,
          0.04377951845526695,
          -34.18518829345703,
          -5.758886337280273,
          -19.728952407836914,
          -18.354921340942383,
          11.681083679199219,
          -29.1058406829834,
          -8.206293106079102,
          -5.377165794372559,
          0.29185107350349426,
          -2.3815977573394775,
          -4.414597511291504,
          -3.5219454765319824,
          -5.3146233558654785,
          -3.3794357776641846,
          -10.585769653320312,
          -10.397001266479492,
          -27.930805206298828,
          -25.73140525817871,
          -25.77728843688965,
          -13.650384902954102,
          14.787622451782227,
          27.889650344848633,
          12.848340034484863,
          6.698243141174316,
          6.572969913482666,
          -3.4846904277801514,
          -15.085941314697266,
          -33.844146728515625,
          -14.792791366577148,
          -15.710285186767578,
          27.0506534576416,
          28.859298706054688,
          29.609323501586914,
          3.195042610168457,
          3.216418743133545,
          28.17105484008789,
          -6.674611568450928,
          -13.90804672241211,
          -17.613765716552734,
          -24.19451904296875,
          -24.427898406982422,
          22.04754638671875,
          22.45261573791504,
          24.114255905151367,
          28.870820999145508,
          16.558183670043945,
          -35.453041076660156,
          11.8090238571167,
          -19.29295539855957,
          -16.88778305053711,
          1.8857181072235107,
          11.405311584472656,
          11.085463523864746,
          -8.20998764038086,
          13.003695487976074,
          -4.341377258300781,
          -29.14121437072754,
          -13.3300199508667,
          -9.753584861755371,
          15.721840858459473,
          -13.93196964263916,
          24.53386116027832,
          24.09314727783203,
          23.279325485229492,
          23.138519287109375,
          -23.203624725341797,
          9.98750114440918,
          -24.415225982666016,
          -25.58661651611328,
          2.6186411380767822,
          2.52976131439209,
          -24.59912872314453,
          -25.07184600830078,
          3.061992645263672,
          -24.061100006103516,
          -1.4662197828292847,
          -38.67494583129883,
          8.983468055725098,
          9.682326316833496,
          9.527731895446777,
          10.366068840026855,
          14.643362045288086,
          13.875419616699219,
          12.685462951660156,
          15.85491943359375,
          24.9512939453125,
          -18.361791610717773,
          1.7188174724578857,
          -12.3931884765625,
          7.172570705413818,
          8.221085548400879,
          7.696597576141357,
          -9.52519702911377,
          -23.411218643188477,
          -23.855562210083008,
          -9.987451553344727,
          7.650108337402344,
          6.517013072967529,
          18.63783836364746,
          -5.1857590675354,
          10.513838768005371,
          -26.822050094604492,
          19.89193344116211,
          -23.6285457611084,
          -10.585769653320312,
          -10.397001266479492,
          -27.930805206298828,
          -13.607840538024902,
          -1.1723865270614624
         ],
         "xaxis": "x",
         "y": [
          28.22908592224121,
          23.0428409576416,
          -7.717273235321045,
          34.59596633911133,
          33.457557678222656,
          -28.358278274536133,
          -28.62753677368164,
          -28.675020217895508,
          13.62773609161377,
          21.520090103149414,
          17.537633895874023,
          25.423370361328125,
          18.490009307861328,
          -22.62644386291504,
          -1.0670154094696045,
          -12.0813570022583,
          -13.982958793640137,
          -35.222171783447266,
          -21.61005973815918,
          11.68894100189209,
          -6.454242706298828,
          38.46382522583008,
          37.711788177490234,
          -30.20382308959961,
          -27.075220108032227,
          -29.180532455444336,
          -27.98196792602539,
          -29.271190643310547,
          -29.00937271118164,
          -4.155236721038818,
          -6.831905364990234,
          -15.153128623962402,
          10.926129341125488,
          10.78954792022705,
          -15.268080711364746,
          -6.758353233337402,
          -3.2981181144714355,
          -34.19144821166992,
          15.195907592773438,
          14.522994041442871,
          -12.944987297058105,
          13.362133979797363,
          -18.118099212646484,
          13.524152755737305,
          16.855173110961914,
          -20.20050621032715,
          -19.55855941772461,
          -20.202163696289062,
          20.966449737548828,
          20.920997619628906,
          -16.683921813964844,
          -7.683536052703857,
          -28.248897552490234,
          -16.528642654418945,
          -14.240592002868652,
          -14.560572624206543,
          -1.7532461881637573,
          -1.0369282960891724,
          -0.9838039875030518,
          22.995866775512695,
          15.27247428894043,
          -24.561382293701172,
          -20.4638671875,
          -23.503149032592773,
          -25.48927116394043,
          -2.6563799381256104,
          6.825287818908691,
          0.17745186388492584,
          -21.242734909057617,
          -0.28057485818862915,
          10.075132369995117,
          6.458076477050781,
          -10.005986213684082,
          -23.341508865356445,
          -1.5342941284179688,
          -7.271544456481934,
          24.69113540649414,
          23.867658615112305,
          22.30133056640625,
          22.282695770263672,
          -7.033239841461182,
          9.691014289855957,
          -6.261514186859131,
          -4.20952844619751,
          13.663358688354492,
          14.204394340515137,
          -6.399412155151367,
          -4.034868240356445,
          -27.535615921020508,
          -30.421152114868164,
          -30.403512954711914,
          -1.816755771636963,
          -26.259164810180664,
          -29.18940544128418,
          -28.901260375976562,
          -28.315940856933594,
          -29.752260208129883,
          -29.608627319335938,
          -29.50334358215332,
          13.997851371765137,
          25.582834243774414,
          14.989151000976562,
          0.10490206629037857,
          -21.133655548095703,
          -13.23459529876709,
          -13.713518142700195,
          -33.297183990478516,
          -14.598832130432129,
          -21.81517791748047,
          -21.835847854614258,
          -13.578389167785645,
          0.894493579864502,
          10.052099227905273,
          14.134419441223145,
          2.389000177383423,
          6.5949482917785645,
          -10.154337882995605,
          7.55955171585083,
          -13.488829612731934,
          -4.155236721038818,
          -6.831905364990234,
          -15.153128623962402,
          -15.262359619140625,
          -17.51329231262207
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "2005.14187",
           "Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but they are difficult to be deployed on hardware due to the intensive computation"
          ],
          [
           "2005.14187",
           "To enable low-latency inference on resource-constrained hardware platforms, we propose to design Hardware-Aware Transformers (HAT) with neural architecture search"
          ],
          [
           "2005.14187",
           "We first construct a large design space with $\\textit{arbitrary encoder-decoder attention}$ and $\\textit{heterogeneous layers}$"
          ],
          [
           "2005.14187",
           "Finally, we perform an evolutionary search with a hardware latency constraint to find a specialized $\\textit{SubTransformer}$ dedicated to run fast on the target hardware"
          ],
          [
           "2005.14187",
           "When running WMT'14 translation task on Raspberry Pi-4, HAT can achieve $\\textbf{3}\\times$ speedup, $\\textbf{3.7}\\times$ smaller size over baseline Transformer; $\\textbf{2.7}\\times$ speedup, $\\textbf{3.6}\\times$ smaller size over Evolved Transformer with $\\textbf{12,041}\\times$ less search cost and no performance loss"
          ],
          [
           "2005.14187",
           "HAT code is https://github.com/mit-han-lab/hardware-aware-transformers.git"
          ],
          [
           "2010.02591",
           "Structured representations like graphs and parse trees play a crucial role in many Natural Language Processing systems"
          ],
          [
           "2010.02591",
           "In recent years, the advancements in multi-turn user interfaces necessitate the need for controlling and updating these structured representations given new sources of information"
          ],
          [
           "2010.02591",
           "In this paper, we explore the novel problem of graph modification, where the systems need to learn how to update an existing scene graph given a new user's command"
          ],
          [
           "2010.02591",
           "Our novel models based on graph-based sparse transformer and cross attention information fusion outperform previous systems adapted from the machine translation and graph generation literature"
          ],
          [
           "2010.02591",
           "We further contribute our large graph modification datasets to the research community to encourage future research for this new problem."
          ],
          [
           "2209.08016",
           "Multiword expression (MWE) is a sequence of words which collectively present a meaning which is not derived from its individual words"
          ],
          [
           "2209.08016",
           "The task of processing MWEs is crucial in many natural language processing (NLP) applications, including machine translation and terminology extraction"
          ],
          [
           "2209.08016",
           "Therefore, detecting MWEs in different domains is an important research topic"
          ],
          [
           "2209.08016",
           "In this paper, we explore state-of-the-art neural transformers in the task of detecting MWEs in flower and plant names"
          ],
          [
           "2209.08016",
           "We evaluate different transformer models on a dataset created from Encyclopedia of Plants and Flower"
          ],
          [
           "2004.13310",
           "Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences"
          ],
          [
           "2004.13310",
           "However, in cross-lingual scenarios, e.g"
          ],
          [
           "2004.13310",
           "machine translation, the PEs of source and target sentences are modeled independently"
          ],
          [
           "2004.13310",
           "Due to word order divergences in different languages, modeling the cross-lingual positional relationships might help SANs tackle this problem"
          ],
          [
           "2004.13310",
           "In this paper, we augment SANs with \\emph{cross-lingual position representations} to model the bilingually aware latent structure for the input sentence"
          ],
          [
           "2004.13310",
           "Specifically, we utilize bracketing transduction grammar (BTG)-based reordering information to encourage SANs to learn bilingual diagonal alignments"
          ],
          [
           "1610.09893",
           "Recurrent neural networks (RNNs) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation"
          ],
          [
           "1610.09893",
           "However, when the vocabulary is large, the RNN model will become very big (e.g., possibly beyond the memory capacity of a GPU device) and its training will become very inefficient"
          ],
          [
           "1610.09893",
           "In this work, we propose a novel technique to tackle this challenge"
          ],
          [
           "1610.09893",
           "The key idea is to use 2-Component (2C) shared embedding for word representations"
          ],
          [
           "1610.09893",
           "We allocate every word in the vocabulary into a table, each row of which is associated with a vector, and each column associated with another vector"
          ],
          [
           "1610.09893",
           "Depending on its position in the table, a word is jointly represented by two components: a row vector and a column vector"
          ],
          [
           "1610.09893",
           "Since the words in the same row share the row vector and the words in the same column share the column vector, we only need $2 \\sqrt{|V|}$ vectors to represent a vocabulary of $|V|$ unique words, which are far less than the $|V|$ vectors required by existing approaches"
          ],
          [
           "1610.09893",
           "Based on the 2-Component shared embedding, we design a new RNN algorithm and evaluate it using the language modeling task on several benchmark datasets"
          ],
          [
           "1610.09893",
           "Remarkably, on the One-Billion-Word benchmark Dataset, our algorithm achieves comparable perplexity to previous language models, whilst reducing the model size by a factor of 40-100, and speeding up the training process by a factor of 2"
          ],
          [
           "1610.09893",
           "We name our proposed algorithm \\emph{LightRNN} to reflect its very small model size and very high training speed."
          ],
          [
           "2212.02437",
           "Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model"
          ],
          [
           "2212.02437",
           "For Machine Translation (MT), these examples are typically randomly sampled from the development dataset with a similar distribution as the evaluation set"
          ],
          [
           "2212.02437",
           "However, it is unclear how the choice of these in-context examples and their ordering impacts the output translation quality"
          ],
          [
           "2212.02437",
           "In this work, we aim to understand the properties of good in-context examples for MT in both in-domain and out-of-domain settings"
          ],
          [
           "2212.02437",
           "While concatenating multiple random examples reduces the effect of noise, a single good prompt optimized to maximize translation quality on the development dataset can elicit learned information from the pre-trained language model"
          ],
          [
           "2212.02437",
           "Adding similar examples based on an n-gram overlap with the test source significantly and consistently improves the translation quality of the outputs, outperforming a strong kNN-MT baseline in 2 out of 4 out-of-domain datasets."
          ],
          [
           "1908.09716",
           "The preprocessing pipelines in Natural Language Processing usually involve a step of removing sentences consisted of illegal characters"
          ],
          [
           "1908.09716",
           "The definition of illegal characters and the specific removal strategy depend on the task, language, domain, etc, which often lead to tiresome and repetitive scripting of rules"
          ],
          [
           "1908.09716",
           "In this paper, we introduce a simple statistical method, uniblock, to overcome this problem"
          ],
          [
           "1908.09716",
           "For each sentence, uniblock generates a fixed-size feature vector using Unicode block information of the characters"
          ],
          [
           "1908.09716",
           "A Gaussian mixture model is then estimated on some clean corpus using variational inference"
          ],
          [
           "1908.09716",
           "The learned model can then be used to score sentences and filter corpus"
          ],
          [
           "1908.09716",
           "We present experimental results on Sentiment Analysis, Language Modeling and Machine Translation, and show the simplicity and effectiveness of our method."
          ],
          [
           "2010.02789",
           "Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation"
          ],
          [
           "2010.02789",
           "Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic"
          ],
          [
           "2010.02789",
           "We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and self-attention networks"
          ],
          [
           "2010.02789",
           "We use the framework of learning energy-based inference networks (Tu and Gimpel, 2018) for dealing with the difficulties of training and inference with such models"
          ],
          [
           "2010.02789",
           "We also find high-order energies to help in noisy data conditions."
          ],
          [
           "2103.11072",
           "As the use of deep learning techniques has grown across various fields over the past decade, complaints about the opaqueness of the black-box models have increased, resulting in an increased focus on transparency in deep learning models"
          ],
          [
           "2103.11072",
           "This work investigates various methods to improve the interpretability of deep neural networks for natural language processing (NLP) tasks, including machine translation and sentiment analysis"
          ],
          [
           "2103.11072",
           "We provide a comprehensive discussion on the definition of the term \\textit{interpretability} and its various aspects at the beginning of this work"
          ],
          [
           "2103.11072",
           "The methods collected and summarised in this survey are only associated with local interpretation and are divided into three categories: 1) explaining the model's predictions through related input features; 2) explaining through natural language explanation; 3) probing the hidden states of models and word representations."
          ],
          [
           "2108.02170",
           "While language models have proven transformational for the natural language processing community, these models have proven expensive, energy-intensive, and challenging to train"
          ],
          [
           "2108.02170",
           "In this work, we explore the effect of curriculum learning on language model pretraining using various linguistically motivated curricula and evaluate transfer performance on the GLUE Benchmark"
          ],
          [
           "1707.06971",
           "We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences"
          ],
          [
           "1707.06971",
           "Like sentence simplification, splitting-and-rephrasing has the potential of benefiting both natural language processing and societal applications"
          ],
          [
           "1707.06971",
           "Because shorter sentences are generally better processed by NLP systems, it could be used as a preprocessing step which facilitates and improves the performance of parsers, semantic role labellers and machine translation systems"
          ],
          [
           "1707.06971",
           "It should also be of use for people with reading disabilities because it allows the conversion of longer sentences into shorter ones"
          ],
          [
           "1707.06971",
           "This paper makes two contributions towards this new task"
          ],
          [
           "1707.06971",
           "First, we create and make available a benchmark consisting of 1,066,115 tuples mapping a single complex sentence to a sequence of sentences expressing the same meaning"
          ],
          [
           "1707.06971",
           "Second, we propose five models (vanilla sequence-to-sequence to semantically-motivated models) to understand the difficulty of the proposed task."
          ],
          [
           "2110.07205",
           "The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets"
          ],
          [
           "2110.07205",
           "After preprocessing the input speech/text through the pre-nets, the shared encoder-decoder network models the sequence-to-sequence transformation, and then the post-nets generate the output in the speech/text modality based on the output of the decoder"
          ],
          [
           "2110.07205",
           "Leveraging large-scale unlabeled speech and text data, we pre-train SpeechT5 to learn a unified-modal representation, hoping to improve the modeling capability for both speech and text"
          ],
          [
           "2110.07205",
           "Extensive evaluations show the superiority of the proposed SpeechT5 framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech enhancement, and speaker identification"
          ],
          [
           "1801.05568",
           "Automatically creating the description of an image using any natural languages sentence like English is a very challenging task"
          ],
          [
           "1801.05568",
           "It requires expertise of both image processing as well as natural language processing"
          ],
          [
           "1801.05568",
           "This paper discuss about different available models for image captioning task"
          ],
          [
           "1801.05568",
           "We have also discussed about how the advancement in the task of object recognition and machine translation has greatly improved the performance of image captioning model in recent years"
          ],
          [
           "1801.05568",
           "In the end, we have also evaluated the performance of model using standard evaluation matrices."
          ],
          [
           "2104.03391",
           "Metaphorical expressions are difficult linguistic phenomena, challenging diverse Natural Language Processing tasks"
          ],
          [
           "2010.01554",
           "Machine translation has been a major motivation of development in natural language processing"
          ],
          [
           "2010.01554",
           "Despite the burgeoning achievements in creating more efficient machine translation systems thanks to deep learning methods, parallel corpora have remained indispensable for progress in the field"
          ],
          [
           "2010.01554",
           "In an attempt to create parallel corpora for the Kurdish language, in this paper, we describe our approach in retrieving potentially-alignable news articles from multi-language websites and manually align them across dialects and languages based on lexical similarity and transliteration of scripts"
          ],
          [
           "2010.01554",
           "We present a corpus containing 12,327 translation pairs in the two major dialects of Kurdish, Sorani and Kurmanji"
          ],
          [
           "2010.01554",
           "We also provide 1,797 and 650 translation pairs in English-Kurmanji and English-Sorani"
          ],
          [
           "2010.01554",
           "The corpus is publicly available under the CC BY-NC-SA 4.0 license."
          ],
          [
           "2204.09269",
           "Non-autoregressive (NAR) generation, which is first proposed in neural machine translation (NMT) to speed up inference, has attracted much attention in both machine learning and natural language processing communities"
          ],
          [
           "2204.09269",
           "While NAR generation can significantly accelerate inference speed for machine translation, the speedup comes at the cost of sacrificed translation accuracy compared to its counterpart, auto-regressive (AR) generation"
          ],
          [
           "2204.09269",
           "In recent years, many new models and algorithms have been designed/proposed to bridge the accuracy gap between NAR generation and AR generation"
          ],
          [
           "2204.09269",
           "In this paper, we conduct a systematic survey with comparisons and discussions of various non-autoregressive translation (NAT) models from different aspects"
          ],
          [
           "2204.09269",
           "Specifically, we categorize the efforts of NAT into several groups, including data manipulation, modeling methods, training criterion, decoding algorithms, and the benefit from pre-trained models"
          ],
          [
           "2204.09269",
           "Furthermore, we briefly review other applications of NAR models beyond machine translation, such as dialogue generation, text summarization, grammar error correction, semantic parsing, speech synthesis, and automatic speech recognition"
          ],
          [
           "2204.09269",
           "In addition, we also discuss potential directions for future exploration, including releasing the dependency of KD, dynamic length prediction, pre-training for NAR, and wider applications, etc"
          ],
          [
           "2204.09269",
           "We hope this survey can help researchers capture the latest progress in NAR generation, inspire the design of advanced NAR models and algorithms, and enable industry practitioners to choose appropriate solutions for their applications"
          ],
          [
           "2204.09269",
           "The web page of this survey is at \\url{https://github.com/LitterBrother-Xiao/Overview-of-Non-autoregressive-Applications}."
          ],
          [
           "2210.00613",
           "The success of deep learning in natural language processing raises intriguing questions about the nature of linguistic meaning and ways in which it can be processed by natural and artificial systems"
          ],
          [
           "2210.00613",
           "One such question has to do with subword segmentation algorithms widely employed in language modeling, machine translation, and other tasks since 2016"
          ],
          [
           "2210.00613",
           "These algorithms often cut words into semantically opaque pieces, such as 'period', 'on', 't', and 'ist' in 'period|on|t|ist'"
          ],
          [
           "2210.00613",
           "The system then represents the resulting segments in a dense vector space, which is expected to model grammatical relations among them"
          ],
          [
           "2210.00613",
           "This representation may in turn be used to map 'period|on|t|ist' (English) to 'par|od|ont|iste' (French)"
          ],
          [
           "2210.00613",
           "Thus, instead of being modeled at the lexical level, translation is reformulated more generally as the task of learning the best bilingual mapping between the sequences of subword segments of two languages; and sometimes even between pure character sequences: 'p|e|r|i|o|d|o|n|t|i|s|t' $\\rightarrow$ 'p|a|r|o|d|o|n|t|i|s|t|e'"
          ],
          [
           "2210.00613",
           "Such subword segmentations and alignments are at work in highly efficient end-to-end machine translation systems, despite their allegedly opaque nature"
          ],
          [
           "2210.00613",
           "The computational value of such processes is unquestionable"
          ],
          [
           "2210.00613",
           "But do they have any linguistic or philosophical plausibility? I attempt to cast light on this question by reviewing the relevant details of the subword segmentation algorithms and by relating them to important philosophical and linguistic debates, in the spirit of making artificial intelligence more transparent and explainable."
          ],
          [
           "1503.06733",
           "Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition"
          ],
          [
           "1503.06733",
           "We introduce the Yara Parser, a fast and accurate open-source dependency parser based on the arc-eager algorithm and beam search"
          ],
          [
           "1503.06733",
           "It achieves an unlabeled accuracy of 93.32 on the standard WSJ test set which ranks it among the top dependency parsers"
          ],
          [
           "1503.06733",
           "At its fastest, Yara can parse about 4000 sentences per second when in greedy mode (1 beam)"
          ],
          [
           "1503.06733",
           "When optimizing for accuracy (using 64 beams and Brown cluster features), Yara can parse 45 sentences per second"
          ],
          [
           "1503.06733",
           "The parser can be trained on any syntactic dependency treebank and different options are provided in order to make it more flexible and tunable for specific tasks"
          ],
          [
           "1503.06733",
           "It is released with the Apache version 2.0 license and can be used for both commercial and academic purposes"
          ],
          [
           "1503.06733",
           "The parser can be found at https://github.com/yahoo/YaraParser."
          ],
          [
           "1909.13104",
           "In the era of social media and networking platforms, Twitter has been doomed for abuse and harassment toward users specifically women"
          ],
          [
           "1909.13104",
           "Monitoring the contents including sexism and sexual harassment in traditional media is easier than monitoring on the online social media platforms like Twitter, because of the large amount of user generated content in these media"
          ],
          [
           "1909.13104",
           "Previous studies have been focused on collecting data about sexism and racism in very broad terms"
          ],
          [
           "1909.13104",
           "However, there is no much study focusing on different types of online harassment attracting natural language processing techniques"
          ],
          [
           "1909.13104",
           "In this work, we present an multi-attention based approach for the detection of different types of harassment in tweets"
          ],
          [
           "1909.13104",
           "Our approach is based on the Recurrent Neural Networks and particularly we are using a deep, classification specific multi-attention mechanism"
          ],
          [
           "1909.13104",
           "Moreover, we tackle the problem of imbalanced data, using a back-translation method"
          ],
          [
           "1909.13104",
           "Finally, we present a comparison between different approaches based on the Recurrent Neural Networks."
          ],
          [
           "2103.16590",
           "Text generation systems are ubiquitous in natural language processing applications"
          ],
          [
           "2103.16590",
           "However, evaluation of these systems remains a challenge, especially in multilingual settings"
          ],
          [
           "2103.16590",
           "In this paper, we propose L'AMBRE -- a metric to evaluate the morphosyntactic well-formedness of text using its dependency parse and morphosyntactic rules of the language"
          ],
          [
           "2103.16590",
           "We present a way to automatically extract various rules governing morphosyntax directly from dependency treebanks"
          ],
          [
           "2103.16590",
           "To tackle the noisy outputs from text generation systems, we propose a simple methodology to train robust parsers"
          ],
          [
           "2103.16590",
           "We show the effectiveness of our metric on the task of machine translation through a diachronic study of systems translating into morphologically-rich languages."
          ],
          [
           "2002.10941",
           "With the increasing computational demands of neural networks, many hardware accelerators for the neural networks have been proposed"
          ],
          [
           "2002.10941",
           "The attention mechanism is widely adopted by many state-of-the-art neural networks for computer vision, natural language processing, and machine translation, and accounts for a large portion of total execution time"
          ],
          [
           "2002.10941",
           "We observe today's practice of implementing this mechanism using matrix-vector multiplication is suboptimal as the attention mechanism is semantically a content-based search where a large portion of computations ends up not being used"
          ],
          [
           "2002.10941",
           "Based on this observation, we design and architect A3, which accelerates attention mechanisms in neural networks with algorithmic approximation and hardware specialization"
          ],
          [
           "2002.10941",
           "Our proposed accelerator achieves multiple orders of magnitude improvement in energy efficiency (performance/watt) as well as substantial speedup over the state-of-the-art conventional hardware."
          ],
          [
           "2006.01175",
           "Lexical normalization, the translation of non-canonical data to standard language, has shown to improve the performance of manynatural language processing tasks on social media"
          ],
          [
           "2006.01175",
           "Yet, using multiple languages in one utterance, also called code-switching (CS), is frequently overlooked by these normalization systems, despite its common use in social media"
          ],
          [
           "2006.01175",
           "In this paper, we propose three normalization models specifically designed to handle code-switched data which we evaluate for two language pairs: Indonesian-English (Id-En) and Turkish-German (Tr-De)"
          ],
          [
           "2006.01175",
           "For the latter, we introduce novel normalization layers and their corresponding language ID and POS tags for the dataset, and evaluate the downstream effect of normalization on POS tagging"
          ],
          [
           "2210.05404",
           "This paper presents work on novel machine translation (MT) systems between spoken and signed languages, where signed languages are represented in SignWriting, a sign language writing system"
          ],
          [
           "2210.05404",
           "Our work seeks to address the lack of out-of-the-box support for signed languages in current MT systems and is based on the SignBank dataset, which contains pairs of spoken language text and SignWriting content"
          ],
          [
           "2210.05404",
           "We introduce novel methods to parse, factorize, decode, and evaluate SignWriting, leveraging ideas from neural factored MT"
          ],
          [
           "2210.05404",
           "In a bilingual setup--translating from American Sign Language to (American) English--our method achieves over 30 BLEU, while in two multilingual setups--translating in both directions between spoken languages and signed languages--we achieve over 20 BLEU"
          ],
          [
           "2205.08001",
           "Cross-lingual natural language processing relies on translation, either by humans or machines, at different levels, from translating training data to translating test sets"
          ],
          [
           "2205.08001",
           "However, compared to original texts in the same language, translations possess distinct qualities referred to as translationese"
          ],
          [
           "2205.08001",
           "In this work, we propose a novel approach to reducing translationese by extending an established bias-removal technique"
          ],
          [
           "2205.08001",
           "To the best of our knowledge, this is the first study to debias translationese as represented in latent embedding space."
          ],
          [
           "1803.03585",
           "In contrast, the ability to model structured data with non-recurrent neural networks has received little attention despite their success in many NLP tasks (Gehring et al., 2017; Vaswani et al., 2017)"
          ],
          [
           "2102.00287",
           "The amplification of biases in language technology has mainly been examined with respect to specific phenomena, such as gender bias"
          ],
          [
           "2102.00287",
           "In this work, we go beyond the study of gender in MT and investigate how bias amplification might affect language in a broader sense"
          ],
          [
           "2102.00287",
           "an exacerbation of frequently observed patterns in combination with a loss of less frequent ones, not only exacerbates societal biases present in current datasets but could also lead to an artificially impoverished language: 'machine translationese'"
          ],
          [
           "2102.00287",
           "We assess the linguistic richness (on a lexical and morphological level) of translations created by different data-driven MT paradigms - phrase-based statistical (PB-SMT) and neural MT (NMT)"
          ],
          [
           "1910.02211",
           "Word embeddings have become a staple of several natural language processing tasks, yet much remains to be understood about their properties"
          ],
          [
           "1910.02211",
           "In this work, we analyze word embeddings in terms of their principal components and arrive at a number of novel and counterintuitive observations"
          ],
          [
           "1910.02211",
           "In particular, we characterize the utility of variance explained by the principal components as a proxy for downstream performance"
          ],
          [
           "1910.02211",
           "Finally, we offer a few precautionary guidelines on applying variance based embedding post-processing and explain why non-isotropic geometry might be integral to word embedding performance."
          ],
          [
           "1906.00378",
           "Bilingual lexicon induction, translating words from the source language to the target language, is a long-standing natural language processing task"
          ],
          [
           "1906.00378",
           "However, these vision-based approaches simply associate words with entire images, which are constrained to translate concrete words and require object-centered images"
          ],
          [
           "1906.00378",
           "We humans can understand words better when they are within a sentence with context"
          ],
          [
           "1906.00378",
           "Therefore, in this paper, we propose to utilize images and their associated captions to address the limitations of previous approaches"
          ],
          [
           "1906.00378",
           "We propose a multi-lingual caption model trained with different mono-lingual multimodal data to map words in different languages into joint spaces"
          ],
          [
           "1906.00378",
           "Two types of word representation are induced from the multi-lingual caption model: linguistic features and localized visual features"
          ],
          [
           "1906.00378",
           "The two types of features are complementary for word translation"
          ],
          [
           "2107.06055",
           "Free-order case-marking languages, such as Russian, Latin or Tamil, have proved more challenging than fixed-order languages for the tasks of syntactic parsing and subject-verb agreement prediction"
          ],
          [
           "2107.06055",
           "In this work, we investigate whether this class of languages is also more difficult to translate by state-of-the-art Neural Machine Translation models (NMT)"
          ],
          [
           "2107.06055",
           "The latter issue is indeed solved by the addition of case marking"
          ],
          [
           "2107.06055",
           "However, in medium- and low-resource settings, the overall NMT quality of fixed-order languages remains unmatched."
          ],
          [
           "1805.11224",
           "Many natural language processing tasks can be modeled into structured prediction and solved as a search problem"
          ],
          [
           "1805.11224",
           "In this paper, we distill an ensemble of multiple models trained with different initialization into a single model"
          ],
          [
           "1805.11224",
           "In addition to learning to match the ensemble's probability output on the reference states, we also use the ensemble to explore the search space and learn from the encountered states in the exploration"
          ],
          [
           "1911.03627",
           "Automatic post-editing (APE), which aims to correct errors in the output of machine translation systems in a post-processing step, is an important task in natural language processing"
          ],
          [
           "1911.03627",
           "While recent work has achieved considerable performance gains by using neural networks, how to model the copying mechanism for APE remains a challenge"
          ],
          [
           "1911.03627",
           "In this work, we propose a new method for modeling copying for APE"
          ],
          [
           "1911.03627",
           "To better identify translation errors, our method learns the representations of source sentences and system outputs in an interactive way"
          ],
          [
           "2207.03169",
           "Conventional automatic speech recognition systems do not produce punctuation marks which are important for the readability of the speech recognition results"
          ],
          [
           "2207.03169",
           "They are also needed for subsequent natural language processing tasks such as machine translation"
          ],
          [
           "2207.03169",
           "However, these studies do not utilize acoustic information for punctuation prediction and are directly affected by speech recognition errors"
          ],
          [
           "2207.03169",
           "This model is expected to predict punctuation robustly against speech recognition errors while using acoustic information"
          ],
          [
           "2207.03169",
           "We also propose to incorporate an auxiliary loss to train the model using the output of the intermediate layer and unpunctuated texts"
          ],
          [
           "2207.03169",
           "The proposed model achieves higher punctuation prediction accuracy than the cascaded system without sacrificing the speech recognition error rate"
          ],
          [
           "2207.03169",
           "Moreover, the proposed model has only about 1/7th of the parameters compared to the cascaded system."
          ],
          [
           "2203.13291",
           "Natural language processing for sign language video - including tasks like recognition, translation, and search - is crucial for making artificial intelligence technologies accessible to deaf individuals, and is gaining research interest in recent years"
          ],
          [
           "2203.13291",
           "In this paper, we address the problem of searching for fingerspelled key-words or key phrases in raw sign language videos"
          ],
          [
           "2203.13291",
           "This is an important task since significant content in sign language is often conveyed via fingerspelling, and to our knowledge the task has not been studied before"
          ],
          [
           "2203.13291",
           "Our experiments, done on a large public dataset of ASL fingerspelling in the wild, show the importance of fingerspelling detection as a component of a search and retrieval model"
          ],
          [
           "2203.13291",
           "Our model significantly outperforms baseline methods adapted from prior work on related tasks"
          ],
          [
           "2205.05901",
           "As the use of natural language processing increases in our day-to-day life, the need to address gender bias inherent in these systems also amplifies"
          ],
          [
           "2205.05901",
           "This is because the inherent bias interferes with the semantic structure of the output of these systems while performing tasks like machine translation"
          ],
          [
           "2205.05901",
           "While research is being done in English to quantify and mitigate bias, debiasing methods in Indic Languages are either relatively nascent or absent for some Indic languages altogether"
          ],
          [
           "2205.05901",
           "Most Indic languages are gendered, i.e., each noun is assigned a gender according to each language's grammar rules"
          ],
          [
           "2205.05901",
           "As a consequence, evaluation differs from what is done in English"
          ],
          [
           "2205.05901",
           "This paper evaluates the gender stereotypes in Hindi and Marathi languages"
          ],
          [
           "2205.05901",
           "The methodologies will differ from the ones in the English language because there are masculine and feminine counterparts in the case of some words"
          ],
          [
           "2205.05901",
           "We create a dataset of neutral and gendered occupation words, emotion words and measure bias with the help of Embedding Coherence Test (ECT) and Relative Norm Distance (RND)"
          ],
          [
           "2205.05901",
           "We also attempt to mitigate this bias from the embeddings"
          ],
          [
           "1809.06858",
           "Continuous word representation (aka word embedding) is a basic building block in many neural network-based models used in natural language processing tasks"
          ],
          [
           "1809.06858",
           "This makes learned word embeddings ineffective, especially for rare words, and consequently limits the performance of these neural network models"
          ],
          [
           "1809.06858",
           "In this paper, we develop a neat, simple yet effective way to learn \\emph{FRequency-AGnostic word Embedding} (FRAGE) using adversarial training"
          ],
          [
           "1809.06858",
           "We conducted comprehensive studies on ten datasets across four natural language processing tasks, including word similarity, language modeling, machine translation and text classification"
          ],
          [
           "1810.12546",
           "In this paper, we propose an additionsubtraction twin-gated recurrent network (ATR) to simplify neural machine translation"
          ],
          [
           "1810.12546",
           "The recurrent units of ATR are heavily simplified to have the smallest number of weight matrices among units of all existing gated RNNs"
          ],
          [
           "1810.12546",
           "With the simple addition and subtraction operation, we introduce a twin-gated mechanism to build input and forget gates which are highly correlated"
          ],
          [
           "1810.12546",
           "Despite this simplification, the essential non-linearities and capability of modeling long-distance dependencies are preserved"
          ],
          [
           "1810.12546",
           "Additionally, the proposed ATR is more transparent than LSTM/GRU due to the simplification"
          ],
          [
           "1810.12546",
           "Forward self-attention can be easily established in ATR, which makes the proposed network interpretable"
          ],
          [
           "1810.12546",
           "Further experiments on NIST Chinese-English translation, natural language inference and Chinese word segmentation verify the generality and applicability of ATR on different natural language processing tasks."
          ],
          [
           "2204.00004",
           "Reproducibility is of utmost concern in machine learning and natural language processing (NLP)"
          ],
          [
           "2204.00004",
           "In the field of natural language generation (especially machine translation), the seminal paper of Post (2018) has pointed out problems of reproducibility of the dominant metric, BLEU, at the time of publication"
          ],
          [
           "2204.00004",
           "Nowadays, BERT-based evaluation metrics considerably outperform BLEU"
          ],
          [
           "2204.00004",
           "(iv) In one case, the problem stems from correlating not to human scores but to a wrong column in the csv file, inflating scores by 5 points"
          ],
          [
           "2204.00004",
           "Motivated by the impact of preprocessing, we then conduct a second study where we examine its effects more closely (for one of the metrics)"
          ],
          [
           "2204.00004",
           "In this case, the effect of preprocessing may be larger than the effect of the aggregation mechanism (e.g., greedy alignment vs"
          ],
          [
           "2204.00004",
           "Word Mover Distance)."
          ],
          [
           "2008.01391",
           "Machine translation is one of the applications of natural language processing which has been explored in different languages"
          ],
          [
           "2008.01391",
           "Recently researchers started paying attention towards machine translation for resource-poor languages and closely related languages"
          ],
          [
           "2008.01391",
           "A widespread and underlying problem for these machine translation systems is the variation in orthographic conventions which causes many issues to traditional approaches"
          ],
          [
           "2008.01391",
           "Two languages written in two different orthographies are not easily comparable, but orthographic information can also be used to improve the machine translation system"
          ],
          [
           "2008.01391",
           "This article offers a survey of research regarding orthography's influence on machine translation of under-resourced languages"
          ],
          [
           "2008.01391",
           "It introduces under-resourced languages in terms of machine translation and how orthographic information can be utilised to improve machine translation"
          ],
          [
           "2008.01391",
           "We describe previous work in this area, discussing what underlying assumptions were made, and showing how orthographic knowledge improves the performance of machine translation of under-resourced languages"
          ],
          [
           "2008.01391",
           "Additionally, multilingual neural machine translation of closely related languages is given a particular focus in this survey"
          ],
          [
           "2008.01391",
           "This article ends with a discussion of the way forward in machine translation with orthographic information, focusing on multilingual settings and bilingual lexicon induction."
          ],
          [
           "2205.00616",
           "Existing approaches to slang interpretation tend to rely on context but ignore semantic extensions common in slang word usage"
          ],
          [
           "2205.00616",
           "Furthermore, we show how the same framework can be applied to enhancing machine translation of slang from English to other languages"
          ],
          [
           "2205.00616",
           "Our work creates opportunities for the automated interpretation and translation of informal language."
          ],
          [
           "2205.10852",
           "Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining"
          ],
          [
           "2205.10852",
           "However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area"
          ],
          [
           "2205.10852",
           "To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer"
          ],
          [
           "2205.10852",
           "Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue"
          ],
          [
           "2205.10852",
           "We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the globally semantic information among sub-graphs"
          ],
          [
           "2205.10852",
           "Moreover, we propose masked knowledge modeling as a new paradigm for knowledge graph representation learning"
          ],
          [
           "2205.10852",
           "We apply Relphormer to three tasks, namely, knowledge graph completion, KG-based question answering and KG-based recommendation for evaluation"
          ],
          [
           "2205.10852",
           "Code is available in https://github.com/zjunlp/Relphormer."
          ],
          [
           "2012.04955",
           "In automatic speech translation (ST), traditional cascade approaches involving separate transcription and translation steps are giving ground to increasingly competitive and more robust direct solutions"
          ],
          [
           "2012.04955",
           "In particular, by translating speech audio data without intermediate transcription, direct ST models are able to leverage and preserve essential information present in the input (e.g"
          ],
          [
           "2012.04955",
           "Although such ability proved to be useful for gender translation, direct ST is nonetheless affected by gender bias just like its cascade counterpart, as well as machine translation and numerous other natural language processing applications"
          ],
          [
           "2012.04955",
           "Going beyond speech signals, in this paper we compare different approaches to inform direct ST models about the speaker's gender and test their ability to handle gender translation from English into Italian and French"
          ],
          [
           "2012.04955",
           "To this aim, we manually annotated large datasets with speakers' gender information and used them for experiments reflecting different possible real-world scenarios"
          ],
          [
           "2012.04955",
           "In particular, the translation of gender-marked words can increase up to 30 points in accuracy while preserving overall translation quality."
          ],
          [
           "1808.09861",
           "For languages with no annotated resources, unsupervised transfer of natural language processing models such as named-entity recognition (NER) from resource-rich languages would be an appealing capability"
          ],
          [
           "1808.09861",
           "However, differences in words and word order across languages make it a challenging problem"
          ],
          [
           "1808.09861",
           "To improve robustness to word order differences, we propose to use self-attention, which allows for a degree of flexibility with respect to word order"
          ],
          [
           "1808.09861",
           "We also evaluate the challenges of applying these methods to Uyghur, a low-resource language."
          ],
          [
           "2210.15224",
           "Machine translation (MT) is one of the main tasks in natural language processing whose objective is to translate texts automatically from one natural language to another"
          ],
          [
           "2210.15224",
           "Nowadays, using deep neural networks for MT tasks has received great attention"
          ],
          [
           "2210.15224",
           "These networks require lots of data to learn abstract representations of the input and store it in continuous vectors"
          ],
          [
           "2210.15224",
           "This paper presents the first relatively large-scale Amharic-English parallel sentence dataset"
          ],
          [
           "2210.15224",
           "Using these compiled data, we build bi-directional Amharic-English translation models by fine-tuning the existing Facebook M2M100 pre-trained model achieving a BLEU score of 37.79 in Amharic-English 32.74 in English-Amharic translation"
          ],
          [
           "2210.15224",
           "Additionally, we explore the effects of Amharic homophone normalization on the machine translation task"
          ],
          [
           "2104.04886",
           "Adversarial regularization has been shown to improve the generalization performance of deep learning models in various natural language processing tasks"
          ],
          [
           "2104.04886",
           "Existing works usually formulate the method as a zero-sum game, which is solved by alternating gradient descent/ascent algorithms"
          ],
          [
           "2104.04886",
           "Such a formulation treats the adversarial and the defending players equally, which is undesirable because only the defending player contributes to the generalization performance"
          ],
          [
           "2104.04886",
           "To address this issue, we propose Stackelberg Adversarial Regularization (SALT), which formulates adversarial regularization as a Stackelberg game"
          ],
          [
           "2104.04886",
           "This formulation induces a competition between a leader and a follower, where the follower generates perturbations, and the leader trains the model subject to the perturbations"
          ],
          [
           "2104.04886",
           "Different from conventional approaches, in SALT, the leader is in an advantageous position"
          ],
          [
           "2104.04886",
           "When the leader moves, it recognizes the strategy of the follower and takes the anticipated follower's outcomes into consideration"
          ],
          [
           "2104.04886",
           "Such a leader's advantage enables us to improve the model fitting to the unperturbed data"
          ],
          [
           "2104.04886",
           "The leader's strategic information is captured by the Stackelberg gradient, which is obtained using an unrolling algorithm"
          ],
          [
           "2104.04886",
           "Our code is available at https://github.com/SimiaoZuo/Stackelberg-Adv."
          ],
          [
           "2104.04946",
           "Transformer architecture achieves great success in abundant natural language processing tasks"
          ],
          [
           "2104.04946",
           "The over-parameterization of the Transformer model has motivated plenty of works to alleviate its overfitting for superior performances"
          ],
          [
           "2104.04946",
           "With some explorations, we find simple techniques such as dropout, can greatly boost model performance with a careful design"
          ],
          [
           "2104.04946",
           "Therefore, in this paper, we integrate different dropout techniques into the training of Transformer models"
          ],
          [
           "2104.04946",
           "Specifically, we propose an approach named UniDrop to unites three different dropout techniques from fine-grain to coarse-grain, i.e., feature dropout, structure dropout, and data dropout"
          ],
          [
           "2104.04946",
           "Empirically, we conduct experiments on both neural machine translation and text classification benchmark datasets"
          ],
          [
           "2201.12926",
           "Standard deep network models lack the inductive biases needed to generalize compositionally in tasks like semantic parsing, translation, and question answering"
          ],
          [
           "2201.12926",
           "when we do not know how to write or infer a symbolic grammar)"
          ],
          [
           "1906.09777",
           "Latest development of neural models has connected the encoder and decoder through a self-attention mechanism"
          ],
          [
           "1906.09777",
           "In particular, Transformer, which is solely based on self-attention, has led to breakthroughs in Natural Language Processing (NLP) tasks"
          ],
          [
           "1906.09777",
           "However, the multi-head attention mechanism, as a key component of Transformer, limits the effective deployment of the model to a resource-limited setting"
          ],
          [
           "1906.09777",
           "In this paper, based on the ideas of tensor decomposition and parameters sharing, we propose a novel self-attention model (namely Multi-linear attention) with Block-Term Tensor Decomposition (BTD)"
          ],
          [
           "1906.09777",
           "We test and verify the proposed attention method on three language modeling tasks (i.e., PTB, WikiText-103 and One-billion) and a neural machine translation task (i.e., WMT-2016 English-German)"
          ],
          [
           "1906.09777",
           "Multi-linear attention can not only largely compress the model parameters but also obtain performance improvements, compared with a number of language modeling approaches, such as Transformer, Transformer-XL, and Transformer with tensor train decomposition."
          ],
          [
           "2103.00747",
           "Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high"
          ],
          [
           "2103.00747",
           "Thus, it is critical to detect and combat such misinformation"
          ],
          [
           "2103.00747",
           "Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation"
          ],
          [
           "2103.00747",
           "In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness"
          ],
          [
           "2103.00747",
           "First, we collected a dataset of 984 claims about COVID-19 with fact checking"
          ],
          [
           "2103.00747",
           "By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19"
          ],
          [
           "2103.00747",
           "Our model was also tested on a larger dataset for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985)"
          ],
          [
           "2103.00747",
           "The performance on both datasets was better than traditional machine learning models"
          ],
          [
           "2103.00747",
           "Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE)"
          ],
          [
           "2103.00747",
           "The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition"
          ],
          [
           "2210.04141",
           "Word alignment which aims to extract lexicon translation equivalents between source and target sentences, serves as a fundamental tool for natural language processing"
          ],
          [
           "2210.04141",
           "Recent studies in this area have yielded substantial improvements by generating alignments from contextualized embeddings of the pre-trained multilingual language models"
          ],
          [
           "2210.04141",
           "To remedy this problem, we propose Cross-Align to model deep interactions between the input sentence pairs, in which the source and target sentences are encoded separately with the shared self-attention modules in the shallow layers, while cross-lingual interactions are explicitly constructed by the cross-attention modules in the upper layers"
          ],
          [
           "2210.04141",
           "Besides, to train our model effectively, we propose a two-stage training framework, where the model is trained with a simple Translation Language Modeling (TLM) objective in the first stage and then finetuned with a self-supervised alignment objective in the second stage"
          ],
          [
           "2210.15461",
           "Multimodal Machine Translation (MMT) focuses on enhancing text-only translation with visual features, which has attracted considerable attention from both natural language processing and computer vision communities"
          ],
          [
           "2210.15461",
           "Recent advances still struggle to train a separate model for each language pair, which is costly and unaffordable when the number of languages increases in the real world"
          ],
          [
           "2210.15461",
           "In other words, the multilingual multimodal machine translation (Multilingual MMT) task has not been investigated, which aims to handle the aforementioned issues by providing a shared semantic space for multiple languages"
          ],
          [
           "2210.15461",
           "Besides, the image modality has no language boundaries, which is superior to bridging the semantic gap between languages"
          ],
          [
           "2210.15461",
           "To this end, we first propose the Multilingual MMT task by establishing two new Multilingual MMT benchmark datasets covering seven languages"
          ],
          [
           "2210.15461",
           "Then, an effective baseline LVP-M3 using visual prompts is proposed to support translations between different languages, which includes three stages (token encoding, language-aware visual prompt generation, and language translation)"
          ],
          [
           "2205.03666",
           "We achieve state-of-the-art (SoTA) result of 98% macro F1 score on the classification task by using the SoTA T5 model"
          ],
          [
           "2205.03666",
           "We experiment with three instances of the SoTA dialogue model, Dialogue Generative Pre-trained Transformer (DialoGPT), for conversation generation"
          ],
          [
           "2205.03666",
           "Their performances are evaluated using the automatic metric perplexity and human evaluation"
          ],
          [
           "2205.03666",
           "We contribute the model checkpoint/demo and code on the HuggingFace hub for public access."
          ],
          [
           "1808.01174",
           "Deep learning models have lately shown great performance in various fields such as computer vision, speech recognition, speech translation, and natural language processing"
          ],
          [
           "1808.01174",
           "However, alongside their state-of-the-art performance, it is still generally unclear what is the source of their generalization ability"
          ],
          [
           "1808.01174",
           "Thus, an important question is what makes deep neural networks able to generalize well from the training set to new data"
          ],
          [
           "1808.01174",
           "In this article, we provide an overview of the existing theory and bounds for the characterization of the generalization error of deep neural networks, combining both classical and more recent theoretical and empirical results."
          ],
          [
           "2109.07048",
           "Adversarial regularization can improve model generalization in many natural language processing tasks"
          ],
          [
           "2109.07048",
           "However, conventional approaches are computationally expensive since they need to generate a perturbation for each sample in each epoch"
          ],
          [
           "2109.07048",
           "We propose a new adversarial regularization method ARCH (adversarial regularization with caching), where perturbations are generated and cached once every several epochs"
          ],
          [
           "2109.07048",
           "As caching all the perturbations imposes memory usage concerns, we adopt a K-nearest neighbors-based strategy to tackle this issue"
          ],
          [
           "2109.07048",
           "The strategy only requires caching a small amount of perturbations, without introducing additional training time"
          ],
          [
           "2109.07048",
           "We evaluate our proposed method on a set of neural machine translation and natural language understanding tasks"
          ],
          [
           "2109.07048",
           "More surprisingly, by reducing the variance of stochastic gradients, ARCH produces a notably better (in most of the tasks) or comparable model generalization"
          ],
          [
           "2109.07048",
           "Our code is available at https://github.com/SimiaoZuo/Caching-Adv."
          ],
          [
           "2104.07874",
           "Natural language processing (NLP) research combines the study of universal principles, through basic science, with applied science targeting specific use cases and settings"
          ],
          [
           "2104.07874",
           "However, the process of exchange between basic NLP and applications is often assumed to emerge naturally, resulting in many innovations going unapplied and many important questions left unstudied"
          ],
          [
           "2104.07874",
           "We describe a new paradigm of Translational NLP, which aims to structure and facilitate the processes by which basic and applied NLP research inform one another"
          ],
          [
           "2104.07874",
           "Translational NLP thus presents a third research paradigm, focused on understanding the challenges posed by application needs and how these challenges can drive innovation in basic science and technology design"
          ],
          [
           "2104.07874",
           "Our framework provides a roadmap for developing Translational NLP as a dedicated research area, and identifies general translational principles to facilitate exchange between basic and applied research."
          ],
          [
           "1706.00878",
           "In this paper, we explore optimizations to run Recurrent Neural Network (RNN) models locally on mobile devices"
          ],
          [
           "1706.00878",
           "RNN models are widely used for Natural Language Processing, Machine Translation, and other tasks"
          ],
          [
           "1706.00878",
           "To address privacy and efficiency concerns, we show how RNN models can be run locally on mobile devices"
          ],
          [
           "1706.00878",
           "Existing work on porting deep learning models to mobile devices focus on Convolution Neural Networks (CNNs) and cannot be applied directly to RNN models"
          ],
          [
           "2005.06537",
           "In this work, we instead \"reallocate\" them -- the model learns to activate different heads on different inputs"
          ],
          [
           "2005.06537",
           "Drawing connections between multi-head attention and mixture of experts, we propose the mixture of attentive experts model (MAE)"
          ],
          [
           "2005.06537",
           "Particularly, on the WMT14 English to German translation dataset, MAE improves over \"transformer-base\" by 0.8 BLEU, with a comparable number of parameters"
          ],
          [
           "2002.02973",
           "This architecture also makes a good candidate for a variational wave function, where the RNN parameters are tuned to learn the approximate ground state of a quantum Hamiltonian"
          ],
          [
           "2002.02973",
           "In this paper, we demonstrate the ability of RNNs to represent several many-body wave functions, optimizing the variational parameters using a stochastic approach"
          ],
          [
           "2002.02973",
           "Among other attractive features of these variational wave functions, their autoregressive nature allows for the efficient calculation of physical estimators by providing independent samples"
          ],
          [
           "2002.02973",
           "We demonstrate the effectiveness of RNN wave functions by calculating ground state energies, correlation functions, and entanglement entropies for several quantum spin models of interest to condensed matter physicists in one and two spatial dimensions."
          ],
          [
           "2210.03768",
           "Numerous works have been proposed to attack the natural language interfaces to databases (NLIDB) problem either as a conventional pipeline-based or an end-to-end deep-learning-based solution"
          ],
          [
           "2210.03768",
           "Nevertheless, regardless of the approach preferred, such solutions exhibit black-box nature, which makes it difficult for potential users targeted by these systems to comprehend the decisions made to produce the translated SQL"
          ],
          [
           "2210.03768",
           "We also evaluate xDBTagger quantitatively in three real-world relational databases"
          ],
          [
           "1910.09329",
           "It is of great importance for downstream natural language processing tasks such as entity linking, machine translation, summarization, chatbots, etc"
          ],
          [
           "1910.09329",
           "This work aims to give a detailed review of current progress on solving Coreference Resolution using neural-based approaches"
          ],
          [
           "1910.09329",
           "We highlight the advantages and disadvantages of the approaches, the challenges of the task, the lack of agreed-upon standards in the task and propose a way to further expand the boundaries of the field."
          ],
          [
           "2205.02536",
           "6D object pose estimation is a crucial prerequisite for autonomous robot manipulation applications"
          ],
          [
           "2205.02536",
           "The state-of-the-art models for pose estimation are convolutional neural network (CNN)-based"
          ],
          [
           "2205.02536",
           "Equipped with the multi-head self-attention mechanism, Transformers enable simple single-stage end-to-end architectures for learning object detection and 6D object pose estimation jointly"
          ],
          [
           "2205.02536",
           "In this work, we propose YOLOPose (short form for You Only Look Once Pose estimation), a Transformer-based multi-object 6D pose estimation method based on keypoint regression"
          ],
          [
           "2205.02536",
           "In contrast to the standard heatmaps for predicting keypoints in an image, we directly regress the keypoints"
          ],
          [
           "2205.02536",
           "Additionally, we employ a learnable orientation estimation module to predict the orientation from the keypoints"
          ],
          [
           "2205.02536",
           "Along with a separate translation estimation module, our model is end-to-end differentiable"
          ],
          [
           "2204.11574",
           "Measuring the performance of natural language processing models is challenging"
          ],
          [
           "2204.11574",
           "Traditionally used metrics, such as BLEU and ROUGE, originally devised for machine translation and summarization, have been shown to suffer from low correlation with human judgment and a lack of transferability to other tasks and languages"
          ],
          [
           "2204.11574",
           "In the past 15 years, a wide range of alternative metrics have been proposed"
          ],
          [
           "2204.11574",
           "However, it is unclear to what extent this has had an impact on NLP benchmarking efforts"
          ],
          [
           "2204.11574",
           "Here we provide the first large-scale cross-sectional analysis of metrics used for measuring performance in natural language processing"
          ],
          [
           "2203.08459",
           "Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks"
          ],
          [
           "2203.08459",
           "However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages"
          ],
          [
           "2203.08459",
           "Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities"
          ],
          [
           "2203.08459",
           "Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages"
          ],
          [
           "1606.08140",
           "Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks"
          ],
          [
           "1606.08140",
           "However, because knowledge bases are typically incomplete, it is useful to be able to perform link prediction or knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true"
          ],
          [
           "1606.08140",
           "STransE is a simple combination of the SE and TransE models, but it obtains better link prediction performance on two benchmark datasets than previous embedding models"
          ],
          [
           "1606.08140",
           "Thus, STransE can serve as a new baseline for the more complex models in the link prediction task."
          ],
          [
           "2203.02982",
           "A discourse containing one or more sentences describes daily issues and events for people to communicate their thoughts and opinions"
          ],
          [
           "2203.02982",
           "As sentences are normally consist of multiple text segments, correct understanding of the theme of a discourse should take into consideration of the relations in between text segments"
          ],
          [
           "2203.02982",
           "The task of implicit discourse relation recognition (IDRR) is to detect implicit relation and classify its sense between two text segments without a connective"
          ],
          [
           "2203.02982",
           "Indeed, the IDRR task is important to diverse downstream natural language processing tasks, such as text summarization, machine translation and so on"
          ],
          [
           "2203.02982",
           "This article provides a comprehensive and up-to-date survey for the IDRR task"
          ],
          [
           "2203.02982",
           "We first summarize the task definition and data sources widely used in the field"
          ],
          [
           "2203.02982",
           "We categorize the main solution approaches for the IDRR task from the viewpoint of its development history"
          ],
          [
           "2203.02982",
           "In each solution category, we present and analyze the most representative methods, including their origins, ideas, strengths and weaknesses"
          ],
          [
           "2203.02982",
           "We also present performance comparisons for those solutions experimented on a public corpus with standard data processing procedures"
          ],
          [
           "2203.02982",
           "Finally, we discuss future research directions for discourse relation analysis."
          ],
          [
           "2110.02869",
           "This discrepancy has led to severe performance degradation of state-of-the-art NLP models when fine-tuned on real-world data"
          ],
          [
           "2110.02869",
           "One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from social media, into a more standardized form"
          ],
          [
           "2110.02869",
           "In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem"
          ],
          [
           "2207.13988",
           "Large pretrained language models have recently conquered the area of natural language processing"
          ],
          [
           "2207.13988",
           "As an alternative to predominant masked language modelling introduced in BERT, the T5 model has introduced a more general training objective, namely sequence to sequence transformation, which includes masked language model but more naturally fits text generation tasks such as machine translation, summarization, open-domain question answering, text simplification, dialogue systems, etc"
          ],
          [
           "2207.13988",
           "The monolingual variants of T5 models have been limited to well-resourced languages, while the massively multilingual T5 model supports 101 languages"
          ],
          [
           "2207.13988",
           "In contrast, we trained two different sized T5-type sequence to sequence models for morphologically rich Slovene language with much less resources and analyzed their behavior"
          ],
          [
           "2207.13988",
           "Concerning classification tasks, the SloT5 models mostly lag behind the monolingual Slovene SloBERTa model but are to be considered for the generative tasks."
          ],
          [
           "2205.15960",
           "Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines"
          ],
          [
           "2205.15960",
           "Despite its success, NLP technology is only widely available for high-resource languages such as English and Chinese, while it remains inaccessible to many languages due to the unavailability of data resources and benchmarks"
          ],
          [
           "2205.15960",
           "In this work, we focus on developing resources for languages in Indonesia"
          ],
          [
           "2205.15960",
           "Despite being the second most linguistically diverse country, most languages in Indonesia are categorized as endangered and some are even extinct"
          ],
          [
           "2205.15960",
           "We develop the first-ever parallel resource for 10 low-resource languages in Indonesia"
          ],
          [
           "2205.15960",
           "Our resource includes datasets, a multi-task benchmark, and lexicons, as well as a parallel Indonesian-English dataset"
          ],
          [
           "2205.15960",
           "We provide extensive analyses and describe the challenges when creating such resources"
          ],
          [
           "1809.05053",
           "State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models"
          ],
          [
           "1809.05053",
           "Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer"
          ],
          [
           "1809.05053",
           "In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu"
          ],
          [
           "1909.12440",
           "Recently, pre-trained language models have achieved remarkable success in a broad range of natural language processing tasks"
          ],
          [
           "1909.12440",
           "However, in multilingual setting, it is extremely resource-consuming to pre-train a deep language model over large-scale corpora for each language"
          ],
          [
           "1909.12440",
           "Instead of exhaustively pre-training monolingual language models independently, an alternative solution is to pre-train a powerful multilingual deep language model over large-scale corpora in hundreds of languages"
          ],
          [
           "1909.12440",
           "However, the vocabulary size for each language in such a model is relatively small, especially for low-resource languages"
          ],
          [
           "1909.12440",
           "This limitation inevitably hinders the performance of these multilingual models on tasks such as sequence labeling, wherein in-depth token-level or sentence-level understanding is essential"
          ],
          [
           "2205.10956",
           "Automatic Program Repair (APR) aims at fixing buggy source code with less manual debugging efforts, which plays a vital role in improving software reliability and development productivity"
          ],
          [
           "2205.10956",
           "Recent APR works have achieved remarkable progress via applying deep learning (DL), particularly neural machine translation (NMT) techniques"
          ],
          [
           "2205.10956",
           "(2) Most of them are developed in an offline manner"
          ],
          [
           "2205.10956",
           "Therefore, they won't function when there are new-coming requirements"
          ],
          [
           "2205.10956",
           "To address the above problems, a T5-based APR framework equipped with continual learning ability across multiple programming languages is proposed, namely \\emph{C}ont\\emph{I}nual \\emph{R}epair a\\emph{C}ross Programming \\emph{L}anguag\\emph{E}s (\\emph{CIRCLE})"
          ],
          [
           "2205.10956",
           "Specifically, (1) CIRCLE utilizes a prompting function to narrow the gap between natural language processing (NLP) pre-trained tasks and APR"
          ],
          [
           "2205.10956",
           "(2) CIRCLE adopts a difficulty-based rehearsal strategy to achieve lifelong learning for APR without access to the full historical data"
          ],
          [
           "2205.10956",
           "(3) An elastic regularization method is employed to strengthen CIRCLE's continual learning ability further, preventing it from catastrophic forgetting"
          ],
          [
           "2205.10956",
           "(4) CIRCLE applies a simple but effective re-repairing method to revise generated errors caused by crossing multiple programming languages"
          ],
          [
           "2205.10956",
           "We train CIRCLE for four languages (i.e., C, JAVA, JavaScript, and Python) and evaluate it on five commonly used benchmarks"
          ],
          [
           "1903.10625",
           "Grammatical error correction (GEC) is one of the areas in natural language processing in which purely neural models have not yet superseded more traditional symbolic models"
          ],
          [
           "1903.10625",
           "Hybrid systems combining phrase-based statistical machine translation (SMT) and neural sequence models are currently among the most effective approaches to GEC"
          ],
          [
           "1903.10625",
           "However, both SMT and neural sequence-to-sequence models require large amounts of annotated data"
          ],
          [
           "1903.10625",
           "Language model based GEC (LM-GEC) is a promising alternative which does not rely on annotated training data"
          ],
          [
           "1903.10625",
           "We show how to improve LM-GEC by applying modelling techniques based on finite state transducers"
          ],
          [
           "1903.10625",
           "We report further gains by rescoring with neural language models"
          ],
          [
           "1903.10625",
           "Our best system outperforms the best published result on the CoNLL-2014 test set, and achieves far better relative improvements over the SMT baselines than previous hybrid systems."
          ],
          [
           "2011.00948",
           "One critical issue of zero anaphora resolution (ZAR) is the scarcity of labeled data"
          ],
          [
           "2011.00948",
           "This study explores how effectively this problem can be alleviated by data augmentation"
          ],
          [
           "2011.00948",
           "The CDA has been reported to work well for several other natural language processing tasks, including text classification and machine translation"
          ],
          [
           "2011.00948",
           "We also propose two methods to adapt CDA to ZAR: [MASK]-based augmentation and linguistically-controlled masking"
          ],
          [
           "2004.14781",
           "Human-curated knowledge graphs provide critical supportive information to various natural language processing tasks, but these graphs are usually incomplete, urging auto-completion of them"
          ],
          [
           "2004.14781",
           "Prevalent graph embedding approaches, e.g., TransE, learn structured knowledge via representing graph elements into dense embeddings and capturing their triple-level relationship with spatial distance"
          ],
          [
           "2004.14781",
           "However, they are hardly generalizable to the elements never visited in training and are intrinsically vulnerable to graph incompleteness"
          ],
          [
           "2004.14781",
           "In contrast, textual encoding approaches, e.g., KG-BERT, resort to graph triple's text and triple-level contextualized representations"
          ],
          [
           "2004.14781",
           "They are generalizable enough and robust to the incompleteness, especially when coupled with pre-trained encoders"
          ],
          [
           "2004.14781",
           "But two major drawbacks limit the performance: (1) high overheads due to the costly scoring of all possible triples in inference, and (2) a lack of structured knowledge in the textual encoder"
          ],
          [
           "2004.14781",
           "In this paper, we follow the textual encoding paradigm and aim to alleviate its drawbacks by augmenting it with graph embedding techniques -- a complementary hybrid of both paradigms"
          ],
          [
           "2004.14781",
           "Specifically, we partition each triple into two asymmetric parts as in translation-based graph embedding approach, and encode both parts into contextualized representations by a Siamese-style textual encoder"
          ],
          [
           "2004.14781",
           "Built upon the representations, our model employs both deterministic classifier and spatial measurement for representation and structure learning respectively"
          ],
          [
           "2004.14781",
           "Moreover, we develop a self-adaptive ensemble scheme to further improve the performance by incorporating triple scores from an existing graph embedding model"
          ],
          [
           "2004.14781",
           "In experiments, we achieve state-of-the-art performance on three benchmarks and a zero-shot dataset for link prediction, with highlights of inference costs reduced by 1-2 orders of magnitude compared to a textual encoding method."
          ],
          [
           "1908.01851",
           "Since deep learning became a key player in natural language processing (NLP), many deep learning models have been showing remarkable performances in a variety of NLP tasks, and in some cases, they are even outperforming humans"
          ],
          [
           "1908.01851",
           "Such high performance can be explained by efficient knowledge representation of deep learning models"
          ],
          [
           "1908.01851",
           "In this paper, we propose a new knowledge distillation method self-knowledge distillation, based on the soft target probabilities of the training model itself, where multimode information is distilled from the word embedding space right below the softmax layer"
          ],
          [
           "1908.01851",
           "In experiments, we applied the proposed method to two different and fundamental NLP tasks: language model and neural machine translation"
          ],
          [
           "2012.05995",
           "The accurate prediction of biological features from genomic data is paramount for precision medicine and sustainable agriculture"
          ],
          [
           "2012.05995",
           "For decades, neural network models have been widely popular in fields like computer vision, astrophysics and targeted marketing given their prediction accuracy and their robust performance under big data settings"
          ],
          [
           "2012.05995",
           "Yet neural network models have not made a successful transition into the medical and biological world due to the ubiquitous characteristics of biological data such as modest sample sizes, sparsity, and extreme heterogeneity"
          ],
          [
           "2012.05995",
           "Here, we investigate the robustness, generalization potential and prediction accuracy of widely used convolutional neural network and natural language processing models with a variety of heterogeneous genomic datasets"
          ],
          [
           "2012.05995",
           "Mainly, recurrent neural network models outperform convolutional neural network models in terms of prediction accuracy, overfitting and transferability across the datasets under study"
          ],
          [
           "2105.00164",
           "Natural language processing (NLP) systems have been proven to be vulnerable to backdoor attacks, whereby hidden features (backdoors) are trained into a language model and may only be activated by specific inputs (called triggers), to trick the model into producing unexpected behaviors"
          ],
          [
           "2105.00164",
           "In this paper, we create covert and natural triggers for textual backdoor attacks, \\textit{hidden backdoors}, where triggers can fool both modern language models and human inspection"
          ],
          [
           "2105.00164",
           "The first approach via homograph replacement, embeds the trigger into deep neural networks through the visual spoofing of lookalike character replacement"
          ],
          [
           "2105.00164",
           "The second approach uses subtle differences between text generated by language models and real natural text to produce trigger sentences with correct grammar and high fluency"
          ],
          [
           "2105.00164",
           "We are able to demonstrate the adversary's high success rate of attacks, while maintaining functionality for regular users, with triggers inconspicuous by the human administrators."
          ],
          [
           "2103.13275",
           "Big languages such as English and Finnish have many natural language processing (NLP) resources and models, but this is not the case for low-resourced and endangered languages as such resources are so scarce despite the great advantages they would provide for the language communities"
          ],
          [
           "2103.13275",
           "The most common types of resources available for low-resourced and endangered languages are translation dictionaries and universal dependencies"
          ],
          [
           "2103.13275",
           "In this paper, we present a method for constructing word embeddings for endangered languages using existing word embeddings of different resource-rich languages and the translation dictionaries of resource-poor languages"
          ],
          [
           "2103.13275",
           "Thereafter, the embeddings are fine-tuned using the sentences in the universal dependencies and aligned to match the semantic spaces of the big languages; resulting in cross-lingual embeddings"
          ],
          [
           "2103.13275",
           "The endangered languages we work with here are Erzya, Moksha, Komi-Zyrian and Skolt Sami"
          ],
          [
           "2103.13275",
           "All our cross-lingual word embeddings and the sentiment analysis model have been released openly via an easy-to-use Python library."
          ],
          [
           "1905.11558",
           "Recurrent Neural Networks (RNNs) are widely used in the field of natural language processing (NLP), ranging from text categorization to question answering and machine translation"
          ],
          [
           "1905.11558",
           "However, RNNs generally read the whole text from beginning to end or vice versa sometimes, which makes it inefficient to process long texts"
          ],
          [
           "1905.11558",
           "When reading a long document for a categorization task, such as topic categorization, large quantities of words are irrelevant and can be skipped"
          ],
          [
           "1905.11558",
           "To this end, we propose Leap-LSTM, an LSTM-enhanced model which dynamically leaps between words while reading texts"
          ],
          [
           "1905.11558",
           "At each step, we utilize several feature encoders to extract messages from preceding texts, following texts and the current word, and then determine whether to skip the current word"
          ],
          [
           "1905.11558",
           "We evaluate Leap-LSTM on several text categorization tasks: sentiment analysis, news categorization, ontology classification and topic classification, with five benchmark data sets"
          ],
          [
           "1905.11558",
           "Compared to previous models which can also skip words, our model achieves better trade-offs between performance and efficiency."
          ],
          [
           "1905.11471",
           "While natural language processing systems often focus on a single language, multilingual transfer learning has the potential to improve performance, especially for low-resource languages"
          ],
          [
           "1905.11471",
           "XLDA enhances performance of all 14 tested languages of the cross-lingual natural language inference (XNLI) benchmark"
          ],
          [
           "1905.11471",
           "With improvements of up to $4.8\\%$, training with XLDA achieves state-of-the-art performance for Greek, Turkish, and Urdu"
          ],
          [
           "2106.09898",
           "Until now, such attacks have primarily targeted visual models, exploiting the gap between human and machine perception"
          ],
          [
           "2106.09898",
           "Although text-based models have also been attacked with adversarial examples, such attacks struggled to preserve semantic meaning and indistinguishability"
          ],
          [
           "2106.09898",
           "Our attacks work against currently-deployed commercial systems, including those produced by Microsoft and Google, in addition to open source models published by Facebook, IBM, and HuggingFace"
          ],
          [
           "2106.09898",
           "This novel series of attacks presents a significant threat to many language processing systems: an attacker can affect systems in a targeted manner without any assumptions about the underlying model"
          ],
          [
           "1906.01617",
           "Lattices are an efficient and effective method to encode ambiguity of upstream systems in natural language processing tasks, for example to compactly capture multiple speech recognition hypotheses, or to represent multiple linguistic analyses"
          ],
          [
           "1906.01617",
           "Previous work has extended recurrent neural networks to model lattice inputs and achieved improvements in various tasks, but these models suffer from very slow computation speeds"
          ],
          [
           "1906.01617",
           "This paper extends the recently proposed paradigm of self-attention to handle lattice inputs"
          ],
          [
           "1906.01617",
           "We also propose a method for adapting positional embeddings to lattice structures"
          ],
          [
           "2001.05315",
           "Language models are generally employed to estimate the probability distribution of various linguistic units, making them one of the fundamental parts of natural language processing"
          ],
          [
           "2001.05315",
           "Applications of language models include a wide spectrum of tasks such as text summarization, translation and classification"
          ],
          [
           "2001.05315",
           "For a low resource language like Bengali, the research in this area so far can be considered to be narrow at the very least, with some traditional count based models being proposed"
          ],
          [
           "2001.05315",
           "This paper attempts to address the issue and proposes a continuous-space neural language model, or more specifically an ASGD weight dropped LSTM language model, along with techniques to efficiently train it for Bengali Language"
          ],
          [
           "2204.01827",
           "Product market demand analysis plays a significant role for originating business strategies due to its noticeable impact on the competitive business field"
          ],
          [
           "2204.01827",
           "Furthermore, there are roughly 228 million native Bengali speakers, the majority of whom use Banglish text to interact with one another on social media"
          ],
          [
           "2204.01827",
           "Consumers are buying and evaluating items on social media with Banglish text as social media emerges as an online marketplace for entrepreneurs"
          ],
          [
           "2204.01827",
           "People use social media to find preferred smartphone brands and models by sharing their positive and bad experiences with them"
          ],
          [
           "2204.01827",
           "For this reason, our goal is to gather Banglish text data and use sentiment analysis and named entity identification to assess Bangladeshi market demand for smartphones in order to determine the most popular smartphones by gender"
          ],
          [
           "2204.01827",
           "We scraped product related data from social media with instant data scrapers and crawled data from Wikipedia and other sites for product information with python web scrapers"
          ],
          [
           "2204.01827",
           "Using Python's Pandas and Seaborn libraries, the raw data is filtered using NLP methods"
          ],
          [
           "2204.01827",
           "To train our datasets for named entity recognition, we utilized Spacey's custom NER model, Amazon Comprehend Custom NER"
          ],
          [
           "2204.01827",
           "A tensorflow sequential model was deployed with parameter tweaking for sentiment analysis"
          ],
          [
           "2204.01827",
           "Meanwhile, we used the Google Cloud Translation API to estimate the gender of the reviewers using the BanglaLinga library"
          ],
          [
           "2204.01827",
           "In this article, we use natural language processing (NLP) approaches and several machine learning models to identify the most in-demand items and services in the Bangladeshi market"
          ],
          [
           "2204.01827",
           "Our model has an accuracy of 87.99% in Spacy Custom Named Entity recognition, 95.51% in Amazon Comprehend Custom NER, and 87.02% in the Sequential model for demand analysis"
          ],
          [
           "2204.01827",
           "After Spacy's study, we were able to manage 80% of mistakes related to misspelled words using a mix of Levenshtein distance and ratio algorithms."
          ],
          [
           "2104.08173",
           "Using pretrained word embeddings has been shown to be a very effective way in improving the performance of natural language processing tasks"
          ],
          [
           "2104.08173",
           "These tasks range from sentiment analysis, translation, sequence prediction amongst many others"
          ],
          [
           "2104.08173",
           "One of the most successful word embeddings is the Word2vec CBOW model proposed by Mikolov trained by the negative sampling technique"
          ],
          [
           "2104.08173",
           "Mai et al"
          ],
          [
           "2104.08173",
           "We used a modified version of the negative sampling objective for our context words, modelling the context embeddings as a Taylor series of rate matrices"
          ],
          [
           "2104.08173",
           "Our Word2rate model is grounded in a statistical foundation using rate matrices while being competitive in variety of language tasks."
          ],
          [
           "1808.04614",
           "Designing a reliable natural language (NL) interface for querying tables has been a longtime goal of researchers in both the data management and natural language processing (NLP) communities"
          ],
          [
           "1808.04614",
           "Such an interface receives as input an NL question, translates it into a formal query, executes the query and returns the results"
          ],
          [
           "1808.04614",
           "Errors in the translation process are not uncommon, and users typically struggle to understand whether their query has been mapped correctly"
          ],
          [
           "1808.04614",
           "We address this problem by explaining the obtained formal queries to non-expert users"
          ],
          [
           "1808.04614",
           "Two methods for query explanations are presented: the first translates queries into NL, while the second method provides a graphic representation of the query cell-based provenance (in its execution on a given table)"
          ],
          [
           "1808.04614",
           "Our solution augments a state-of-the-art NL interface over web tables, enhancing it in both its training and deployment phase"
          ],
          [
           "1811.03199",
           "Word vector representations are a crucial part of Natural Language Processing (NLP) and Human Computer Interaction"
          ],
          [
           "1811.03199",
           "The representational ambiguity of acoustics, which manifests itself in word confusions, is often resolved by both humans and machines through contextual cues"
          ],
          [
           "1811.03199",
           "A range of representational ambiguities can emerge in various domains further to acoustic perception, such as morphological transformations, paraphrasing for NLP tasks like machine translation etc"
          ],
          [
           "1811.03199",
           "In this work, we present a case study in application to Automatic Speech Recognition (ASR), where the word confusions are related to acoustic similarity"
          ],
          [
           "1811.03199",
           "We present several techniques to train an acoustic perceptual similarity representation ambiguity"
          ],
          [
           "1811.03199",
           "We term this Confusion2Vec and learn on unsupervised-generated data from ASR confusion networks or lattice-like structures"
          ],
          [
           "1811.03199",
           "Appropriate evaluations for the Confusion2Vec are formulated for gauging acoustic similarity in addition to semantic-syntactic and word similarity evaluations"
          ],
          [
           "1811.03199",
           "The Confusion2Vec is able to model word confusions efficiently, without compromising on the semantic-syntactic word relations, thus effectively enriching the word vector space with extra task relevant ambiguity information"
          ],
          [
           "1811.03199",
           "We provide an intuitive exploration of the 2-dimensional Confusion2Vec space using Principal Component Analysis of the embedding and relate to semantic, syntactic and acoustic relationships"
          ],
          [
           "1811.03199",
           "The potential of Confusion2Vec in the utilization of uncertainty present in lattices is demonstrated through small examples relating to ASR error correction."
          ],
          [
           "2209.02967",
           "The evolution of language follows the rule of gradual change"
          ],
          [
           "2209.02967",
           "Grammar, vocabulary, and lexical semantic shifts take place over time, resulting in a diachronic linguistic gap"
          ],
          [
           "2209.02967",
           "As such, a considerable amount of texts are written in languages of different eras, which creates obstacles for natural language processing tasks, such as word segmentation and machine translation"
          ],
          [
           "2209.02967",
           "Although the Chinese language has a long history, previous Chinese natural language processing research has primarily focused on tasks within a specific era"
          ],
          [
           "2209.02967",
           "Therefore, we propose a cross-era learning framework for Chinese word segmentation (CWS), CROSSWISE, which uses the Switch-memory (SM) module to incorporate era-specific linguistic knowledge"
          ],
          [
           "1804.05017",
           "Clinical Named Entity Recognition (CNER) aims to identify and classify clinical terms such as diseases, symptoms, treatments, exams, and body parts in electronic health records, which is a fundamental and crucial task for clinical and translational research"
          ],
          [
           "1804.05017",
           "In recent years, deep neural networks have achieved significant success in named entity recognition and many other Natural Language Processing (NLP) tasks"
          ],
          [
           "1804.05017",
           "Most of these algorithms are trained end to end, and can automatically learn features from large scale labeled datasets"
          ],
          [
           "1804.05017",
           "However, these data-driven methods typically lack the capability of processing rare or unseen entities"
          ],
          [
           "1804.05017",
           "In this paper, we address the problem by incorporating dictionaries into deep neural networks for the Chinese CNER task"
          ],
          [
           "2206.02291",
           "Since the advent of Federated Learning (FL), research has applied these methods to natural language processing (NLP) tasks"
          ],
          [
           "2206.02291",
           "Despite a plethora of papers in FL for NLP, no previous works have studied how multilingual text impacts FL algorithms"
          ],
          [
           "2206.02291",
           "Furthermore, multilingual text provides an interesting avenue to examine the impact of non-IID text (e.g"
          ],
          [
           "2206.02291",
           "different languages) on FL in naturally occurring data"
          ],
          [
           "2206.02291",
           "We explore three multilingual language tasks, language modeling, machine translation, and text classification using differing federated and non-federated learning algorithms"
          ],
          [
           "2012.13736",
           "Generative Adversarial Networks (GANs) have been extremely successful in various application domains such as computer vision, medicine, and natural language processing"
          ],
          [
           "2012.13736",
           "Moreover, transforming an object or person to a desired shape become a well-studied research in the GANs"
          ],
          [
           "2012.13736",
           "GANs are powerful models for learning complex distributions to synthesize semantically meaningful samples"
          ],
          [
           "2012.13736",
           "However, there is a lack of comprehensive review in this field, especially lack of a collection of GANs loss-variant, evaluation metrics, remedies for diverse image generation, and stable training"
          ],
          [
           "2012.13736",
           "Given the current fast GANs development, in this survey, we provide a comprehensive review of adversarial models for image synthesis"
          ],
          [
           "2012.13736",
           "We summarize the synthetic image generation methods, and discuss the categories including image-to-image translation, fusion image generation, label-to-image mapping, and text-to-image translation"
          ],
          [
           "2012.13736",
           "We organize the literature based on their base models, developed ideas related to architectures, constraints, loss functions, evaluation metrics, and training datasets"
          ],
          [
           "2012.13736",
           "We present milestones of adversarial models, review an extensive selection of previous works in various categories, and present insights on the development route from the model-based to data-driven methods"
          ],
          [
           "2012.13736",
           "Further, we highlight a range of potential future research directions"
          ],
          [
           "2011.08072",
           "Recent advances in natural language processing have enabled automation of a wide range of tasks, including machine translation, named entity recognition, and sentiment analysis"
          ],
          [
           "2011.08072",
           "Automated summarization of documents, or groups of documents, however, has remained elusive, with many efforts limited to extraction of keywords, key phrases, or key sentences"
          ],
          [
           "2011.08072",
           "Accurate abstractive summarization has yet to be achieved due to the inherent difficulty of the problem, and limited availability of training data"
          ],
          [
           "2011.08072",
           "In this paper, we propose a topic-centric unsupervised multi-document summarization framework to generate extractive and abstractive summaries for groups of scientific articles across 20 Fields of Study (FoS) in Microsoft Academic Graph (MAG) and news articles from DUC-2004 Task 2"
          ],
          [
           "2011.08072",
           "The proposed algorithm generates an abstractive summary by developing salient language unit selection and text generation techniques"
          ],
          [
           "2011.08072",
           "Our approach matches the state-of-the-art when evaluated on automated extractive evaluation metrics and performs better for abstractive summarization on five human evaluation metrics (entailment, coherence, conciseness, readability, and grammar)"
          ],
          [
           "2011.08072",
           "We plan to publicly share MAG-20, a human-validated gold standard dataset of topic-clustered research articles and their summaries to promote research in abstractive summarization."
          ],
          [
           "1912.11637",
           "Self-attention based Transformer has demonstrated the state-of-the-art performances in a number of natural language processing tasks"
          ],
          [
           "1912.11637",
           "Self-attention is able to model long-term dependencies, but it may suffer from the extraction of irrelevant information in the context"
          ],
          [
           "1912.11637",
           "To tackle the problem, we propose a novel model called \\textbf{Explicit Sparse Transformer}"
          ],
          [
           "1912.11637",
           "Explicit Sparse Transformer is able to improve the concentration of attention on the global context through an explicit selection of the most relevant segments"
          ],
          [
           "1912.11637",
           "Code will be available at \\url{https://github.com/lancopku/Explicit-Sparse-Transformer}"
          ],
          [
           "2212.01650",
           "Transformer variants dominate the state-of-the-art in different natural language processing tasks such as translation, reading comprehension and summarization"
          ],
          [
           "2212.01650",
           "Our paper is more directed to use general memory slots added to the inputs and studying the results of adding these slots"
          ],
          [
           "2212.01650",
           "We have two main tasks;1) pretraining task using masked language modeling and b) fine tuning task using HotpotQA "
          ],
          [
           "2212.01650",
           "This study aims to verify the ability of the proposed model to handle chunks as if they were one chunk comparing with the base model"
          ],
          [
           "2212.01650",
           "As baseline we used T5 transformer"
          ],
          [
           "2212.01650",
           "We studied the rule of memory slots augmented to each input chunk and studied the model performance without selector"
          ],
          [
           "2212.01650",
           "Ablation study reveals the ability of using the compressed input chunks with a degradation in performance."
          ],
          [
           "2001.06588",
           "The design of machine learning systems often requires trading off different objectives, for example, prediction error and energy consumption for deep neural networks (DNNs)"
          ],
          [
           "2001.06588",
           "Typically, no single design performs well in all objectives; therefore, finding Pareto-optimal designs is of interest"
          ],
          [
           "2001.06588",
           "However, measuring different objectives incurs different costs"
          ],
          [
           "2001.06588",
           "Current state-of-the-art methods do not consider this difference in objective evaluation cost, potentially incurring expensive evaluations of objective functions in the optimization process"
          ],
          [
           "2001.06588",
           "In this paper, we develop a novel decoupled and cost-aware multi-objective optimization algorithm, we call Flexible Multi-Objective Bayesian Optimization (FlexiBO) to address this issue"
          ],
          [
           "2001.06588",
           "FlexiBO weights the improvement of the hypervolume of the Pareto region by the measurement cost of each objective to balance the expense of collecting new information with the knowledge gained through objective evaluations, preventing us from performing expensive measurements for little to no gain"
          ],
          [
           "2001.06588",
           "We evaluate FlexiBO on seven state-of-the-art DNNs for image recognition, natural language processing (NLP), and speech-to-text translation"
          ],
          [
           "0912.3747",
           "Paraphrasing can be seen as bidirectional textual entailment and methods from the two areas are often similar"
          ],
          [
           "0912.3747",
           "Both kinds of methods are useful, at least in principle, in a wide range of natural language processing applications, including question answering, summarization, text generation, and machine translation"
          ],
          [
           "0912.3747",
           "We summarize key ideas from the two areas by considering in turn recognition, generation, and extraction methods, also pointing to prominent articles and resources."
          ],
          [
           "1911.00317",
           "Despite the recent success of deep neural networks in natural language processing (NLP), their interpretability remains a challenge"
          ],
          [
           "1911.00317",
           "We analyze the representations learned by neural machine translation models at various levels of granularity and evaluate their quality through relevant extrinsic properties"
          ],
          [
           "2006.03158",
           "Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses"
          ],
          [
           "2006.03158",
           "These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empirically performs well as a surrogate objective"
          ],
          [
           "2011.12631",
           "The term natural language refers to any system of symbolic communication (spoken, signed or written) without intentional human planning and design"
          ],
          [
           "2011.12631",
           "This distinguishes natural languages such as Arabic and Japanese from artificially constructed languages such as Esperanto or Python"
          ],
          [
           "2011.12631",
           "Natural language processing (NLP) is the sub-field of artificial intelligence (AI) focused on modeling natural languages to build applications such as speech recognition and synthesis, machine translation, optical character recognition (OCR), sentiment analysis (SA), question answering, dialogue systems, etc"
          ],
          [
           "2011.12631",
           "NLP is a highly interdisciplinary field with connections to computer science, linguistics, cognitive science, psychology, mathematics and others"
          ],
          [
           "2011.12631",
           "Some of the earliest AI applications were in NLP (e.g., machine translation); and the last decade (2010-2020) in particular has witnessed an incredible increase in quality, matched with a rise in public awareness, use, and expectations of what may have seemed like science fiction in the past"
          ],
          [
           "2011.12631",
           "machine translation systems can be built for a variety of languages using the same basic mechanisms and models"
          ],
          [
           "2011.12631",
           "Arabic, the primary language of the Arab world and the religious language of millions of non-Arab Muslims is somewhere in the middle of this continuum"
          ],
          [
           "2011.12631",
           "Though Arabic NLP has many challenges, it has seen many successes and developments"
          ],
          [
           "2011.12631",
           "Next we discuss Arabic's main challenges as a necessary background, and we present a brief history of Arabic NLP"
          ],
          [
           "2011.12631",
           "We then survey a number of its research areas, and close with a critical discussion of the future of Arabic NLP."
          ],
          [
           "1811.05121",
           "Recurrent Neural Networks (RNNs) have been widely used in processing natural language tasks and achieve huge success"
          ],
          [
           "1811.05121",
           "Traditional RNNs usually treat each token in a sentence uniformly and equally"
          ],
          [
           "1811.05121",
           "However, this may miss the rich semantic structure information of a sentence, which is useful for understanding natural languages"
          ],
          [
           "1811.05121",
           "Since semantic structures such as word dependence patterns are not parameterized, it is a challenge to capture and leverage structure information"
          ],
          [
           "1811.05121",
           "In this paper, we propose an improved variant of RNN, Multi-Channel RNN (MC-RNN), to dynamically capture and leverage local semantic structure information"
          ],
          [
           "1811.05121",
           "Concretely, MC-RNN contains multiple channels, each of which represents a local dependence pattern at a time"
          ],
          [
           "1811.05121",
           "An attention mechanism is introduced to combine these patterns at each step, according to the semantic information"
          ],
          [
           "1811.05121",
           "Then we parameterize structure information by adaptively selecting the most appropriate connection structures among channels"
          ],
          [
           "1811.05121",
           "In this way, diverse local structures and dependence patterns in sentences can be well captured by MC-RNN"
          ],
          [
           "1811.05121",
           "To verify the effectiveness of MC-RNN, we conduct extensive experiments on typical natural language processing tasks, including neural machine translation, abstractive summarization, and language modeling"
          ],
          [
           "1910.06720",
           "Word-embeddings are vital components of Natural Language Processing (NLP) models and have been extensively explored"
          ],
          [
           "1910.06720",
           "However, they consume a lot of memory which poses a challenge for edge deployment"
          ],
          [
           "1910.06720",
           "Embedding matrices, typically, contain most of the parameters for language models and about a third for machine translation systems"
          ],
          [
           "1910.06720",
           "In this paper, we propose Distilled Embedding, an (input/output) embedding compression method based on low-rank matrix decomposition and knowledge distillation"
          ],
          [
           "1910.06720",
           "First, we initialize the weights of our decomposed matrices by learning to reconstruct the full pre-trained word-embedding and then fine-tune end-to-end, employing knowledge distillation on the factorized embedding"
          ],
          [
           "1910.06720",
           "We conduct extensive experiments with various compression rates on machine translation and language modeling, using different data-sets with a shared word-embedding matrix for both embedding and vocabulary projection matrices"
          ],
          [
           "1910.06764",
           "Harnessing the transformer's ability to process long time horizons of information could provide a similar performance boost in partially observable reinforcement learning (RL) domains, but the large-scale transformers used in NLP have yet to be successfully applied to the RL setting"
          ],
          [
           "1910.06764",
           "GTrXL offers an easy-to-train, simple-to-implement but substantially more expressive architectural alternative to the standard multi-layer LSTM ubiquitously used for RL agents in partially observable environments."
          ],
          [
           "1906.11455",
           "Chinese word segmentation (CWS) is a fundamental step of Chinese natural language processing"
          ],
          [
           "1906.11455",
           "In this paper, we build a new toolkit, named PKUSEG, for multi-domain word segmentation"
          ],
          [
           "1906.11455",
           "Unlike existing single-model toolkits, PKUSEG targets multi-domain word segmentation and provides separate models for different domains, such as web, medicine, and tourism"
          ],
          [
           "1906.11455",
           "Besides, due to the lack of labeled data in many domains, we propose a domain adaptation paradigm to introduce cross-domain semantic knowledge via a translation system"
          ],
          [
           "1906.11455",
           "Through this method, we generate synthetic data using a large amount of unlabeled data in the target domain and then obtain a word segmentation model for the target domain"
          ],
          [
           "1906.11455",
           "We also further refine the performance of the default model with the help of synthetic data"
          ],
          [
           "1906.11455",
           "The new toolkit also supports POS tagging and model training to adapt to various application scenarios"
          ],
          [
           "1906.11455",
           "The toolkit is now freely and publicly available for the usage of research and industry."
          ],
          [
           "2211.15464",
           "Automatic sign language processing is gaining popularity in Natural Language Processing (NLP) research (Yin et al., 2021)"
          ],
          [
           "2211.15464",
           "In machine translation (MT) in particular, sign language translation based on glosses is a prominent approach"
          ],
          [
           "2211.15464",
           "In this paper, we review recent works on neural gloss translation"
          ],
          [
           "2211.15464",
           "To address these issues, we put forward concrete recommendations for future research on gloss translation"
          ],
          [
           "2211.15464",
           "Our suggestions advocate awareness of the inherent limitations of gloss-based approaches, realistic datasets, stronger baselines and convincing evaluation."
          ],
          [
           "2102.06991",
           "Hausa language belongs to the Afroasiatic phylum, and with more first-language speakers than any other sub-Saharan African language"
          ],
          [
           "2102.06991",
           "Hence, making it one of the most spoken Chadic language"
          ],
          [
           "2102.06991",
           "While Hausa is considered well-studied and documented language among the sub-Saharan African languages, it is viewed as a low resource language from the perspective of natural language processing (NLP) due to limited resources to utilise in NLP-related tasks"
          ],
          [
           "2102.06991",
           "While there exist useful datasets, notably from news sites and religious texts, more diversity is needed in the corpus"
          ],
          [
           "2102.06991",
           "We provide an expansive collection of curated datasets consisting of both formal and informal forms of the language from refutable websites and online social media networks, respectively"
          ],
          [
           "2102.06991",
           "The collection is large and more diverse than the existing corpora by providing the first and largest set of Hausa social media data posts to capture the peculiarities in the language"
          ],
          [
           "2102.06991",
           "The collection also consists of a parallel dataset, which can be used for tasks such as machine translation with applications in areas such as the detection of spurious or inciteful online content"
          ],
          [
           "2104.08721",
           "A popular natural language processing task decades ago, word alignment has been dominated until recently by GIZA++, a statistical method based on the 30-year-old IBM models"
          ],
          [
           "2104.08721",
           "We introduce Embedding-Enhanced GIZA++, and outperform GIZA++ without any of the aforementioned factors"
          ],
          [
           "2104.08721",
           "Taking advantage of monolingual embedding spaces of source and target language only, we exceed GIZA++'s performance in every tested scenario for three languages pairs"
          ],
          [
           "2104.08721",
           "In the lowest-resource setting, we outperform GIZA++ by 8.5, 10.9, and 12 AER for Ro-En, De-En, and En-Fr, respectively"
          ],
          [
           "2004.05001",
           "The rapid development of such natural language processing tasks as style transfer, paraphrase, and machine translation often calls for the use of semantic similarity metrics"
          ],
          [
           "2004.05001",
           "In recent years a lot of methods to measure the semantic similarity of two short texts were developed"
          ],
          [
           "2004.05001",
           "This paper provides a comprehensive analysis for more than a dozen of such methods"
          ],
          [
           "2004.05001",
           "A number of recently proposed metrics provide comparable results, yet Word Mover Distance is shown to be the most reasonable solution to measure semantic similarity in reformulated texts at the moment."
          ],
          [
           "2102.12895",
           "Transformer is a ubiquitous model for natural language processing and has attracted wide attentions in computer vision"
          ],
          [
           "2102.12895",
           "The attention maps are indispensable for a transformer model to encode the dependencies among input tokens"
          ],
          [
           "2102.12895",
           "However, they are learned independently in each layer and sometimes fail to capture precise patterns"
          ],
          [
           "2102.12895",
           "In this paper, we propose a novel and generic mechanism based on evolving attention to improve the performance of transformers"
          ],
          [
           "2102.12895",
           "On one hand, the attention maps in different layers share common knowledge, thus the ones in preceding layers can instruct the attention in succeeding layers through residual connections"
          ],
          [
           "2102.12895",
           "On the other hand, low-level and high-level attentions vary in the level of abstraction, so we adopt convolutional layers to model the evolutionary process of attention maps"
          ],
          [
           "2102.12895",
           "The proposed evolving attention mechanism achieves significant performance improvement over various state-of-the-art models for multiple tasks, including image classification, natural language understanding and machine translation."
          ],
          [
           "2006.04229",
           "Transformer-based language models are now widely used in Natural Language Processing (NLP)"
          ],
          [
           "2006.04229",
           "This statement is especially true for English language, in which many pre-trained models utilizing transformer-based architecture have been published in recent years"
          ],
          [
           "2006.04229",
           "This has driven forward the state of the art for a variety of standard NLP tasks such as classification, regression, and sequence labeling, as well as text-to-text tasks, such as machine translation, question answering, or summarization"
          ],
          [
           "2006.04229",
           "The situation have been different for low-resource languages, such as Polish, however"
          ],
          [
           "2006.04229",
           "Although some transformer-based language models for Polish are available, none of them have come close to the scale, in terms of corpus size and the number of parameters, of the largest English-language models"
          ],
          [
           "2006.04229",
           "In this study, we present two language models for Polish based on the popular BERT architecture"
          ],
          [
           "2006.04229",
           "The larger model was trained on a dataset consisting of over 1 billion polish sentences, or 135GB of raw text"
          ],
          [
           "2006.04229",
           "We describe our methodology for collecting the data, preparing the corpus, and pre-training the model"
          ],
          [
           "2006.04229",
           "We then evaluate our models on thirteen Polish linguistic tasks, and demonstrate improvements over previous approaches in eleven of them."
          ],
          [
           "1707.05438",
           "Pairwise ranking methods are the basis of many widely used discriminative training approaches for structure prediction problems in natural language processing(NLP)"
          ],
          [
           "1707.05438",
           "Decomposing the problem of ranking hypotheses into pairwise comparisons enables simple and efficient solutions"
          ],
          [
           "1707.05438",
           "However, neglecting the global ordering of the hypothesis list may hinder learning"
          ],
          [
           "1707.05438",
           "We propose a listwise learning framework for structure prediction problems such as machine translation"
          ],
          [
           "1707.05438",
           "Our framework directly models the entire translation list's ordering to learn parameters which may better fit the given listwise samples"
          ],
          [
           "1707.05438",
           "Furthermore, we propose top-rank enhanced loss functions, which are more sensitive to ranking errors at higher positions"
          ],
          [
           "2109.01411",
           "The Linked Open Data practice has led to a significant growth of structured data on the Web in the last decade"
          ],
          [
           "2109.01411",
           "Such structured data describe real-world entities in a machine-readable way, and have created an unprecedented opportunity for research in the field of Natural Language Processing"
          ],
          [
           "2109.01411",
           "However, there is a lack of studies on how such data can be used, for what kind of tasks, and to what extent they can be useful for these tasks"
          ],
          [
           "2109.01411",
           "Our evaluation on an extensive set of benchmarks shows word embeddings to be the most reliable and consistent method to improve the accuracy on both tasks (with up to 6.9 percentage points in macro-average F1 on some datasets)"
          ],
          [
           "2109.01411",
           "The other two methods however, are not as useful"
          ],
          [
           "2207.11680",
           "Pre-trained models have been shown effective in many code intelligence tasks"
          ],
          [
           "2207.11680",
           "These models are pre-trained on large-scale unlabeled corpus and then fine-tuned in downstream tasks"
          ],
          [
           "2207.11680",
           "However, as the inputs to pre-training and downstream tasks are in different forms, it is hard to fully explore the knowledge of pre-trained models"
          ],
          [
           "2207.11680",
           "Besides, the performance of fine-tuning strongly relies on the amount of downstream data, while in practice, the scenarios with scarce data are common"
          ],
          [
           "2207.11680",
           "In prompt tuning, the prompts inserted during tuning provide task-specific knowledge, which is especially beneficial for tasks with relatively scarce data"
          ],
          [
           "2207.11680",
           "In this paper, we empirically evaluate the usage and effect of prompt tuning in code intelligence tasks"
          ],
          [
           "2207.11680",
           "We conduct prompt tuning on popular pre-trained models CodeBERT and CodeT5 and experiment with three code intelligence tasks including defect prediction, code summarization, and code translation"
          ],
          [
           "2207.11680",
           "In addition, prompt tuning shows great potential in low-resource scenarios, e.g., improving the BLEU scores of fine-tuning by more than 26\\% on average for code summarization"
          ],
          [
           "2109.12104",
           "The current state of adoption of well-structured electronic health records and integration of digital methods for storing medical patient data in structured formats can often considered as inferior compared to the use of traditional, unstructured text based patient data documentation"
          ],
          [
           "2109.12104",
           "Data mining in the field of medical data analysis often needs to rely solely on processing of unstructured data to retrieve relevant data"
          ],
          [
           "2109.12104",
           "In natural language processing (NLP), statistical models have been shown successful in various tasks like part-of-speech tagging, relation extraction (RE) and named entity recognition (NER)"
          ],
          [
           "2109.12104",
           "In this work, we present GERNERMED, the first open, neural NLP model for NER tasks dedicated to detect medical entity types in German text data"
          ],
          [
           "2109.12104",
           "The sample code and the statistical model is available at: https://github.com/frankkramer-lab/GERNERMED"
          ],
          [
           "2210.06929",
           "Lately, methods have been developed to address the aforementioned challenges and present satisfactory explanations on Natural Language Processing (NLP) models"
          ],
          [
           "2210.06929",
           "However, such methods are yet to be studied in a comprehensive framework where common challenges are properly stated and rigorous evaluation practices and metrics are proposed"
          ],
          [
           "2210.06929",
           "Such methods can either develop inherently interpretable NLP models or operate on pre-trained models in a post-hoc manner"
          ],
          [
           "2210.06929",
           "We make this distinction and we further decompose the methods into three categories according to what they explain: (1) word embeddings (input-level), (2) inner workings of NLP models (processing-level) and (3) models' decisions (output-level)"
          ],
          [
           "2210.06929",
           "We also detail the different evaluation approaches interpretability methods in the NLP field"
          ],
          [
           "2210.06929",
           "Finally, we present a case-study on the well-known neural machine translation in an appendix and we propose promising future research directions for ExAI in the NLP field."
          ],
          [
           "1910.06411",
           "It is very challenging to work with low-resource languages due to the inadequate availability of data"
          ],
          [
           "1910.06411",
           "Using a dictionary to map independently trained word embeddings into a shared vector space has proved to be very useful in learning bilingual embeddings in the past"
          ],
          [
           "1910.06411",
           "Here we have tried to map individual embeddings of words in English and their corresponding translated words in low-resource languages like Estonian, Slovenian, Slovakian, and Hungarian"
          ],
          [
           "1910.06411",
           "We have used a supervised learning approach"
          ],
          [
           "1708.00993",
           "Linguistic resources such as part-of-speech (POS) tags have been extensively used in statistical machine translation (SMT) frameworks and have yielded better performances"
          ],
          [
           "1708.00993",
           "However, usage of such linguistic annotations in neural machine translation (NMT) systems has been left under-explored"
          ],
          [
           "1708.00993",
           "By jointly training several natural language processing (NLP) tasks in one system, we are able to leverage common information and improve the performance of the individual task"
          ],
          [
           "1708.00993",
           "We analyze the impact of three design decisions in multi-task learning: the tasks used in training, the training schedule, and the degree of parameter sharing across the tasks, which is defined by the network architecture"
          ],
          [
           "1708.00993",
           "The experiments are conducted for an German to English translation task"
          ],
          [
           "1708.00993",
           "As additional linguistic resources, we exploit POS information and named-entities (NE)"
          ],
          [
           "1708.00993",
           "The performance of the POS tagger is also improved using the multi-task learning scheme."
          ],
          [
           "1908.05672",
           "GPT-2 and BERT demonstrate the effectiveness of using pre-trained language models (LMs) on various natural language processing tasks"
          ],
          [
           "1908.05672",
           "However, LM fine-tuning often suffers from catastrophic forgetting when applied to resource-rich tasks"
          ],
          [
           "1908.05672",
           "Our experiments in machine translation show CTNMT gains of up to 3 BLEU score on the WMT14 English-German language pair which even surpasses the previous state-of-the-art pre-training aided NMT by 1.4 BLEU score"
          ],
          [
           "1908.05672",
           "While for the large WMT14 English-French task with 40 millions of sentence-pairs, our base model still significantly improves upon the state-of-the-art Transformer big model by more than 1 BLEU score"
          ],
          [
           "1908.05672",
           "The code and model can be downloaded from https://github.com/bytedance/neurst/ tree/master/examples/ctnmt."
          ],
          [
           "2102.00881",
           "Learning idiomatic expressions is seen as one of the most challenging stages in second language learning because of their unpredictable meaning"
          ],
          [
           "2102.00881",
           "A similar situation holds for their identification within natural language processing applications such as machine translation and parsing"
          ],
          [
           "2102.00881",
           "The lack of high-quality usage samples exacerbates this challenge not only for humans but also for artificial intelligence systems"
          ],
          [
           "2102.00881",
           "This article introduces a gamified crowdsourcing approach for collecting language learning materials for idiomatic expressions; a messaging bot is designed as an asynchronous multiplayer game for native speakers who compete with each other while providing idiomatic and nonidiomatic usage examples and rating other players' entries"
          ],
          [
           "2102.00881",
           "As opposed to classical crowdprocessing annotation efforts in the field, for the first time in the literature, a crowdcreating & crowdrating approach is implemented and tested for idiom corpora construction"
          ],
          [
           "2102.00881",
           "The approach is language independent and evaluated on two languages in comparison to traditional data preparation techniques in the field"
          ],
          [
           "2102.00881",
           "The reaction of the crowd is monitored under different motivational means (namely, gamification affordances and monetary rewards)"
          ],
          [
           "2102.00881",
           "The approach has been shown to have the potential to speed up the construction of idiom corpora for different natural languages to be used as second language learning material, training data for supervised idiom identification systems, or samples for lexicographic studies."
          ],
          [
           "2208.07832",
           "Multiword expressions (MWEs) present groups of words in which the meaning of the whole is not derived from the meaning of its parts"
          ],
          [
           "2208.07832",
           "The task of processing MWEs is crucial in many natural language processing (NLP) applications, including machine translation and terminology extraction"
          ],
          [
           "2208.07832",
           "Therefore, detecting MWEs is a popular research theme"
          ],
          [
           "2208.07832",
           "In this paper, we explore state-of-the-art neural transformers in the task of detecting MWEs.We empirically evaluate several transformer models in the dataset for SemEval-2016 Task 10: Detecting Minimal Semantic Units and their Meanings (DiMSUM)"
          ],
          [
           "2208.07832",
           "The code and pre-trained model will be made freely available to the community."
          ],
          [
           "2208.14923",
           "Recently, deep learning has achieved state-of-the-art performance in many clinical NLP tasks"
          ],
          [
           "2208.14923",
           "However, training deep learning models usually requires large annotated datasets, which are normally not publicly available and can be time-consuming to build in clinical domains"
          ],
          [
           "2208.14923",
           "A widely adopted approach is fine-tuning existing Pre-trained Language Models (PLMs), but these attempts fall short when the training dataset contains only a few annotated samples"
          ],
          [
           "2208.14923",
           "Few-Shot Learning (FSL) has recently been investigated to tackle this problem"
          ],
          [
           "2208.14923",
           "Siamese Neural Network (SNN) has been widely utilized as an FSL approach in computer vision, but has not been studied well in NLP"
          ],
          [
           "2208.14923",
           "Furthermore, the literature on its applications in clinical domains is scarce"
          ],
          [
           "2208.14923",
           "In this paper, we propose two SNN-based FSL approaches for clinical NLP, including Pre-Trained SNN (PT-SNN) and SNN with Second-Order Embeddings (SOE-SNN)"
          ],
          [
           "2208.14923",
           "We evaluated the proposed approaches on two clinical tasks, namely clinical text classification and clinical named entity recognition"
          ],
          [
           "2208.14923",
           "We tested three few-shot settings including 4-shot, 8-shot, and 16-shot learning"
          ],
          [
           "2208.14923",
           "Both clinical NLP tasks were benchmarked using three PLMs, including BERT,BioBERT, and BioClinicalBERT"
          ],
          [
           "2212.08330",
           "Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis"
          ],
          [
           "2212.08330",
           "In all kinds of attention networks, the attention maps are crucial as they encode semantic dependencies between input tokens"
          ],
          [
           "2212.08330",
           "However, most existing attention networks perform modeling or reasoning based on representations, wherein the attention maps of different layers are learned separately without explicit interactions"
          ],
          [
           "2212.08330",
           "In this paper, we propose a novel and generic evolving attention mechanism, which directly models the evolution of inter-token relationships through a chain of residual convolutional modules"
          ],
          [
           "2212.08330",
           "The major motivations are twofold"
          ],
          [
           "2212.08330",
           "On the one hand, the attention maps in different layers share transferable knowledge, thus adding a residual connection can facilitate the information flow of inter-token relationships across layers"
          ],
          [
           "2212.08330",
           "On the other hand, there is naturally an evolutionary trend among attention maps at different abstraction levels, so it is beneficial to exploit a dedicated convolution-based module to capture this process"
          ],
          [
           "2212.08330",
           "Equipped with the proposed mechanism, the convolution-enhanced evolving attention networks achieve superior performance in various applications, including time-series representation, natural language understanding, machine translation, and image classification"
          ],
          [
           "2212.08330",
           "Especially on time-series representation tasks, Evolving Attention-enhanced Dilated Convolutional (EA-DC-) Transformer outperforms state-of-the-art models significantly, achieving an average of 17% improvement compared to the best SOTA"
          ],
          [
           "2212.08330",
           "Our implementation is available at https://github.com/pkuyym/EvolvingAttention"
          ],
          [
           "2009.02016",
           "Multimodal machine translation (MMT), which mainly focuses on enhancing text-only translation with visual features, has attracted considerable attention from both computer vision and natural language processing communities"
          ],
          [
           "2009.02016",
           "Most current MMT models resort to attention mechanism, global context modeling or multimodal joint representation learning to utilize visual features"
          ],
          [
           "2009.02016",
           "However, the attention mechanism lacks sufficient semantic interactions between modalities while the other two provide fixed visual context, which is unsuitable for modeling the observed variability when generating translation"
          ],
          [
           "2009.02016",
           "To address the above issues, in this paper, we propose a novel Dynamic Context-guided Capsule Network (DCCN) for MMT"
          ],
          [
           "2009.02016",
           "Specifically, at each timestep of decoding, we first employ the conventional source-target attention to produce a timestep-specific source-side context vector"
          ],
          [
           "2009.02016",
           "Next, DCCN takes this vector as input and uses it to guide the iterative extraction of related visual features via a context-guided dynamic routing mechanism"
          ],
          [
           "2009.02016",
           "Particularly, we represent the input image with global and regional visual features, we introduce two parallel DCCNs to model multimodal context vectors with visual features at different granularities"
          ],
          [
           "2009.02016",
           "Finally, we obtain two multimodal context vectors, which are fused and incorporated into the decoder for the prediction of the target word"
          ],
          [
           "2009.02016",
           "Our code is available on https://github.com/DeepLearnXMU/MM-DCCN."
          ],
          [
           "2103.03457",
           "With sequentially stacked self-attention, (optional) encoder-decoder attention, and feed-forward layers, Transformer achieves big success in natural language processing (NLP), and many variants have been proposed"
          ],
          [
           "2103.03457",
           "Based on this observation, in this work, we break the assumption of the fixed layer order in the Transformer and introduce instance-wise layer reordering into the model structure"
          ],
          [
           "2103.03457",
           "Our Instance-wise Ordered Transformer (IOT) can model variant functions by reordered layers, which enables each sample to select the better one to improve the model performance under the constraint of almost the same number of parameters"
          ],
          [
           "2103.03457",
           "To achieve this, we introduce a light predictor with negligible parameter and inference cost to decide the most capable and favorable layer order for any input sequence"
          ],
          [
           "2103.03457",
           "Experiments on 3 tasks (neural machine translation, abstractive summarization, and code generation) and 9 datasets demonstrate consistent improvements of our method"
          ],
          [
           "2103.03457",
           "Our code is released at Github."
          ],
          [
           "1807.02911",
           "Deep neural networks have shown good data modelling capabilities when dealing with challenging and large datasets from a wide range of application areas"
          ],
          [
           "1807.02911",
           "Convolutional Neural Networks (CNNs) offer advantages in selecting good features and Long Short-Term Memory (LSTM) networks have proven good abilities of learning sequential data"
          ],
          [
           "1807.02911",
           "Sentiment classification for short text messages from Twitter is a challenging task, and the complexity increases for Arabic language sentiment classification tasks because Arabic is a rich language in morphology"
          ],
          [
           "1807.02911",
           "In addition, the availability of accurate pre-processing tools for Arabic is another current limitation, along with limited research available in this area"
          ],
          [
           "1807.02911",
           "In this paper, we investigate the benefits of integrating CNNs and LSTMs and report obtained improved accuracy for Arabic sentiment analysis on different datasets"
          ],
          [
           "1807.02911",
           "Additionally, we seek to consider the morphological diversity of particular Arabic words by using different sentiment classification levels."
          ],
          [
           "2005.00333",
           "In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects"
          ],
          [
           "2005.00333",
           "Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences"
          ],
          [
           "2005.00333",
           "Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks"
          ],
          [
           "2005.00333",
           "Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apur\\'imac Quechua and Haitian Creole"
          ],
          [
           "2005.00333",
           "Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline"
          ],
          [
           "2005.00333",
           "The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa."
          ],
          [
           "2111.14706",
           "As Automatic Speech Processing (ASR) systems are getting better, there is an increasing interest of using the ASR output to do downstream Natural Language Processing (NLP) tasks"
          ],
          [
           "2111.14706",
           "We present ESPnet-SLU, which is designed for quick development of spoken language understanding in a single framework"
          ],
          [
           "2111.14706",
           "ESPnet-SLU is a project inside end-to-end speech processing toolkit, ESPnet, which is a widely used open-source standard for various speech processing tasks like ASR, Text to Speech (TTS) and Speech Translation (ST)"
          ],
          [
           "2111.14706",
           "The toolkit is publicly available at https://github.com/espnet/espnet."
          ],
          [
           "1911.07613",
           "Language models are at the core of natural language processing"
          ],
          [
           "1911.07613",
           "The ability to represent natural language gives rise to its applications in numerous NLP tasks including text classification, summarization, and translation"
          ],
          [
           "1911.07613",
           "Research in this area is very limited in Bangla due to the scarcity of resources, except for some count-based models and very recent neural language models being proposed, which are all based on words and limited in practical tasks due to their high perplexity"
          ],
          [
           "1911.07613",
           "This paper attempts to approach this issue of perplexity and proposes a subword level neural language model with the AWD-LSTM architecture and various other techniques suitable for training in Bangla language"
          ],
          [
           "1911.07613",
           "The model is trained on a corpus of Bangla newspaper articles of an appreciable size consisting of more than 28.5 million word tokens"
          ],
          [
           "1911.07613",
           "The performance comparison with various other models depicts the significant reduction in perplexity the proposed model provides, reaching as low as 39.84, in just 20 epochs."
          ],
          [
           "1604.04661",
           "Word2Vec is a widely used algorithm for extracting low-dimensional vector representations of words"
          ],
          [
           "1604.04661",
           "It generated considerable excitement in the machine learning and natural language processing (NLP) communities recently due to its exceptional performance in many NLP applications such as named entity recognition, sentiment analysis, machine translation and question answering"
          ],
          [
           "1604.04661",
           "State-of-the-art algorithms including those by Mikolov et al"
          ],
          [
           "1604.04661",
           "In this paper, we improve reuse of various data structures in the algorithm through the use of minibatching, hence allowing us to express the problem using matrix multiply operations"
          ],
          [
           "1604.04661",
           "We also explore different techniques to distribute word2vec computation across nodes in a compute cluster, and demonstrate good strong scalability up to 32 nodes"
          ],
          [
           "1604.04661",
           "In combination, these techniques allow us to scale up the computation near linearly across cores and nodes, and process hundreds of millions of words per second, which is the fastest word2vec implementation to the best of our knowledge."
          ],
          [
           "1807.03756",
           "Neural attention has become central to many state-of-the-art models in natural language processing and related domains"
          ],
          [
           "1807.03756",
           "Attention networks are an easy-to-train and effective method for softly simulating alignment; however, the approach does not marginalize over latent alignments in a probabilistic sense"
          ],
          [
           "1807.03756",
           "This property makes it difficult to compare attention to other alignment approaches, to compose it with probabilistic models, and to perform posterior inference conditioned on observed data"
          ],
          [
           "1807.03756",
           "A related latent approach, hard attention, fixes these issues, but is generally harder to train and less accurate"
          ],
          [
           "1807.03756",
           "This work considers variational attention networks, alternatives to soft and hard attention for learning latent variable alignment models, with tighter approximation bounds based on amortized variational inference"
          ],
          [
           "1807.03756",
           "We further propose methods for reducing the variance of gradients to make these approaches computationally feasible"
          ],
          [
           "1807.03756",
           "On the other hand, variational attention retains most of the performance gain but with training speed comparable to neural attention."
          ]
         ],
         "hovertemplate": "type=Academic<br>x=%{x}<br>y=%{y}<br>article_id=%{customdata[0]}<br>claim=%{customdata[1]}<extra></extra>",
         "legendgroup": "Academic",
         "marker": {
          "color": "#4ECDC4",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Academic",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          9.70711898803711,
          -12.329882621765137,
          3.6693341732025146,
          -12.866667747497559,
          15.278000831604004,
          -10.356847763061523,
          21.74081802368164,
          -27.141845703125,
          24.26504135131836,
          6.669437885284424,
          24.056224822998047,
          22.554061889648438,
          15.440621376037598,
          -32.40843963623047,
          15.746045112609863,
          15.358753204345703,
          11.022364616394043,
          -6.261938571929932,
          -1.2896156311035156,
          -2.3183155059814453,
          -2.836019992828369,
          -1.8380519151687622,
          4.812203884124756,
          1.5525708198547363,
          -34.73582458496094,
          24.189359664916992,
          35.30778121948242,
          35.52320098876953,
          34.583290100097656,
          5.5504279136657715,
          8.750428199768066,
          -17.248552322387695,
          8.49305534362793,
          -8.701873779296875,
          -9.454090118408203,
          -10.189107894897461,
          -9.877464294433594,
          -8.045560836791992,
          17.212858200073242,
          17.223831176757812,
          -32.68883514404297,
          0.27263447642326355,
          19.090444564819336,
          6.408815860748291,
          22.7149658203125,
          17.52277374267578,
          -6.244335651397705,
          -3.013496160507202,
          -3.4978954792022705,
          -26.24127769470215,
          -4.249098777770996,
          13.376471519470215,
          17.21623992919922,
          12.300837516784668,
          9.91712474822998,
          -7.555957317352295,
          20.071998596191406,
          19.9382266998291,
          17.18630027770996,
          18.030330657958984,
          -34.89451217651367,
          7.349042892456055,
          -2.3672077655792236,
          16.73699951171875,
          16.158693313598633,
          16.784000396728516,
          17.863367080688477,
          -12.71638298034668,
          -10.43924331665039,
          -13.71613597869873,
          -13.461849212646484,
          -27.08458709716797,
          23.369787216186523,
          11.835076332092285,
          -7.3294854164123535,
          1.857577919960022,
          1.1372559070587158,
          0.9131654500961304,
          4.428346633911133,
          -4.212998390197754,
          -4.59735107421875,
          -21.03163719177246,
          -5.04109525680542,
          -6.038520336151123,
          -5.003470420837402,
          -13.551709175109863,
          -21.063547134399414,
          -33.30474853515625,
          13.353734016418457,
          13.562764167785645,
          13.996197700500488,
          23.010900497436523,
          13.713500022888184,
          -1.8525311946868896,
          12.706786155700684,
          -25.12186050415039,
          14.11982536315918,
          21.545499801635742,
          22.90467643737793,
          21.06195068359375,
          35.792945861816406,
          35.805442810058594,
          21.499980926513672,
          -35.772281646728516,
          23.871017456054688,
          -27.702720642089844,
          -27.41708755493164,
          -25.544668197631836,
          -28.389055252075195,
          -28.939348220825195,
          2.8774871826171875,
          -28.175378799438477,
          5.148015022277832,
          8.67692756652832,
          -5.481811046600342,
          22.378049850463867,
          22.44158172607422,
          8.750688552856445,
          -3.499927043914795,
          -14.754901885986328,
          1.3742303848266602,
          -2.3302836418151855,
          0.3111971914768219,
          -14.76291561126709,
          4.073898792266846,
          -0.2407153993844986,
          0.03228658810257912,
          1.4013127088546753,
          -4.167940139770508,
          -3.880963087081909,
          -5.259296894073486,
          -3.328244209289551,
          -6.830283164978027,
          -13.398730278015137,
          -15.313860893249512,
          22.037755966186523,
          7.105424404144287,
          -21.063610076904297,
          -21.259557723999023,
          -16.411762237548828,
          -3.4103713035583496,
          21.226959228515625,
          22.378835678100586,
          -21.48040199279785,
          22.438232421875,
          -3.6530072689056396,
          -10.892454147338867,
          26.598649978637695,
          -14.655494689941406,
          -12.888703346252441,
          -12.860499382019043,
          -0.6579283475875854,
          10.227685928344727,
          -1.81801438331604,
          9.872213363647461,
          -13.092133522033691,
          17.833505630493164,
          -14.814194679260254,
          -13.106523513793945,
          10.177618026733398,
          -2.3452935218811035,
          -2.3481967449188232,
          -0.897741436958313,
          39.78379821777344,
          13.073426246643066,
          38.867095947265625,
          39.06390380859375,
          5.520115375518799,
          39.29798126220703,
          -24.807884216308594,
          -2.0061795711517334,
          -0.9479080438613892,
          -1.6397745609283447,
          0.008905045688152313,
          -15.605415344238281,
          -22.033267974853516,
          -18.113330841064453,
          -19.069583892822266,
          -20.4434757232666,
          -4.885540962219238,
          -22.190446853637695,
          -20.906543731689453,
          25.031278610229492,
          22.49140167236328,
          19.615034103393555,
          18.65983009338379,
          18.558687210083008,
          11.83627700805664,
          -0.9401378035545349,
          -0.5548696517944336,
          -18.550235748291016,
          -12.32257080078125,
          -1.2023687362670898,
          7.268763065338135,
          27.103534698486328,
          13.617727279663086,
          6.193452835083008,
          -24.44335174560547,
          -31.253665924072266,
          -37.934627532958984,
          -38.010520935058594,
          33.46122360229492,
          11.594460487365723,
          -10.662278175354004,
          -2.2873787879943848,
          -1.9106730222702026,
          -3.2272889614105225,
          -3.6564197540283203,
          -3.303185224533081,
          -9.274599075317383,
          -3.603177785873413,
          18.703903198242188,
          18.623878479003906,
          7.788662910461426,
          9.309667587280273,
          25.80004119873047,
          26.12461280822754,
          23.35460662841797,
          20.851022720336914,
          26.71489715576172,
          30.416017532348633,
          -37.78071975708008,
          -13.342565536499023,
          -13.54389762878418,
          -21.248149871826172,
          -22.06907081604004,
          -23.40198516845703,
          -21.11288833618164,
          18.257171630859375,
          -2.5072267055511475,
          10.46231460571289,
          -13.925134658813477,
          10.7393798828125,
          -3.4175169467926025,
          -6.912121295928955,
          -7.785125732421875,
          -8.342840194702148,
          -8.726688385009766,
          9.377635955810547,
          -30.122896194458008,
          -20.328828811645508,
          -19.358518600463867,
          -29.852596282958984,
          -31.573549270629883,
          -30.574087142944336,
          -29.854124069213867,
          -30.631778717041016,
          -38.73805236816406,
          10.428915023803711,
          10.775304794311523,
          -17.82741355895996,
          10.454102516174316,
          -17.174306869506836,
          -0.3571782410144806,
          7.9301676750183105,
          12.925447463989258,
          6.370649337768555,
          9.927502632141113,
          10.517927169799805,
          5.893328666687012,
          -1.1606701612472534,
          6.382835388183594,
          -34.96005630493164,
          -36.407012939453125,
          11.318778991699219,
          -33.13500213623047,
          -34.04975891113281,
          -33.45455551147461,
          -33.4395866394043,
          -24.751665115356445,
          -32.96103286743164,
          -35.440059661865234,
          17.97428321838379,
          -6.5362229347229,
          5.0656914710998535,
          -7.099708557128906,
          -11.837471961975098,
          -12.954157829284668,
          -11.601339340209961,
          -10.672754287719727,
          -11.41688346862793,
          -13.518186569213867,
          -4.573272228240967,
          13.556280136108398,
          -26.366926193237305,
          -34.63423538208008,
          -4.752768516540527,
          -25.08255386352539,
          -8.294260025024414,
          -8.68845272064209,
          9.314637184143066,
          -24.465024948120117,
          -18.863861083984375,
          -20.326969146728516,
          -20.401981353759766,
          0.9977777004241943,
          -23.62887954711914,
          -39.091102600097656,
          9.411093711853027,
          8.408452033996582,
          7.360111713409424,
          7.629140377044678,
          7.275750160217285,
          -0.3094097673892975,
          4.407002925872803,
          -0.4205333888530731,
          -0.6267181038856506,
          -7.49629545211792,
          1.6684927940368652,
          14.771716117858887,
          -11.710865020751953,
          -12.447099685668945,
          -13.25404167175293,
          -11.027335166931152,
          22.943634033203125,
          -16.095680236816406,
          -24.226917266845703,
          13.278196334838867,
          1.5498675107955933,
          -31.24648094177246,
          1.6329389810562134,
          0.2686237692832947,
          1.720914363861084,
          1.1058135032653809,
          -2.5540874004364014,
          -2.0394630432128906,
          -5.854480743408203,
          9.51996898651123,
          5.505842208862305,
          -29.389551162719727,
          7.011953830718994,
          9.44497299194336,
          8.379338264465332,
          12.03273868560791,
          9.972161293029785,
          -14.032273292541504,
          20.82989501953125,
          30.018709182739258,
          29.682310104370117,
          29.676166534423828,
          29.161680221557617,
          29.668312072753906,
          30.475601196289062,
          13.824755668640137,
          -32.79218292236328,
          -31.02073860168457,
          -32.8472785949707,
          -32.70534133911133,
          5.170382499694824,
          29.849899291992188,
          7.8123955726623535,
          4.1718430519104,
          -3.1682910919189453,
          8.306441307067871,
          8.999791145324707,
          -12.00009536743164,
          0.18879444897174835,
          0.2407192438840866,
          10.28409481048584,
          -10.036113739013672,
          -13.108026504516602,
          -11.957123756408691,
          -13.22514820098877,
          -14.488842010498047,
          -32.01983642578125,
          11.40186595916748,
          -8.4560546875,
          -10.898088455200195,
          7.406129837036133,
          -7.779228687286377,
          -7.687355041503906,
          -11.138477325439453,
          -6.126134395599365,
          -23.493038177490234,
          -3.340080976486206,
          -36.061702728271484,
          -39.546409606933594,
          -20.951547622680664,
          -19.990819931030273,
          -20.2398624420166,
          -10.014202117919922,
          -23.04140853881836,
          -21.47637176513672,
          2.3314380645751953,
          -0.3650067448616028,
          -1.7230725288391113,
          2.8095293045043945,
          1.9372460842132568,
          3.748446464538574,
          -20.53191375732422,
          -21.48102569580078,
          -17.60472297668457,
          13.918242454528809,
          10.683783531188965,
          28.935590744018555,
          25.716753005981445,
          -9.174574851989746,
          23.11321449279785,
          -9.409232139587402,
          -8.016003608703613,
          23.196903228759766,
          23.120967864990234,
          -6.2300872802734375,
          21.784835815429688,
          29.705936431884766,
          12.655289649963379,
          -5.4977126121521,
          23.10807991027832,
          4.410068511962891,
          10.057254791259766,
          -5.818478584289551,
          11.030499458312988,
          9.842733383178711,
          1.574708342552185,
          -32.45435333251953,
          -32.93807601928711,
          -18.528955459594727,
          4.898919105529785,
          -34.029911041259766,
          -10.605128288269043,
          -9.877992630004883,
          -8.987359046936035,
          -5.445130348205566,
          -11.25825023651123,
          23.47321128845215,
          5.556469440460205,
          2.0808701515197754,
          16.846813201904297,
          27.455720901489258,
          25.40001678466797,
          27.72049331665039,
          -7.32971715927124,
          -8.483457565307617,
          -10.79584789276123,
          -11.49853515625,
          -19.067092895507812,
          -19.148618698120117,
          -34.05001449584961,
          -32.126949310302734,
          31.469276428222656,
          3.6632471084594727,
          7.886993885040283,
          30.94766616821289,
          13.703500747680664,
          13.84260368347168,
          -7.98928165435791,
          4.968817234039307,
          -42.692718505859375,
          -6.8575439453125,
          7.0243330001831055,
          7.0304484367370605,
          6.991891860961914,
          26.307100296020508,
          8.591379165649414,
          19.6278076171875,
          -0.7019379138946533,
          -22.58612632751465,
          7.082006931304932,
          19.704421997070312,
          33.65612030029297,
          20.474193572998047,
          15.936311721801758,
          24.272493362426758,
          -19.18228530883789,
          20.469160079956055,
          14.566686630249023,
          23.92697525024414,
          23.49817657470703,
          -16.030778884887695,
          1.60084068775177,
          24.615888595581055,
          24.147029876708984,
          20.525165557861328,
          34.029518127441406,
          33.93743896484375,
          34.542762756347656,
          34.9586067199707,
          33.82966995239258,
          33.922664642333984,
          33.39107894897461,
          32.89790344238281,
          34.01738739013672,
          -4.9840087890625,
          -4.175633430480957,
          13.048741340637207,
          19.015357971191406,
          28.464149475097656,
          29.30574607849121,
          12.40805721282959,
          -7.493500709533691,
          -27.541501998901367,
          11.961240768432617,
          4.099066734313965,
          -3.509502410888672,
          -4.4794840812683105,
          -3.4893124103546143,
          3.3919076919555664,
          -15.154354095458984,
          -15.436666488647461,
          -14.549703598022461,
          -15.584174156188965,
          -16.06690216064453,
          -14.15958023071289,
          -17.848087310791016,
          -18.923925399780273,
          -33.83858108520508,
          12.8012056350708,
          13.71985912322998,
          14.554369926452637,
          14.753838539123535,
          13.530552864074707,
          15.046971321105957,
          15.007253646850586,
          9.85768985748291,
          8.482915878295898,
          7.517251491546631,
          7.251968860626221,
          7.4038872718811035,
          11.595824241638184,
          -19.647987365722656,
          4.843209743499756,
          -23.940216064453125,
          11.87757682800293,
          -19.858612060546875,
          -23.707828521728516,
          -9.95162296295166,
          -26.633943557739258,
          -28.744951248168945,
          -28.414180755615234,
          -28.1079158782959,
          -27.129606246948242,
          13.740151405334473,
          29.343191146850586,
          14.829607009887695,
          12.599546432495117,
          13.384544372558594,
          -1.7292009592056274,
          6.064056873321533,
          -16.27170753479004,
          -6.724878311157227,
          -7.392013072967529,
          8.933801651000977,
          8.26653003692627,
          10.058089256286621,
          -3.208831787109375,
          -1.8064385652542114,
          -0.7737030982971191,
          -0.21566015481948853,
          -0.003702918067574501,
          5.340841770172119,
          2.819889783859253,
          26.035301208496094,
          25.863759994506836,
          4.682074546813965,
          3.942706823348999,
          -1.3681809902191162,
          -15.52866268157959,
          4.220241069793701,
          3.6416826248168945,
          20.97323989868164,
          -19.88178253173828,
          21.3082275390625,
          23.123626708984375,
          22.98234748840332,
          21.318950653076172,
          8.600295066833496,
          7.44895601272583,
          28.13649559020996,
          30.91195297241211,
          31.065216064453125,
          1.6209789514541626,
          30.54990005493164,
          -19.614116668701172,
          -19.258268356323242,
          -33.292503356933594,
          -2.265880584716797,
          -3.8665146827697754,
          -21.389970779418945,
          -21.88068199157715,
          -22.750289916992188,
          -13.492074012756348,
          -13.940956115722656,
          -13.374767303466797,
          4.4136810302734375,
          5.781484603881836,
          4.792238712310791,
          -6.3729352951049805,
          18.155080795288086,
          -17.308719635009766,
          -17.032400131225586,
          -18.235076904296875,
          31.483152389526367,
          32.02936935424805,
          -31.90483856201172,
          32.27302551269531,
          9.747053146362305,
          4.380949974060059,
          -8.64155101776123,
          10.939360618591309,
          1.3329846858978271,
          1.87667715549469,
          0.8330535292625427,
          15.282387733459473,
          7.910061836242676,
          14.205545425415039,
          -12.144277572631836,
          1.9544445276260376,
          2.7208054065704346,
          8.117359161376953,
          5.997294902801514,
          2.246966600418091,
          17.724864959716797,
          -32.45892333984375,
          -32.98649978637695,
          -6.512516498565674,
          -6.779985427856445,
          -30.97381019592285,
          27.75178337097168,
          21.147998809814453,
          -28.916030883789062,
          21.18039321899414,
          -32.06452560424805,
          -23.81542205810547,
          6.075603008270264,
          -6.0778374671936035,
          -20.10629653930664,
          -26.235349655151367,
          -25.300853729248047,
          -24.293102264404297,
          -25.729644775390625,
          28.89028549194336,
          29.950550079345703,
          16.049076080322266,
          17.166303634643555,
          -35.601375579833984,
          14.385273933410645,
          -29.921674728393555,
          11.16576862335205,
          18.537561416625977,
          16.819679260253906,
          -0.4040614068508148,
          -12.97524356842041,
          -3.6716740131378174,
          -8.656731605529785,
          -7.382949352264404,
          -2.0377397537231445,
          -1.607516884803772,
          16.2222843170166,
          -11.303145408630371,
          -17.341691970825195,
          19.684551239013672,
          -19.211505889892578,
          7.867849826812744,
          -11.44753360748291,
          -2.5263049602508545,
          13.58851432800293,
          -36.745548248291016,
          22.9240665435791,
          15.645214080810547,
          -29.121702194213867,
          21.9172306060791,
          22.135026931762695,
          -2.551248073577881,
          -40.41398620605469,
          22.724287033081055,
          22.55020523071289,
          15.441052436828613,
          -32.403297424316406,
          12.775097846984863,
          -35.329063415527344,
          13.941370010375977,
          11.701202392578125,
          4.098250865936279,
          -8.000577926635742,
          15.088603019714355,
          30.955768585205078,
          14.909667015075684,
          29.25848960876465,
          -7.982297420501709,
          27.990724563598633,
          4.620987892150879,
          3.4382646083831787,
          2.095370054244995,
          2.485788106918335,
          -39.970455169677734,
          1.075221061706543,
          1.8091074228286743,
          1.09988534450531,
          9.629629135131836,
          -40.480438232421875,
          -11.806009292602539,
          -0.9205849766731262,
          -0.8045971989631653,
          -3.215444326400757,
          5.47742223739624,
          -1.9494297504425049,
          -1.3475836515426636,
          24.38077735900879,
          -37.406829833984375,
          9.09771728515625,
          11.07622241973877,
          11.066360473632812,
          -16.81458854675293,
          1.2458842992782593,
          -36.8724479675293,
          -6.330174922943115,
          2.7904648780822754,
          1.9336552619934082,
          -1.6251153945922852,
          25.06407928466797,
          2.0398852825164795,
          13.512224197387695,
          -7.855302810668945,
          -7.053880214691162,
          -7.804227828979492,
          -9.98587703704834,
          -33.92524719238281,
          12.376667022705078,
          -15.677154541015625,
          -15.713844299316406,
          -32.40275192260742,
          13.10162353515625,
          13.82822322845459,
          5.743014335632324,
          5.422893047332764,
          9.034722328186035,
          -21.45197105407715,
          25.767833709716797,
          11.971687316894531,
          -31.568262100219727,
          -31.63225555419922,
          28.287830352783203,
          28.15760040283203,
          3.345444917678833,
          1.8764863014221191,
          2.013834238052368,
          0.024463707581162453,
          1.7968791723251343,
          -24.309595108032227,
          -1.1336077451705933
         ],
         "xaxis": "x",
         "y": [
          -19.85755729675293,
          -36.48089599609375,
          -32.122398376464844,
          -36.333229064941406,
          -23.15525245666504,
          -37.19979476928711,
          13.366740226745605,
          18.985204696655273,
          -24.243370056152344,
          -24.758392333984375,
          -23.835702896118164,
          28.769201278686523,
          18.93950080871582,
          22.820932388305664,
          -35.65500259399414,
          -35.87558364868164,
          -26.772676467895508,
          23.665119171142578,
          8.952685356140137,
          21.892179489135742,
          19.74724578857422,
          20.309484481811523,
          -11.158761024475098,
          -11.33987045288086,
          -21.389997482299805,
          -3.9713408946990967,
          -9.970420837402344,
          -9.923243522644043,
          -9.98641300201416,
          -9.030572891235352,
          5.700386047363281,
          -29.157848358154297,
          -4.741227626800537,
          3.0843894481658936,
          6.051470756530762,
          5.792177200317383,
          2.7962870597839355,
          3.0373446941375732,
          26.253854751586914,
          26.474430084228516,
          -21.750417709350586,
          18.510297775268555,
          -8.630009651184082,
          3.165618419647217,
          2.2041704654693604,
          12.165671348571777,
          -20.590391159057617,
          -24.073911666870117,
          -23.78142738342285,
          -28.582548141479492,
          -17.14671516418457,
          -4.236464023590088,
          1.9803916215896606,
          1.8388612270355225,
          1.470310091972351,
          18.249576568603516,
          23.95592498779297,
          23.877979278564453,
          21.56072235107422,
          22.42738914489746,
          -21.1926326751709,
          7.300357818603516,
          3.068732500076294,
          -15.746440887451172,
          -16.0640811920166,
          -15.078438758850098,
          -16.071306228637695,
          -5.872838020324707,
          -12.102351188659668,
          -3.4433324337005615,
          -3.2430386543273926,
          -18.906892776489258,
          33.01900100708008,
          18.068525314331055,
          12.719879150390625,
          36.44965362548828,
          37.33881759643555,
          37.651092529296875,
          11.178739547729492,
          -0.2618008852005005,
          -0.20308610796928406,
          -16.906776428222656,
          8.985318183898926,
          -5.7394304275512695,
          -1.167275071144104,
          -24.48318862915039,
          -16.89010238647461,
          -7.043973445892334,
          -5.967872619628906,
          23.03007698059082,
          25.301380157470703,
          13.329997062683105,
          26.090259552001953,
          13.370508193969727,
          22.3880615234375,
          -29.705238342285156,
          23.61660385131836,
          16.422693252563477,
          16.589237213134766,
          17.707942962646484,
          11.628683090209961,
          11.6167573928833,
          16.38224983215332,
          1.4424693584442139,
          16.378360748291016,
          26.91098403930664,
          26.891254425048828,
          26.405654907226562,
          27.643632888793945,
          27.5920467376709,
          -25.428945541381836,
          14.731295585632324,
          -13.028266906738281,
          24.516695022583008,
          22.937177658081055,
          19.860366821289062,
          19.527631759643555,
          24.5544490814209,
          12.187769889831543,
          -36.3541374206543,
          -28.005935668945312,
          -32.73429489135742,
          -29.007057189941406,
          -36.365535736083984,
          27.711000442504883,
          27.094083786010742,
          27.044891357421875,
          26.837610244750977,
          43.79722595214844,
          44.47529983520508,
          44.71475601196289,
          42.147979736328125,
          20.25183868408203,
          15.845690727233887,
          16.450536727905273,
          -7.704033374786377,
          -10.96595287322998,
          26.219703674316406,
          26.015281677246094,
          22.925539016723633,
          6.613112449645996,
          -2.9274044036865234,
          -3.8965253829956055,
          -27.80027961730957,
          -5.056882858276367,
          17.582855224609375,
          -9.550091743469238,
          20.242189407348633,
          -3.997509002685547,
          -0.36325696110725403,
          -0.317268967628479,
          15.797297477722168,
          28.351198196411133,
          -1.3361120223999023,
          28.996870040893555,
          21.469398498535156,
          11.990976333618164,
          -22.592100143432617,
          -24.701316833496094,
          20.056821823120117,
          -20.509231567382812,
          -20.506912231445312,
          9.766204833984375,
          2.357966423034668,
          17.354337692260742,
          2.685886859893799,
          1.9494245052337646,
          -6.2082109451293945,
          1.519607663154602,
          -35.89326477050781,
          45.80472183227539,
          45.478878021240234,
          44.44059753417969,
          45.219966888427734,
          -19.2497501373291,
          25.760656356811523,
          23.00269889831543,
          27.61579132080078,
          28.24168586730957,
          22.120840072631836,
          27.456100463867188,
          29.519014358520508,
          -1.146793246269226,
          -6.6827850341796875,
          -2.7551932334899902,
          -4.194457054138184,
          -6.037020683288574,
          8.61467456817627,
          -8.351006507873535,
          -9.472332000732422,
          -37.870357513427734,
          -32.446800231933594,
          -10.01904010772705,
          -29.87734031677246,
          14.807991027832031,
          6.974808692932129,
          23.73017120361328,
          11.702710151672363,
          15.32918643951416,
          -15.288528442382812,
          -15.339347839355469,
          21.530445098876953,
          18.372072219848633,
          23.288654327392578,
          15.634180068969727,
          15.11684799194336,
          14.87294864654541,
          14.451151847839355,
          14.287080764770508,
          13.78709602355957,
          16.907915115356445,
          31.34670639038086,
          31.358686447143555,
          20.316226959228516,
          -20.613359451293945,
          -17.821123123168945,
          -18.002737045288086,
          -22.3155574798584,
          -24.758682250976562,
          -19.05428123474121,
          -18.75923728942871,
          -0.8678898215293884,
          6.849015235900879,
          6.481459140777588,
          24.35555648803711,
          24.418935775756836,
          25.0686092376709,
          22.698020935058594,
          7.344947338104248,
          22.5616512298584,
          -25.870464324951172,
          27.2991886138916,
          19.15675926208496,
          -15.254598617553711,
          -21.175491333007812,
          12.003129959106445,
          9.736310005187988,
          10.29201889038086,
          -7.404641628265381,
          -23.378583908081055,
          -11.144937515258789,
          -11.505084991455078,
          -32.1471061706543,
          -32.708984375,
          -32.40974044799805,
          -30.857820510864258,
          -31.60556983947754,
          -0.506396472454071,
          -21.20325469970703,
          -36.61642074584961,
          -24.348237991333008,
          -37.29847717285156,
          -25.272375106811523,
          -3.651763677597046,
          -8.709809303283691,
          30.084720611572266,
          -29.144447326660156,
          -23.307327270507812,
          -33.6002311706543,
          -26.64427375793457,
          -5.51840353012085,
          -25.83893394470215,
          15.022783279418945,
          13.074836730957031,
          -5.820983409881592,
          12.405116081237793,
          15.173778533935547,
          15.254386901855469,
          16.181968688964844,
          -10.69296646118164,
          11.757821083068848,
          15.399683952331543,
          18.647153854370117,
          16.114938735961914,
          -22.97885513305664,
          9.060853004455566,
          10.420441627502441,
          23.877729415893555,
          11.899182319641113,
          -9.817214012145996,
          13.338926315307617,
          10.977279663085938,
          -10.383119583129883,
          -17.393081665039062,
          -18.258359909057617,
          3.9240150451660156,
          -16.11992073059082,
          -18.255760192871094,
          -18.938148498535156,
          -18.4053897857666,
          -7.298534870147705,
          -27.872665405273438,
          -12.536941528320312,
          -32.023521423339844,
          -31.676212310791016,
          -2.936155319213867,
          -25.823020935058594,
          -0.05817184969782829,
          13.60578441619873,
          16.3789119720459,
          17.77354621887207,
          16.78062629699707,
          17.906476974487305,
          -13.747716903686523,
          -9.792939186096191,
          -13.27595043182373,
          -14.17092227935791,
          -26.620193481445312,
          -33.77745819091797,
          -22.55628204345703,
          -42.629032135009766,
          -42.50624465942383,
          -42.44620895385742,
          -42.79661178588867,
          6.133135795593262,
          19.20614242553711,
          -2.903008222579956,
          15.269978523254395,
          -6.498183727264404,
          -12.63532829284668,
          -43.2994499206543,
          -43.15900421142578,
          -42.533809661865234,
          -42.96247100830078,
          -42.22037887573242,
          -42.446739196777344,
          8.34992790222168,
          7.866236686706543,
          23.7142391204834,
          -18.08595085144043,
          9.922356605529785,
          8.295994758605957,
          -1.0213581323623657,
          23.405168533325195,
          -1.504587173461914,
          26.399635314941406,
          10.736865043640137,
          -21.120325088500977,
          -26.492124557495117,
          -26.513614654541016,
          29.827463150024414,
          29.065105438232422,
          28.560789108276367,
          14.942977905273438,
          -15.772374153137207,
          -12.306355476379395,
          -16.126750946044922,
          -18.564807891845703,
          10.958468437194824,
          29.30093765258789,
          10.006689071655273,
          27.57752799987793,
          3.971555233001709,
          0.6321765184402466,
          -2.689361572265625,
          24.506702423095703,
          5.59418249130249,
          5.413142204284668,
          14.074797630310059,
          28.16414451599121,
          30.393890380859375,
          31.254318237304688,
          29.770994186401367,
          30.26791000366211,
          -10.684163093566895,
          4.894495487213135,
          20.87101936340332,
          19.50372314453125,
          0.08162706345319748,
          15.470776557922363,
          15.599416732788086,
          26.405841827392578,
          14.677908897399902,
          6.364489555358887,
          -4.174553394317627,
          -10.096597671508789,
          -9.573162078857422,
          5.348629951477051,
          5.103407859802246,
          4.807720184326172,
          -28.69851303100586,
          6.920382022857666,
          8.335158348083496,
          0.49982950091362,
          1.8744337558746338,
          0.9056082367897034,
          2.310006856918335,
          2.8873462677001953,
          -5.985524654388428,
          -20.13768196105957,
          -3.9377241134643555,
          -16.476116180419922,
          12.9932222366333,
          -2.6596641540527344,
          -19.272769927978516,
          -20.20761489868164,
          -24.755664825439453,
          -20.24632453918457,
          -22.798778533935547,
          -1.3604068756103516,
          -19.613855361938477,
          -20.65361976623535,
          -22.887393951416016,
          -22.041255950927734,
          -25.53318214416504,
          -6.943896770477295,
          -15.476749420166016,
          -14.702399253845215,
          4.755477428436279,
          -10.277320861816406,
          -17.65166664123535,
          -13.501644134521484,
          -8.850051879882812,
          -14.891806602478027,
          7.359205722808838,
          7.237400531768799,
          -7.12552547454834,
          5.7749152183532715,
          6.453588008880615,
          27.784822463989258,
          26.002826690673828,
          25.475534439086914,
          18.71225929260254,
          31.452198028564453,
          1.8426231145858765,
          -10.78545093536377,
          -10.60240650177002,
          -3.667405366897583,
          -10.230424880981445,
          -9.817739486694336,
          -10.149386405944824,
          -3.0741562843322754,
          19.948326110839844,
          19.34461784362793,
          17.8104248046875,
          -7.882659435272217,
          -9.277846336364746,
          5.137756824493408,
          6.775990009307861,
          -7.489529132843018,
          -12.4856595993042,
          -30.578815460205078,
          -8.289545059204102,
          2.9850986003875732,
          9.6458158493042,
          29.058053970336914,
          -3.645555019378662,
          -14.627666473388672,
          29.933101654052734,
          38.0748291015625,
          38.45458984375,
          36.264408111572266,
          11.25361156463623,
          11.628230094909668,
          4.786657810211182,
          -17.62803077697754,
          22.757919311523438,
          35.925132751464844,
          4.612586498260498,
          18.725929260253906,
          -4.1301140785217285,
          11.118325233459473,
          -4.83497428894043,
          14.41052532196045,
          -8.183334350585938,
          0.9254770874977112,
          7.543339729309082,
          8.529354095458984,
          18.314584732055664,
          12.163887977600098,
          8.986163139343262,
          7.2598161697387695,
          -1.0959997177124023,
          0.6925774812698364,
          0.9208328723907471,
          -1.3579962253570557,
          -0.24563802778720856,
          -4.675971031188965,
          -1.9109079837799072,
          -2.9713194370269775,
          -2.6075432300567627,
          -5.078460693359375,
          35.25314712524414,
          34.8674430847168,
          19.80953025817871,
          14.47803020477295,
          14.84807300567627,
          5.529468536376953,
          -7.598318576812744,
          -11.851131439208984,
          -9.65272331237793,
          -9.012356758117676,
          17.224763870239258,
          25.875686645507812,
          24.325637817382812,
          26.575162887573242,
          17.511016845703125,
          -10.953656196594238,
          -11.986320495605469,
          -11.323265075683594,
          -10.298714637756348,
          -10.765679359436035,
          -7.603184223175049,
          -20.820077896118164,
          -10.331526756286621,
          -12.125009536743164,
          12.512089729309082,
          35.843467712402344,
          35.00136947631836,
          36.854740142822266,
          33.762916564941406,
          34.74485397338867,
          36.85976028442383,
          -24.0299015045166,
          -28.769649505615234,
          -36.9080810546875,
          -35.76151657104492,
          -37.57716369628906,
          -21.718706130981445,
          -36.7133903503418,
          -0.2948683202266693,
          -36.92642593383789,
          -36.00749206542969,
          -36.841915130615234,
          -37.40890121459961,
          -18.14034080505371,
          -22.917980194091797,
          -20.82216453552246,
          -21.680892944335938,
          -22.233749389648438,
          -23.105392456054688,
          -11.27780818939209,
          23.11214256286621,
          9.001812934875488,
          35.5932502746582,
          -4.315533638000488,
          -2.26131272315979,
          -7.077913284301758,
          -19.931081771850586,
          37.50334548950195,
          35.57533264160156,
          14.22896671295166,
          14.243460655212402,
          15.607744216918945,
          11.011585235595703,
          33.04464340209961,
          31.939712524414062,
          32.219608306884766,
          31.93861198425293,
          -11.322019577026367,
          -9.976576805114746,
          19.265687942504883,
          18.77873420715332,
          -16.627979278564453,
          -17.400348663330078,
          -32.01172637939453,
          -31.209732055664062,
          -16.58015251159668,
          -8.580333709716797,
          -2.18617582321167,
          -33.69278335571289,
          -10.40255069732666,
          -14.01536750793457,
          -13.375245094299316,
          -10.565174102783203,
          -18.134824752807617,
          -16.904443740844727,
          14.860488891601562,
          13.88567066192627,
          14.096037864685059,
          22.056976318359375,
          13.054801940917969,
          -22.301176071166992,
          -0.5553286075592041,
          -0.5298164486885071,
          45.18020248413086,
          43.30839920043945,
          17.071338653564453,
          17.14211082458496,
          17.142683029174805,
          34.64738845825195,
          35.63238525390625,
          34.32734298706055,
          30.910907745361328,
          30.042072296142578,
          30.247535705566406,
          12.084556579589844,
          18.58640480041504,
          9.655941009521484,
          9.877094268798828,
          9.690768241882324,
          21.26633644104004,
          20.36473846435547,
          -21.642602920532227,
          20.893339157104492,
          -22.003002166748047,
          -29.940919876098633,
          -25.378957748413086,
          -33.974769592285156,
          -32.05462646484375,
          -30.272172927856445,
          -27.156986236572266,
          4.284464359283447,
          -21.787063598632812,
          11.095734596252441,
          27.22805404663086,
          8.24577522277832,
          7.510998249053955,
          4.751912593841553,
          1.9894343614578247,
          8.29606819152832,
          10.146208763122559,
          -28.258087158203125,
          -28.24463653564453,
          5.846441268920898,
          6.012282848358154,
          -28.937416076660156,
          8.580901145935059,
          11.416414260864258,
          -10.420431137084961,
          -4.4948272705078125,
          -19.25113868713379,
          1.6226463317871094,
          0.19066020846366882,
          -7.426523685455322,
          -27.43752670288086,
          1.7907602787017822,
          1.9607529640197754,
          1.9443148374557495,
          2.6808829307556152,
          7.87889289855957,
          7.744470119476318,
          6.5187835693359375,
          5.865340232849121,
          -2.837754011154175,
          6.093703746795654,
          -19.385459899902344,
          2.8458914756774902,
          -0.4709608256816864,
          1.9900894165039062,
          -2.3171627521514893,
          27.556699752807617,
          19.14259910583496,
          25.101865768432617,
          -10.780712127685547,
          7.6200079917907715,
          -0.5202034711837769,
          13.761345863342285,
          -18.14691734313965,
          16.165374755859375,
          8.634644508361816,
          -0.5732591152191162,
          -1.2430012226104736,
          -28.750377655029297,
          -4.677412033081055,
          -21.66936492919922,
          -2.6389148235321045,
          33.99673843383789,
          16.892333984375,
          -6.352911472320557,
          35.8698616027832,
          35.684471130371094,
          27.793468475341797,
          -19.71213150024414,
          34.55327606201172,
          28.7992000579834,
          18.9395694732666,
          22.819992065429688,
          -19.959259033203125,
          -0.5660073161125183,
          -8.835771560668945,
          -12.846932411193848,
          1.8764489889144897,
          -33.177879333496094,
          -10.672089576721191,
          5.559253692626953,
          -9.900361061096191,
          5.51408052444458,
          -33.19352340698242,
          3.5242464542388916,
          -28.59984016418457,
          -30.013389587402344,
          -31.382598876953125,
          -29.038860321044922,
          -19.34646987915039,
          -32.37513732910156,
          -29.727930068969727,
          -26.71695899963379,
          -35.31456756591797,
          -2.3338239192962646,
          10.469513893127441,
          -36.37816619873047,
          -26.51162338256836,
          -37.44002914428711,
          -32.460716247558594,
          -37.54620361328125,
          -37.282493591308594,
          -9.399632453918457,
          -2.478248119354248,
          -24.696218490600586,
          -39.61859130859375,
          -39.733341217041016,
          -29.279558181762695,
          -4.274680137634277,
          -0.4702058732509613,
          -16.492685317993164,
          -14.438817977905273,
          32.86626052856445,
          30.98405647277832,
          2.4694976806640625,
          32.71921157836914,
          4.917998313903809,
          32.672855377197266,
          20.727853775024414,
          22.76821517944336,
          22.051719665527344,
          -3.445512056350708,
          14.827630996704102,
          3.623729944229126,
          3.633556365966797,
          -0.10536567866802216,
          3.2575361728668213,
          10.617667198181152,
          -2.819387674331665,
          -3.3086817264556885,
          3.0409133434295654,
          -24.251670837402344,
          -4.567536354064941,
          12.349112510681152,
          -22.86887550354004,
          -24.44733428955078,
          -4.819241523742676,
          -4.598001956939697,
          -27.28643798828125,
          -22.333696365356445,
          -21.304101943969727,
          -23.600893020629883,
          -22.638124465942383,
          -26.79256248474121,
          -28.285036087036133
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "hoverlabel": {
         "bgcolor": "white"
        },
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "t-SNE visualization of conclusion claims"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "industry_claims = [\n",
    "    claim for claims in industry_papers[\"abstract_claims\"] for claim in claims\n",
    "]\n",
    "academic_claims = [\n",
    "    claim for claims in academic_papers[\"abstract_claims\"] for claim in claims\n",
    "]\n",
    "\n",
    "# Create labels (0 for industry, 1 for academic)\n",
    "labels = [0] * len(industry_claims) + [1] * len(academic_claims)\n",
    "\n",
    "# Combine all claims\n",
    "all_claims = industry_claims + academic_claims\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(all_claims, show_progress_bar=True)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame with all information\n",
    "plot_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": tsne_results[:, 0],\n",
    "        \"y\": tsne_results[:, 1],\n",
    "        \"type\": [\"Industry\" if l == 0 else \"Academic\" for l in labels],\n",
    "        \"claim\": all_claims,\n",
    "        \"article_id\": (\n",
    "            [\n",
    "                i\n",
    "                for row in industry_papers.iterrows()\n",
    "                for i in [row[1][\"id\"]] * len(row[1][\"abstract_claims\"])\n",
    "            ]\n",
    "            + [\n",
    "                i\n",
    "                for row in academic_papers.iterrows()\n",
    "                for i in [row[1][\"id\"]] * len(row[1][\"abstract_claims\"])\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "fig = px.scatter(\n",
    "    plot_data,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"type\",\n",
    "    hover_data=[\"article_id\", \"claim\"],\n",
    "    title=\"t-SNE visualization of conclusion claims\",\n",
    "    color_discrete_map={\"Industry\": \"#FF6B6B\", \"Academic\": \"#4ECDC4\"},\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(hoverlabel=dict(bgcolor=\"white\"), width=1000, height=600)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1271d206a84514babdddec945a98ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "2011.00890",
           "In theory, it makes this paradigm applicable to any of the world's languages, most of which suffer from the paucity of annotated data"
          ],
          [
           "2011.00890",
           "In particular, we focused on neural machine translation (NMT) with limited parallel data as a downstream task"
          ],
          [
           "2011.00890",
           "In the future, we plan to experiment with other state-of-the-art NMT architectures, apply our method to extremely low-resource languages, and extend the scope of our work to other tasks beyond NMT."
          ],
          [
           "2209.15236",
           "We have presented a novel approach for fine-tuning a pretrained multilingual model for NMT using language-family adapters"
          ],
          [
           "2209.15236",
           "We also contrast our method of grouping languages together based on language families to an automatic way of clustering data from different languages, using the representations of a pretrained multilingual model and discuss the potential utility of this method"
          ],
          [
           "2209.15236",
           "In the future, a more elaborate approach to encode lexical-level representations could further boost the performance of language-family adapters"
          ],
          [
           "1910.13299",
           "This paper summarized the results of the Third Workshop on Neural Generation and Translation, where we saw a number of research advances"
          ],
          [
           "2104.08677",
           "Our work points towards the need of rethinking the process of encoding tokens to real valued vectors for machine translation"
          ],
          [
           "2104.08677",
           "Our variant of product quantization was able to approximate the embedding matrix in an almost $~100$ % discrete space, with better performance than the baseline model"
          ],
          [
           "2104.08677",
           "A discrete space is easier to interpret, compared to a continuous space, and can motivate future research to handle unknown tokens through optimum cluster selection."
          ],
          [
           "1703.04908",
           "This abstract language is formed without any exposure to human language use"
          ],
          [
           "1610.08613",
           "To better understand the main shortcoming of previous active memory models, let us look at the average log-perplexities of different attention models in Table REF "
          ],
          [
           "1610.08613",
           "A pure Neural GPU model yields $3.5$ , a Markovian one yields $2.5$ , and only a model with full dependence, trained with teacher forcing, achieves $1.3$ "
          ],
          [
           "1610.08613",
           "The recurrent dependence in generating the output distribution turns out to be the key to achieving good performance"
          ],
          [
           "1610.08613",
           "In earlier works, such dependence (and training with teacher forcing) was always used in LSTM and GRU models, but very rarely in other kinds models"
          ],
          [
           "1610.08613",
           "It allows us to create the Extended Neural GPU and this way of thinking might also prove fruitful for other classes of models"
          ],
          [
           "1610.08613",
           "When the issue of recurrent output dependencies is addressed, as we do in the Extended Neural GPU, an active memory model can indeed match or exceed attention models on a large-scale real-world task"
          ],
          [
           "1610.08613",
           "Does this mean we can always replace attention by active memory? The answer could be yes for the case of soft attention"
          ],
          [
           "1610.08613",
           "Its cost is approximately the same as active memory, it performs much worse on some tasks like learning algorithms, and – with the introduction of the Extended Neural GPU – we do not know of a task where it performs clearly better"
          ],
          [
           "1610.08613",
           "This is especially obvious for hard attention: it can be used over large memories with potentially much less computational cost than an active memory, so it might be indispensable for devising long-term memory mechanisms"
          ],
          [
           "1411.4555",
           "The model is trained to maximize the likelihood of the sentence given the image"
          ],
          [
           "1411.4555",
           "Furthermore, it will be interesting to see how one can use unsupervised data, both from images alone and text alone, to improve image description approaches."
          ],
          [
           "2205.01398",
           "and recommendations In this paper, we overview recent progress on NLP application to computer languages, and project its potential impact to the area of automated network configuration"
          ],
          [
           "2205.01398",
           "In light of our analysis, we make the following conclusive observations:  Generally speaking, the bootstrap cost in terms of amounts of data, as well as computational power for unsupervised learning, could be affordable but only for top largest vendors and ISPs"
          ],
          [
           "2205.01398",
           "The expected performance for code/configuration synthesis is still elementary given the use cases tried so far are rather simple"
          ],
          [
           "2205.01398",
           "We expect this use case to be further developed, conditioned to success to the previous two"
          ],
          [
           "2205.01398",
           "As such, a growing research trend is expected to emerge in the community, increasing the availability, spread and knowledge of NLP tools for networking in general"
          ],
          [
           "1909.05362",
           "In this work, we explained 27 problems in automating translation for movie and TV show subtitles and share frequency of 16 key problems for six language pairs"
          ],
          [
           "1909.05362",
           "While we do not provide possible solutions for any problems, we present an insight into the problem domain"
          ],
          [
           "1909.05362",
           "The examples provided encourage the reader to design error-specific, language-specific and language-agnostic solutions"
          ],
          [
           "1909.05362",
           "One can solve these problems by pre-processing the input, post-processing the MT output or by improving MT engines"
          ],
          [
           "1909.05362",
           "Creating one solution for all languages may not always work."
          ],
          [
           "2201.04843",
           "and Future Work We present a multi-task pre-training knowledge graph BERT, named LP-BERT, for link prediction, which not only uses MLM to learn the knowledge of context corpus, but also introduces Mask Entity Model (MEM) and Mask Relation Model (MRM) tasks to learn the relationship information of triples"
          ],
          [
           "2201.04843",
           "According to this method, the structural relationship informations are introduced into pre-training model after transformed into unstructured corpus informations"
          ],
          [
           "2201.04843",
           "Experimental results on dataset demonstrate both the efficiency and effectiveness of LP-BERT"
          ],
          [
           "2201.04843",
           "In future work, we will add more diverse pre-training tasks and increase the model parameter size to enable LP-BERT to store more graph knowledge."
          ],
          [
           "1808.05505",
           "Sentence embedding is one of the most important text processing techniques in NLP"
          ],
          [
           "1808.05505",
           "To date, various sentence embedding models have been proposed and have yielded good performances in document classification and sentiment analysis tasks"
          ],
          [
           "1808.05505",
           "However, the fundamental ability of sentence embedding methods, i.e., how effectively the meanings of the original sentences are preserved in the embedded vectors, cannot be fully evaluated through such indirect methods"
          ],
          [
           "1808.05505",
           "The proposed model was evaluated based on the MS-COCO caption and STS Benchmark datasets"
          ],
          [
           "1808.05505",
           "P-thought models with more complex encoder structures tend to overfit the MS-COCO datasets"
          ],
          [
           "1808.05505",
           "Although this problem can be resolved by acquiring more paraphrase sentences, it is not easy in practice to obtain a large number of paraphrase sentences"
          ],
          [
           "1503.02427",
           "We propose a generic model for matching two short-texts, which relies on a tree-mining algorithm to discover a vast amount of matching patterns and a DNN to further perform the task using those patterns"
          ],
          [
           "1909.11556",
           "Structured dropout regularizes neural networks to be more robust to applying structured pruning at inference time"
          ],
          [
           "1909.11556",
           "We focus on the setting where structures are layers, enabling pruning of shallow and efficient models of any desired depth"
          ],
          [
           "2203.06462",
           " and Future Work In this work we discretised the outputs of Softmax and showed how dimensionality constraints shrink the set of feasible class rankings and can lead to some classes being impossible to predict using argmax"
          ],
          [
           "2203.06462",
           "Moreover, for the models we tested the unargmaxable tokens would not create discernible differences in translation quality as the tokens are noisy and infrequent"
          ],
          [
           "2203.06462",
           "In future work, we aim to investigate any learnability consequences more closely"
          ],
          [
           "2203.06462",
           "As we saw, when using an approximate search algorithm, it is much harder to find argmaxable classes in some models than it is in others"
          ],
          [
           "2203.06462",
           "Hence, although some tokens may not be provably unargmaxable because of constraints imposed by the Softmax parameters of the last layer, some tokens may still be very hard to produce because of difficulties encountered by the feature encoder"
          ],
          [
           "2203.06462",
           "To this end, a more holistic investigation into the consequences of the loss in expressivity in low-rank classifiers is warranted."
          ],
          [
           "2001.10238",
           " Generative models are increasingly more powerful but suffer from little control over the generative process and the lack of interpretability in their latent representations"
          ],
          [
           "2001.10238",
           "In this context, we propose a method to extract meaningful directions in the latent space of such models and use them to control precisely some properties of the generated images"
          ],
          [
           "2001.10238",
           "It is an important step toward the understanding of the representations learned by generative models"
          ],
          [
           "2001.10238",
           "Penalty on the amplitude of frequencies due to MSE In Section REF , we consider a target image $I\\in \\mathcal {I}$  and a generated image $\\hat{I}=G(\\hat{z})$  to be determined according to a reconstruction loss $\\mathcal {L}$  (Equation REF )"
          ],
          [
           "2001.10238",
           "Let us note $\\mathcal {F}\\lbrace  \\cdot \\rbrace $  the Fourier transform"
          ],
          [
           "2001.10238",
           "If $\\mathcal {L}$  is the usual MSE, from the Plancherel theorem, we have $||\\hat{I}-I||^2 = ||\\mathcal {F}\\lbrace \\hat{I}\\rbrace  - \\mathcal {F}\\lbrace I\\rbrace ||^2$ "
          ],
          [
           "2001.10238",
           "Let us consider a particular frequency $\\omega $  in the Fourier space and compute its contribution to the loss"
          ],
          [
           "2001.10238",
           "The Fourier transform of $I$  (resp"
          ],
          [
           "2001.10238",
           "$\\hat{I}$ ) having a magnitude $r$  (resp"
          ],
          [
           "2001.10238",
           "$\\hat{r}$ ) and a phase $\\theta $  (resp"
          ],
          [
           "2001.10238",
           "The contribution to the total loss $\\mathcal {L}$  thus directly depends on $\\hat{r}^2$ "
          ],
          [
           "2001.10238",
           "$\\beta $ -VAE architecture The $\\beta $ -VAE framework was introduced by [12] to discover interpretable factorized latent representations for images without supervision"
          ],
          [
           "2001.10238",
           "For our experiments, we designed a simple convolutional VAE architecture to generate images of size 64x64, the decoder network is the opposite of the encoder with transposed convolutions"
          ],
          [
           "2001.10238",
           "Table: β\\beta -VAE architecture used during experiments with the dSprites dataset"
          ],
          [
           "2001.10238",
           "With or without the constraint on ||𝐳||||{\\mathbf {z}}||"
          ],
          [
           "2001.10238",
           "Note the artifacts when using our loss without constraining 𝐳{\\mathbf {z}} (best seen with zoom).On Fig"
          ],
          [
           "2001.10238",
           "REF ) for several values of $\\sigma $ "
          ],
          [
           "2001.10238",
           "We also illustrate on Fig"
          ],
          [
           "2001.10238",
           "REF  a comparison of our approach to two others, namely classical Mean Square Error (MSE) and Structural dissimilarity (DSSIM) proposed by [32]"
          ],
          [
           "2001.10238",
           "Results are also presented with an unconstrained latent code during optimization (Eq"
          ],
          [
           "2001.10238",
           "REF ) and the approach proposed (Eq"
          ],
          [
           "2001.10238",
           "REF )"
          ],
          [
           "2001.10238",
           "We also performed a quantitative evaluation of the performance of our approach"
          ],
          [
           "2001.10238",
           "We randomly selected one image for each of the 1000 categories of the ILSVRC dataset and reconstructed it with our method with a budget of 3000 iterations"
          ],
          [
           "2001.10238",
           "We then computed the Learned Perceptual Image Patch Similarity (LPIPS), proposed by [31], between the final reconstruction and the target image"
          ],
          [
           "2001.10238",
           "We used the official implementation of the LPIPS paper with default parameters"
          ],
          [
           "2001.10238",
           "Results are reported in Table REF "
          ],
          [
           "2001.10238",
           "It can be the case for the textured ones in particular, for the reasons explained in the Section "
          ],
          [
           "2001.10238",
           "Table: Perceptual similarity measurements between an image and its reconstruction for different reconstruction errors"
          ],
          [
           "2001.10238",
           "On the difficulty of optimization on the natural image manifold"
          ],
          [
           "2001.10238",
           "The curvature of the natural image manifold makes the optimization problem of Equation REF  difficult to solve"
          ],
          [
           "2001.10238",
           "This is especially true for factors of variation which correspond to curved walks in pixel-space (for example translation or rotation by opposition to brightness or contrast changes which are linear)"
          ],
          [
           "2001.10238",
           "We consider three types of transformations, namely translation, rotation and scaling, and get images from the dSprites [24] dataset which correspond to the progressive transformation (interpolation) of an image"
          ],
          [
           "2001.10238",
           "To visualize, we compute the PCA of the resulting trajectories and plot the trajectories on the two main axes of the PCA"
          ],
          [
           "2001.10238",
           "The result of this experiment can be seen in Figure REF "
          ],
          [
           "2001.10238",
           "Figure: Two trajectories are shown in the pixel space, between an image and its transformed version, for three types of transformations: translation, scale and orientation"
          ],
          [
           "2001.10238",
           "Red: shortest path (interpolation) between the two extremes of the trajectory"
          ],
          [
           "2001.10238",
           "Blue: trajectory of the actual transformation"
          ],
          [
           "2001.10238",
           "The same problem occurs for rotation and, at a smaller extent, for scale"
          ],
          [
           "2001.10238",
           "However this problem does not exist for brightness for example, as its change is a linear transformation in pixel-space"
          ],
          [
           "2001.10238",
           "This is problematic during optimization of the latent code because the gradient of the reconstruction loss with respect to the generated image is tangent to this direction"
          ],
          [
           "2001.10238",
           "Thus, when we are in the case of near orthogonality, the gradient of the error with respect to the latent code is small"
          ],
          [
           "2001.10238",
           "Indeed, let us consider an ideal case where $G$  is a bijection between $\\mathcal {Z}$  and the manifold of natural images"
          ],
          [
           "2001.10238",
           "Let be ${\\mathbf {z}}\\in \\mathcal {Z}$ , a basis of vectors tangent to the manifold at point $G({\\mathbf {z}})$  is given by $\\left( \\frac{\\partial G({\\mathbf {z}})}{\\partial {\\mathbf {z}}_1}, ..., \\frac{\\partial G({\\mathbf {z}})}{\\partial {\\mathbf {z}}_d} \\right)$ "
          ],
          [
           "2001.10238",
           "Let consider a generated image with the circle on the left of the image and we want to move it to the right"
          ],
          [
           "2001.10238",
           "Obviously, we thus have $\\nabla _{\\mathbf {z}}||G({\\mathbf {z}}) - \\mathcal {T}_T(G({\\mathbf {z}}_1))||^2 = 0$  if the intersection of the two circles is empty (see Figure REF ) since a small translation of the object does not change the reconstruction error"
          ],
          [
           "2001.10238",
           "The images latent codes are sampled in the following way: ${\\mathbf {z}}- \\mathinner {\\langle {{\\mathbf {z}},{\\mathbf {u}}}\\rangle }{\\mathbf {u}}+ \\alpha {\\mathbf {u}}$  with $\\alpha \\in [-3,3]$  and ${\\mathbf {u}}$  the learned direction"
          ],
          [
           "2001.10238",
           "It is likely due to the absence of dark images for these categories in the training data"
          ],
          [
           "2001.10238",
           "for position and scale, the direction is learned on the ten categories presented here while for brightness only the five top categories are used"
          ],
          [
           "2001.10238",
           "Qualitative comparison between our optimization method and the naive method"
          ],
          [
           "2001.10238",
           "Figure: Comparison of the speed of convergence on a single example for our method (top) given by equation  and a naive approach (bottom) given by equation "
          ],
          [
           "2001.10238",
           "The numbers indicate the step of optimization"
          ],
          [
           "2001.10238",
           "Both experiences have been conducted with Adam optimizer with a learning rate of 1e-11\\mathrm {e}{-1}."
          ],
          [
           "cmp-lg/9505042",
           "We have proposed a method for completing partial parses of ill-formed sentences on the basis of information extracted from complete parses of well-formed sentences in the discourse"
          ],
          [
           "cmp-lg/9505042",
           "The basic idea of our method is to improve the accuracy of sentence analysis simply by maintaining consistency in the usage of morphologically identical words within the same text"
          ],
          [
           "cmp-lg/9505042",
           "However, the results have been encouraging at least with technical documents such as computer manuals, where words with the same lemma are frequently repeated in a small area of text"
          ],
          [
           "2012.01303",
           "This work is a step towards incorporating complex meta-analyses in brain mapping models"
          ],
          [
           "2012.01303",
           "We encode a cbma database in a probabilistic logic program on which general logic-based queries can be solved"
          ],
          [
           "2012.01303",
           "Leveraging efficient query resolution strategies on probabilistic databases, we are able to scale to the size of neuroimaging data"
          ],
          [
           "2012.01303",
           "We experimented with a new method for solving two-term cq using tfidf features more efficiently than the hard thresholding scheme used by Neurosynth"
          ],
          [
           "2012.01303",
           "The proposed method requires the same computational power as Neurosynth."
          ],
          [
           "2204.13353",
           "We visualize the averaged attention values over one case from WMT'17 Zh-En dev set"
          ],
          [
           "2204.13353",
           "As seen, our model can give good aligned information, where preposition phrase \"around 50 years ago\" is arranged at the end of sentence in English, while its aligned phrase is at the front in Chinese"
          ],
          [
           "2204.13353",
           "Figure: Case study from WMT'17 Zh-En dev set."
          ],
          [
           "1911.12864",
           "mplementation The reference code for our implementations is provided in the supplementary material."
          ],
          [
           "2204.00471",
           "We identified a major culprit behind various inference-related issues in sequence-to-sequence models such as the intractability of the search space, degenerate large beam or exact search outputs and the large spread in probability mass over the output space"
          ],
          [
           "2204.00471",
           "This factor is intrinsic uncertainty – the existence of multiple ways to correctly map an input sequence"
          ],
          [
           "1910.06762",
           "We proposed a Transformer architecture with Gaussian-weighted self-attention for speech enhancement"
          ],
          [
           "1910.06762",
           "The attention weights are attenuated proportionally to the distance between the target frame and the symbols attended to, while preserving the correlation signs"
          ],
          [
           "2202.12934",
           "The goal of the work was to demonstrate how GAs can be uniquely leveraged to accelerate multi-objective neural architecture search on the modalities of machine translation and image classification"
          ],
          [
           "2202.12934",
           "As NAS research continues to gain momentum, we highlight the need to continue to investigate the generalizability of NAS approaches in modalities outside of computer vision"
          ],
          [
           "2202.12934",
           "Future work includes evaluating the use of proxy functions [19] and advances in meta-learning [20] to extend this type of algorithmic framework."
          ],
          [
           "1907.12461",
           "We performed an extensive study on leveraging pre-trained checkpoints for sequence generation"
          ],
          [
           "1907.12461",
           "Most tasks also profit from sharing the weights between the encoder and the decoder, which additionally decreases the memory footprint"
          ],
          [
           "1907.12461",
           "Training a language specific BERT model also improves performance over using the multilingual version."
          ],
          [
           "2108.11703",
           "In this paper, we adapt backtranslation to the token-level sequence tagging task of NER"
          ],
          [
           "2108.11703",
           "The experiments on two domain-specific datasets demonstrate the effectiveness of backtranslation as a competitive data augmentation strategy for NER."
          ],
          [
           "1609.06647",
           "The model is trained to maximize the likelihood of the sentence given the image"
          ],
          [
           "1609.06647",
           "The produced descriptions are one of many possible image interpretations"
          ],
          [
           "1609.06647",
           "One possible direction is the have a system which is capable of more targeted descriptions – either anchoring the descriptions to given image properties and locations or being a response to a user specified question or task"
          ],
          [
           "1609.06647",
           "Further research direction are better evaluation metrics or evaluation through higher level goals found in application such as robotics."
          ]
         ],
         "hovertemplate": "type=Industry<br>x=%{x}<br>y=%{y}<br>article_id=%{customdata[0]}<br>claim=%{customdata[1]}<extra></extra>",
         "legendgroup": "Industry",
         "marker": {
          "color": "#FF6B6B",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Industry",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -9.553838729858398,
          11.46986198425293,
          20.262676239013672,
          20.989660263061523,
          1.1630951166152954,
          12.433036804199219,
          11.804107666015625,
          5.283287525177002,
          2.240166187286377,
          2.399076461791992,
          -10.04702377319336,
          24.99994659423828,
          23.54021644592285,
          19.233041763305664,
          22.58205795288086,
          24.444887161254883,
          23.775421142578125,
          25.719463348388672,
          24.691791534423828,
          25.666934967041016,
          21.116209030151367,
          0.37631386518478394,
          -14.170621871948242,
          16.296184539794922,
          7.261216640472412,
          -13.056105613708496,
          -13.781990051269531,
          -2.9127197265625,
          -17.69124984741211,
          -9.865934371948242,
          6.175823211669922,
          -9.6884765625,
          -7.909676551818848,
          -6.186230182647705,
          -10.870173454284668,
          -8.633301734924316,
          -3.995415687561035,
          -3.9095282554626465,
          -2.453667163848877,
          7.989018440246582,
          9.626254081726074,
          -22.41965675354004,
          -9.418723106384277,
          33.494144439697266,
          33.00742721557617,
          14.339179992675781,
          5.496604919433594,
          -12.646834373474121,
          14.606691360473633,
          6.734696388244629,
          12.332525253295898,
          24.00716209411621,
          23.318788528442383,
          23.986309051513672,
          26.607421875,
          28.4384822845459,
          26.304811477661133,
          27.791248321533203,
          28.135114669799805,
          26.693843841552734,
          26.696308135986328,
          27.196630477905273,
          25.249923706054688,
          26.503400802612305,
          25.075191497802734,
          23.210081100463867,
          23.07213020324707,
          -36.042381286621094,
          14.4835205078125,
          21.708457946777344,
          21.04486083984375,
          1.8917032480239868,
          1.2806484699249268,
          4.312710762023926,
          30.66486167907715,
          29.288860321044922,
          4.324886322021484,
          -24.93439292907715,
          16.593347549438477,
          29.301738739013672,
          25.88031005859375,
          25.76054573059082,
          21.70288848876953,
          32.0721549987793,
          33.621116638183594,
          14.50822925567627,
          32.22062301635742,
          32.59596252441406,
          32.22265625,
          21.92520523071289,
          21.615968704223633,
          22.380537033081055,
          21.93305206298828,
          26.826658248901367,
          25.530948638916016,
          30.753976821899414,
          25.301218032836914,
          22.893333435058594,
          16.652057647705078,
          17.911497116088867,
          11.088906288146973,
          11.858654022216797,
          19.46277618408203,
          25.077659606933594,
          -21.105253219604492,
          -4.765673637390137,
          -16.215744018554688,
          -18.531877517700195,
          -20.236574172973633,
          -19.420827865600586,
          8.665273666381836,
          8.521773338317871,
          30.121822357177734,
          -23.05658531188965,
          30.267972946166992,
          4.255293846130371,
          18.72218132019043,
          21.974163055419922,
          30.789918899536133,
          26.96233558654785,
          13.905477523803711,
          27.238040924072266,
          10.998236656188965,
          14.86817455291748,
          28.673105239868164,
          -9.974913597106934,
          -6.042139053344727,
          12.04510498046875,
          21.116220474243164,
          -1.072331428527832,
          -0.3525199294090271,
          2.0347559452056885
         ],
         "xaxis": "x",
         "y": [
          -23.512338638305664,
          -9.927929878234863,
          -11.264511108398438,
          -11.809322357177734,
          -20.24203109741211,
          -19.45786476135254,
          -8.02220344543457,
          -7.8759636878967285,
          3.2408547401428223,
          4.784804344177246,
          -24.22610855102539,
          2.1536269187927246,
          -1.5667732954025269,
          6.147127151489258,
          -3.1672003269195557,
          -1.0437233448028564,
          0.5662394762039185,
          2.0813663005828857,
          -0.24992702901363373,
          0.18867892026901245,
          17.16855812072754,
          12.595205307006836,
          -18.845272064208984,
          8.857344627380371,
          2.657710075378418,
          29.457727432250977,
          -19.09119987487793,
          -29.143613815307617,
          14.372268676757812,
          -29.740657806396484,
          21.885705947875977,
          -29.767026901245117,
          2.30243182182312,
          -23.67620086669922,
          3.6692235469818115,
          2.5180299282073975,
          -3.022082567214966,
          -2.838419198989868,
          -3.3752665519714355,
          -3.2454519271850586,
          -2.521371841430664,
          -7.995878219604492,
          -15.380903244018555,
          13.871846199035645,
          14.12979507446289,
          17.236555099487305,
          -7.91709041595459,
          27.782859802246094,
          17.18794059753418,
          -0.6858086585998535,
          17.942296981811523,
          18.675308227539062,
          21.55746078491211,
          18.70567512512207,
          32.534114837646484,
          35.15836715698242,
          34.420005798339844,
          33.58842468261719,
          35.625247955322266,
          36.352054595947266,
          36.560142517089844,
          33.39950180053711,
          16.674684524536133,
          16.54842758178711,
          15.888409614562988,
          32.80303192138672,
          32.10834503173828,
          14.907234191894531,
          35.453067779541016,
          26.94508171081543,
          24.41753387451172,
          37.268646240234375,
          39.169288635253906,
          23.30902671813965,
          24.53827476501465,
          24.30595588684082,
          32.227474212646484,
          15.369223594665527,
          31.337453842163086,
          24.352479934692383,
          27.63218879699707,
          27.597810745239258,
          30.13715362548828,
          26.654315948486328,
          27.83939552307129,
          35.426937103271484,
          27.32693862915039,
          29.140766143798828,
          28.21382713317871,
          31.248762130737305,
          29.799558639526367,
          24.53527069091797,
          25.523447036743164,
          28.98262596130371,
          29.967012405395508,
          27.92823028564453,
          30.5506534576416,
          22.873226165771484,
          30.858972549438477,
          30.070993423461914,
          23.04442024230957,
          24.649248123168945,
          24.192720413208008,
          -5.566423416137695,
          -15.178336143493652,
          -14.813576698303223,
          -9.954675674438477,
          11.347586631774902,
          10.073570251464844,
          10.739107131958008,
          25.958513259887695,
          25.89413833618164,
          10.289554595947266,
          -23.658292770385742,
          10.486570358276367,
          31.9754638671875,
          6.1996049880981445,
          20.902149200439453,
          4.25954532623291,
          4.356630325317383,
          -7.580729961395264,
          12.301108360290527,
          15.275203704833984,
          -4.044710159301758,
          -0.8879731893539429,
          2.603336811065674,
          -8.86091136932373,
          2.4969124794006348,
          17.168901443481445,
          13.043292999267578,
          12.260711669921875,
          21.956806182861328
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "2005.14187",
           "We propose Hardware-Aware Transformers (HAT) framework to solve the challenge of efficient deployments of Transformer models on various hardware platforms"
          ],
          [
           "2005.14187",
           "We conduct hardware-aware neural architecture search in an ample design space with an efficient weight-shared SuperTransformer, consuming four orders of magnitude less cost than the prior Evolved Transformer, and discover high-performance low-latency models"
          ],
          [
           "2005.14187",
           "We hope HAT can open up an avenue towards efficient Transformer deployments for real-world applications."
          ],
          [
           "2010.02591",
           "In this paper, we explore a novel problem of conditional graph modification, in which a system needs to modify a source graph according to a modification command"
          ],
          [
           "2010.02591",
           "Our best system, which is based on graph-conditioned transformers and cross-attention information fusion, outperforms strong baselines adapted from machine translations and graph generations"
          ],
          [
           "2010.02591",
           "The code and datasets will be released to encourage further research in this direction."
          ],
          [
           "2209.08016",
           "MWE detection has significant importance in many NLP applications, especially in translation and terminology studies"
          ],
          [
           "2209.08016",
           "In this paper, we focus on an empirical analysis of multiple neural transformer models in the MWE detection task using a flowers and plants dataset"
          ],
          [
           "2209.08016",
           "In the future, we would like to explore more specific domains similar to flower and plant names"
          ],
          [
           "2209.08016",
           "It would be interesting to study how MWEs detection works in different languages with different flower and plant names"
          ],
          [
           "2209.08016",
           "We are encouraged to explore cross-lingual models more in this regard to understand how well these models perform across languages on the MWEs detection task for similar datasets."
          ],
          [
           "2004.13310",
           " and Future Work In this paper, we presented a novel cross-lingual position encoding to augment SANs by considering cross-lingual information (i.e., reordering indices) for the input sentence"
          ],
          [
           "2004.13310",
           "We designed two strategies to integrate it into SANs"
          ],
          [
           "2004.13310",
           "In the future, we plan to extend the cross-lingual position encoding to non-autoregressive MT [11] and unsupervised NMT [16]."
          ],
          [
           "1610.09893",
           "and future work In this work, we have proposed a novel algorithm, LightRNN, for natural language processing tasks"
          ],
          [
           "1610.09893",
           "Through the 2-Component shared embedding for word representations, LightRNN achieves high efficiency in terms of both model size and running time, especially for text corpora with large vocabularies"
          ],
          [
           "1610.09893",
           "There are many directions to explore in the future"
          ],
          [
           "1610.09893",
           "First, we plan to apply LightRNN on even larger corpora, such as the ClueWeb dataset, for which conventional RNN models cannot be fit into a modern GPU"
          ],
          [
           "1610.09893",
           "Second, we will apply LightRNN to other NLP tasks such as machine translation and question answering"
          ],
          [
           "1610.09893",
           "Third, we will explore $k$ -Component shared embedding ($k>2$ ) and study the role of $k$  in the tradeoff between efficiency and effectiveness"
          ],
          [
           "1610.09893",
           "Fourth, we are cleaning our codes and will release them soon through CNTK [27]."
          ],
          [
           "2212.02437",
           "We investigate the choice of in-context examples selection for MT in both in-domain and out-of-domain settings"
          ],
          [
           "2212.02437",
           "We propose a novel recall-based re-ranking approach to utilize similar training examples as prompts and show their efficacy across multiple datasets and domains"
          ],
          [
           "1908.09716",
           "In this work, we develop a simple and effective statistical method called uniblock"
          ],
          [
           "1908.09716",
           "Using Unicode block information as feature vectors, a GMM is estimated with variational inference on some clean corpus, which can then be used to score and filter corpus"
          ],
          [
           "1908.09716",
           "We release our implementation which supports parallel corpus filtering and different thresholding"
          ],
          [
           "2010.02789",
           "We explore arbitrary-order models with different neural parameterizations on sequence labeling tasks via energy-based inference networks"
          ],
          [
           "2010.02789",
           "This approach achieve substantial improvement using high-order energy terms, especially in noisy data conditions, while having same decoding speed as simple local classifiers."
          ],
          [
           "2103.11072",
           "This paper focused on the local interpretable methods commonly used for natural language processing models"
          ],
          [
           "2103.11072",
           "For each method type, we have also briefly outlined common datasets used for different NLP tasks and different evaluation methods for examining the validity and efficacy of the explanations provided."
          ],
          [
           "2108.02170",
           "Your conclusion here"
          ],
          [
           "1707.06971",
           "We have proposed a new sentence simplification task which we call “Split-and-Rephrase”"
          ],
          [
           "1707.06971",
           "We have constructed a new corpus for this task which is built from readily-available data used for NLG (Natural Language Generation) evaluation"
          ],
          [
           "1707.06971",
           "In future work, it would be interesting to see whether and if so how, sentence splitting can be learned in the absence of explicit semantic information in the input"
          ],
          [
           "1707.06971",
           "Another direction for future work concerns the exploitation of the extended WebNLG corpus"
          ],
          [
           "1707.06971",
           "While the results presented in this paper use a version of the WebNLG corpus consisting of 13,308 MR-Text pairs, 7049 distinct MRs and 8 DBpedia categories, the current WebNLG corpus encompasses 43,056 MR-Text pairs, 16,138 distinct MRs and 15 DBpedia categories"
          ],
          [
           "1707.06971",
           "We plan to exploit this extended corpus to make available a correspondingly extended WebSplit corpus, to learn optimised Split-and-Rephrase models and to explore sentence fusion (converting a sequence of sentences into a single complex sentence)."
          ],
          [
           "2110.07205",
           "and Future Work In this paper, we have presented SpeechT5 as a pre-trained encoder-decoder model for various spoken language tasks"
          ],
          [
           "2110.07205",
           "We convert all spoken language processing tasks into a speech/text to speech/text format, and propose a novel joint pre-training method to utilize cross-modal information by leveraging the unlabeled speech and text data"
          ],
          [
           "2110.07205",
           "Our unified model can support both spoken language understanding and generation tasks, such as speaker identification and voice conversion"
          ],
          [
           "2110.07205",
           "For future work, we plan to investigate more efficient pre-training methods, such as waveform learning representation via masked prediction like Hubert [18], aligning text token and phoneme explicitly as unsupervised ASR [2]"
          ],
          [
           "2110.07205",
           "Besides, we will pre-train the SpeechT5 with a larger model and more unlabeled data, and fine-tune it on more spoken language processing tasks"
          ],
          [
           "2110.07205",
           "We are also interested in extending the proposed SpeechT5 framework to address the multilingual spoken language processing problem."
          ],
          [
           "1801.05568",
           "This system is capable to autonomously view an image and generate a reasonable description in natural language with better accuracy and naturalness."
          ],
          [
           "2104.03391",
           "We propose an unsupervised model for metaphor interpretation based on BERT and WordNet, yielding large gains against the baseline on metaphor paraphrasing tasks"
          ],
          [
           "2104.03391",
           "In future work, we will test our model on other downstream tasks."
          ],
          [
           "2010.01554",
           "The candidate sentences are then provided to native speakers to validate if they are translation pairs"
          ],
          [
           "2010.01554",
           "This way, the task of translation is carried out as an annotation task"
          ],
          [
           "2010.01554",
           "Our corpus contains 12,327 Sorani-Kurmanji, 1,797 Kurmanji-English and 650 Sorani-English translation pairs"
          ],
          [
           "2204.09269",
           "and Outlooks This paper reviews the development of non-autoregressive methods in neural machine translation and other related tasks"
          ],
          [
           "2204.09269",
           "We first summarize the main challenge encountered in NAT research"
          ],
          [
           "2204.09269",
           "Then, we structure existing solutions from different perspectives, including data manipulation, modeling, criterion, decoding, and benefiting from pre-trained models, along with a discussion on their effectiveness and inference speed"
          ],
          [
           "2204.09269",
           "Besides, we present an overview of the applications of NAR methods in extensive tasks, e.g., summarization, semantic parsing, text to speech, and speech translation"
          ],
          [
           "2204.09269",
           "We hope this survey can help researchers and engineers better understand the non-autoregressive techniques and choose suitable strategies for their application tasks"
          ],
          [
           "2204.09269",
           "Although impressive progress has been made on non-autoregressive models, there still exist some open problems:  KD is the most effective method utilized in NAR models, which depends on pre-training an AR model in advance"
          ],
          [
           "2204.09269",
           "However, how to release this condition and improve the performance of NAR models on raw datasets are worthy of further consideration"
          ],
          [
           "2204.09269",
           "Iterative-based models achieve comparable performance with AR models, with extra computation cost"
          ],
          [
           "2204.09269",
           "Therefore, more attention should be paid to improving the performance of fully NAR models"
          ],
          [
           "2204.09269",
           "Although existing length prediction strategies can achieve appealing performance on many tasks with easy-to-learn alignment patterns, the fixed target length damages their flexibility in generation, which may prevent the further application of NAR methods on extensive tasks, e.g., various open-ended generation tasks with a wide dynamic range for the target length"
          ],
          [
           "2204.09269",
           "As a result, dynamic length prediction mechanisms are expected when introducing NAR methods to more tasks"
          ],
          [
           "2204.09269",
           "AR models are generally applied to various application scenarios, including bilingual and multilingual, high-resource and low-resource, etc"
          ],
          [
           "2204.09269",
           "However, most applications of NAR models are limited to the bilingual scenario until now"
          ],
          [
           "2204.09269",
           "Therefore, to expand the impact of NAR models, it is worthy of applying NAR to more application scenarios"
          ],
          [
           "2204.09269",
           "In recent years, considerable efforts have been made to enhance auto-regressive models with powerful pre-training techniques and models, with impressive performance being achieved"
          ],
          [
           "2204.09269",
           "However, only very few papers apply these powerful pre-trained models to help NAR models [80], [101], and there is only a preliminary exploration of the pre-training techniques for NAR models [105], [40]"
          ],
          [
           "2204.09269",
           "Thus, it is promising to explore pre-training methods for non-autoregressive generation and other related tasks."
          ],
          [
           "2210.00613",
           "n: Quine and Kaplan on the insignificance of ‘nine’ in ‘canine’ Words can be split into smaller segments in different ways"
          ],
          [
           "2210.00613",
           "Some of them are illustrated below:  Table: NO_CAPTION(1a) is a typical case of morphemic segmentation dividing words into morphemes, the smallest units of meaning contributing to the whole according to the rules of morphosemantics"
          ],
          [
           "2210.00613",
           "The segments in (1b – 1d), on the other hand, cut across morpheme boundaries and are, in this sense, accidental"
          ],
          [
           "2210.00613",
           "(1e) is the limit case of purely orthographic or character segmentation which appears to have nothing to do with semantics"
          ],
          [
           "2210.00613",
           "The contexts in which they appear are usually deemed to be semantically opaque"
          ],
          [
           "2210.00613",
           "Cases like (1b), (1c), and (1e) were made famous by  and "
          ],
          [
           "2210.00613",
           "Quine drew a stark contrast between the occurrence of singular terms like ‘nine’ in semantically transparent contexts such as (2)        Nine is greater than seven"
          ],
          [
           "2210.00613",
           "and in modal and propositional-attitude contexts, which he regarded as hopelessly opaque due to their resistance to substitution and existential generalization: (3)        Necessarily, nine is greater than seven"
          ],
          [
           "2210.00613",
           "Kaplan’s approach, in contrast, was more optimistic"
          ],
          [
           "2210.00613",
           "Getting inspiration from Frege’s notion of referential shift , he took the occurrences of ‘nine’ in (3) and (4) to be fully transparent but denoting, not the number nine, but themselves (i.e"
          ],
          [
           "2210.00613",
           "the expression ‘nine’, as in ), or their sense (in his version of intensional logic)"
          ],
          [
           "2210.00613",
           "With the aid of additional resources this allows one to make full sense of (3) – (6): ($3^\\prime $ )        $ \\exists \\alpha (\\Delta (\\alpha , \\text{nine}) $  & N $\\alpha \\hspace{3.0pt} \\text{is greater than five} $ )"
          ],
          [
           "2210.00613",
           "($4^\\prime $ )        $ \\exists \\alpha (\\Delta (\\alpha , \\text{nine}) $  & Frank B $\\alpha \\hspace{3.0pt} \\text{is greater than five}$ )"
          ],
          [
           "2210.00613",
           "($5^\\prime $ )        $ \\exists \\beta (\\Delta (\\beta , \\text{nine}) $  & $\\lnot $  Frank B $\\beta \\hspace{3.0pt} \\text{is greater than five} $ )"
          ],
          [
           "2210.00613",
           "($6^\\prime $ )        $ \\exists x \\hspace{3.0pt} (x \\hspace{3.0pt} \\text{is a number} \\hspace{3.0pt} \\wedge \\hspace{3.0pt}\\exists \\alpha (\\Delta (\\alpha , x) \\hspace{3.0pt} \\wedge $  Frank B $\\alpha \\text{ is greater than five}$ ))"
          ],
          [
           "2210.00613",
           "where $\\alpha $  and $\\beta $  range over expressions, ‘N’ and ‘B’ are sentential analogs of the necessity and belief operators, and ‘$\\Delta $ ’ is Church’s denotation predicate adapted by Kaplan"
          ],
          [
           "2210.00613",
           "One can fully expect all of $(3^\\prime )$  – $(6^\\prime )$  to be true"
          ],
          [
           "2210.00613",
           "As Kaplan notes , this is only the first step in a good, Fregean direction, ripe with insight"
          ],
          [
           "2210.00613",
           "And his early response to Quine is just the tip of an iceberg.I.e"
          ],
          [
           "2210.00613",
           "the ongoing debate on propositional attitude reports"
          ],
          [
           "2210.00613",
           "For a recent overview, see "
          ],
          [
           "2210.00613",
           "I began with this classic exchange because it provides a useful background and a point of reference for my case study"
          ],
          [
           "2210.00613",
           "To paraphrase Kaplan, semantic concerns — substitution, existential generalization, and contribution to the meaning of the whole — are simply inappropriate to (1b – 1e) alike.Presumably, neither Quine nor Kaplan would object to a standard morphosemantic analysis of (1a).,Quine’s take on character segmentation such as (1e) is notable in the present context"
          ],
          [
           "2210.00613",
           "I revisit character segmentation in Section  REF This seems to be a reasonable common ground"
          ],
          [
           "2210.00613",
           "Maybe the atomic unit of language should be just the consonants and vowels, or in their written form, a character in the writing system — a letter in Latin script, a logograph or just a stroke in Chinese"
          ],
          [
           "2210.00613",
           "Koehn is speaking of the semantic import of the intermediate hidden vector representation of subword pieces and separate characters, such as (1a – 1e) above, not simply of their initial encoding in the form of useful numerical indices"
          ],
          [
           "2210.00613",
           "Such claims require careful examination, and the devil may be in the details"
          ],
          [
           "2210.00613",
           "Language translation, I submit, is a natural place to examine them"
          ],
          [
           "2210.00613",
           "I return to the relationship between translation and meaning at the end of the paper"
          ],
          [
           "2210.00613",
           "Thinkers as different as Schleiermacher, Heidegger, Benjamin, Quine, and Davidson approached this idea from rather different angles.For recent discussions of their views on translation, see "
          ],
          [
           "2210.00613",
           "put it in a slogan: The meaning of any linguistic sign is its translation into some further, alternative sign"
          ],
          [
           "2210.00613",
           "But this is just a starting point"
          ],
          [
           "2210.00613",
           "‘dog$\\vert $ s’ is translated as chien$\\vert $ s or chien$\\vert $ nes, and ‘kick the bucket’ as casser sa pipe (break his pipe)"
          ],
          [
           "2210.00613",
           "Signs, or semantic atoms, therefore, may be word-internal functional morphemes such as ‘-s’, or entire idiomatic phrases; they may be smaller or larger than words"
          ],
          [
           "2210.00613",
           "In a broader perspective, different languages describe (model, represent) the extra-linguistic reality (i.e"
          ],
          [
           "2210.00613",
           "who did what to whom) in very different ways reflected in numerous and often crosscutting typologies"
          ],
          [
           "2210.00613",
           "both lexical and functional morphemes):Examples from  and "
          ],
          [
           "2210.00613",
           "Table: Concluding remarks"
          ],
          [
           "1503.06733",
           "and Future Work We presented an introduction to our open-source dependency parser"
          ],
          [
           "1503.06733",
           "This parser can also be used for non-projective languages with a very slight loss in performance"
          ],
          [
           "1503.06733",
           "Our future plans include extending this parser to handle non-projectivity and also use continuous value representation features such as word embeddings to improve the accuracy of the parser."
          ],
          [
           "1909.13104",
           "- Future work We present an attention-based approach for the detection of harassment language in tweets and the detection of different types of harassment as well"
          ],
          [
           "1909.13104",
           "Our approach is based on the Recurrent Neural Networks and particularly we are using a deep, classification specific attention mechanism"
          ],
          [
           "1909.13104",
           "Moreover, we present a comparison between different variations of this attention-based approach and a few baseline methods"
          ],
          [
           "1909.13104",
           "Also, we tackled the problem of the imbalance between the training, validation and test sets performing the technique of back-translation"
          ],
          [
           "1909.13104",
           "In the future, we would like to perform more experiments with this dataset applying different models using BERT [22]"
          ],
          [
           "1909.13104",
           "Also, we would like to apply the models presented in this work, in other datasets about hate speech in social media."
          ],
          [
           "2103.16590",
           "and Future Work We introduced l'ambre, a framework to evaluate grammatical acceptability of text by verifying morphosyntactic rules over dependency parse trees"
          ],
          [
           "2103.16590",
           "We presented a method to automatically extract such rules for many languages along with a method to train robust parsing models which facilitate better verification of these rules on natural language text"
          ],
          [
           "2103.16590",
           "We showed an application of l'ambre on the popular generation task of machine translation"
          ],
          [
           "2103.16590",
           "For future work, we identify two main areas of interest"
          ],
          [
           "2103.16590",
           "Firstly, the grammatical rule sets can be expanded to include other morphosyntactic rules (e.g"
          ],
          [
           "2103.16590",
           "word order), automatically extracted or hand-crafted ones a la [31]"
          ],
          [
           "2103.16590",
           "This would allow for even more in-depth analysis of NLG systems"
          ],
          [
           "2002.10941",
           "Neural network (NN) has been a popular target for hardware accelerators for its wide applicability, a large amount of computation, massive parallelism, and static computation pattern"
          ],
          [
           "2002.10941",
           "However, the presence of an existing accelerator does not necessarily preclude the need for an another accelerator for NN primitives"
          ],
          [
           "2002.10941",
           "In fact, when other NN primitives (e.g., CNNs, RNNs) are optimized, it is critical to accelerate relatively less optimized portion according to Amdahl's Law"
          ],
          [
           "2006.01175",
           "and Conclusion Code-switching provides many challenges for natural language processing systems"
          ],
          [
           "2006.01175",
           "In this work we attempt to overcome some of these challenges by identifying the word level language labels and normalizing the data"
          ],
          [
           "2006.01175",
           "To evaluate for all these tasks, we use an Indonesian-English dataset [8] as well as a German-Turkish dataset, for which we provide novel layers adapted for normalization, and LID and POS annotation mappings for these new layers"
          ],
          [
           "2006.01175",
           "For the language identification, we examine three different sequence prediction models"
          ],
          [
           "2006.01175",
           "Somewhat unsurprisingly, a BERT tagger outperforms a BiLSTM tagger, which in turn outperformed a CRF tagger"
          ],
          [
           "2006.01175",
           "For the normalization, we introduced three different models to process code-switched data"
          ],
          [
           "2006.01175",
           "The first method splits the data into monolingual fragments before normalizing it, and thus uses monolingual normalization models"
          ],
          [
           "2006.01175",
           "The second model did not use any explicit language labels, and just modeled all language specific features twice"
          ],
          [
           "2006.01175",
           "The third model instead only generated features for the language of the current token"
          ],
          [
           "2006.01175",
           "In general, the best performance was achieved by the last model (except for the Tr-De test data), because it combines a small feature-space while also modeling language-specific features"
          ],
          [
           "2006.01175",
           "In general all models outperform the baselines as well as the monolingual models (trained on the same data)"
          ],
          [
           "2006.01175",
           "These models could potentially also be trained by mixing two monolingual normalization datasets (resulting in a dataset with only intersentential code-switching), and then be used on intrasentential CS data"
          ],
          [
           "2006.01175",
           "This approach enables a much wider use case; with the seven languages used in  [41] this would enable training of a code-switched model for 21 language pairs (however, for evaluation, a CS normalization annotated dataset is necessary)"
          ],
          [
           "2006.01175",
           "We expect the model to perform rather well; it is not heavily dependent on context, and perhaps synthetic intrasentential code-switched data can be generated to improve the performance even further"
          ],
          [
           "2006.01175",
           "The Tr-De dataset is available on www.github.com/ozlemcek/TrDeNormData Source code for the experiments can be found on www.bitbucket.org/robvanderg/codeswitchmonoise"
          ],
          [
           "2210.05404",
           "This work explores building bilingual and multilingual translation systems between spoken and signed languages"
          ],
          [
           "2210.05404",
           "Instead of representing sign language as videos (or as continuous features derived from videos) common in previous research, we propose to represent sign language in SignWriting, a sign language writing system"
          ],
          [
           "2210.05404",
           "However, encoding or decoding SignWriting in an MT system requires specialized tools"
          ],
          [
           "2210.05404",
           "Therefore, we propose novel methods to parse, factorize, decode, and evaluate SignWriting sequences"
          ],
          [
           "2210.05404",
           "Our factorization technique divides SignWriting sequences into meaningful units such as sign symbols and positional numbers"
          ],
          [
           "2210.05404",
           "The factors are then encoded or decoded by a factored Transformer model"
          ],
          [
           "2210.05404",
           "As a result, we achieve over 30 BLEU in the bilingual setting and over 20 BLEU for some high-resource language pairs in both directions in the multilingual setting"
          ],
          [
           "2210.05404",
           "Using SignWriting as an intermediate representation enables us to reuse tools (e.g., evaluation metrics) from spoken language translation"
          ],
          [
           "2210.05404",
           "We also observe striking similarities to spoken language MT in the experiments themselves"
          ],
          [
           "2210.05404",
           "For example, low-resource optimizations have a similar impact, and multilingual models exhibit similar transfer effects"
          ],
          [
           "2205.08001",
           "In this work, we remove translationese artifacts by extending the debiasing INLP approach at both word and sentence level"
          ],
          [
           "2205.08001",
           "Our word-based debiasing study provides a systematic view of translationese biases contained in static embeddings"
          ],
          [
           "2205.08001",
           "We also explore translationese debiasing at sentence level embeddings computed from contextualised word embeddings"
          ],
          [
           "2205.08001",
           "Further, we evaluate the effects of debiasing translation artifacts on a standard NLI task in two settings"
          ],
          [
           "2205.08001",
           "We hope to account for this in future work."
          ],
          [
           "1803.03585",
           "and Conclusion We have compared a recurrent architecture (LSTM) to a non-recurrent one (FAN) with respect to the ability of capturing the underlying hierarchical structure of sequential data"
          ],
          [
           "1803.03585",
           "In fact, both FAN- and CNN-based networks have proved to perform comparably or better than LSTM-based ones on a very complex task like machine translation [7], [18]"
          ],
          [
           "2102.00287",
           " In this work, we explore the effects of MT algorithms on the richness and complexity of language"
          ],
          [
           "2102.00287",
           "Assessing diversity or richness in language is a multifacted task spanning over various domains"
          ],
          [
           "2102.00287",
           "As such, we approach this task from multiple angles focusing on lexical diversity and sophistication, morphological variety and a more translation specific metric focusing on synonymy"
          ],
          [
           "2102.00287",
           "To do so, we analyse the results of 9 different metrics including established, newly proposed and adapted ones"
          ],
          [
           "2102.00287",
           "The metrics suit we developed is unprecedented in the study of MT quality and we believe it could drive future research on MT evaluation"
          ],
          [
           "1811.05544",
           "and Prospects In this paper, we have surveyed through recent works on the attention mechanism and conducted an introductory summary based on its formulation, variation, application and evaluation"
          ],
          [
           "1811.05544",
           "Compared to its wide usage in various NLP tasks, attempts to explore its mathematical justification still remain scarce"
          ],
          [
           "1906.00378",
           "In this paper, we address the problem of bilingual lexicon induction without reliance on parallel corpora"
          ],
          [
           "1906.00378",
           "images) as pivot, we propose a new vision-based approach to induce bilingual lexicon with images and their associated sentences"
          ],
          [
           "1906.00378",
           "We build a multi-lingual caption model from multiple mono-lingual multimodal data to map words in different languages into joint spaces"
          ],
          [
           "1906.00378",
           "Two types of word representation, linguistic features and localized visual features, are induced from the caption model"
          ],
          [
           "1906.00378",
           "The two types of features are complementary for word translation"
          ],
          [
           "1906.00378",
           "In the future, we will further expand the vision-pivot approaches for zero-resource machine translation without parallel sentences."
          ],
          [
           "2107.06055",
           "s to this document This document was adapted by Lillian Lee and Kristina Toutanova from the instructions and files for ACL 2018, by Shay Cohen, Kevin Gimpel, and Wei Lu"
          ],
          [
           "2107.06055",
           "Those files were drawn from earlier *ACL proceedings, including those for ACL 2017 by Dan Gildea and Min-Yen Kan, NAACL 2017 by Margaret Mitchell, ACL 2012 by Maggie Li and Michael White, those from ACL 2010 by Jing-Shing Chang and Philipp Koehn, those for ACL 2008 by Johanna D"
          ],
          [
           "2107.06055",
           "Moore, Simone Teufel, James Allan, and Sadaoki Furui, those for ACL 2005 by Hwee Tou Ng and Kemal Oflazer, those for ACL 2002 by Eugene Charniak and Dekang Lin, and earlier ACL and EACL formats, which were written by several people, including John Chen, Henry S"
          ],
          [
           "2107.06055",
           "Thompson and Donald Walker"
          ],
          [
           "2107.06055",
           "Additional elements were taken from the formatting instructions of the International Joint Conference on Artificial Intelligence and the Conference on Computer Vision and Pattern Recognition."
          ],
          [
           "1805.11224",
           "In this paper, we study knowledge distillation for search-based structured prediction and propose to distill an ensemble into a single model both from reference and exploration states"
          ],
          [
           "1911.03627",
           "We have presented a new method for modeling the copying mechanism for automatic post-editing"
          ],
          [
           "1911.03627",
           "By making the source sentence and machine translation attend to each other, representations learned in such an interactive way help to identify whether a target word should be copied or be re-generated"
          ],
          [
           "2207.03169",
           "The proposed model can utilize acoustic information for punctuation prediction and can be robust against ASR errors and segmentation errors"
          ],
          [
           "2207.03169",
           "In addition, we showed the effectiveness of using an auxiliary loss using unpunctuated texts for the output of the intermediate layer"
          ],
          [
           "2207.03169",
           "Our approach also has advantages in terms of inference speed and the simplicity of its architecture"
          ],
          [
           "2207.03169",
           "In the future, we plan to study the improvement of the proposed model using different architectures and its application to real-time speech recognition."
          ],
          [
           "2203.13291",
           "One important aspect of our approach is the use of explicit fingerspelling detection within the model"
          ],
          [
           "2203.13291",
           "An interesting avenue for future work is to address the case where the training data does not include segment boundaries for detector training"
          ],
          [
           "2203.13291",
           "Finally, a complete sign language search system should consider both fingerspelling and lexical sign search."
          ],
          [
           "2205.05901",
           "and Future work In this paper, we attempted to find gender stereotypes on occupations and emotions and tried to debias them"
          ],
          [
           "2205.05901",
           "Embedding Coherence Test and Relative Norm Distance were used as a bias metric in the gender subspace"
          ],
          [
           "2205.05901",
           "The debiasing methods used were projection and partial projection"
          ],
          [
           "2205.05901",
           "Future work could include trying out these techniques on downstream tasks and checking the performance before and after debiasing"
          ],
          [
           "2205.05901",
           "The main problem with experimenting on downstream tasks is the availability of datasets in these languages"
          ],
          [
           "2205.05901",
           "We would also like to experiment with debiasing contextual embeddings and large language models"
          ],
          [
           "1809.06858",
           "This makes learned word embeddings ineffective, especially for rare words, and consequently limits the performance of these neural network models"
          ],
          [
           "1809.06858",
           "We propose a neat, simple yet effective adversarial training method to improve the model performance which is verified in a wide range of tasks"
          ],
          [
           "1809.06858",
           "We will explore several directions in the future"
          ],
          [
           "1809.06858",
           "First, we will investigate the theoretical aspects of word embedding learning and our adversarial training method"
          ],
          [
           "1809.06858",
           "Second, we will study more applications which have the similar problem even beyond NLP."
          ],
          [
           "1810.12546",
           "and Future Work This paper has presented a twin-gated recurrent network (ATR) to simplify neural machine translation"
          ],
          [
           "1810.12546",
           "There are only two weight matrices and matrix transformations in recurrent units of ATR, making it efficient in physical memory usage and running speed"
          ],
          [
           "1810.12546",
           "To avoid the gradient vanishing problem, ATR introduces a twin-gated mechanism to generate an input gate and forget gate through linear addition and subtraction operation respectively, without introducing any additional parameters"
          ],
          [
           "1810.12546",
           "Experiments on English-German and English-French translation tasks demonstrate the effectiveness of our model"
          ],
          [
           "1810.12546",
           "It is also able to transparently model long-distance dependencies"
          ],
          [
           "1810.12546",
           "We also adapt our ATR to other natural language processing tasks"
          ],
          [
           "1810.12546",
           "Experiments show encouraging performance of our model on Chinese-English translation, natural language inference and Chinese word segmentation, demonstrating its generality and applicability on various NLP tasks"
          ],
          [
           "1810.12546",
           "In the future, we will continue to examine the effectiveness of ATR on different neural models for NMT, such as the hierarchical NMT model [29] as well as the generative NMT model [28]"
          ],
          [
           "1810.12546",
           "We are also interested in adapting our ATR to summarization, semantic parsing etc."
          ],
          [
           "2204.00004",
           "We investigated reproducibility for BERT-based evaluation metrics, finding several problematic aspects, including using heavy undocumented preprocessing, reporting lower scores for competitors, selective evaluation on datasets, and copying correlation scores from wrong indices"
          ],
          [
           "2204.00004",
           "To better compare the effect of aggregation schemes on top of BERT, we recommend to minimize its role in the future, and employ uniform preprocessing across metrics"
          ],
          [
           "2204.00004",
           "On the positive side, as authors are nowadays much more willing to publish their resources, it is considerably easier to spot such problems, which may also be one reason why critique papers such as ours have become more popular in the last few years [4]"
          ],
          [
           "2204.00004",
           "In a wider context, our paper contributes to addressing the “cracked foundations” of evaluation for text generation [22] and to better understanding their limitations [28]"
          ],
          [
           "2204.00004",
           "In the future, we would like to reproduce more recent BERT-based metrics (e.g., with other aggregation mechanisms [10], [43], normalization schemes [56] or different design choices [54]) to obtain a broader assessment of reproducibility issues in this context"
          ],
          [
           "2204.00004",
           "We would also like to quantify, at a larger scale, the bias in research induced from overestimating one's own model vis-à-vis competitor models."
          ],
          [
           "2008.01391",
           "In this work, we presented a review of the current state-of-the-art in machine translation utilising orthographic information, covering rule-based machine translation, statistical machine translation, neural machine translation and unsupervised machine translation"
          ],
          [
           "2008.01391",
           "As a part of this survey, we introduced different machine translations methods and have shown how orthography played a role in machine translation results"
          ],
          [
           "2008.01391",
           "For the rule-based machine translation, translation between the closely related language is simplified to transliteration due to the cognates"
          ],
          [
           "2008.01391",
           "Statistical machine translation deals with data sparsity problem by using orthographic information"
          ],
          [
           "2008.01391",
           "Since statistical machine translation has been studied a long time, most of the orthographic properties are studies for different types of languages"
          ],
          [
           "2008.01391",
           "Recent neural machine translation is completely end-to-end, however, it suffers from data sparsity when dealing with morphologically rich languages or under-resourced languages"
          ],
          [
           "2008.01391",
           "These issues are dealt by utilising orthographic information in neural machine translation"
          ],
          [
           "2008.01391",
           "One such method which improves the translation is a transliteration of cognates"
          ],
          [
           "2008.01391",
           "Code-switching is another issue with under-resourced languages due to the data collected from voluntary annotator, web crawling or other such methods"
          ],
          [
           "2008.01391",
           "However, dealing with code-switching based on orthography or using character-based neural machine translation has been shown to improve the results significantly"
          ],
          [
           "2008.01391",
           "While exciting advances have been made in machine translation in recent years, there is still an exciting direction for exploration from leveraging linguistic information to it, such as orthographic information"
          ],
          [
           "2008.01391",
           "One such area is unsupervised machine translation or bilingual lexicon induction"
          ],
          [
           "2205.00616",
           "Our current study shows promise for advancing methodologies in informal language processing toward these avenues of future research."
          ],
          [
           "2205.10852",
           "and Future Work In this paper, we propose Relphormer for knowledge graph representation"
          ],
          [
           "2205.10852",
           "We propose Triple2Seq dynamically generating contextualized sub-graphs as input sequences and structure-enhanced self-attention to inject vital structure information"
          ],
          [
           "2205.10852",
           "Besides, we introduced masked knowledge modeling as a new paradigm for knowledge representation learning"
          ],
          [
           "2205.10852",
           "Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed Relphormer model"
          ],
          [
           "2205.10852",
           "We point out three directions for future work"
          ],
          [
           "2205.10852",
           "First, as we discussed in Section REF , Triple2Seq is a simple but effective way to consider context information to address the limitation of input length for Transformer"
          ],
          [
           "2205.10852",
           "It is worth studying what contexts play a more critical role for the triple and proposing efficient sampling strategies"
          ],
          [
           "2205.10852",
           "Second, it is a promising direction to consider leveraging more sophisticated architecture to inject structure knowledge"
          ],
          [
           "2205.10852",
           "Finally, Relphormer can also be regarded as a pre-trained model for knowledge graphs or heterogeneous graphs"
          ],
          [
           "2205.10852",
           "It is interesting to investigate its performances for specific tasks such as heterogeneous graph-based recommendation or KG-based question answering."
          ],
          [
           "2012.04955",
           "We rose to the challenge posed by bentivogli-etal-2020-gender to further explore gender translation in direct ST"
          ],
          [
           "2012.04955",
           "Going beyond direct systems' attested ability to leverage speaker's vocal characteristics from the audio input, we developed gender-aware models suitable for operating conditions where speaker's gender is known"
          ],
          [
           "2012.04955",
           "To this aim, we annotated the large MuST-C dataset with speaker's gender information, and used the new annotations to experiment with different architectural solutions: “multi-gender” and “specialized”"
          ],
          [
           "2012.04955",
           "In particular, our specialized systems outperform the gender-unaware ST models by 30 points in gender accuracy without affecting overall translation quality."
          ],
          [
           "1808.09861",
           "In this paper, we propose two methods to tackle the cross-lingual NER problem under the unsupervised transfer setting"
          ],
          [
           "1808.09861",
           "To address the challenge of lexical mapping, we find translations of words in a shared embedding space built from a seed lexicon"
          ],
          [
           "1808.09861",
           "To alleviate word order divergence across languages, we add a self-attention mechanism to our neural architecture"
          ],
          [
           "1808.09861",
           "We also evaluate the challenges of applying these methods to an extremely low-resource language, Uyghur."
          ],
          [
           "2210.15224",
           "We gathered more than 888K parallel unique sentences and applied different pre-processing techniques"
          ],
          [
           "2210.15224",
           "This is the first large-scale parallel data (more than 5 times bigger than the data in the previously conducted MT works) which can be used as a good benchmark for future machine translation research"
          ],
          [
           "2210.15224",
           "Our work will solve this issue and be used as a benchmark"
          ],
          [
           "2210.15224",
           "The morphological richness of the Amharic language and the size of the parallel dataset has a great impact on Amharic-English MT experiments"
          ],
          [
           "2210.15224",
           "For the future, we will expand this work for more languages by including other Ethiopian low-resourced languages and also use data augmentation techniques"
          ],
          [
           "2210.15224",
           "Additionally, we plan to explore the applicability of other pre-trained language models for Amharic-English translations"
          ],
          [
           "2210.15224",
           "Our dataset of parallel Amharic-English sentence pairs, the models, and pre-processing scripts will be released in the GitHub repositoryhttps://github.com/atnafuatx/EthioNMT-datasets"
          ],
          [
           "2104.04886",
           "Such a formulation induces a competition between a leader (the model) and a follower (the adversary)"
          ],
          [
           "2104.04886",
           "In SALT, the leader is in an advantageous position by recognizing the follower's strategy, and this strategic information is captured by the Stackelberg gradient"
          ],
          [
           "2104.04886",
           "We compute the Stackelberg gradient, and hence find the equilibrium of the Stackelberg game, using an unrolled optimization approach"
          ],
          [
           "2104.04946",
           "In this paper, we present an integrated dropout approach, $\\mathtt {UniDrop}$ , to specifically regularize the Transformer architecture"
          ],
          [
           "2104.04946",
           "The proposed $\\mathtt {UniDrop}$  unites three different level dropout techniques from fine-grain to coarse-grain, feature dropout, structure dropout, and data dropout respectively"
          ],
          [
           "2104.04946",
           "Further analysis also validates the effectiveness of different dropout components and our two-stage data dropout strategy"
          ],
          [
           "2104.04946",
           "In conclusion, the $\\mathtt {UniDrop}$  improves the performance and generalization of the Transformer without additional computational cost and resource requirement."
          ],
          [
           "2201.12926",
           "This method is derived from a new characterization of the principle of compositionality as a constraint on the symmetries of data distributions, and a procedure for automatically identifying these symmetries using token-level alignments"
          ],
          [
           "1906.09777",
           "and Further Work We have proposed a novel self attention encoder layer, namely the Multi-linear attention, to compress the original multi-head attention and derive a novel encoding scheme"
          ],
          [
           "1906.09777",
           "Our main contribution lies in a structure of Tensorized Transformer based on Block-Term tensor decomposition which is represented by the combination of a group of 3-order tensors, with low-rank approximation and parameters sharing ideas adopted"
          ],
          [
           "1906.09777",
           "In the future, we will continue to optimize the Tensorized Transformer framework and apply it in other NLP tasks"
          ],
          [
           "1906.09777",
           "As we stated earlier, our model may suffer from overfitting when the number of cores is large in language modeling"
          ],
          [
           "2103.00747",
           "and Future Work We built a trustworthy prediction model to debunk false claims of COVID-19 by capitalizing DistilBERT and SHAP"
          ],
          [
           "2103.00747",
           "Among the three conditions, participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition"
          ],
          [
           "2103.00747",
           "One of the limitations in building such a machine learning model is to potentially verify a large number of claims about COVID-19"
          ],
          [
           "2103.00747",
           "Our model is built on a small dataset collected by April 2020 and the COVID-19 Fake News Detection dataset [36]"
          ],
          [
           "2103.00747",
           "Thus, it might be limited to detect new misinformation related to COVID-19"
          ],
          [
           "2103.00747",
           "In order to maintain and help improve the trustworthiness of the proposed model, it is imperative to include more data as the pandemic unfolds over time, such as the COVID-19 Healthcare Misinformation Dataset [42]"
          ],
          [
           "2103.00747",
           "In addition, although BERT aims to learn contextualized representation across a wide range of NLP tasks, it is still challenging to leverage BERT (i.e., it has almost no understanding of COVID-19) without domain knowledge about COVID-19"
          ],
          [
           "2103.00747",
           "Thus, in the future we plan to increase the domain task awareness with an unsupervised training method by making use of the COVID-19 Open Research Dataset (CORD-19) and strengthen the end task awareness using supervised fine-tuning by labeling and augmenting the claims"
          ],
          [
           "2103.00747",
           "In this research, we recruited participants using AMT"
          ],
          [
           "2103.00747",
           "Therefore, the selected sample may not be well-representative of the population"
          ],
          [
           "2103.00747",
           "In addition, we were not able to calibrate participants’ political and ideological biases related to COVID-19 claims, which could potentially have a significant effect on their belief and/or disbelief in such claims, although we tried to minimize such an effect through randomly assigning participants into three conditions"
          ],
          [
           "2103.00747",
           "Future studies should include extra survey questions in order to calibrate such biases"
          ],
          [
           "2103.00747",
           "Managing the quality of the survey data from AMT was also challenging"
          ],
          [
           "2103.00747",
           "We removed the invalid participants by examining their responses on the three designed attention questions"
          ],
          [
           "2103.00747",
           "However, the quality could also be affected by the compensation rate"
          ],
          [
           "2103.00747",
           "Further investigation should include demographic factors"
          ],
          [
           "2103.00747",
           "In addition, interpreting the explanations provided by SHAP can be challenging for the first time"
          ],
          [
           "2103.00747",
           "Even though we provided a training section at the beginning of the survey, some participants found it confusing to make predictions based on individual words"
          ],
          [
           "2103.00747",
           "In the future, more intuitive explanations should be explored to better improve trust."
          ],
          [
           "2210.04141",
           "This paper presents a novel LM based aligner named Cross-Align, which models deep interactions between the input sentence pairs"
          ],
          [
           "2210.04141",
           "Cross-Align first encodes the source and target sentences separately with the shared self-attention modules in the shallow layers, then explicitly constructs cross-lingual interactions with the cross-attention modules in the upper layers"
          ],
          [
           "2210.04141",
           "Additionally, we propose a simple yet effective two-stage training framework, where the model is first trained with a simple TLM objective and then finetuned with a self-supervised alignment objective"
          ],
          [
           "2210.04141",
           "In future work, we plan to improve the alignment quality on more low-resource language pairs."
          ],
          [
           "2210.15461",
           "Then, we propose an effective LVP-M$^{3}$  baseline method for the Multilingual MMT task, where a language-aware prompt generation module is proposed to generate visual prompts for different target languages dynamically"
          ],
          [
           "2205.03666",
           "It is, therefore, important to train open-domain conversational systems on idioms data, so as to achieve diversity and more fitting responses in ml models"
          ],
          [
           "2205.03666",
           "This is especially since idioms are part of everyday speech in many cultures [8]"
          ],
          [
           "2205.03666",
           "Future efforts may be directed at exploring more datasets of figurative language or idioms and more diverse sota models for training."
          ],
          [
           "1808.01174",
           " Even though deep neural networks were shown to be a promising and powerful machine leaning tool which is highly useful in many tasks, the source of their capabilities remains somewhat elusive"
          ],
          [
           "1808.01174",
           "Deep learning models are highly expressive, over-parameterized, complex, non-convex models, which are usually trained (optimized) with a stochastic gradient method"
          ],
          [
           "1808.01174",
           "In this article we reviewed the generalization capabilities of these models, shedding light on the reasons for their ability to generalize well from the training phase to the test phase, thus maintaining a low generalization error"
          ],
          [
           "1808.01174",
           "We reviewed some of the fundamental work on this subject and also provided some more recent findings and theoretical explanations to the generalization characteristics of deep neural networks and the influence of different parameters on their performance"
          ],
          [
           "1808.01174",
           "We also reviewed various emerging open problems in deep learning, ranging from the interplay between robustness, generalization and memorization, to robustness to adversarial attacks, the generalization error of generative models and the relation between the generalization error and the information bottleneck"
          ],
          [
           "1808.01174",
           "These open problems require a deeper understanding to fully unlock the potential applicability of deep learning models in real environments"
          ],
          [
           "2109.07048",
           "We propose a new caching method to speedup the training of neural models with adversarial regularization"
          ],
          [
           "2109.07048",
           "By reusing the generated perturbations, our proposed method significantly amortizes the computational cost of the backward passes at each iteration"
          ],
          [
           "2104.07874",
           "We have outlined a new model of NLP research, Translational NLP, which aims to bridge the gap between basic and applied NLP research with generalizable principles, tools, and processes"
          ],
          [
           "2104.07874",
           "We identified key types of stakeholders in NLP applications and how they inform the translational process, and presented a checklist of common variables and translational principles to consider in basic, translational, or applied NLP research"
          ],
          [
           "1706.00878",
           "yright EMDL'17,June 23, 2017, Niagara Falls, NY, USA 978-1-4503-4962-8/17/06$15.00 http://dx.doi.org/10.1145/3089801.3089804 MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU  Qingqing CaoNiranjan BalasubramanianAruna Balasubramanian  Table: Conclusion"
          ],
          [
           "2005.06537",
           "We presented MAE"
          ],
          [
           "2005.06537",
           "It is inspired by a mixture-of-experts perspective of multi-head attention"
          ],
          [
           "2005.06537",
           "With a learned gating function, MAE activates different experts on different inputs"
          ],
          [
           "2005.06537",
           "MAE is trained using a block coordinate descent algorithm, which alternates between updating the responsibilities of the experts and their parameters"
          ],
          [
           "2005.06537",
           "The code is publicly available at https://github.com/Noahs-ARK/MAE."
          ],
          [
           "2002.02973",
           "ters In Tab"
          ],
          [
           "2002.02973",
           "REF , we present the hyperparameters used to train the RNN wave functions in this paper"
          ],
          [
           "2002.02973",
           "Seeds are listed in the table for reproducibility purposes"
          ],
          [
           "2210.03768",
           "In this work, we presented xDBTagger, the first end-to-end explainable NLIDB solution to translate NLQs into their counterpart SQLs"
          ],
          [
           "2210.03768",
           "xDBTagger is a hybrid solution taking advantage of both deep learning and rule-based approaches"
          ],
          [
           "2210.03768",
           "First, we detect keyword mappings of the tokens in the input NLQ using a novel deep learning model trained in a multi-task learning setup"
          ],
          [
           "2210.03768",
           "Next, we explain the decisions for the keyword mappings using a modified version of a state-of-the-art XAI solution LIME [33]"
          ],
          [
           "2210.03768",
           "We visually illustrate the importance of each surrounding word for each mapping by highlighting their contributions which can be either positive or negative"
          ],
          [
           "2210.03768",
           "In addition, we draw the schema graph to visualize better the database schema over which the query is issued"
          ],
          [
           "2210.03768",
           "We also color the nodes representing tables and attributes in the graph to explain how the required join conditions in the result SQL are extracted"
          ],
          [
           "2210.03768",
           "This research is supported by The Scientific and Technological Research Council of Türkiye (TÜBİTAK) under the grant no 118E724."
          ],
          [
           "1910.09329",
           " and future work Coreference Resolution is a very important part of discourse and by extension of language modelling and language understanding"
          ],
          [
           "1910.09329",
           "In order for the task to improve, the immediate need of a better way of measuring the performance is required"
          ],
          [
           "1910.09329",
           "Agreed-upon metrics and a better benchmark dataset for the evaluation of the task are sought after, as the performance of current approaches changes dramatically in out-of-domain evaluation"
          ],
          [
           "1910.09329",
           "Furthermore, the lack of a clear baseline model needs addressing as approaches are built on top of sub-par models"
          ],
          [
           "1910.09329",
           "The importance of improvements in the task can be found in its use in state-of-the-art approaches of other tasks such as Entity Linking , , Machine Translation , , , Summarization ,  and Chat Bots , "
          ],
          [
           "1910.09329",
           "This research is co-financed by Greece and the European Union (European Social Fund- ESF) through the Operational Programme “Human Resources Development, Education and Lifelong Learning” in the context of the project “Strengthening Human Resources Research Potential via Doctorate Research” (MIS-5000432), implemented by the State Scholarships Foundation (ΙΚΥ)."
          ],
          [
           "2205.02536",
           "& Conclusion We presented YOLOPose, a Transformer-based single-stage multi-object pose estimation method using keypoint regression"
          ],
          [
           "2205.02536",
           "Our model jointly estimates bounding boxes, class labels, translation vectors, and pixel coordinates of 3D keypoints for all objects in the given input image"
          ],
          [
           "2205.02536",
           "Employing the learnable RotEst module to estimate the object orientation from the predicted keypoints coordinate enables the model to be end-to-end differentiable"
          ],
          [
           "2205.02536",
           "In the future, we plan to extend our model to video sequences and exploit temporal consistency to improve the pose estimation accuracy further."
          ],
          [
           "2204.11574",
           " The reporting of metrics was partly inconsistent and partly unspecific, which may lead to ambiguities when comparing model performances, thus negatively impacting the transparency and reproducibility of NLP research"
          ],
          [
           "2204.11574",
           "Large comparative evaluation studies of different NLP-specific metrics across multiple benchmarking tasks are needed."
          ],
          [
           "2203.08459",
           "This work demonstrates the effectiveness of explicitly incorporating morphological information in language model pre-training"
          ],
          [
           "2203.08459",
           "The proposed two-tier Transformer architecture allows the model to represent morphological compositionality"
          ],
          [
           "2203.08459",
           "Experiments conducted on Kinyarwanda, a low resource morphologically rich language, reveal significant performance improvement on several downstream NLP tasks when using the proposed architecture"
          ],
          [
           "2203.08459",
           "These findings should motivate more research into morphology-aware language models."
          ],
          [
           "1606.08140",
           "and future work This paper presented a new embedding model for link prediction and KB completion"
          ],
          [
           "1606.08140",
           "Thus it is a suitable candidate for serving as future baseline for more complex models in the link prediction task"
          ],
          [
           "1606.08140",
           "In future work we plan to extend STransE to exploit relation path information in knowledge bases, in a manner similar to lin-EtAl:2015:EMNLP1, guu-miller-liang:2015:EMNLP or NguyenCoNLL2016."
          ],
          [
           "2203.02982",
           "and Discussion Implicit discourse relation recognition is to detect relations and classify their senses in between arguments without explicit connectives"
          ],
          [
           "2203.02982",
           "As a crucial task in the NLP field, the IDRR task has been intensively researched in the last decade"
          ],
          [
           "2203.02982",
           "This article has presented a comprehensive survey for the IDRR task, including the task definitions, common datasets, solution approaches and performance comparisons"
          ],
          [
           "2203.02982",
           "We have adopted the mostly researched PDTB corpus and its task definition to review three main groups of almost all solutions proposed in the literature"
          ],
          [
           "2203.02982",
           "Those machine learning solutions manually design many features by domain experts to train classifiers; Those deep learning solutions design neural networks with different architectures to enable a kind of end-to-end relation recognition without manual feature construction"
          ],
          [
           "2203.02982",
           "Both ML and DL solutions require large amounts of labeled training data; While semi-supervised approaches apply data expansion techniques to augment model training to deal with the data sparsity problem"
          ],
          [
           "2203.02982",
           "The challenge of the IDRR task mainly lies in the absence of explicit connectives in raw texts"
          ],
          [
           "2203.02982",
           "If explicit connectives exists in raw texts, Pilter et al"
          ],
          [
           "2203.02982",
           "(2008) [107] have reported as high as 93% relation recognition accuracy; While the most advanced neural models can only achieve about 80% recognition accuracy in the IDRR task"
          ],
          [
           "2203.02982",
           "Lin et al"
          ],
          [
           "2203.02982",
           "[80] summarized four reasons for the poor performance, namely, ambiguity between relations, inference, contextual modeling and world knowledge"
          ],
          [
           "2203.02982",
           "In what follows, we discuss possible future research directions for the IDRR task."
          ],
          [
           "2110.02869",
           " In this work, we presented a method to perform lexical normalization by fine-tuning a multilingual machine translation model on pairs of noisy and normalized sentences from various languages"
          ],
          [
           "2110.02869",
           "We employed mBART, as it is currently the state-of-the-art in transformer-based multilingual machine translation, allowing us to fine-tune on all available languages simultaneously"
          ],
          [
           "2110.02869",
           "Furthermore, we used mBART as a denoising autoencoder and tuned it in a supervised fashion"
          ],
          [
           "2110.02869",
           "As opposed to current two-stage methods for word candidate generation and ranking, our approach is more straightforward"
          ],
          [
           "2110.02869",
           "Moreover, it scales to multiple languages without increasing computational demand (i.e"
          ],
          [
           "2110.02869",
           "not increasing vocabulary size, increasing search space and others)"
          ],
          [
           "2110.02869",
           "For future work, we aim to develop our method for better post-processing of the output and increasing augmentation levels - i.e"
          ],
          [
           "2110.02869",
           "injecting more noise in the form of spelling mistakes, backwards translations etc"
          ],
          [
           "2110.02869",
           "Moreover, since our method is supervised, the quality and quantity of training data play an essential role in the final performance"
          ],
          [
           "2110.02869",
           "In this regard, we aim to explore ways to take into account inconsistent annotations."
          ],
          [
           "2207.13988",
           " work was partially supported by the Slovenian Research Agency (ARRS) core research programme P6-0411 and projects J6-2581, J7-3159 and J1-2480, as well as the Ministry of Culture of Republic of Slovenia through project Development of Slovene in Digital Environment (RSDO)"
          ],
          [
           "2207.13988",
           "We acknowledge the efforts of SLING, Slovene national supercomputing grid for providing the necessary computational resources."
          ],
          [
           "2205.15960",
           "In this paper, we propose NusaX, the first parallel corpus for 10 low-resource Indonesian languages"
          ],
          [
           "2205.15960",
           "We create a new benchmark of sentiment analysis and machine translation in few-shot and full-data settings"
          ],
          [
           "2205.15960",
           "We present a comprehensive analysis of the language similarity of these languages from both linguistics and empirical perspective by assessing the cross-lingual transferability of existing Indonesian and multilingual pre-trained models."
          ],
          [
           "1809.05053",
           "A typical problem in industrial applications is the lack of supervised data for languages other than English, and particularly for low-resource languages"
          ],
          [
           "1809.05053",
           "Since annotating data in every language is not a realistic approach, there has been a growing interest in cross-lingual understanding and low-resource transfer in multilingual scenarios"
          ],
          [
           "1809.05053",
           "In this work, we extend the development and test sets of the Multi-Genre Natural Language Inference Corpus to 15 languages, including low-resource languages such as Swahili and Urdu"
          ],
          [
           "1809.05053",
           "Our dataset, dubbed XNLI, is designed to address the lack of standardized evaluation protocols in cross-lingual understanding, and will hopefully help the community make further strides in this area"
          ],
          [
           "1809.05053",
           "We present several approaches based on cross-lingual sentence encoders and machine translation systems"
          ],
          [
           "1909.12440",
           "Scores Overall Recommendation: 3.5"
          ],
          [
           "2205.10956",
           "Specifically, CIRCLE consists of five components: a prompt-based representation, a T5-based model, a difficulty-based example replay, an EWC-based regularization, and a re-repairing mechanism"
          ],
          [
           "2205.10956",
           "The T5-based model is the skeleton of APR model"
          ],
          [
           "2205.10956",
           "The prompt-based representation converts program repairing to fill-in-the-blank task, filling the gap between T5's pre-trained task and APR task"
          ],
          [
           "2205.10956",
           "The difficulty-based replay and EWC-based regularization are two lifelong strategies, enabling CIRCLE to continually update its parameters according to the incremental task requirements"
          ],
          [
           "2205.10956",
           "Finally, a simple yet effective re-repairing method is applied to eliminate the form error caused by multiple languages repairing"
          ],
          [
           "2205.10956",
           "To the best of our knowledge, it is the first time to construct an APR model simultaneously addressing multiple programming languages based on continual learning approaches"
          ],
          [
           "2205.10956",
           "We conduct extensive experiments with 4 programming languages on 5 benchmarks to demonstrate the effectiveness of our CIRCLE"
          ],
          [
           "1903.10625",
           "We also applied our approach to SMT lattices and reported much better relative gains over the SMT baselines than previous work on hybrid systems"
          ],
          [
           "2011.00948",
           "ement Approaches This section compares alternative approaches of the CDA method described in Section REF "
          ],
          [
           "2011.00948",
           "We compare several different procedures for filling [MASK] tokens using the pretrained MLM"
          ],
          [
           "2011.00948",
           "Specifically, we consider two aspects: (i) how many [MASK] tokens to fill simultaneously and (ii) how to determine a word symbol in each time step"
          ],
          [
           "2011.00948",
           "For (i) how many [MASK] tokens to fill simultaneously, we compare the following two methods:  Single: The overview of this method is presented in Figure REF "
          ],
          [
           "2011.00948",
           "Here, each $\\mathbf {X}_{n}^{\\prime }$  contains a single [MASK] token and the rest of tokens are from the original sentence $\\mathbf {X}$ "
          ],
          [
           "2011.00948",
           "We then feed $(\\mathbf {X}_{1}^{\\prime },\\dots ,\\mathbf {X}_{N}^{\\prime })$  to MLM independently and fill each [MASK] token with another token to obtain $(\\mathbf {X}_{1}^{\\prime \\prime },\\dots ,\\mathbf {X}_{N}^{\\prime \\prime })$ "
          ],
          [
           "2011.00948",
           "Finally, we merge the outputs $(\\mathbf {X}_{1}^{\\prime \\prime },\\dots ,\\mathbf {X}_{N}^{\\prime \\prime })$  to construct a symbolically modified sentence $\\mathbf {X}^{\\prime \\prime }$ "
          ],
          [
           "2011.00948",
           "Multi: The overview of this method is presented in Figure REF "
          ],
          [
           "2011.00948",
           "Given a masked sentence $\\mathbf {X}^{\\prime }$ , we feed $\\mathbf {X}^{\\prime }$  to MLM and fill all [MASK] tokens simultaneously"
          ],
          [
           "2011.00948",
           "The output of MLM is a symbolically modified sentence $\\mathbf {X}^{\\prime \\prime }$ "
          ],
          [
           "2011.00948",
           "Argmax: From the probability distribution over the vocabulary, we determine the output symbol by choosing the token with the highest probability"
          ],
          [
           "2011.00948",
           "Figure: Overview of two replacement approaches.Table: F 1 \\mathrm {F}_{1} scores on the NTC 1.5 validation set"
          ],
          [
           "2011.00948",
           "In this experiment, the conditions of the POS category are identical across all models with the setting of $\\mathcal {S}_{all\\backslash (\\mathrm {verb} \\cup \\mathrm {symbol})}$ , which achieves the best overall $\\mathrm {F}_{1}$  in Table REF "
          ],
          [
           "2011.00948",
           "Thus, we used the Multi+Argmax setting for CDA in the experiment of Section REF ."
          ],
          [
           "2004.14781",
           "In this work, we propose a structure-augmented text representation (StAR) model to tackle link prediction task for knowledge graph completion"
          ],
          [
           "2004.14781",
           "Inspired by translation-based graph embedding designed for structure learning, we first apply a Siamese-style textual encoder to a triple for two contextualized representations"
          ],
          [
           "2004.14781",
           "Then, based on the two representations, we present a scoring module where two parallel scoring strategies are used to learn both contextualized and structured knowledge"
          ],
          [
           "2004.14781",
           "Moreover, we propose a self-adaptive ensemble scheme with graph embedding approach, to further boost the performance"
          ],
          [
           "1908.01851",
           "We proposed a new knowledge distillation method, self-knowledge distillation, from the probabilities of the currently training model itself"
          ],
          [
           "1908.01851",
           "This method can be straightforwardly applied to other tasks where the cross-entropy is used"
          ],
          [
           "1908.01851",
           "Also, we can develop an automatic way for the parameters like $\\alpha $  in Eq"
          ],
          [
           "1908.01851",
           "(REF ), and generalize the equation for $q_n$  in Eq"
          ],
          [
           "1908.01851",
           "(REF )."
          ],
          [
           "2012.05995",
           "e Julia Script for Random Order of First Authors using Random s = 313627913 Random.seed! (s) people = [\"songyang\",\"zhaoyi\"] people[randperm(length(people))]"
          ],
          [
           "2105.00164",
           "urces Nam id fermentum dui"
          ],
          [
           "2105.00164",
           "Suspendisse sagittis tortor a nulla mollis, in pulvinar ex pretium"
          ],
          [
           "2105.00164",
           "Sed interdum orci quis metus euismod, et sagittis enim maximus"
          ],
          [
           "2105.00164",
           "Vestibulum gravida massa ut felis suscipit congue"
          ],
          [
           "2105.00164",
           "Quisque mattis elit a risus ultrices commodo venenatis eget dui"
          ],
          [
           "2105.00164",
           "Etiam sagittis eleifend elementum"
          ],
          [
           "2105.00164",
           "Nam interdum magna at lectus dignissim, ac dignissim lorem rhoncus"
          ],
          [
           "2105.00164",
           "Maecenas eu arcu ac neque placerat aliquam"
          ],
          [
           "2105.00164",
           "Nunc pulvinar massa et mattis lacinia."
          ],
          [
           "2103.13275",
           "and Conclusions The work conducted in this paper has been a first step for using machine learning in modelling the semantics of some of the endangered Uralic languages"
          ],
          [
           "2103.13275",
           "Alignment can only get us so far and using models trained on larger languages has its inherent problems when applied to completely new domains in a completely different language"
          ],
          [
           "2103.13275",
           "Even the starting quality for the pretrained embeddings was low"
          ],
          [
           "2103.13275",
           "When the quality of the models available for a high-resourced languages is substandard, one cannot expect any sophisticated machine learning method to come to the rescue"
          ],
          [
           "2103.13275",
           "Unfortunately in our field, too little attention is paid to the quality of resources and more attention is paid into single values representing overall accuracies and overall performance"
          ],
          [
           "2103.13275",
           "As there is no shortcut to happiness, we should look into the data available in the endangered languages themselves"
          ],
          [
           "2103.13275",
           "Of course, this requires collaboration between many parties and willingness to make data openly available"
          ],
          [
           "2103.13275",
           "While this might not be an issue with FU-Lab, it might be with some other instances holding onto their immaterial rights too tight"
          ],
          [
           "2103.13275",
           "At the current, stage our dictionary editing system, Ve$\\textsuperscript {{\\prime }}$ rdd [4], [3], contains words for multiple endangered languages and their translations in a graph structure"
          ],
          [
           "2103.13275",
           "This data could be extended by predicting new relations into the graph with semantic models such as word embeddings"
          ],
          [
           "2103.13275",
           "This could help at least in resolving meaning groups and polysemy of the lexical entries"
          ],
          [
           "2103.13275",
           "However, the word embeddings available for the endangered languages in question has not yet reached to a stage mature enough for their incorporation as a part of the lexicon."
          ],
          [
           "1905.11558",
           " In this paper, we present Leap-LSTM, an LSTM-enhanced model which can perform skip behavior with strictly controllable skip rate"
          ],
          [
           "1905.11558",
           "In the model, we combine messages from three aspects for skipping at each step"
          ],
          [
           "1905.11558",
           "We conduct skipping analysis to explore its tendency for skipping words by some specific examples"
          ],
          [
           "1905.11558",
           "Moreover, we design a novel schedule-training scheme to train LSTM, and get close test accuracies to our model"
          ],
          [
           "1905.11558",
           "Our model is simple and flexible and it would be promising to integrate it into sophisticated structures to achieve even better performance in the future."
          ],
          [
           "1905.11471",
           "We show the effectiveness of the approach with both massive pretrained models and smaller randomly initialized models"
          ],
          [
           "1905.11471",
           "We boost performance on all languages in the XNLI dataset, by up to $4.8\\%$ , and achieve state of the art results on 3 languages including the low resource language Urdu"
          ],
          [
           "1905.11471",
           "While the empirical results of XLDA are promising, further investigation is needed to understand the causal and linguistic relationship between XLDA and performance on downstream tasks"
          ],
          [
           "1905.11471",
           "Additionally, it would be interesting to investigate the use a similar heuristic during test time; inference can be performed in multiple languages (even if one target language is of interest) and they can be aggregated together"
          ],
          [
           "2106.09898",
           "Text-based NLP models are vulnerable to a broad class of imperceptible perturbations which can alter model output and increase inference runtime without modifying the visual appearance of the input"
          ],
          [
           "2106.09898",
           "These attacks exploit language coding features, such as invisible characters and homoglyphs"
          ],
          [
           "2106.09898",
           "We have presented a systematic exploration of text-encoding exploits against NLP systems"
          ],
          [
           "2106.09898",
           "We have developed a taxonomy of these attacks and explored in some detail how they can be used to mislead and to poison machine-translation, toxic content detection, and textual entailment classification systems"
          ],
          [
           "2106.09898",
           "Furthermore, they can be used to degrade the quality of search engine results and hide data from indexing and filtering algorithms"
          ],
          [
           "1906.01617",
           "This work extended existing sequential self-attentional models to lattice inputs, which have been useful for various purposes in the past"
          ],
          [
           "1906.01617",
           "We achieve this by introducing probabilistic reachability masks and lattice positional encodings"
          ],
          [
           "1906.01617",
           "Promising future work includes extension to tree-structured inputs and application to other tasks."
          ],
          [
           "2001.05315",
           "In this work, we discuss strategies for effective training of continuous-space neural language models and introduce the weight-dropped LSTM to Bengali Language"
          ],
          [
           "2001.05315",
           "On the corpora consisting of Bengali news articles, the proposed approach yields a perplexity of 51.2 which is significantly lower than the perplexities achieved through traditional language models currently existing in Bengali"
          ],
          [
           "2001.05315",
           "Since the applications of language models have flourished over the years, we hope to see the implementation of this model for tasks such as text summarization, classification and translation of Bengali language in the future."
          ],
          [
           "2204.01827",
           "and future work In this paper, we used several machine learning algorithms such as the Spacy NER Model, Amazon Comprehend Custom Entity Recognition model"
          ],
          [
           "2204.01827",
           "Then we used a Sequential model from keras for name entity recognition and we predicted gender from BanglaLinga library"
          ],
          [
           "2204.01827",
           "Through the name entity recognition model we successfully identified the gender of the person based on their names"
          ],
          [
           "2204.01827",
           "Our model successfully identified the most demandable device model names from consumers' comments and posts data"
          ],
          [
           "2204.01827",
           "Then we performed sentiment analysis and it accurately predicted the positive reviewed devices"
          ],
          [
           "2104.08173",
           "In other words, it is feasible to model word embeddings as a series of transitions from an initial distribution"
          ],
          [
           "2104.08173",
           "We have shown how these word embeddings can be formed by taking the first order, second order series or product approximation of our Taylor expansion of rate matrices"
          ],
          [
           "2104.08173",
           "The FOS embeddings have shown comparable performance to the existing word2vec model on a number of linguistic probing as well asdownstream tasks"
          ],
          [
           "2104.08173",
           "Their sensitivity to word order is also useful in linguistic probing tasks such as Bshift and Coordinv where they outperform CBOW"
          ],
          [
           "2104.08173",
           "While our model does share some similarities with CMOW, our model uses rate matrices rather than random matrix which are constrained in their diagonal elements"
          ],
          [
           "2104.08173",
           "This allows us to ground our embeddings in a statistical foundation"
          ],
          [
           "2104.08173",
           "Our embeddings are also formed from a combination of rate matrix-vector pair instead of the unrolling operation employed by CMOW"
          ],
          [
           "2104.08173",
           "On the other hand, the second order series Taylor expansion seems to be a mixture the first order series and the first order product, sharing both sum and product matrix operations"
          ],
          [
           "2104.08173",
           "While it has shown to have outperform both CBOW and CMOW in some tasks, it does not perform as well as training the sum and product terms individually like in our FOS and FOP embeddings"
          ],
          [
           "2104.08173",
           "In essence, we have proposed a novel way of representing a language model and in a deeper sense a model of how we form concepts in our mind"
          ],
          [
           "2104.08173",
           "This is modelled as a series of statistical transitions from an initial distribution can be interpreted as the evolution of our thoughts."
          ],
          [
           "1808.04614",
           "and Future Work We have studied in this paper the problem of explaining complex NL queries to non expert users"
          ],
          [
           "1808.04614",
           "We introduced visual query explanations in the form of table highlights, based on a novel cell-based provenance model tested on web tables from hundreds of distinct domains"
          ],
          [
           "1808.04614",
           "Table highlights provide immediate visual feedback for identifying correct candidate queries"
          ],
          [
           "1808.04614",
           "We combine table highlights with utterance based query explanations, significantly improving their effectiveness"
          ],
          [
           "1808.04614",
           "Using our query explanations we enhanced an NL interface for querying tables by providing it with feedback at both deployment and training time"
          ],
          [
           "1808.04614",
           "Feedback is procured through query explanations, allowing users with no technical background to query tables with confidence, while simultaneously providing feedback to enhance the interface itself"
          ],
          [
           "1808.04614",
           "We implement a human in the loop paradigm, where our users both exploit the underlying Machine Learning algorithm while providing it with further data to train on"
          ],
          [
           "1808.04614",
           "We have put our methods to the test, having conducted an extensive user study to determine the clarity of our explanations"
          ],
          [
           "1808.04614",
           "Experimenting with explanations for hundreds of formal queries, users proved to be successful in interactively choosing correct queries, easily topping the baseline parser correctness"
          ],
          [
           "1808.04614",
           "The addition of provenance-based highlights helps boost the efficacy of user feedback, cutting average work-time by a third compared to the utterances baseline."
          ],
          [
           "1811.03199",
           "All the correlations are found to be statistically significant."
          ],
          [
           "2209.02967",
           "In this study, a flexible model, called CROSSWISE, for cross-era Chinese word segmentation is proposed"
          ],
          [
           "2209.02967",
           "This model is capable of improving the performance of each dataset by fully integrating era-specific knowledge"
          ],
          [
           "2209.02967",
           "Experiments on four corpora show the effectiveness of this model"
          ],
          [
           "2209.02967",
           "In the future, the incorporation of other labeling tasks into CROSSWISE, such as POS tagging and named entity recognition, may prove to be insightful."
          ],
          [
           "1804.05017",
           " model The Chinese clinical named entity recognition task is usually regarded as a sequence labeling task"
          ],
          [
           "1804.05017",
           "Due to the ambiguity in the boundary of Chinese words, following our previous work , we label the sequence in the character level to avoid introducing noise caused by segmentation error"
          ],
          [
           "1804.05017",
           "Thus, given a clinical sentence $X=<x_1,...,x_n>$ , our goal is to label each character $x_i$  in the sentence $X$  with BIEOS (Begin, Inside, End, Outside, Single) tag scheme"
          ],
          [
           "1804.05017",
           "An example of the tag sequence for “腹平坦，未见腹壁静脉曲张。” (The abdomen is flat and no varicose veins can be seen on the abdominal wall) can be found in Table REF "
          ],
          [
           "1804.05017",
           "Table: Acknowledgment"
          ],
          [
           "2206.02291",
           "In this work we provided the first analysis of multilingual language data on federated learning algorithms"
          ],
          [
           "2206.02291",
           "However, models trained from random initializations still show a large gap between centralized and federated learning"
          ],
          [
           "2012.13736",
           "and Discussion This paper reviewed the existing GAN-variants for synthetic image generation based on architecture, performance, and stable training"
          ],
          [
           "2012.13736",
           "In particular, it is difficult, yet important for image synthesis tasks to explicitly define the loss"
          ],
          [
           "2012.13736",
           "For instance, to perform style transfer, it is difficult to set a loss function to evaluate the matching of an image to a certain style"
          ],
          [
           "2012.13736",
           "Each input image in synthetic image generation may have several legitimate outputs, however these outputs may not cover all the conditions"
          ],
          [
           "2012.13736",
           "For synthetic image generation, several recent supervised and unsupervised methods have been reviewed, their strengths and weaknesses are thoroughly discussed"
          ],
          [
           "2012.13736",
           "Although we have conducted several experimental evaluation, GANs for synthetic image generation, still lacks a thorough study of domain adaptation and transfer learning"
          ],
          [
           "2012.13736",
           "At the time of this writing, there are a few published works on using GANs for video, time series generation, and natural language processing"
          ],
          [
           "2012.13736",
           "Future research should be directed towards investigating the use of GANs in those fields as well as others."
          ],
          [
           "2011.08072",
           "Our framework consists of extractive and abstractive phases"
          ],
          [
           "2011.08072",
           "In the extractive phase, we use coreference resolution to extract groups of inter-dependent sentences from source articles and centroid-based clustering followed by an enhanced multi-sentence compression algorithm to generate topically informative and relevant summaries"
          ],
          [
           "2011.08072",
           "The number of summaries in our proposed method is adaptively determined based on the semantic analysis of the topics discussed in the documents"
          ],
          [
           "2011.08072",
           "We introduce MAG-20, a dataset of topically-clustered groups of scientific articles across 20 Fields of Study and their abstractive summaries"
          ],
          [
           "2011.08072",
           "In the future, we plan to use additional knowledge and metadata such as citation relationships among scientific articles for document summarization."
          ],
          [
           "1912.11637",
           "In this paper, we propose a novel model called Explicit Sparse Transformer"
          ],
          [
           "1912.11637",
           "Explicit Sparse Transformer is able to make the attention in vanilla Transformer more concentrated on the most contributive components"
          ],
          [
           "1912.11637",
           "We conducted a series of qualitative analyses to investigate the reasons why Explicit Sparse Transformer outperforms the vanilla Transformer"
          ],
          [
           "1912.11637",
           "Furthermore, we find an obvious problem of the attention at the top layer of the vanilla Transformer, and Explicit Sparse Transformer can alleviate this problem effectively with improved alignment effects."
          ],
          [
           "2212.01650",
           "As can be seen in table REF  T5Mem model surpasses the base line"
          ],
          [
           "2212.01650",
           "Table REF  T5Mem model surpasses the base line for both two variants using just one chunk or using four chunks"
          ],
          [
           "2212.01650",
           "Increasing input length while pretraining did not bring any good, and lower number of chunks with shorter length were more efficient than longer ones"
          ],
          [
           "2212.01650",
           "In result, The proposed model using four chunks or one chunk outperformed the base line for both 128 input length as one chunk, 512 input length as one chunk, or 512 input length divided into four chunks each chunk of 128 length as seen in tables REF  and REF "
          ],
          [
           "2212.01650",
           "Table: Experimental results on train and dev set of wikitext-103-raw-v1 dataset for Masked language modeling task using just one chunk as input length 128"
          ],
          [
           "2001.06588",
           "In this work, we developed a novel cost-aware Bayesian multi-objective optimization algorithm called FlexiBO"
          ],
          [
           "2001.06588",
           "We carried out our experiments using 7 different DNN architectures for tasks of object detection, NLP and speech recognition, and optimized accuracy and energy consumption on a resource-constrained device"
          ],
          [
           "2001.06588",
           "Moreover, FlexiBO determines a Pareto front of similar quality were compared to the state-of-the-art with 80.23% less cost"
          ],
          [
           "2001.06588",
           "An immediate future direction of this work is to compare FlexiBO with other Bayesian optimization frameworks such as Spearmint [22], which offers multiple acquisition functions such as ParEGO [34], SMSego [47] and PESMO [22]"
          ],
          [
           "2001.06588",
           "Acknowledgments"
          ],
          [
           "2001.06588",
           "This work was supported by AFRL and DARPA (FA8750-16-2-0042)"
          ],
          [
           "2001.06588",
           "This work is also partially supported by an ASPIRE grant from the Office of the Vice President for Research at the University of South Carolina"
          ],
          [
           "2001.06588",
           "We would like to thank Marilyn Gartley for copyediting the paper."
          ],
          [
           "0912.3747",
           " Paraphrasing and textual entailment is currently a popular research topic"
          ],
          [
           "0912.3747",
           "Paraphrasing can be seen as bidirectional textual entailment and, hence, similar methods are often used for both"
          ],
          [
           "0912.3747",
           "Recognition methods, which classify input pairs of natural language expressions (or templates) as correct or incorrect paraphrases or textual entailment pairs, often rely on supervised machine learning to combine similarity measures possibly operating at different representation levels (surface, syntactic, semantic)"
          ],
          [
           "0912.3747",
           "The rte challenges provide a significant thrust to recognition work, and they have helped establish benchmarks and attract more researchers"
          ],
          [
           "0912.3747",
           "There are fewer publications on generation, compared to recognition (and extraction), and most of them focus on paraphrasing; furthermore, there are no established challenges or benchmarks, unlike recognition"
          ],
          [
           "0912.3747",
           "Nevertheless, generation may provide opportunities for novel research, especially to researchers with experience in statistical machine translation, who may for example wish to develop alignment or decoding techniques especially for paraphrasing or textual entailment generation"
          ],
          [
           "0912.3747",
           "Extraction methods extract paraphrases or textual entailment pairs (also called “rules”) from corpora, usually off-line"
          ],
          [
           "0912.3747",
           "Many extraction methods are based on the Distributional Hypothesis, though they often operate at different representation levels"
          ],
          [
           "0912.3747",
           "Alignment techniques originating from statistical machine translation are recently also popular and they allow existing large bilingual parallel corpora to be exploited"
          ],
          [
           "0912.3747",
           "Extraction methods also differ depending on whether they require parallel, comparable, or simply large corpora, monolingual or bilingual"
          ],
          [
           "0912.3747",
           "As in generation, most extraction research has focused on paraphrasing, and there are no established challenges or benchmarks"
          ],
          [
           "0912.3747",
           "The underlying ideas of generation and extraction methods are in effect the same, as shown in Table REF , even if the methods perform different tasks; recognition work has relied on rather different ideas"
          ],
          [
           "0912.3747",
           "Generation and extraction have mostly focused on paraphrasing, as already noted, which is why fewer ideas have been explored in generation and extraction for (unidirectional) textual entailment"
          ],
          [
           "0912.3747",
           "We expect to see more interplay among recognition, generation, and extraction methods in the near future"
          ],
          [
           "0912.3747",
           "For example, recognizers and generators may use extracted rules to a larger extent; recognizers may be used to filter candidate paraphrases or textual entailment pairs in extraction or generation approaches; and generators may help produce more monolingual parallel corpora or recognition benchmarks"
          ],
          [
           "0912.3747",
           "We also expect to see paraphrasing and textual entailment methods being used more often in larger natural language processing tasks, including question answering, information extraction, text summarization, natural language generation, and machine translation"
          ],
          [
           "0912.3747",
           "Table: Main ideas discussed and main resources they typically require."
          ],
          [
           "1911.00317",
           "and Future Work In this article, we presented a comprehensive analysis of the representations learned during NMT training from the perspective of core linguistic phenomena, namely morphology, syntax, and semantics"
          ],
          [
           "1911.00317",
           "We evaluated the representation quality on the tasks of morphological, syntactic and semantic tagging and using syntactic and semantic dependency labeling"
          ],
          [
           "1911.00317",
           "They are more robust towards handling unknown and low frequency words"
          ],
          [
           "1911.00317",
           "Character-based representations, on the other hand, are poor at handling long-range dependencies and therefore inferior when translating syntactically divergent language pairs such as German-English"
          ],
          [
           "1911.00317",
           "We found morpheme segmented units to give better representations than the ones learned using non-linguistic BPE units"
          ],
          [
           "1911.00317",
           "The former outperformed the latter in most scenarios, even giving slightly better translation quality"
          ],
          [
           "1911.00317",
           "Future work can expand the analysis into many directions"
          ],
          [
           "1911.00317",
           "For instance, in terms of the studied linguistic properties, moving beyond words and relations to explore phrase and sentence structures could be an interesting frontier to explore"
          ],
          [
           "1911.00317",
           "The current study focused on NMT models based on LSTMs"
          ],
          [
           "1911.00317",
           "Analyzing other architectures such as Transformers [119], which recently set a new state-of-the-art compared to both recurrent and convolutional models [46], would be an exciting direction to pursue."
          ],
          [
           "2006.03158",
           "We propose maximum-likelihood guided parameter search (MGS), a training method for optimizing an arbitrary sequence-level task loss"
          ],
          [
           "2006.03158",
           "MGS samples update directions and weights them according to their improvement in task loss"
          ],
          [
           "2006.03158",
           "Key to our method is a proposal distribution which either performs random search around the current parameter or around the maximum-likelihood gradient"
          ],
          [
           "2006.03158",
           "MGS substantially reduced non-termination and repetition in a text completion task, and outperformed maximum likelihood on machine translation, with fine-tuning and when trained from scratch"
          ],
          [
           "2011.12631",
           "ook Arabic NLP has many challenges, but it has also seen many successes and developments over the last 40 years"
          ],
          [
           "2011.12631",
           "We are optimistic by its continuously positive albeit (sometimes) slow development trajectory"
          ],
          [
           "2011.12631",
           "For the next decade or two, we expect a large growth in the Arabic NLP market"
          ],
          [
           "2011.12631",
           "This is consistent with the global rising demands and expectations for language technologies and the increase in NLP research and development in the Arab world"
          ],
          [
           "2011.12631",
           "The growing number of researchers and developers working on NLP in the Arab world makes it a very fertile ground ready for major breakthroughs"
          ],
          [
           "2011.12631",
           "Such an organization can support NLP education in the Arab world, serve as a hub for resources, and advocate for educators and researchers in changing old-fashioned university policies regarding journal-focused evaluation, and encouraging collaborations within the Arab world by connecting academic, industry, and governmental stakeholders"
          ],
          [
           "1811.05121",
           "and Future Work In this work, we proposed a new RNN model with multi-channel multi-block structure to better capture and utilize local patterns in sequential data for language-related tasks"
          ],
          [
           "1811.05121",
           "Experiments on machine translation, abstractive summarization, and language modeling validated the effectiveness of the proposed model"
          ],
          [
           "1811.05121",
           "We achieved new state-of-the-art results on Gigaword on text summarization and Penn Treebank on language modeling"
          ],
          [
           "1811.05121",
           "For the future work, we will apply our model to more tasks, such as question answering, image captioning and so on."
          ],
          [
           "1910.06720",
           "and future work In this paper we proposed Distilled Embedding, a low-rank matrix decomposition with non-linearity in the bottleneck layer for a shared word-embedding and vocabulary projection matrix"
          ],
          [
           "1910.06720",
           "We also introduce knowledge distillation of the embedding during fine-tuning using the full embedding matrix as the teacher and the decomposed embedding as the student"
          ],
          [
           "1910.06720",
           "For future work, we will apply our approach to compress feed-forward and multi-head attention layers of the transformer network."
          ],
          [
           "1910.06764",
           "We presented a new architectural variant of the transformer model, the GTrXL, which has increased performance, more stable optimization, and greater robustness to initial seed and hyperparameters than the canonical architecture"
          ],
          [
           "1910.06764",
           "The key contributions of the GTrXL are reordered layer normalization modules, enabling an initially Markov regime of training, and a gating layer instead of the standard residual connections"
          ],
          [
           "1910.06764",
           "We performed extensive ablation experiments testing the robustness, ease of optimization and final performance of the gating layer variations, as well as the effect of the reordered layer normalization"
          ],
          [
           "1910.06764",
           "Furthermore, the GTrXL (GRU) learns faster, more stably and achieves a higher final performance (even when controlled for parameters) than the other gating variants on the challenging multitask DMLab-30 benchmark suite"
          ],
          [
           "1910.06764",
           "Having demonstrated substantial and consistent improvement in DMLab-30, Numpad and Memory Maze over the ubiquitous LSTM architectures currently in use, the GTrXL makes the case for wider adoption of transformers in RL"
          ],
          [
           "1910.06764",
           "A core benefit of the transformer architecture is its ability to scale to very large and deep models, and to effectively utilize this additional capacity in larger datasets"
          ],
          [
           "1910.06764",
           "In future work, we hope to test the limits of the GTrXL's ability to scale in the RL setting by providing it with a large and varied set of training environments."
          ],
          [
           "1906.11455",
           "and Future Work In this paper, we propose a new toolkit PKUSEG for multi-domain Chinese word segmentation"
          ],
          [
           "1906.11455",
           "PKUSEG provides simple and user-friendly interfaces for users"
          ],
          [
           "1906.11455",
           "So far PKUSEG supports domains like medicine, tourism, web, and news"
          ],
          [
           "1906.11455",
           "In the future, we plan to release more domain-specific models and improve the efficiency of PKUSEG further."
          ],
          [
           "2211.15464",
           "In order to make future research on gloss translation more meaningful, we make practical recommendations (§)"
          ],
          [
           "2211.15464",
           "We urge researchers to spell out limitations of gloss translation approaches, e.g"
          ],
          [
           "2211.15464",
           "in the now mandatory limitation sections of *ACL papers, and to strengthen their findings by implementing existing best practices in MT"
          ],
          [
           "2102.06991",
           "From the computational linguistic point of view, Hausa, among other African languages, is categorised as low-resource language owing to the limited resources to handle various NLP-related tasks"
          ],
          [
           "2102.06991",
           "This limitation slows down the pace of development of the language in terms of computational linguistic and for downstream tasks"
          ],
          [
           "2102.06991",
           "We contributed the first comprehensive collection of curated datasets to support various NLP-related tasks in Hausa language"
          ],
          [
           "2102.06991",
           "Essentially, the corpus consists of two categories according to collection sources: online social network and websites and blogs"
          ],
          [
           "2102.06991",
           "Due to the collection sources, the themes in the datasets span many aspects of social life"
          ],
          [
           "2102.06991",
           "Moreover, the inclusion of social media data will help in capturing the peculiarities in the language and how colloquial expressions manifest in the language"
          ],
          [
           "2102.06991",
           "We also presented a process to streamline the activity of obtaining more diverse datasets in Hausa from social media platforms, and how to retrieve the hydrated version of the data."
          ],
          [
           "2104.08721",
           "Embedding-Enhanced Giza++ shines in lowest-resource scenarios, outperforming Giza++ by 8.5, 10.9, and 12 AER for Romanian-English, German-English, and English-French, respectively—performance unlikely to be matched by data-hungry neural models."
          ],
          [
           "2004.05001",
           "In this paper, we examine more than a dozen metrics for semantic similarity in the context of NLP tasks of style transfer and paraphrase"
          ],
          [
           "2004.05001",
           "This is not only to be expected but also justifies the proposed order-theory methodology"
          ],
          [
           "2004.05001",
           "POS-distance, Word2Vec and FastText cosine similarities are somehow less aligned with this general semantic similarity order"
          ],
          [
           "2004.05001",
           "This fact is essential in the context of future style transfer research"
          ],
          [
           "2102.12895",
           "In this paper, we propose a novel mechanism, Evolving Attention for Transformers, which facilitates the learning of attention maps via a chain of residual convolutional neural networks"
          ],
          [
           "2102.12895",
           "It obtains superior performance in various tasks in both CV and NLP domains"
          ],
          [
           "2102.12895",
           "Future works are considered in three aspects"
          ],
          [
           "2102.12895",
           "First, we will apply evolving attention to more tasks and domains, such as object detection, question answering and time-series forecasting"
          ],
          [
           "2102.12895",
           "Second, we aim to investigate other modules instead of convolutions to capture generic patterns in attention maps"
          ],
          [
           "2006.04229",
           " We have presented two transformer-based language models for Polish, pre-trained using a combination of publicly available text corpora and a large collection of methodically pre-processed web data"
          ],
          [
           "2006.04229",
           "We have shown the effectiveness of our models by comparing them with other transformer-based approaches and recent state-of-the-art approaches"
          ],
          [
           "2006.04229",
           "We conducted a comprehensive evaluation on a wide set of Polish linguistic tasks, including binary and multi-class classification, regression, and sequence labeling"
          ],
          [
           "2006.04229",
           "In our experiments, the larger model performed better than other methods in eleven of the thirteen cases"
          ],
          [
           "2006.04229",
           "To accelerate research on NLP for Polish language, we have released the pre-trained models publicly."
          ],
          [
           "1707.05438",
           "In this paper, we propose a listwise learning framework for statistical machine translation"
          ],
          [
           "1707.05438",
           "In order to adapt listwise approaches, we use an iterative training framework in which instances from different iterations are aggregated into the training set"
          ],
          [
           "1707.05438",
           "To emphasize the top order of the list, we further propose top-rank enhanced listwise learning losses"
          ],
          [
           "1707.05438",
           "Our current work focuses on the traditional SMT task"
          ],
          [
           "1707.05438",
           "For future work, it will be interesting to integrate our methods to modern neural machine translation systems or other structure prediction problems"
          ],
          [
           "1707.05438",
           "It may also be interesting to explore more methods on listwise tuning framework, such as investigating different methods to enhance top order of translation list directly w.r.t a given evaluation metric."
          ],
          [
           "2109.01411",
           "This work presented an in-depth study of using structured linked data embedded within HTML webpages for the creation of language resources for downstream NLP tasks"
          ],
          [
           "2109.01411",
           "These language resources are then thoroughly evaluated on two typical product-related NLP tasks (product classification and linking) using a large number of benchmarking datasets and algorithms"
          ],
          [
           "2109.01411",
           "Previous studies however, are typically ad-hoc, and evaluated on a single task, using a confined set of datasets"
          ],
          [
           "2109.01411",
           "First, due to the highly decentralised nature in publishing such structured linked data, understandably, the published data are highly unbalanced in terms of the domains, with data related to fashion dominating a significant percentage"
          ],
          [
           "2109.01411",
           "Informed by these findings, we discuss a number of implications for future research in this direction"
          ],
          [
           "2109.01411",
           "Ultimately, one may devise a `selection' process to ensure a representative sample is constructed from such a enormous dataset, and only use this sample instead of the entire linked dataset available"
          ],
          [
           "2109.01411",
           "This may not be as straightforward as it seems"
          ],
          [
           "2109.01411",
           "On the one hand, there isn't a limited set of universally accepted domains for defining a website"
          ],
          [
           "2109.01411",
           "On the other hand, there isn't an easy way to gauge what domain a particular website represents"
          ],
          [
           "2109.01411",
           "An interesting direction would be to allow users to provide a `seed' list of websites, which can be used by an automated process to `find' a representative subset of the structured linked dataset"
          ],
          [
           "2109.01411",
           "Second, it may be worth to explore the use of these structured data in less domain-agnostic tasks"
          ],
          [
           "2109.01411",
           "Next, apply the learned model to tag individual listing pages of GoodReads, or even the more generic Amazon product listing pages"
          ],
          [
           "2109.01411",
           "The idea here is how different types of content are formatted `relative to each other' on a product listing web page can be consistent across many different domains and websites"
          ],
          [
           "2109.01411",
           "This has been validated in different contexts such as [46]"
          ],
          [
           "2109.01411",
           "The abundance of already annotated product listing pages in the form of semantic markup data can create an opportunity to train such taggers in a self-supervised way"
          ],
          [
           "2109.01411",
           "Our future work will explore both directions."
          ],
          [
           "2207.11680",
           "In this paper, we experimentally investigate the effectiveness of prompt tuning on three code intelligence tasks with two pre-trained models"
          ],
          [
           "2207.11680",
           "Our source code and experimental data are publicly available at:https://github.com/adf1178/PT4Code."
          ],
          [
           "2109.12104",
           "We described the method to extract and postprocess texts from the masked English texts, and generate German texts by translating and cross-lingual token aligning"
          ],
          [
           "2109.12104",
           "In addition, the NER model architecture was described and the final model performance was evaluated for single NER tags as well as its performance in total"
          ],
          [
           "2109.12104",
           "The need for independent datasets in order to further improve the situation for the research community on this matter has been highlighted"
          ],
          [
           "2109.12104",
           "We are looking forward to compare our model to upcoming German medical NER models"
          ],
          [
           "2109.12104",
           "The model as well as the training/test data are available at the following repository on GitHub: https://github.com/frankkramer-lab/GERNERMED."
          ],
          [
           "2210.06929",
           "According to the assumptions made on explained models, we make the distinction between model-agnostic and model-specific methods"
          ],
          [
           "2210.06929",
           "Some of those methods rely on altering the embedding space by imposing a sparsity constraint or applying a rotation transformation while others integrate external knowledge bases and ontologies or rely on bidirectional language models to derive contextualized embeddings"
          ],
          [
           "2210.06929",
           "Moreover, we survey existing work on the interpretation of hidden representations of NLP models, general RNNs, and transformers in terms of human-understandable concepts"
          ],
          [
           "2210.06929",
           "We discuss the debate over the interpretability of attention weights and we derive the following conclusion: attention weights are relatively more inherently interpretable than traditional models' parameters but further analysis is required for complete transparency in attention-based models"
          ],
          [
           "2210.06929",
           "Figure REF  summarizes the work done on the interpretability of word embeddings, inner workings of RNNs and transformers, the model's decision, and the different visualization methods while highlighting the interconnections between the different methods"
          ],
          [
           "2210.06929",
           "Figure: References for Sections , ,  visualized over similarity of scopes.To date, there is no common evaluation ground for explainability methods on NLP models"
          ],
          [
           "2210.06929",
           "These setups are aggregated according to what the corresponding ExAI method is addressing: embeddings, inner workings, or model's decisions"
          ],
          [
           "1910.06411",
           "Here we have tried to replicate the steps as described by [1] to train individual monolingual word embeddings and then map them to a shared vector space to generate bilingual word embeddings between two languages, from English to a low-resource European language"
          ],
          [
           "1910.06411",
           "Compared to the 49.2% CSLS retrieval accuracy in case of English-German bilingual mapping, we achieve the highest score of 18.06% CSLS accuracy for English-Hungarian among all the low-resource languages"
          ],
          [
           "1708.00993",
           "In this paper we proposed the use of multi-task learning for attention-based encoder-decoder models in order to exploit linguistic resourced for NMT"
          ],
          [
           "1708.00993",
           "By training the models not only on the machine translation task, but also on other NLP tasks, we yielded clear improvements on the translation performance"
          ],
          [
           "1708.00993",
           "As a by product, we were also able to improved the performance of the POS tagging by 30% to 50% relatively"
          ],
          [
           "1708.00993",
           "This is especially helpful since data annotation for many NLP tasks is very time-consuming and expensive"
          ],
          [
           "1708.00993",
           "We addressed the influence of three design decisions: the involved tasks, the training schedule and the architecture of the model"
          ],
          [
           "1708.00993",
           "The largest influence on the final performance was given by the training schedule "
          ],
          [
           "1708.00993",
           "By adapting the system on the individual tasks, we were able to make most use of available additional resources"
          ],
          [
           "1708.00993",
           "spoken TED talks versus written style"
          ],
          [
           "1708.00993",
           "Furthermore, these corpora were significantly smaller than the available parallel data"
          ],
          [
           "1708.00993",
           "Finally, the amount of parameter sharing defined by the architecture of the model has less influence on the final performance"
          ],
          [
           "1708.00993",
           "Although, the best performance on both tasks was achieved with a model sharing only the encoder between the tasks"
          ],
          [
           "1708.00993",
           "In this work, the performance of machine translation task was improved by adopting multi-task training with other source language NLP tasks"
          ],
          [
           "1708.00993",
           "In future work, we will also investigate methods to include target-language NLP tasks into the joint framework."
          ],
          [
           "1908.05672",
           "Our conclusions have practical effects on the recommendations for how to effectively integrate pre-trained models in NMT: 1) Adding pre-trained LMs to the encoder is more effective than the decoder network"
          ],
          [
           "1908.05672",
           "2) Employing CTnmt addresses the catastrophic forgetting problem suffered by pre-training for NMT"
          ],
          [
           "1908.05672",
           "3) Pre-training distillation is a good choice with nice performance for computational resource constrained scenarios"
          ],
          [
           "1908.05672",
           "On the other two large datasets, our method still achieves remarkable performance."
          ],
          [
           "2102.00881",
           "Idiom corpora are valuable resources for foreign language learning, natural language processing, and lexicographic studies"
          ],
          [
           "2102.00881",
           "Unfortunately, they are rare and hard to construct"
          ],
          [
           "2102.00881",
           "The approach has been evaluated under different motivational strategies on two languages, which produced the first idiom corpora for Turkish and Italian"
          ],
          [
           "2102.00881",
           "The implementation developed as a Telegram messaging bot and the collected data for the two languages in a time span of 30 days are shared with the researchers"
          ],
          [
           "2102.00881",
           "Gift cards were found to be very effective in incentivizing the users to continue playing the game in addition to gamification affordances"
          ],
          [
           "2208.07832",
           "MWE detection is an important research area for many NLP applications"
          ],
          [
           "2208.07832",
           "In the future, we would like to explore the cross-lingual capabilities of the transformer models in the MWE detection task"
          ],
          [
           "2208.14923",
           "We have conducted few-shot learning experiments evaluating the performance of SNN models on text classification tasks - SC and NER"
          ],
          [
           "2208.14923",
           "SNN models were based on transformer models - BERT, BioBERT, and BioClinicalBERT"
          ],
          [
           "2208.14923",
           "Fine-tuned versions of BERT, BioBERT, and BioClinicalBERT were also used as the baseline models"
          ],
          [
           "2208.14923",
           "Since performance evaluation on small datasets may suffer from instability, a special evaluation strategy was used"
          ],
          [
           "2208.14923",
           "As for NER, SNN models, once again, outperformed the baseline models, yet the performance difference was not statistically significant"
          ],
          [
           "2208.14923",
           "Limitations of the work have also been discussed and alongside with potential future directions of exploration."
          ],
          [
           "2212.08330",
           "In this paper, we propose a novel mechanism, Evolving Attention, which is applicable to various kinds of attention neural networks"
          ],
          [
           "2212.08330",
           "Equipped with this mechanism, the Convolution-enhanced Evolving Attention Networks produce better attention maps and achieve superior performance on various tasks in time-series, NLP, and CV domains"
          ],
          [
           "2212.08330",
           "Future works are considered in three aspects"
          ],
          [
           "2212.08330",
           "First, we will apply the evolving attention networks to more tasks and domains, such as image generation [2], multi-modal tasks [7], recommendation systems [95], and graph neural networks [72]"
          ],
          [
           "2212.08330",
           "Second, we would like to investigate other modules instead of convolutions to capture the generic patterns in attention maps"
          ],
          [
           "2009.02016",
           "In this paper, we have proposed a novel context-guided capsule network (DCCN) for MMT"
          ],
          [
           "2009.02016",
           "As a significant extension of the conventional capsule network, DCCN utilizes the timestep-specific source-side context vector to dynamically guide the extraction of visual features at different timesteps, where the semantic interactions between modalities can be fully exploited for MMT via context-guided dynamic routing mechanism"
          ],
          [
           "2009.02016",
           "Moreover, we employ DCCN to extract visual features in two complementary granularities: global visual features and regional visual features, respectively"
          ],
          [
           "2009.02016",
           "In the future, we plan to apply DCCN to other multimodal tasks such as visual question answering and multimodal text summarization."
          ],
          [
           "2103.03457",
           "In this work, we propose Instance-wise Ordered Transformer, which leverages instance-wise learning to reorder the layers in Transformer for each data"
          ],
          [
           "2103.03457",
           "Compared with standard Transformer, IOT only introduces slightly increased time cost"
          ],
          [
           "2103.03457",
           "Experiments on 3 sequence generation tasks and 9 datasets demonstrate the effectiveness of IOT"
          ],
          [
           "2103.03457",
           "In future, we plan to work on more complicated reordering in each block, as well as other tasks such as multi-lingual translation and text classification."
          ],
          [
           "1807.02911",
           "ons and Future Work This paper investigated the benefits of combining CNNs and LSTMs networks in an Arabic sentiment classification task"
          ],
          [
           "1807.02911",
           "It also explored the effectiveness of using different levels of sentiment analysis because of the complexities of morphology and orthography in Arabic"
          ],
          [
           "1807.02911",
           "We used character level to increase the number of features for each tweet, as we are dealing with short messages, which was not an ideal option for our model"
          ],
          [
           "1807.02911",
           "Future work will use some pre-trained word representation models, such as word2vec [16], GloVe [35], and Fasttext [36] for the embedding layer."
          ],
          [
           "2005.00333",
           "and Future Work We presented the Cross-lingual Choice of Plausible Alternatives (XCOPA), a multilingual evaluation benchmark for causal commonsense reasoning"
          ],
          [
           "2005.00333",
           "All XCOPA instances are aligned across 11 languages, which enables cross-lingual comparisons"
          ],
          [
           "2005.00333",
           "The language selection was informed by variety sampling, in order to maximise diversity in terms of typological features, geographical macro-area, and language family"
          ],
          [
           "2005.00333",
           "This allows us to test the robustness of machine learning models for an array of rare phenomena displayed by the chosen languages"
          ],
          [
           "2005.00333",
           "We also ran a series of cross-lingual transfer experiments, evaluating state-of-the-art transfer methods based on multilingual pretraining and fine-tuning on English"
          ],
          [
           "2005.00333",
           "Finally, we investigated resource-lean adaptation of pretrained multilingual models to out-of-sample languages, exploiting only small monolingual corpora and/or bilingual dictionaries, reporting notable gains"
          ],
          [
           "2111.14706",
           "We present ESPnet-SLU, a new open-source E2E-SLU toolkit, with the objective of facilitating fast research and development of SLU systems through standardized recipes for various benchmarks containing data preparation, training, and model evaluation"
          ],
          [
           "2111.14706",
           "ESPnet-SLU contains recipes for over 10 diverse SLU corpora, encompassing multiple languages and task types, with performance nearing or exceeding the prior state-of-the-art"
          ],
          [
           "2111.14706",
           "Furthermore, our design is a modular extension of the popular ESPnet toolkit with access to the entire pre-existing infrastructure of various speech processing tasks, models and architectures"
          ],
          [
           "2111.14706",
           "In the future, we will support more corpora and implement more SLU systems like NLU multi-tasking to further advance the performance of our SLU systems."
          ],
          [
           "1911.07613",
           "In this paper, we discuss the ways to effectively train a weight-dropped LSTM language model in Bangla using subword tokenization and other strategies"
          ],
          [
           "1911.07613",
           "This is a significantly low perplexity achieved in Bangla language so far"
          ],
          [
           "1911.07613",
           "Besides this, the structure of Bangla language makes it difficult to perform modeling tasks, which we attempted to solve using subword tokenization"
          ],
          [
           "1911.07613",
           "By using subwords instead of words, not only does it bring together the same words with various extensions, but it also significantly reduces the vocabulary size required to train the model to a similar level of accuracy"
          ],
          [
           "1604.04661",
           "gorithm and improvements In order to solve the optimization problem described in the previous section, Stochastic Gradient Descent (SGD) is commonly used"
          ],
          [
           "1604.04661",
           "SGD is an iterative algorithm; at each iteration, a single $(w_I, w_O)$  pair is picked, where $w_I$  is an input context word and $w_O$  is a target word or a negative sample"
          ],
          [
           "1604.04661",
           "The gradient of the objective function is then calculated w.r.t"
          ],
          [
           "1604.04661",
           "the word vectors for $w_I$  and $w_O$ ; and a small change/update is made to these vectors"
          ],
          [
           "1604.04661",
           "The original implementation of word2vec by Mikolov et al"
          ],
          [
           "1604.04661",
           "https://code.google.com/archive/p/word2vec/ uses Hogwild  to parallelize SGD"
          ],
          [
           "1604.04661",
           "The psuedocode of Hogwild SGD update is shown in Algorithm REF "
          ],
          [
           "1604.04661",
           "Each word is represented as an array of $D$  floating point numbers, corresponding to one row of the two matrices"
          ],
          [
           "1604.04661",
           "These matrices are updated during the computation"
          ],
          [
           "1604.04661",
           "We also take in a specific target word, and a set of $N$  input context words around the target as depicted in Fig"
          ],
          [
           "1604.04661",
           "REF "
          ],
          [
           "1604.04661",
           "The algorithm iterates over the $N$  input words in Lines 2-3"
          ],
          [
           "1604.04661",
           "The psuedocode only shows a single thread; in Hogwild, the loop in Line 2 is parallelized over threads without any additional change in the code"
          ],
          [
           "1604.04661",
           "In the loop at Line 6, we pick either the positive example (the target word in Line 8) or a negative example at random (Line 10)"
          ],
          [
           "1604.04661",
           "Lines 13-15 compute the gradient of the objective function with respect to the choice of input word and positive/negative example"
          ],
          [
           "1604.04661",
           "Lines 17–20 perform the update to the entries $M_{out}[\\text{pos/neg example}]$  and $M_{in}[\\text{input context}]$ "
          ],
          [
           "1604.04661",
           "Table: Conclusion"
          ],
          [
           "1807.03756",
           "Attention methods are ubiquitous tool for areas like natural language processing; however they are difficult to use as latent variable models"
          ],
          [
           "1807.03756",
           "This work explores alternative approaches to latent alignment, through variational attention with promising result"
          ],
          [
           "1807.03756",
           "Future work will experiment with scaling the method on larger-scale tasks and in more complex models, such as multi-hop attention models, transformer models, and structured models, as well as utilizing these latent variables for interpretability and as a way to incorporate prior knowledge."
          ]
         ],
         "hovertemplate": "type=Academic<br>x=%{x}<br>y=%{y}<br>article_id=%{customdata[0]}<br>claim=%{customdata[1]}<extra></extra>",
         "legendgroup": "Academic",
         "marker": {
          "color": "#4ECDC4",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Academic",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          37.50751876831055,
          33.72487258911133,
          37.69859313964844,
          -3.987217664718628,
          10.856277465820312,
          -6.031993865966797,
          -0.7319338321685791,
          38.462928771972656,
          -27.183862686157227,
          0.6377363204956055,
          1.2501991987228394,
          12.263138771057129,
          13.504342079162598,
          11.908370971679688,
          -9.699030876159668,
          -0.7591581344604492,
          -9.65834903717041,
          20.84956169128418,
          -10.079974174499512,
          0.3670385181903839,
          -6.926998615264893,
          -3.8110005855560303,
          -7.888339996337891,
          4.960141658782959,
          -7.453378677368164,
          -4.313398838043213,
          17.44540786743164,
          10.477920532226562,
          -13.772416114807129,
          -13.774421691894531,
          -25.08078384399414,
          -19.076807022094727,
          -17.719621658325195,
          -20.322189331054688,
          -11.264241218566895,
          -10.987778663635254,
          -19.305068969726562,
          17.38492202758789,
          17.482227325439453,
          18.101816177368164,
          16.988082885742188,
          17.137203216552734,
          16.56399154663086,
          -0.15148210525512695,
          -21.652254104614258,
          -0.5100058317184448,
          2.2626452445983887,
          3.1546127796173096,
          -1.873491883277893,
          11.175982475280762,
          -18.245922088623047,
          9.120190620422363,
          -7.235278606414795,
          11.178252220153809,
          11.657317161560059,
          13.113541603088379,
          10.895770072937012,
          12.692778587341309,
          15.498819351196289,
          15.302657127380371,
          9.13229751586914,
          8.476543426513672,
          12.124606132507324,
          12.701420783996582,
          12.615193367004395,
          12.056800842285156,
          -33.0052375793457,
          -29.82139015197754,
          -28.82556915283203,
          -28.559165954589844,
          -28.154033660888672,
          -29.873655319213867,
          -32.57748794555664,
          -34.24470138549805,
          -15.164822578430176,
          -33.56965255737305,
          -33.93921661376953,
          -37.2368278503418,
          -37.857913970947266,
          -38.314659118652344,
          -37.84296417236328,
          -26.9833927154541,
          -37.32898712158203,
          -15.345186233520508,
          -30.958620071411133,
          -16.89539909362793,
          -15.909679412841797,
          -17.72593879699707,
          -29.821468353271484,
          -26.811363220214844,
          -30.264341354370117,
          -27.70066261291504,
          -23.31019401550293,
          2.512160539627075,
          2.121617078781128,
          0.23311898112297058,
          -32.95207595825195,
          -25.200456619262695,
          -33.8977165222168,
          -31.82283592224121,
          11.3584623336792,
          -35.22020721435547,
          -32.23689270019531,
          -24.910017013549805,
          -19.28666114807129,
          -18.250303268432617,
          -18.55915069580078,
          -14.407645225524902,
          24.964574813842773,
          25.226667404174805,
          8.918392181396484,
          -10.344351768493652,
          -14.458988189697266,
          -21.719655990600586,
          -21.454879760742188,
          7.475489139556885,
          -12.677840232849121,
          -22.453054428100586,
          -18.085119247436523,
          -15.062503814697266,
          25.625593185424805,
          26.13861656188965,
          25.562034606933594,
          9.309881210327148,
          -7.004700183868408,
          -6.558929920196533,
          -3.857916831970215,
          -12.521062850952148,
          10.677146911621094,
          -0.9116209149360657,
          8.91257095336914,
          8.689491271972656,
          9.508050918579102,
          9.478187561035156,
          9.833889961242676,
          9.362027168273926,
          10.92546272277832,
          -5.343669414520264,
          -2.294137954711914,
          -3.428913116455078,
          -3.6548547744750977,
          -4.479706764221191,
          -4.660203456878662,
          38.374881744384766,
          3.0577666759490967,
          -2.877258539199829,
          -6.065153121948242,
          4.135274410247803,
          1.3149824142456055,
          0.6577155590057373,
          0.6755548715591431,
          1.5971012115478516,
          -7.0353169441223145,
          17.949304580688477,
          17.142894744873047,
          5.987664222717285,
          -5.9691853523254395,
          -33.433841705322266,
          -0.8547248244285583,
          -0.5380287766456604,
          25.837785720825195,
          -15.203319549560547,
          0.8922256827354431,
          2.581488609313965,
          7.204035758972168,
          6.9107842445373535,
          3.6359028816223145,
          10.203225135803223,
          -33.45390701293945,
          -33.7416877746582,
          -33.72553253173828,
          -0.9493891596794128,
          0.40290722250938416,
          7.398660182952881,
          -2.473156452178955,
          -1.6266076564788818,
          20.0690860748291,
          25.26857566833496,
          8.3342866897583,
          20.703662872314453,
          20.43168067932129,
          15.446507453918457,
          20.419178009033203,
          3.289200782775879,
          3.686011552810669,
          -7.866971969604492,
          -0.19952712953090668,
          -1.9882317781448364,
          0.15331880748271942,
          1.3751144409179688,
          18.195899963378906,
          -10.042928695678711,
          0.9704498052597046,
          -14.345429420471191,
          13.0134916305542,
          29.1470947265625,
          29.369022369384766,
          4.553056240081787,
          6.206396579742432,
          -8.355913162231445,
          -24.17786407470703,
          23.0457820892334,
          -8.197297096252441,
          -12.413517951965332,
          -11.633784294128418,
          -10.659514427185059,
          -18.082063674926758,
          -11.823793411254883,
          -11.847221374511719,
          6.4825310707092285,
          5.491875648498535,
          3.1188278198242188,
          5.498499870300293,
          4.896403789520264,
          11.777422904968262,
          6.465175628662109,
          2.8529789447784424,
          8.145499229431152,
          9.776198387145996,
          5.792269706726074,
          0.9026698470115662,
          -11.687403678894043,
          -5.960418224334717,
          11.732880592346191,
          -3.7707011699676514,
          -5.983993053436279,
          -10.560630798339844,
          39.52251052856445,
          -14.762518882751465,
          5.378166675567627,
          -5.749050140380859,
          -15.880921363830566,
          5.48186731338501,
          5.5923566818237305,
          5.506289958953857,
          5.461214065551758,
          6.892463684082031,
          3.932729482650757,
          15.886736869812012,
          5.927090167999268,
          -3.814786911010742,
          9.334617614746094,
          3.7454607486724854,
          -4.267001152038574,
          0.6090076565742493,
          -3.8454604148864746,
          -3.9281561374664307,
          9.316221237182617,
          9.686248779296875,
          10.474237442016602,
          37.791465759277344,
          34.977787017822266,
          35.402069091796875,
          38.41337966918945,
          -2.2936112880706787,
          28.741558074951172,
          37.26197052001953,
          36.70407485961914,
          4.847349643707275,
          -24.14387321472168,
          -22.357126235961914,
          -23.970022201538086,
          -25.01138687133789,
          -23.509431838989258,
          -24.169322967529297,
          -10.0248384475708,
          -7.30413293838501,
          -12.987038612365723,
          -14.296213150024414,
          -22.517559051513672,
          -15.562797546386719,
          -13.248906135559082,
          -18.892732620239258,
          -1.2094988822937012,
          -15.338301658630371,
          -14.9672269821167,
          -17.321887969970703,
          -14.444130897521973,
          16.01866912841797,
          15.897425651550293,
          13.012763977050781,
          6.094951152801514,
          14.410846710205078,
          -7.581597805023193,
          -9.048851013183594,
          -7.12817907333374,
          19.505537033081055,
          19.067338943481445,
          14.829404830932617,
          18.43701934814453,
          19.103168487548828,
          19.759334564208984,
          18.145057678222656,
          12.090209007263184,
          -13.151778221130371,
          -13.19550895690918,
          21.955888748168945,
          -4.104129314422607,
          26.924070358276367,
          17.723342895507812,
          17.659114837646484,
          -3.652562379837036,
          -27.148685455322266,
          19.871240615844727,
          -21.038166046142578,
          -21.584543228149414,
          19.169279098510742,
          4.559182167053223,
          -12.751852035522461,
          -12.874114990234375,
          -23.68766975402832,
          -24.177583694458008,
          -3.1435697078704834,
          -25.932723999023438,
          1.021803855895996,
          2.48455548286438,
          9.220038414001465,
          -7.326602935791016,
          -7.751675605773926,
          33.9165153503418,
          32.986446380615234,
          32.42546081542969,
          34.02438735961914,
          -11.977753639221191,
          -11.459717750549316,
          -5.5575737953186035,
          36.345436096191406,
          -6.476707458496094,
          -5.7621355056762695,
          -5.738725662231445,
          -6.074191093444824,
          -7.10930061340332,
          -24.471193313598633,
          -14.20959758758545,
          -4.401955604553223,
          -15.674206733703613,
          18.69774055480957,
          7.478601932525635,
          -24.940792083740234,
          -25.53023338317871,
          18.334470748901367,
          -40.272064208984375,
          0.9266648292541504,
          -4.91867733001709,
          7.806191921234131,
          7.699032783508301,
          15.31059455871582,
          -18.153118133544922,
          -8.966777801513672,
          -8.669292449951172,
          5.917445659637451,
          1.6893601417541504,
          6.687962532043457,
          -23.28941535949707,
          -3.191265344619751,
          -2.9844412803649902,
          -3.035053014755249,
          12.237018585205078,
          2.5491933822631836,
          4.613470077514648,
          1.5591882467269897,
          -1.9285471439361572,
          -0.22156983613967896,
          6.29307222366333,
          -16.23699188232422,
          16.582443237304688,
          2.05130934715271,
          3.831383228302002,
          16.573930740356445,
          -9.067883491516113,
          2.1138131618499756,
          6.613706111907959,
          -1.6197773218154907,
          7.574114799499512,
          -21.953100204467773,
          -21.65590476989746,
          -21.819129943847656,
          -23.663877487182617,
          -23.863100051879883,
          -25.890363693237305,
          32.93941116333008,
          -23.419401168823242,
          -25.914958953857422,
          -12.672675132751465,
          -16.484189987182617,
          -18.97640037536621,
          7.611484050750732,
          -6.054244041442871,
          11.494344711303711,
          -4.327210903167725,
          9.994049072265625,
          7.880931854248047,
          6.5687336921691895,
          4.063329696655273,
          3.3263111114501953,
          1.512912631034851,
          -16.952749252319336,
          -41.64741134643555,
          -43.54628372192383,
          -42.4945068359375,
          -42.64503860473633,
          -40.96200180053711,
          -42.250648498535156,
          -43.02225112915039,
          -42.26649856567383,
          -41.21050262451172,
          3.20749831199646,
          6.431737422943115,
          5.439194679260254,
          4.284845352172852,
          0.31126031279563904,
          -12.304858207702637,
          -11.133075714111328,
          17.83684539794922,
          -5.389813423156738,
          -5.731264591217041,
          -32.923065185546875,
          0.0930408462882042,
          19.072908401489258,
          -7.493447303771973,
          -7.883587837219238,
          20.337779998779297,
          6.227965831756592,
          13.821969985961914,
          -1.181395173072815,
          -2.3382089138031006,
          8.11566162109375,
          -17.539323806762695,
          -18.687780380249023,
          -18.1962833404541,
          -18.108753204345703,
          -10.436175346374512,
          23.790510177612305,
          23.215402603149414,
          3.630845308303833,
          1.4598597288131714,
          -2.1490964889526367,
          -2.235874652862549,
          3.2317731380462646,
          2.759904384613037,
          2.7493185997009277,
          -19.164884567260742,
          -18.836368560791016,
          -0.07064073532819748,
          1.647864818572998,
          -2.0371487140655518,
          -9.494074821472168,
          3.7385127544403076,
          -0.7763230204582214,
          2.939542055130005,
          14.934929847717285,
          3.5889055728912354,
          11.472018241882324,
          -7.614495754241943,
          -22.706710815429688,
          -25.034852981567383,
          -24.66652488708496,
          -24.743389129638672,
          -23.040010452270508,
          -23.133249282836914,
          9.060810089111328,
          -14.685431480407715,
          -23.624662399291992,
          -25.906810760498047,
          -10.024150848388672,
          -24.943700790405273,
          4.510751724243164,
          -9.486442565917969,
          -15.644194602966309,
          -25.564102172851562,
          -25.932689666748047,
          -26.34874725341797,
          -27.2487850189209,
          -29.065095901489258,
          -0.003578071715310216,
          15.110281944274902,
          28.068605422973633,
          25.72117042541504,
          25.9094181060791,
          26.73370933532715,
          27.61444664001465,
          28.148157119750977,
          29.442502975463867,
          29.397741317749023,
          -20.8210506439209,
          -25.960737228393555,
          -26.07733154296875,
          -26.70978355407715,
          -26.817420959472656,
          36.73492431640625,
          35.514259338378906,
          36.24082946777344,
          34.90322494506836,
          -9.293290138244629,
          -8.932866096496582,
          5.886360168457031,
          -8.266785621643066,
          4.42296028137207,
          11.374802589416504,
          18.385009765625,
          10.634482383728027,
          11.146233558654785,
          -29.164318084716797,
          3.806931972503662,
          -7.504948616027832,
          -5.965035438537598,
          -21.250139236450195,
          -21.334714889526367,
          -17.828594207763672,
          1.9042516946792603,
          -19.480588912963867,
          -19.28148651123047,
          -21.288719177246094,
          -20.06318473815918,
          0.9063076972961426,
          -1.1894805431365967,
          -19.624732971191406,
          -20.236040115356445,
          -20.13374900817871,
          1.4208462238311768,
          -18.64484977722168,
          -20.51044273376465,
          -23.6365966796875,
          21.005760192871094,
          -13.933867454528809,
          -9.99924087524414,
          12.216089248657227,
          -29.575580596923828,
          4.597879409790039,
          -11.011125564575195,
          -10.61865520477295,
          22.35614585876465,
          33.1378059387207,
          16.746065139770508,
          8.535953521728516,
          12.801361083984375,
          8.329704284667969,
          -13.13189697265625,
          -8.744342803955078,
          -13.700953483581543,
          -13.201058387756348,
          -13.440947532653809,
          -14.440807342529297,
          18.203556060791016,
          6.102734565734863,
          -16.423830032348633,
          3.7900547981262207,
          0.011600437574088573,
          -0.2333826869726181,
          32.932212829589844,
          35.89958572387695,
          33.53281021118164,
          34.637939453125,
          32.72398376464844,
          33.349510192871094,
          34.99604034423828,
          33.060359954833984,
          -24.979589462280273,
          -13.939004898071289,
          -13.394683837890625,
          -13.24482536315918,
          -0.20579779148101807,
          -0.27008938789367676,
          -33.15284729003906,
          -8.135870933532715,
          -8.477259635925293,
          -12.019737243652344,
          -10.256048202514648,
          -10.521883010864258,
          -10.125189781188965,
          -12.086418151855469,
          12.698882102966309,
          -16.24291229248047,
          0.5010610222816467,
          -8.45480728149414,
          -8.557713508605957,
          26.547414779663086,
          -10.57314682006836,
          -12.008883476257324,
          24.023286819458008,
          28.14396858215332,
          -4.087405204772949,
          37.33015060424805,
          -3.3018620014190674,
          -9.864964485168457,
          -4.2845778465271,
          9.568964004516602,
          9.676563262939453,
          12.224443435668945,
          -2.095372438430786,
          12.396936416625977,
          9.78684139251709,
          -12.123713493347168,
          -11.29283332824707,
          -9.127317428588867,
          -13.992918014526367,
          -11.816000938415527,
          -13.4850435256958,
          -17.130577087402344,
          -27.733034133911133,
          -27.618947982788086,
          -13.555136680603027,
          2.8862006664276123,
          -23.305511474609375,
          -25.3615779876709,
          -31.15017318725586,
          -23.718868255615234,
          -10.579769134521484,
          4.312141418457031,
          -5.414384365081787,
          4.235158920288086,
          12.359721183776855,
          -10.159550666809082,
          12.421252250671387,
          -4.078413963317871,
          8.931971549987793,
          -1.8693121671676636,
          4.961935520172119,
          25.47296905517578,
          5.414092540740967,
          -13.978870391845703,
          0.2500150501728058,
          3.3911712169647217,
          4.803979396820068,
          22.643436431884766,
          6.969104290008545,
          -15.765629768371582,
          -12.981526374816895,
          2.0006814002990723,
          6.486185550689697,
          0.9537709951400757,
          -18.160491943359375,
          -2.986802816390991,
          7.047781944274902,
          28.76087188720703,
          6.815659523010254,
          -11.652504920959473,
          21.9919376373291,
          22.69007682800293,
          8.529390335083008,
          4.888872146606445,
          -10.241262435913086,
          -10.643406867980957,
          -10.458330154418945,
          -6.946577548980713,
          0.8195104002952576,
          -0.803084671497345,
          38.40721893310547,
          12.4059419631958,
          15.708184242248535,
          15.140317916870117,
          3.2262375354766846,
          11.035255432128906,
          -11.838883399963379,
          25.529342651367188,
          25.34478187561035,
          -12.00873851776123,
          24.876968383789062,
          28.211496353149414,
          28.2497615814209,
          28.249513626098633,
          28.22814178466797,
          9.401368141174316,
          34.070037841796875,
          39.26872634887695,
          15.335834503173828,
          10.026291847229004,
          15.525871276855469,
          -13.218624114990234,
          5.72835111618042,
          -0.9847524166107178,
          -0.4123446047306061,
          0.799752950668335,
          -5.9827046394348145,
          4.134580612182617,
          2.998211622238159,
          2.914166212081909,
          22.900470733642578,
          22.167858123779297,
          20.641910552978516,
          21.671119689941406,
          1.143990159034729,
          -0.589622974395752,
          0.2397077977657318,
          2.4700496196746826,
          13.004283905029297,
          -5.061809539794922,
          18.07166290283203,
          -2.624391794204712,
          -2.597721815109253,
          -4.675816535949707,
          -4.388336658477783,
          -1.8133487701416016,
          -1.7852754592895508,
          -14.613079071044922,
          0.9587006568908691,
          -15.687484741210938,
          -4.249192237854004,
          -15.86691951751709,
          18.06734275817871,
          -14.846793174743652,
          -25.092588424682617,
          23.579208374023438,
          22.836814880371094,
          22.252273559570312
         ],
         "xaxis": "x",
         "y": [
          2.4645071029663086,
          1.870068907737732,
          2.6257119178771973,
          -6.9560546875,
          -7.06830358505249,
          21.381546020507812,
          -27.36894416809082,
          -0.7165725231170654,
          -0.04936017468571663,
          -26.65387725830078,
          -25.40342903137207,
          -16.292537689208984,
          -16.26677703857422,
          -16.165029525756836,
          -14.246175765991211,
          0.3168099522590637,
          32.06627655029297,
          -1.4392061233520508,
          -13.497186660766602,
          4.269590854644775,
          20.941091537475586,
          13.230587005615234,
          16.40522003173828,
          25.329504013061523,
          -19.167186737060547,
          -18.468637466430664,
          -2.9716360569000244,
          19.082616806030273,
          -7.50035285949707,
          -9.8512601852417,
          19.722576141357422,
          -14.88298511505127,
          -12.493765830993652,
          -14.140799522399902,
          -18.270849227905273,
          -18.150243759155273,
          -14.783564567565918,
          -20.165205001831055,
          -19.0036563873291,
          -21.438180923461914,
          -17.578229904174805,
          -20.67060089111328,
          -20.901582717895508,
          12.859394073486328,
          -10.68601131439209,
          25.451812744140625,
          -11.810225486755371,
          -10.556241035461426,
          -18.39975357055664,
          -8.787585258483887,
          26.619226455688477,
          12.403702735900879,
          -10.645306587219238,
          9.845752716064453,
          9.372845649719238,
          6.412094593048096,
          12.52374267578125,
          6.3310465812683105,
          4.663629531860352,
          4.69096565246582,
          -20.330751419067383,
          -19.646883010864258,
          6.15313720703125,
          10.64969539642334,
          7.794187068939209,
          10.706947326660156,
          -10.593318939208984,
          -18.563997268676758,
          -17.60702133178711,
          -16.266550064086914,
          -15.100445747375488,
          -15.771342277526855,
          -11.184798240661621,
          -11.474745750427246,
          30.257688522338867,
          -11.926319122314453,
          -11.117399215698242,
          14.007699012756348,
          14.268856048583984,
          14.434489250183105,
          13.499201774597168,
          -12.1780424118042,
          12.50904655456543,
          30.234128952026367,
          -12.128172874450684,
          21.843477249145508,
          33.44569778442383,
          29.55985450744629,
          -13.109987258911133,
          -19.979671478271484,
          -20.34551239013672,
          -16.639728546142578,
          24.866785049438477,
          -11.329899787902832,
          -10.11921501159668,
          -12.928803443908691,
          -21.27605438232422,
          20.661561965942383,
          -8.717726707458496,
          -19.504776000976562,
          -28.969194412231445,
          -12.963556289672852,
          -18.503459930419922,
          17.236087799072266,
          -18.007997512817383,
          -19.056171417236328,
          -18.493314743041992,
          -30.183773040771484,
          6.626236915588379,
          5.305360794067383,
          -7.37257194519043,
          4.0089898109436035,
          -30.124059677124023,
          -17.220970153808594,
          -16.538015365600586,
          -11.302437782287598,
          33.0113525390625,
          -17.62380027770996,
          -2.6519055366516113,
          -12.466789245605469,
          -3.478966236114502,
          -3.7231528759002686,
          -4.4480133056640625,
          -23.258054733276367,
          -16.827800750732422,
          -17.038000106811523,
          -25.72282600402832,
          2.9641549587249756,
          -24.47667694091797,
          -15.519216537475586,
          -30.896974563598633,
          -30.776203155517578,
          -31.784969329833984,
          4.253836154937744,
          -25.406471252441406,
          -25.119569778442383,
          -25.25947380065918,
          22.27933120727539,
          -13.085275650024414,
          -11.96090030670166,
          -10.703645706176758,
          -10.305041313171387,
          -10.309203147888184,
          7.015807628631592,
          -20.827974319458008,
          -12.320920944213867,
          -27.077566146850586,
          -22.750896453857422,
          -7.613718509674072,
          -5.89649772644043,
          -5.991501808166504,
          -7.8279547691345215,
          33.1690673828125,
          -6.657120227813721,
          -7.31298828125,
          -27.876705169677734,
          -29.417604446411133,
          -17.598934173583984,
          20.280813217163086,
          21.554161071777344,
          5.018558979034424,
          -10.65190315246582,
          -17.885099411010742,
          -17.729888916015625,
          -4.238465785980225,
          -3.777855634689331,
          -12.857684135437012,
          -10.406023025512695,
          6.6279377937316895,
          5.924744129180908,
          5.989825248718262,
          40.39046096801758,
          14.883360862731934,
          9.30351734161377,
          -8.113753318786621,
          -8.390679359436035,
          -22.386770248413086,
          23.400850296020508,
          12.90730094909668,
          -20.614173889160156,
          -26.972890853881836,
          29.726032257080078,
          -27.0206356048584,
          -40.99915313720703,
          -40.92621612548828,
          7.850217342376709,
          25.223909378051758,
          25.73280143737793,
          -4.975644111633301,
          -1.0307949781417847,
          14.264300346374512,
          32.12389373779297,
          -0.9510142803192139,
          -11.85991096496582,
          -9.822650909423828,
          -3.7792770862579346,
          -4.714053630828857,
          -11.076255798339844,
          13.949084281921387,
          -11.02534008026123,
          -21.887765884399414,
          -10.33092212677002,
          -10.963427543640137,
          4.332064151763916,
          5.0778069496154785,
          28.14837074279785,
          -12.087958335876465,
          4.753119945526123,
          25.009370803833008,
          -14.382668495178223,
          -13.543829917907715,
          -14.723233222961426,
          -14.655597686767578,
          -13.736555099487305,
          -11.203170776367188,
          -13.638062477111816,
          -14.748920440673828,
          -24.23314094543457,
          -22.8514404296875,
          -13.113212585449219,
          -18.097787857055664,
          -20.356172561645508,
          4.304820537567139,
          -4.7570271492004395,
          3.900986433029175,
          14.943770408630371,
          32.99419403076172,
          6.016541481018066,
          20.319080352783203,
          11.964465141296387,
          4.514299392700195,
          5.407435894012451,
          -36.94088363647461,
          -39.81037902832031,
          -39.87244415283203,
          -37.029178619384766,
          -18.89780044555664,
          -18.330617904663086,
          -11.269207000732422,
          -24.360769271850586,
          -17.572898864746094,
          -10.924834251403809,
          22.772958755493164,
          -20.616432189941406,
          -21.896135330200195,
          -21.110488891601562,
          -20.086912155151367,
          38.943214416503906,
          38.83186340332031,
          38.54672622680664,
          5.344653606414795,
          13.131328582763672,
          13.280889511108398,
          4.92078161239624,
          -5.825654029846191,
          4.803819179534912,
          8.0199556350708,
          8.516111373901367,
          -29.198808670043945,
          26.278249740600586,
          27.564332962036133,
          26.477413177490234,
          26.845455169677734,
          27.262149810791016,
          27.756040573120117,
          1.608810544013977,
          18.22798728942871,
          22.034494400024414,
          18.286815643310547,
          26.683393478393555,
          21.700700759887695,
          21.854475021362305,
          22.13538360595703,
          22.341751098632812,
          22.657926559448242,
          27.223867416381836,
          19.5283145904541,
          27.40785789489746,
          -12.96982479095459,
          -12.053997039794922,
          13.75979232788086,
          -21.849807739257812,
          -22.144344329833984,
          -34.91794967651367,
          -35.57844924926758,
          -34.755836486816406,
          1.4374467134475708,
          11.204453468322754,
          11.516636848449707,
          11.50249195098877,
          12.552068710327148,
          12.270706176757812,
          14.331551551818848,
          24.935701370239258,
          -12.16375732421875,
          -12.014330863952637,
          -0.41970470547676086,
          35.29375457763672,
          5.710131645202637,
          18.185848236083984,
          18.210063934326172,
          35.178001403808594,
          16.769376754760742,
          -3.5411529541015625,
          0.7459073662757874,
          8.515008926391602,
          9.255561828613281,
          -5.745520114898682,
          -4.689470291137695,
          -4.342924118041992,
          11.955936431884766,
          12.52650260925293,
          18.300874710083008,
          -7.88100004196167,
          22.739826202392578,
          21.21487808227539,
          4.860797882080078,
          -13.01220989227295,
          26.233510971069336,
          22.542234420776367,
          22.852462768554688,
          22.315704345703125,
          22.157712936401367,
          -9.403825759887695,
          -10.0509033203125,
          -24.663888931274414,
          4.097219467163086,
          -21.15447425842285,
          -25.267763137817383,
          1.1049082279205322,
          1.961605429649353,
          4.3902106285095215,
          -11.096695899963379,
          -13.37990665435791,
          26.903093338012695,
          -14.320183753967285,
          2.423990249633789,
          17.212055206298828,
          -12.77279281616211,
          -12.340483665466309,
          2.676541566848755,
          2.965193271636963,
          18.43461036682129,
          27.15616226196289,
          -15.12900161743164,
          -12.695829391479492,
          14.108497619628906,
          -11.35787582397461,
          -26.228845596313477,
          -7.777855396270752,
          22.221031188964844,
          -14.081216812133789,
          18.291820526123047,
          -3.722224235534668,
          17.241544723510742,
          16.510480880737305,
          -19.290699005126953,
          -1.2225209474563599,
          -23.28374671936035,
          -25.333101272583008,
          -22.177993774414062,
          -21.336214065551758,
          -23.229249954223633,
          -17.332517623901367,
          7.156966686248779,
          21.502086639404297,
          8.833672523498535,
          8.531052589416504,
          21.49538230895996,
          -31.064428329467773,
          8.543320655822754,
          2.284914493560791,
          30.963943481445312,
          33.01935958862305,
          -30.565343856811523,
          -29.715898513793945,
          -29.949176788330078,
          -30.606569290161133,
          -31.080854415893555,
          -31.65903091430664,
          25.19417953491211,
          -31.366886138916016,
          -31.75798797607422,
          -1.2445757389068604,
          7.685396671295166,
          4.272562026977539,
          33.004878997802734,
          0.9481265544891357,
          -4.668649196624756,
          5.2294840812683105,
          17.279048919677734,
          9.30397891998291,
          25.536563873291016,
          35.70156478881836,
          36.677711486816406,
          39.4133415222168,
          1.1655360460281372,
          -0.147007018327713,
          1.197006106376648,
          1.8468303680419922,
          0.5939702391624451,
          1.6466267108917236,
          1.6534247398376465,
          3.287487745285034,
          3.0224974155426025,
          1.201225996017456,
          -27.53953742980957,
          -22.15359115600586,
          5.308796405792236,
          -27.4366397857666,
          22.15096092224121,
          -27.00095558166504,
          18.25417709350586,
          34.532806396484375,
          -5.905433654785156,
          -0.07178030163049698,
          -17.862171173095703,
          -2.973853349685669,
          -6.898776054382324,
          -2.9868459701538086,
          -3.4105336666107178,
          -7.264692783355713,
          12.754402160644531,
          10.693769454956055,
          -22.81232261657715,
          25.765268325805664,
          -26.371389389038086,
          -22.1068058013916,
          -23.63478660583496,
          -23.515357971191406,
          -24.501317977905273,
          -2.923292636871338,
          4.155125617980957,
          12.890127182006836,
          11.695741653442383,
          -30.86882972717285,
          -31.882015228271484,
          -31.715545654296875,
          -4.663349628448486,
          -38.45772933959961,
          -38.46681594848633,
          17.672204971313477,
          18.173444747924805,
          -2.3495559692382812,
          1.3646950721740723,
          -0.5828801989555359,
          -5.111348628997803,
          3.07069993019104,
          4.310145854949951,
          2.5777275562286377,
          25.758827209472656,
          1.4828773736953735,
          -28.92877960205078,
          29.34221076965332,
          8.359606742858887,
          11.193714141845703,
          10.852631568908691,
          9.903651237487793,
          9.609956741333008,
          10.18251895904541,
          15.356158256530762,
          25.471614837646484,
          8.556086540222168,
          9.574178695678711,
          21.483510971069336,
          -21.703105926513672,
          17.170875549316406,
          23.761375427246094,
          -4.992724895477295,
          -23.99060821533203,
          -21.645326614379883,
          -24.445390701293945,
          -23.011144638061523,
          13.75483512878418,
          -20.21324920654297,
          10.058518409729004,
          20.154146194458008,
          24.166574478149414,
          24.42363166809082,
          21.706649780273438,
          21.063140869140625,
          20.1619873046875,
          17.996795654296875,
          18.03367805480957,
          -2.7104849815368652,
          -7.081534385681152,
          -5.692196846008301,
          -4.842039585113525,
          -4.582955360412598,
          6.3910417556762695,
          6.096193313598633,
          5.851072788238525,
          6.308802604675293,
          11.907269477844238,
          11.816937446594238,
          5.845370769500732,
          11.68832015991211,
          -30.296714782714844,
          28.782136917114258,
          -0.06358956545591354,
          29.710102081298828,
          29.025104522705078,
          13.740662574768066,
          30.98920440673828,
          25.650157928466797,
          35.27927780151367,
          -9.063737869262695,
          -8.917573928833008,
          -7.637087345123291,
          15.749351501464844,
          -6.009369850158691,
          -9.479776382446289,
          -7.541114807128906,
          -1.2840468883514404,
          -16.637094497680664,
          -15.785632133483887,
          -6.134612560272217,
          -0.2818353772163391,
          -9.02148723602295,
          15.267121315002441,
          -7.120174407958984,
          -8.439866065979004,
          17.570507049560547,
          -12.617260932922363,
          -16.011810302734375,
          -4.227916240692139,
          -19.3828182220459,
          -19.5173282623291,
          -9.469731330871582,
          30.7808895111084,
          -6.574182033538818,
          -9.839862823486328,
          3.31227445602417,
          5.941523551940918,
          21.738731384277344,
          21.54189109802246,
          -9.287906646728516,
          -23.51094627380371,
          29.521406173706055,
          -23.31388282775879,
          -22.501493453979492,
          -22.21445083618164,
          -22.148937225341797,
          -6.031153202056885,
          -10.89009952545166,
          -16.78215980529785,
          13.405622482299805,
          1.3902145624160767,
          2.5995378494262695,
          5.91142463684082,
          3.0118043422698975,
          -2.185281991958618,
          -3.129714012145996,
          -1.4326037168502808,
          -0.4138222336769104,
          3.939971446990967,
          -2.2551980018615723,
          -21.351146697998047,
          10.756948471069336,
          10.620077133178711,
          10.633224487304688,
          -10.871190071105957,
          -10.891623497009277,
          7.354381084442139,
          -21.60019302368164,
          -25.7551326751709,
          -15.363364219665527,
          -18.603822708129883,
          16.384126663208008,
          -22.12813949584961,
          14.716596603393555,
          -12.100615501403809,
          -7.939906597137451,
          35.617835998535156,
          -5.507317066192627,
          36.96680450439453,
          8.42426872253418,
          -9.73876667022705,
          34.20578384399414,
          8.87674617767334,
          7.73891544342041,
          -23.34884262084961,
          4.39851713180542,
          -24.282155990600586,
          23.91891098022461,
          -23.38418960571289,
          -13.329360961914062,
          16.01139259338379,
          17.676490783691406,
          30.35105323791504,
          -8.282745361328125,
          -13.44920825958252,
          -13.986322402954102,
          -11.447027206420898,
          17.88042449951172,
          15.451606750488281,
          29.152402877807617,
          17.0473575592041,
          33.90890121459961,
          2.5944294929504395,
          2.6021876335144043,
          16.512367248535156,
          11.745798110961914,
          3.1458981037139893,
          3.3076467514038086,
          -9.641827583312988,
          3.0032384395599365,
          32.08504867553711,
          8.35417366027832,
          21.760591506958008,
          -16.557920455932617,
          4.690274238586426,
          17.84339141845703,
          4.16167688369751,
          21.051395416259766,
          6.379931449890137,
          -3.0093090534210205,
          -2.9978020191192627,
          4.178577899932861,
          -2.725804328918457,
          -8.81916618347168,
          5.719577312469482,
          -18.617883682250977,
          -20.68982696533203,
          3.2348337173461914,
          -9.872200965881348,
          -4.187500953674316,
          -14.213512420654297,
          26.463027954101562,
          19.157285690307617,
          27.473730087280273,
          -29.563262939453125,
          -16.404693603515625,
          12.449102401733398,
          -0.8376286029815674,
          -9.624974250793457,
          -13.458072662353516,
          -10.139540672302246,
          -8.940979957580566,
          9.315217018127441,
          17.72347640991211,
          -35.674922943115234,
          8.423221588134766,
          -35.69404602050781,
          -13.829461097717285,
          28.71027946472168,
          -27.462779998779297,
          -0.28674080967903137,
          -0.7219011783599854,
          0.37852558493614197,
          0.46093931794166565,
          19.47351837158203,
          3.1066477298736572,
          31.65363121032715,
          7.886291980743408,
          8.345260620117188,
          34.205955505371094,
          8.92618465423584,
          7.760605335235596,
          -10.385249137878418,
          -10.356527328491211,
          13.579751014709473,
          0.06418196856975555,
          4.667992115020752,
          3.7002320289611816,
          -3.8810226917266846,
          -16.750225067138672,
          -26.230527877807617,
          -24.710853576660156,
          -32.374488830566406,
          -0.8783549666404724,
          -24.53829574584961,
          -24.315977096557617,
          -29.29920768737793,
          -27.313932418823242,
          -22.41758918762207,
          -21.827274322509766,
          -17.219749450683594,
          -17.505958557128906,
          -20.068618774414062,
          -17.349294662475586,
          -31.040876388549805,
          -32.18625259399414,
          -31.690237045288086,
          -1.4931976795196533,
          22.15960121154785,
          8.599573135375977,
          25.581119537353516,
          1.6583211421966553,
          -0.24703259766101837,
          9.166655540466309,
          9.816100120544434,
          7.789036750793457,
          7.951825141906738,
          -0.8103621006011963,
          39.16826629638672,
          -0.6631342172622681,
          10.264411926269531,
          0.6918197274208069,
          25.521957397460938,
          0.7754757404327393,
          17.167680740356445,
          5.806394100189209,
          6.1948981285095215,
          7.981233596801758
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "hoverlabel": {
         "bgcolor": "white"
        },
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "t-SNE visualization of conclusion claims"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get conclusion claims\n",
    "industry_claims = [\n",
    "    claim for claims in industry_papers[\"conclusion_claims\"] for claim in claims\n",
    "]\n",
    "academic_claims = [\n",
    "    claim for claims in academic_papers[\"conclusion_claims\"] for claim in claims\n",
    "]\n",
    "\n",
    "# Create labels (0 for industry, 1 for academic)\n",
    "labels = [0] * len(industry_claims) + [1] * len(academic_claims)\n",
    "\n",
    "# Combine all claims\n",
    "all_claims = industry_claims + academic_claims\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(all_claims, show_progress_bar=True)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame with all information\n",
    "plot_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": tsne_results[:, 0],\n",
    "        \"y\": tsne_results[:, 1],\n",
    "        \"type\": [\"Industry\" if l == 0 else \"Academic\" for l in labels],\n",
    "        \"claim\": all_claims,\n",
    "        \"article_id\": (\n",
    "            [\n",
    "                i\n",
    "                for row in industry_papers.iterrows()\n",
    "                for i in [row[1][\"id\"]] * len(row[1][\"conclusion_claims\"])\n",
    "            ]\n",
    "            + [\n",
    "                i\n",
    "                for row in academic_papers.iterrows()\n",
    "                for i in [row[1][\"id\"]] * len(row[1][\"conclusion_claims\"])\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "fig = px.scatter(\n",
    "    plot_data,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"type\",\n",
    "    hover_data=[\"article_id\", \"claim\"],\n",
    "    title=\"t-SNE visualization of conclusion claims\",\n",
    "    color_discrete_map={\"Industry\": \"#FF6B6B\", \"Academic\": \"#4ECDC4\"},\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(hoverlabel=dict(bgcolor=\"white\"), width=1000, height=600)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbered_sections(text_array):\n",
    "    # Initialize result dictionary\n",
    "    result = {}\n",
    "\n",
    "    # Extract title (first array)\n",
    "    result[\"title\"] = text_array[0][0]\n",
    "\n",
    "    # Extract abstract (second array)\n",
    "    result[\"abstract\"] = \" \".join(text_array[1]) if len(text_array) > 1 else \"\"\n",
    "\n",
    "    # Process remaining sections\n",
    "    for i, section in enumerate(text_array[2:], 1):\n",
    "        if len(section) > 0:\n",
    "            section_name = section[0].strip()\n",
    "            section_content = \" \".join(section[1:]) if len(section) > 1 else \"\"\n",
    "            result[f\"section_{i}\"] = (section_name, section_content)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Find max number of sections\n",
    "max_sections_industry = max(\n",
    "    len(text) - 2 for text in industry_papers[\"text\"]\n",
    ")  # -2 for title and abstract\n",
    "\n",
    "# Create DataFrame with numbered sections\n",
    "sections_df_industry = pd.DataFrame(\n",
    "    [extract_numbered_sections(text) for text in industry_papers[\"text\"]]\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "sections_df_industry = sections_df_industry.fillna(\"\")\n",
    "\n",
    "# Find max number of sections\n",
    "max_sections_academic = max(\n",
    "    len(text) - 2 for text in academic_papers[\"text\"]\n",
    ")  # -2 for title and abstract\n",
    "\n",
    "# Create DataFrame with numbered sections\n",
    "sections_df_academic = pd.DataFrame(\n",
    "    [extract_numbered_sections(text) for text in academic_papers[\"text\"]]\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "sections_df_academic = sections_df_academic.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry papers statistics:\n",
      "Mean: 17.28\n",
      "Median: 18.00\n",
      "Std: 8.76\n",
      "\n",
      "Academic papers statistics:\n",
      "Mean: 19.56\n",
      "Median: 18.00\n",
      "Std: 9.30\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count sections for each paper (excluding title and abstract)\n",
    "industry_sections = [len(text) - 2 for text in industry_papers[\"text\"]]\n",
    "academic_sections = [len(text) - 2 for text in academic_papers[\"text\"]]\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(\n",
    "    [industry_sections, academic_sections],\n",
    "    label=[\"Industry\", \"Academic\"],\n",
    "    bins=range(\n",
    "        min(min(industry_sections), min(academic_sections)),\n",
    "        max(max(industry_sections), max(academic_sections)) + 2,\n",
    "        1,\n",
    "    ),\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Number of Sections in Papers\")\n",
    "plt.xlabel(\"Number of Sections\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Industry papers statistics:\")\n",
    "print(f\"Mean: {np.mean(industry_sections):.2f}\")\n",
    "print(f\"Median: {np.median(industry_sections):.2f}\")\n",
    "print(f\"Std: {np.std(industry_sections):.2f}\")\n",
    "print(f\"\\nAcademic papers statistics:\")\n",
    "print(f\"Mean: {np.mean(academic_sections):.2f}\")\n",
    "print(f\"Median: {np.median(academic_sections):.2f}\")\n",
    "print(f\"Std: {np.std(academic_sections):.2f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 99/99 [00:18<00:00,  5.37it/s]\n",
      "/Users/omar/Library/Caches/pypoetry/virtualenvs/streem-wind-prod-forecast-jFLq_jOy-py3.9/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning:\n",
      "\n",
      "The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "\n",
      "/Users/omar/Library/Caches/pypoetry/virtualenvs/streem-wind-prod-forecast-jFLq_jOy-py3.9/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning:\n",
      "\n",
      "The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Findings of the Third Workshop on Neural Generation and Translation"
          ],
          [
           "Abstract  This document describes the findings of the Third Workshop on Neural Generation and Translation, held in concert with the annual conference of the Empirical Methods in Natural Language Processing (EMNLP 2019)."
          ],
          [
           "Introduction"
          ],
          [
           "Summary of Research Contributions"
          ],
          [
           "Shared Task: Document-level Generation and Translation"
          ],
          [
           "Evaluation Measures"
          ],
          [
           "Data"
          ],
          [
           "Baseline Systems"
          ],
          [
           "Submitted Systems"
          ],
          [
           "Team EdiNLG"
          ],
          [
           "Team FIT-Monash"
          ],
          [
           "Team Microsoft"
          ],
          [
           "Team Naver Labs Europe"
          ],
          [
           "Team SYSTRAN-AI"
          ],
          [
           "Results"
          ],
          [
           "Shared Task: Efficient NMT"
          ],
          [
           "Evaluation Measures"
          ],
          [
           "Data"
          ],
          [
           "Baseline Systems"
          ],
          [
           "Submitted Systems"
          ],
          [
           "Team Marian"
          ],
          [
           "Team Notre Dame"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Full Shared Task Results"
          ],
          [
           "From Fully Trained to Fully Random Embeddings: Improving Neural Machine\n  Translation with Compact Word Embedding Tables"
          ],
          [
           "Abstract  Embedding matrices are key components in neural natural language processing (NLP) models that are responsible to provide numerical representations of input tokens.\\footnote{In this paper words and subwords are referred to as \\textit{tokens} and the term \\textit{embedding} only refers to embeddings of inputs.}"
          ],
          [
           "Introduction"
          ],
          [
           "Product Quantization (PQ)"
          ],
          [
           "Methodology"
          ],
          [
           "Random Word Embeddings (RWE)"
          ],
          [
           "Gaussian Product Quantization (GPQ)"
          ],
          [
           "Structured Partitioning"
          ],
          [
           "Unified Partitioning"
          ],
          [
           "Experiments"
          ],
          [
           "Evaluation"
          ],
          [
           "Model and Training Details"
          ],
          [
           "Random Word Embeddings"
          ],
          [
           "Gaussian Product Quantization"
          ],
          [
           "Experiments for Discrete Space Approximation"
          ],
          [
           "Experiments for Compression Analysis"
          ],
          [
           "Cluster and Group Size Analysis"
          ],
          [
           "Compression Analysis"
          ],
          [
           "Importance of Variance"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Emergence of Grounded Compositional Language in Multi-Agent Populations"
          ],
          [
           "Abstract  By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Problem Formulation"
          ],
          [
           "Grounded Communication Environment"
          ],
          [
           "Policy Learning with Backpropagation"
          ],
          [
           "Discrete Communication and Gumbel-Softmax Estimator"
          ],
          [
           "Policy Architecture"
          ],
          [
           "Auxiliary Prediction Reward"
          ],
          [
           "Compositionality and Vocabulary Size"
          ],
          [
           "Experiments"
          ],
          [
           "Syntactic Structure"
          ],
          [
           "Symbol Vocabulary Usage"
          ],
          [
           "Generalization to Unseen Configurations"
          ],
          [
           "Non-verbal Communication and Other Strategies"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Can Active Memory Replace Attention?"
          ],
          [
           "Abstract  Several mechanisms to focus attention of a neural network on selected parts of its input or memory have been used successfully in deep learning models in recent years."
          ],
          [
           "Introduction"
          ],
          [
           "Active Memory Models"
          ],
          [
           "The Markovian Neural GPU"
          ],
          [
           "The Extended Neural GPU"
          ],
          [
           "Related Models"
          ],
          [
           "Experiments"
          ],
          [
           "Parsing."
          ],
          [
           "Discussion"
          ],
          [
           "Show and Tell: A Neural Image Caption Generator"
          ],
          [
           "Abstract  Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Model"
          ],
          [
           "LSTM-based Sentence Generator"
          ],
          [
           "Training"
          ],
          [
           "Inference"
          ],
          [
           "Experiments"
          ],
          [
           "Evaluation Metrics"
          ],
          [
           "Datasets"
          ],
          [
           "Results"
          ],
          [
           "Training Details"
          ],
          [
           "Generation Results"
          ],
          [
           "Transfer Learning, Data Size and Label Quality"
          ],
          [
           "Generation Diversity Discussion"
          ],
          [
           "Ranking Results"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Analysis of Embeddings"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Neural language models for network configuration: Opportunities and\n  reality check"
          ],
          [
           "Abstract  Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (e.g."
          ],
          [
           "Introduction"
          ],
          [
           "NLP for “Network Language” Processing"
          ],
          [
           "Configuration Verification"
          ],
          [
           "Configuration Synthesis"
          ],
          [
           "Configuration Translation"
          ],
          [
           "Current State of the Art in Network Configuration"
          ],
          [
           "Configuration Verification"
          ],
          [
           "Configuration Synthesis"
          ],
          [
           "Configuration Explanation"
          ],
          [
           "NLP for “Computer Language” Processing"
          ],
          [
           "Code Verification"
          ],
          [
           "Code Synthesis"
          ],
          [
           "Code Translation"
          ],
          [
           "Other software-related tasks"
          ],
          [
           "Automated code documentation"
          ],
          [
           "Automated code completion/repair"
          ],
          [
           "Transfer from programming to configuration languages: a reality check"
          ],
          [
           "Lessons from computer language field"
          ],
          [
           "Impact on network configuration"
          ],
          [
           "Lessons from computer language field"
          ],
          [
           "Impact on network configuration"
          ],
          [
           "Lessons from computer language field"
          ],
          [
           "Impact on network configuration"
          ],
          [
           "Lessons from computer language field"
          ],
          [
           "Impact on network configuration"
          ],
          [
           "Lessons from computer language field"
          ],
          [
           "Impact on network configuration"
          ],
          [
           "Conclusion and recommendations"
          ],
          [
           "Problems with automating translation of movie/TV show subtitles"
          ],
          [
           "Abstract  We present 27 problems encountered in automating the translation of movie/TV show subtitles."
          ],
          [
           "Introduction"
          ],
          [
           "Problems"
          ],
          [
           "Problems related to subtitle creation guidelines"
          ],
          [
           "Problems related to textual translation"
          ],
          [
           "Machine Translation adaptability Problems"
          ],
          [
           "Subtitle Validation Experiment"
          ],
          [
           "Conclusion"
          ],
          [
           "Multi-task Pre-training Language Model for Semantic Network Completion"
          ],
          [
           "Abstract  Semantic networks, such as the knowledge graph, can represent the knowledge leveraging the graph structure."
          ],
          [
           "Introduction"
          ],
          [
           "Link Prediction"
          ],
          [
           "Language Model Pre-training"
          ],
          [
           "Overall Framework"
          ],
          [
           "Multi-task Pre-training"
          ],
          [
           "Mask Entity Modeling(MEM)"
          ],
          [
           "Mask Relation Modeling(MRM)"
          ],
          [
           "Mask Language Modeling(MLM)"
          ],
          [
           "Pre-traning Loss Designing"
          ],
          [
           "Knowledge Representation"
          ],
          [
           "Contrastive Learning"
          ],
          [
           "Triple Augmentation"
          ],
          [
           "Mixed Precision"
          ],
          [
           "Fine-tuning Loss Designing"
          ],
          [
           "Experiments"
          ],
          [
           "Experiment Settings and Datasets"
          ],
          [
           "Experimental Results"
          ],
          [
           "Ablation Study"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Paraphrase Thought: Sentence Embedding Module Imitating Human Language\n  Recognition"
          ],
          [
           "Abstract  Sentence embedding is an important research topic in natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Defining semantic coherence"
          ],
          [
           "Evaluating semantic coherence: paraphrase coherence"
          ],
          [
           "Model structure"
          ],
          [
           "Objective"
          ],
          [
           "Vocabulary expansion"
          ],
          [
           "Experimental settings"
          ],
          [
           "P-coherence"
          ],
          [
           "STS Benchmark task"
          ],
          [
           "Conclusion"
          ],
          [
           "Syntax-based Deep Matching of Short Texts"
          ],
          [
           "Abstract  Many tasks in natural language processing, ranging from machine translation to question answering, can be reduced to the problem of matching two sentences or more generally two short texts."
          ],
          [
           "Introduction"
          ],
          [
           "Direct Product of Graphs (PoG)"
          ],
          [
           "Dependency Tree"
          ],
          [
           "Direct Product of Graphs"
          ],
          [
           "Abstraction"
          ],
          [
           "Sub-graphs of PoG as Matching Patterns"
          ],
          [
           "Mining of Matching Patterns"
          ],
          [
           "Speeding-up the Mining Process"
          ],
          [
           "Mining without Abstraction"
          ],
          [
           "Mining with Abstraction"
          ],
          [
           "Advantage of Tree Pattern Mining"
          ],
          [
           "The Deep Matching Model"
          ],
          [
           "Model Description"
          ],
          [
           "Learning"
          ],
          [
           "Architecture Learning"
          ],
          [
           "The Selection of Overall Architecture"
          ],
          [
           "Parameter Learning"
          ],
          [
           "Experiments"
          ],
          [
           "Datasets and Evaluation Metric"
          ],
          [
           "Original-vs-Random:"
          ],
          [
           "Retrieval-based Conversation:"
          ],
          [
           "Competitor Methods"
          ],
          [
           "Results on Original-vs-Random"
          ],
          [
           "Comparison to Competitor Models"
          ],
          [
           "Results on Conversation Data"
          ],
          [
           "Deep vs. Shallow Patterns"
          ],
          [
           "The effect of abstraction"
          ],
          [
           "Related Work"
          ],
          [
           "Deep Matching Models"
          ],
          [
           "Graph-based Kernel"
          ],
          [
           "String-Rewriting Kernel"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledge"
          ],
          [
           "Reducing Transformer Depth on Demand with Structured Dropout"
          ],
          [
           "Abstract  Overparameterized transformer networks have obtained state of the art results in various natural language processing tasks, such as machine translation, language modeling, and question answering."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Method"
          ],
          [
           "The Transformer Architecture"
          ],
          [
           "Training Transformers with Random Structured Pruning"
          ],
          [
           "Randomly Dropping Structures at Training Time"
          ],
          [
           "Random Structured Dropout."
          ],
          [
           "Selecting Layers to Prune"
          ],
          [
           "Setting the drop rate for optimal pruning."
          ],
          [
           "Experimental Setup"
          ],
          [
           "Neural Machine Translation."
          ],
          [
           "Language Modeling."
          ],
          [
           "Summarization."
          ],
          [
           "Long Form Question Answering."
          ],
          [
           "Sentence representation Pre-training."
          ],
          [
           "Language Modeling."
          ],
          [
           "Sequence to sequence modeling."
          ],
          [
           "Bi-Directional Pre-training."
          ],
          [
           "Pruning Generation Tasks."
          ],
          [
           "Pruning BERT-like Models."
          ],
          [
           "Comparison of Structured Dropout"
          ],
          [
           "Comparison of Various Pruning Strategies."
          ],
          [
           "Choosing which Layers to Prune."
          ],
          [
           "Relationship between LayerDrop at Training Time and Pruning at Inference Time."
          ],
          [
           "Conclusion"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Language Modeling"
          ],
          [
           "Summarization"
          ],
          [
           "Long Form Question Answering"
          ],
          [
           "Bi-Directional Pre-Training"
          ],
          [
           "IWSLT"
          ],
          [
           "Pruning BERT Models"
          ],
          [
           "Impact of LayerDrop on training time."
          ],
          [
           "BERT: Relationship between LayerDrop at Training Time and Pruning at Inference Time"
          ],
          [
           "Impact of Finetuning."
          ],
          [
           "Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in\n  Practice"
          ],
          [
           "Abstract  Classifiers in natural language processing (NLP) often have a large number of output classes."
          ],
          [
           "Introduction"
          ],
          [
           "Low-Rank Softmax (Softmax Bottleneck)"
          ],
          [
           "Unargmaxable Classes"
          ],
          [
           "Detecting Unargmaxable Classes"
          ],
          [
           "Definitions"
          ],
          [
           "Softmax"
          ],
          [
           "Discretising the Output Space into Permutations"
          ],
          [
           "How Can Unargmaxable Classes Arise?"
          ],
          [
           "Effect of Softmax Bias Term"
          ],
          [
           "Exact Algorithm"
          ],
          [
           "Chebyshev Center Linear Programme"
          ],
          [
           "Approximate Algorithm"
          ],
          [
           "Braid Reflect"
          ],
          [
           "Experiments"
          ],
          [
           "Language Models (0/7 Unargmaxable)"
          ],
          [
           "Machine Translation (13/143 Unargmaxable)"
          ],
          [
           "Discussion"
          ],
          [
           "Infrequent Tokens Are the Victims"
          ],
          [
           "Some Models Are Easier to Verify"
          ],
          [
           "Conclusions and Future Work"
          ],
          [
           "Broader Impact"
          ],
          [
           "Halfspace interpretation"
          ],
          [
           "Hyperplane Arrangements"
          ],
          [
           "Braid Arrangement"
          ],
          [
           "Restricting the Braid Arrangement to Lower Dimensions"
          ],
          [
           "Number of Regions (Feasible Permutations) of the Restricted Braid Arrangement"
          ],
          [
           "Softmax with no Bias Term"
          ],
          [
           "Softmax with Bias Term"
          ],
          [
           "Activation Range of Softmax Layer Inputs"
          ],
          [
           "Controlling generative models with continuous factors of variations"
          ],
          [
           "Abstract  Recent deep generative models are able to provide photo-realistic images as well as visual or textual content embeddings useful to address various tasks of computer vision and natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Latent Space Directions of a Factor of Variation"
          ],
          [
           "Latent Space Trajectories of an Image transformation "
          ],
          [
           "Choice of the reconstruction error $\\mathcal {L}$"
          ],
          [
           "Recursive Estimation of the Trajectory"
          ],
          [
           "Encoding Model of the Factor of Variation in the Latent Space."
          ],
          [
           "Experiments"
          ],
          [
           "Quantitative evaluation method"
          ],
          [
           "Results on BigGAN"
          ],
          [
           "The importance of disentangled representations"
          ],
          [
           "Related works"
          ],
          [
           "Conclusions"
          ],
          [
           "Penalty on the amplitude of frequencies due to MSE"
          ],
          [
           "$\\beta $ -VAE architecture"
          ],
          [
           "Qualitative and quantitative experiments with our reconstruction error"
          ],
          [
           "On the difficulty of optimization on the natural image manifold."
          ],
          [
           "Additional qualitative examples"
          ],
          [
           "Robust Parsing Based on Discourse Information: Completing partial parses\n  of ill-formed sentences on the basis of discourse information"
          ],
          [
           "Abstract  In a consistent text, many words and phrases are repeatedly used in more than one sentence."
          ],
          [
           "Introduction"
          ],
          [
           "Discourse information for completing incomplete parses"
          ],
          [
           "Algorithm"
          ],
          [
           "Step 1: Inspecting each partial parse and restructuring\nit on the basis of the discourse information"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Complex Coordinate-Based Meta-Analysis with Probabilistic Programming"
          ],
          [
           "Abstract  With the growing number of published functional magnetic resonance imaging (fMRI) studies, meta-analysis databases and models have become an integral part of brain mapping research."
          ],
          [
           "Introduction"
          ],
          [
           "Term-based queries on cbma databases"
          ],
          [
           "plp"
          ],
          [
           "CP-Logic"
          ],
          [
           "Syntactic restrictions and probabilistic databases"
          ],
          [
           "Probabilistic cbma databases"
          ],
          [
           "Encoding a cbma database as a probabilistic logic program"
          ],
          [
           "Equivalence between the program of fig:program and the\ncbma approach of sec:term-based-queries"
          ],
          [
           "Solving queries on probabilistic cbma databases"
          ],
          [
           "kc approaches do not scale to the size of neuroimaging data\n"
          ],
          [
           "Lifted processing of ucq on probabilistic cbma\ndatabases"
          ],
          [
           "Relating terms and studies probabilistically"
          ],
          [
           "Experiments and results"
          ],
          [
           "Gain of statistical power when solving two-term cq\n$\\textbf {P}\\left[A_k|T_i \\wedge T_j\\right]$  on smaller simulated\ncbma databases\n"
          ],
          [
           "Gain of activation consistency on a real cbma database"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Free software"
          ],
          [
           "Attention Mechanism with Energy-Friendly Operations"
          ],
          [
           "Abstract  Attention mechanism has become the dominant module in natural language processing models."
          ],
          [
           "Dataset Preprocessing"
          ],
          [
           "Experimental Setting"
          ],
          [
           "Binarization Statistics"
          ],
          [
           "Case Study"
          ],
          [
           "Self-attention with Functional Time Representation Learning"
          ],
          [
           "Abstract  Sequential modelling with self-attention has achieved cutting edge performances in natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Preliminaries"
          ],
          [
           "Bochner Time Embedding"
          ],
          [
           "Mercer Time Embedding"
          ],
          [
           "Time-event Interaction"
          ],
          [
           "Experiment and Result"
          ],
          [
           "Data Sets"
          ],
          [
           "Baselines and Model configurations"
          ],
          [
           "Experimental results"
          ],
          [
           "Conlusion"
          ],
          [
           "Proof of Claim 1"
          ],
          [
           "Proof of Proposition 1"
          ],
          [
           "Fourier series under truncation"
          ],
          [
           "Flow-based distribution learning"
          ],
          [
           "Dataset details"
          ],
          [
           "Training and model configuration"
          ],
          [
           "Initialization for time embedding methods"
          ],
          [
           "Training efficiency"
          ],
          [
           "Sensitivity analysis"
          ],
          [
           "Cases study for attention weights"
          ],
          [
           "Visualization of time embeddings and time kernel functions"
          ],
          [
           "Reference implementation"
          ],
          [
           "Uncertainty Determines the Adequacy of the Mode and the Tractability of\n  Decoding in Sequence-to-Sequence Models"
          ],
          [
           "Abstract  In many natural language processing (NLP) tasks the same input (e.g."
          ],
          [
           "Introduction"
          ],
          [
           "Measuring Intrinsic Uncertainty"
          ],
          [
           "Mode-seeking Search"
          ],
          [
           "$N$ -best Search"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Results"
          ],
          [
           "Finding the Most Likely Hypothesis"
          ],
          [
           "Sentence-level uncertainty"
          ],
          [
           "The Spread of Probability Mass"
          ],
          [
           "Sentence-level uncertainty"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "T-GSA: Transformer with Gaussian-weighted self-attention for speech\n  enhancement"
          ],
          [
           "Abstract  Transformer neural networks (TNN) demonstrated state-of-art performance on many natural language processing (NLP) tasks, replacing recurrent neural networks (RNNs), such as LSTMs or GRUs."
          ],
          [
           "Introduction"
          ],
          [
           "Proposed Architectures"
          ],
          [
           "GSA: Gaussian-weighted Self-Attention"
          ],
          [
           "Extension to Complex Transformer Architecture"
          ],
          [
           "End-to-End Metric Optimization"
          ],
          [
           "Experimental Settings"
          ],
          [
           "Main Result"
          ],
          [
           "Comparison with Generative Models"
          ],
          [
           "Conclusion"
          ],
          [
           "Accelerating Neural Architecture Exploration Across Modalities Using\n  Genetic Algorithms"
          ],
          [
           "Abstract  Neural architecture search (NAS), the study of automating the discovery of optimal deep neural network architectures for tasks in domains such as computer vision and natural language processing, has seen rapid growth in the machine learning research community."
          ],
          [
           "Introduction"
          ],
          [
           "Proposed Algorithm"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks"
          ],
          [
           "Abstract  Unsupervised pre-training of large neural models has recently revolutionized Natural Language Processing."
          ],
          [
           "Introduction"
          ],
          [
           "Models and Pre-trained Checkpoints"
          ],
          [
           "Investigated Model Variants"
          ],
          [
           "Sentence Fusion"
          ],
          [
           "Split and Rephrase"
          ],
          [
           "Machine Translation"
          ],
          [
           "Abstractive Summarization"
          ],
          [
           "Combining Different Checkpoints."
          ],
          [
           "Tuning GPT-2 Based Models."
          ],
          [
           "Initializing only Embeddings."
          ],
          [
           "Initializing only Layers."
          ],
          [
           "Initializing a Subset of Layers."
          ],
          [
           "Analysis of Abstractive Summaries"
          ],
          [
           "Human Assessment of Summary Quality."
          ],
          [
           "Summary Lengths and Repetitions."
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Data Augmentation for Low-Resource Named Entity Recognition Using\n  Backtranslation"
          ],
          [
           "Abstract  The state of art natural language processing systems relies on sizable training datasets to achieve high performance."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Data Augmentation via Backtranslation"
          ],
          [
           "Datasets"
          ],
          [
           "NER Model"
          ],
          [
           "Backtranslation Models"
          ],
          [
           "Hyperparameters"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning\n  Challenge"
          ],
          [
           "Abstract  Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Model"
          ],
          [
           "LSTM-based Sentence Generator"
          ],
          [
           "Inference"
          ],
          [
           "Experiments"
          ],
          [
           "Evaluation Metrics"
          ],
          [
           "Datasets"
          ],
          [
           "Results"
          ],
          [
           "Training Details"
          ],
          [
           "Generation Results"
          ],
          [
           "Transfer Learning, Data Size and Label Quality"
          ],
          [
           "Generation Diversity Discussion"
          ],
          [
           "Ranking Results"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Analysis of Embeddings"
          ],
          [
           "The MS COCO Image Captioning Challenge"
          ],
          [
           "Metrics"
          ],
          [
           "Improvements Over Our CVPR15 Model"
          ],
          [
           "Image Model Improvement"
          ],
          [
           "Image Model Fine Tuning"
          ],
          [
           "Scheduled Sampling"
          ],
          [
           "Ensembling"
          ],
          [
           "Beam Size Reduction"
          ],
          [
           "Automatic Evaluation"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgment"
          ]
         ],
         "hovertemplate": "type=Industry<br>x=%{x}<br>y=%{y}<br>section_name=%{customdata[0]}<extra></extra>",
         "legendgroup": "Industry",
         "marker": {
          "color": "#FF6B6B",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Industry",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          6.306635856628418,
          6.352681636810303,
          15.336811065673828,
          -25.685611724853516,
          -2.9663784503936768,
          -2.395252227783203,
          -2.891631603240967,
          24.40161895751953,
          -15.113088607788086,
          -19.733163833618164,
          -20.767995834350586,
          -19.900127410888672,
          -23.070276260375977,
          -20.324010848999023,
          -20.50540542602539,
          47.40854263305664,
          -2.3955647945404053,
          -3.6158668994903564,
          24.401588439941406,
          -15.113088607788086,
          -20.958332061767578,
          -20.991718292236328,
          -20.5528621673584,
          -55.84619140625,
          -55.460105895996094,
          -13.843140602111816,
          4.671195030212402,
          16.6567325592041,
          10.646578788757324,
          19.29499053955078,
          5.842380523681641,
          14.5195951461792,
          19.824138641357422,
          11.975663185119629,
          11.970787048339844,
          43.77104187011719,
          -3.726116418838501,
          38.118804931640625,
          14.701172828674316,
          19.817989349365234,
          15.965959548950195,
          15.627265930175781,
          -17.08404541015625,
          15.627715110778809,
          11.883831024169922,
          -18.9193058013916,
          -47.18475341796875,
          -0.8496171236038208,
          -5.051381587982178,
          16.358417510986328,
          -20.42240333557129,
          16.095962524414062,
          -36.53679275512695,
          34.01881790161133,
          34.97004318237305,
          32.071983337402344,
          35.22987365722656,
          -20.471162796020508,
          42.816715240478516,
          -19.645797729492188,
          -19.253114700317383,
          13.741913795471191,
          -36.4014778137207,
          -45.42448806762695,
          -36.72683334350586,
          40.508872985839844,
          32.99458694458008,
          13.440930366516113,
          41.04649353027344,
          25.93443489074707,
          25.951078414916992,
          22.699020385742188,
          43.772239685058594,
          -22.640522003173828,
          -42.40605926513672,
          11.294700622558594,
          12.080806732177734,
          14.440091133117676,
          -20.963640213012695,
          26.30420684814453,
          16.308759689331055,
          40.213233947753906,
          -27.225963592529297,
          44.7335090637207,
          -0.34935128688812256,
          4.143885612487793,
          -20.708436965942383,
          40.460716247558594,
          -30.207759857177734,
          6.339697360992432,
          -32.0830192565918,
          -11.655545234680176,
          -6.544799327850342,
          19.083524703979492,
          -59.093048095703125,
          -35.63644027709961,
          24.87059211730957,
          18.768789291381836,
          12.007413864135742,
          -8.428637504577637,
          43.8807487487793,
          42.83273696899414,
          43.0172119140625,
          37.660057067871094,
          43.880645751953125,
          42.83266830444336,
          43.2646369934082,
          -8.324054718017578,
          -9.455102920532227,
          -9.089430809020996,
          -9.73824405670166,
          -15.197981834411621,
          -9.87475872039795,
          -10.135184288024902,
          43.04819869995117,
          -3.5764927864074707,
          38.43326187133789,
          -3.578268527984619,
          38.429595947265625,
          -3.5775465965270996,
          38.42962646484375,
          -3.577321767807007,
          38.42955017089844,
          -3.5765466690063477,
          38.43390655517578,
          -47.5223503112793,
          -3.4107565879821777,
          -3.4152214527130127,
          12.164774894714355,
          -20.568248748779297,
          -41.500484466552734,
          -7.118284702301025,
          -2.3764679431915283,
          -41.4986457824707,
          -46.146488189697266,
          7.293744087219238,
          2.5973381996154785,
          13.018381118774414,
          -22.8179874420166,
          6.106279373168945,
          11.673932075500488,
          45.00535202026367,
          5.227259159088135,
          5.2582926750183105,
          4.033697605133057,
          26.53648567199707,
          3.6985671520233154,
          17.06629753112793,
          4.308319091796875,
          10.30872917175293,
          26.498048782348633,
          43.263465881347656,
          43.573856353759766,
          45.00785827636719,
          61.64140701293945,
          -58.623477935791016,
          13.643503189086914,
          15.105473518371582,
          2.6519525051116943,
          -26.584823608398438,
          -23.982410430908203,
          -24.110244750976562,
          27.40472412109375,
          0.9939791560173035,
          -18.375202178955078,
          44.17924880981445,
          -24.10771942138672,
          4.983310222625732,
          -58.974788665771484,
          -2.2409262657165527,
          -2.5347464084625244,
          13.86507511138916,
          -16.66962242126465,
          -27.6727237701416,
          -16.817716598510742,
          -30.65567970275879,
          -16.0050106048584,
          -14.912859916687012,
          -12.888046264648438,
          -13.189013481140137,
          -13.23704719543457,
          -14.710774421691895,
          20.4630069732666,
          26.384031295776367,
          36.48935317993164,
          31.60032844543457,
          33.02573013305664,
          30.91888999938965,
          44.7335090637207,
          1.3798080682754517,
          39.77505874633789,
          -34.44184875488281,
          2.8069498538970947,
          39.78300476074219,
          2.7886924743652344,
          -34.429935455322266,
          20.222509384155273,
          -30.683807373046875,
          -17.918678283691406,
          20.484668731689453,
          14.375040054321289,
          -13.121210098266602,
          -44.91139602661133,
          -34.702796936035156,
          44.99898147583008,
          24.741121292114258,
          19.584041595458984,
          -22.736133575439453,
          9.49388599395752,
          45.65721893310547,
          44.141300201416016,
          41.69873809814453,
          41.73663330078125,
          41.40323257446289,
          36.66963577270508,
          47.723541259765625,
          2.6899585723876953,
          2.2560360431671143,
          -38.3227424621582,
          -9.868330955505371,
          8.92489242553711,
          2.2553043365478516,
          13.52258014678955,
          42.92512130737305,
          37.02591323852539,
          -0.6591692566871643,
          41.658321380615234,
          36.83641052246094,
          41.39834976196289,
          40.80409240722656,
          -46.39327621459961,
          3.2602622509002686,
          2.257908344268799,
          -38.18037796020508,
          -9.862067222595215,
          42.91825485229492,
          -24.061004638671875,
          -0.6648913025856018,
          40.87997817993164,
          40.761844635009766,
          -4.910656452178955,
          36.988555908203125,
          -4.122269630432129,
          16.412229537963867,
          35.83823776245117,
          37.80882263183594,
          37.83415603637695,
          5.810940742492676,
          35.540096282958984,
          19.0506591796875,
          37.7799186706543,
          35.716796875,
          14.27383041381836,
          16.931419372558594,
          14.99008846282959,
          -39.52040481567383,
          42.66546630859375,
          1.699751615524292,
          -3.814025640487671,
          -40.620601654052734,
          -14.785343170166016,
          23.86141586303711,
          -57.23941421508789,
          -6.435641765594482,
          -29.23529052734375,
          18.65993881225586,
          18.873716354370117,
          18.902606964111328,
          18.86121940612793,
          35.679893493652344,
          35.658206939697266,
          35.45541763305664,
          26.986026763916016,
          20.100074768066406,
          1.458672285079956,
          16.371919631958008,
          16.637025833129883,
          49.97076416015625,
          16.4591121673584,
          16.339879989624023,
          44.775230407714844,
          -1.921684980392456,
          -17.828140258789062,
          19.89743995666504,
          -23.885452270507812,
          -49.51286315917969,
          28.781034469604492,
          30.23784065246582,
          50.139957427978516,
          17.93278694152832,
          -10.836811065673828,
          -26.245729446411133,
          -22.95992088317871,
          15.583883285522461,
          -26.454891204833984,
          13.974250793457031,
          -26.41693687438965,
          -22.501541137695312,
          -55.42265701293945,
          -36.31412124633789,
          -42.073055267333984,
          -41.972412109375,
          13.322731018066406,
          -8.80870532989502,
          -27.481367111206055,
          -27.843332290649414,
          -19.742090225219727,
          -8.113666534423828,
          -8.13871955871582,
          -8.94049072265625,
          -8.265340805053711,
          33.994754791259766,
          -7.98176908493042,
          -14.220893859863281,
          44.85118103027344,
          -7.513527870178223,
          -7.955766677856445,
          -40.727813720703125,
          -45.17851257324219,
          -7.603598594665527,
          33.915321350097656,
          29.852602005004883,
          -2.247650146484375,
          44.7011604309082,
          10.122270584106445,
          -11.49808120727539,
          33.87694549560547,
          28.04714012145996,
          12.890717506408691,
          -19.343372344970703,
          22.550350189208984,
          22.6063175201416,
          22.73883819580078,
          27.82602882385254,
          46.37395095825195,
          3.3011345863342285,
          24.795589447021484,
          45.008209228515625,
          -56.44602966308594,
          -53.49510192871094,
          -53.50080108642578,
          26.17090606689453,
          10.796822547912598,
          1.2935047149658203,
          38.5493049621582,
          22.093284606933594,
          39.691829681396484,
          10.778634071350098,
          34.46387481689453,
          22.812292098999023,
          16.537071228027344,
          13.90179443359375,
          -4.087264060974121,
          14.314352989196777,
          10.361958503723145,
          37.34354019165039,
          9.4542236328125,
          48.419246673583984,
          -21.901126861572266,
          -28.598079681396484,
          -17.767620086669922,
          20.263626098632812,
          -17.767606735229492,
          -18.16506576538086,
          -59.41434860229492,
          32.57025146484375,
          22.47277069091797,
          11.955894470214844,
          32.47325134277344,
          33.075443267822266,
          45.44932556152344,
          1.4889209270477295,
          44.17989730834961,
          -21.731977462768555,
          27.167715072631836,
          -58.61967086791992,
          31.579992294311523,
          30.97186851501465,
          1.06132972240448,
          13.868202209472656,
          48.2923698425293,
          -23.165552139282227,
          -59.81600570678711,
          -55.409523010253906,
          8.611027717590332,
          2.007838249206543,
          -55.438385009765625,
          24.424341201782227,
          -27.718229293823242,
          -28.93115234375,
          -3.9729790687561035,
          -37.07829666137695,
          -55.465763092041016,
          24.97608757019043,
          21.154190063476562,
          41.93097686767578,
          41.83637237548828,
          -37.04182052612305,
          -7.682157516479492,
          -36.52771759033203,
          -27.64378547668457,
          -58.416114807128906,
          -54.63146209716797,
          6.162176132202148,
          -0.13964205980300903,
          1.572277545928955,
          -19.741764068603516,
          4.295773983001709,
          5.385383129119873,
          18.57447052001953,
          5.057380676269531,
          32.23881149291992,
          -22.43548011779785,
          -60.007164001464844,
          10.9365816116333,
          12.080820083618164,
          11.70521068572998,
          -26.963485717773438,
          26.304410934448242,
          16.3088321685791,
          -27.226032257080078,
          43.14486312866211,
          -0.3497043550014496,
          4.394131660461426,
          -21.81163215637207,
          40.4608154296875,
          -30.207759857177734,
          6.339697360992432,
          -32.08278274536133,
          -11.655546188354492,
          -6.54495096206665,
          19.083396911621094,
          10.903741836547852,
          2.7334630489349365,
          22.912612915039062,
          18.415996551513672,
          18.53475570678711,
          5.608966827392578,
          20.99325180053711,
          36.23988723754883,
          -4.39206600189209,
          -6.54495096206665,
          -46.753456115722656,
          -55.23356628417969
         ],
         "xaxis": "x",
         "y": [
          54.70536804199219,
          54.70174026489258,
          -66.99767303466797,
          -40.553253173828125,
          51.583702087402344,
          -17.507946014404297,
          1.0412461757659912,
          -26.14337158203125,
          -20.78713035583496,
          -12.697540283203125,
          -13.459266662597656,
          -12.687888145446777,
          -11.72380256652832,
          -12.862627029418945,
          -27.568296432495117,
          -2.915025234222412,
          -17.50795555114746,
          1.0661325454711914,
          -26.143367767333984,
          -20.78713035583496,
          -13.788718223571777,
          -13.86719036102295,
          -25.923770904541016,
          0.807284951210022,
          -42.68159103393555,
          -6.837323188781738,
          54.94936752319336,
          42.826324462890625,
          -51.188995361328125,
          16.77477264404297,
          -38.28047180175781,
          47.57794189453125,
          16.862659454345703,
          -6.102421760559082,
          -6.106858253479004,
          -39.208953857421875,
          -19.230356216430664,
          -1.2963937520980835,
          47.456661224365234,
          16.868688583374023,
          -26.847270965576172,
          -4.891844749450684,
          -12.477285385131836,
          -4.891480922698975,
          -11.634659767150879,
          -54.95475387573242,
          -6.583405494689941,
          32.40789031982422,
          45.27943801879883,
          -65.34049224853516,
          -54.93324661254883,
          -30.162433624267578,
          33.81936264038086,
          8.170236587524414,
          19.531904220581055,
          -17.75406265258789,
          8.099403381347656,
          40.714820861816406,
          -40.90403366088867,
          32.94549560546875,
          43.60346603393555,
          8.842482566833496,
          33.7064323425293,
          -7.976871490478516,
          -38.25851058959961,
          32.25368118286133,
          35.7096061706543,
          -67.24008178710938,
          31.89794158935547,
          26.215179443359375,
          26.207826614379883,
          -17.520980834960938,
          -39.4472770690918,
          28.352052688598633,
          -21.34324836730957,
          61.253822326660156,
          58.30474090576172,
          -67.25990295410156,
          -55.4203987121582,
          -16.79645538330078,
          31.61886215209961,
          0.7889688014984131,
          2.010040044784546,
          -39.47517013549805,
          -16.528179168701172,
          -0.2517770528793335,
          -26.178430557250977,
          -0.4770510196685791,
          8.298020362854004,
          5.435296058654785,
          7.449172019958496,
          -14.363853454589844,
          -17.555326461791992,
          46.465614318847656,
          -5.904728412628174,
          -36.625789642333984,
          23.270992279052734,
          39.28892517089844,
          -66.04637145996094,
          40.790489196777344,
          -20.52222442626953,
          -19.503372192382812,
          -19.371112823486328,
          -17.609848022460938,
          -20.522336959838867,
          -19.503467559814453,
          -20.54642677307129,
          40.75645446777344,
          15.986072540283203,
          16.33272933959961,
          17.53775405883789,
          -8.727121353149414,
          13.656697273254395,
          13.241423606872559,
          -18.74631118774414,
          30.64037322998047,
          -17.219160079956055,
          30.640962600708008,
          -17.21710777282715,
          30.64081573486328,
          -17.217477798461914,
          30.640869140625,
          -17.217384338378906,
          30.640647888183594,
          -17.219202041625977,
          -15.16507339477539,
          62.91145324707031,
          62.91109085083008,
          -59.86538314819336,
          -32.79207992553711,
          39.89383316040039,
          54.702301025390625,
          56.878448486328125,
          39.8900146484375,
          -6.996781349182129,
          35.22843933105469,
          23.323074340820312,
          -59.61205291748047,
          8.576691627502441,
          34.62044143676758,
          -28.794984817504883,
          2.619973659515381,
          27.14508628845215,
          27.115571975708008,
          28.833520889282227,
          -5.233560562133789,
          23.348649978637695,
          1.0499658584594727,
          8.022242546081543,
          -17.922914505004883,
          -5.355772495269775,
          -37.70867919921875,
          -30.32305908203125,
          -45.48191452026367,
          -29.745792388916016,
          -23.047304153442383,
          44.233985900878906,
          42.32649612426758,
          -47.6435546875,
          -57.24345016479492,
          39.143314361572266,
          39.38513946533203,
          -17.49618148803711,
          -41.92462921142578,
          43.12589645385742,
          -29.70246124267578,
          38.98821258544922,
          -19.075376510620117,
          -6.453803062438965,
          45.09206008911133,
          44.77075958251953,
          -59.3193359375,
          7.88791036605835,
          25.45111656188965,
          7.973166465759277,
          12.968016624450684,
          7.501781940460205,
          6.940738201141357,
          8.02513599395752,
          8.493856430053711,
          8.566840171813965,
          6.819091796875,
          11.945857048034668,
          -18.915943145751953,
          4.36560583114624,
          18.757444381713867,
          -20.23331642150879,
          -30.01415252685547,
          -39.47517013549805,
          -12.456323623657227,
          -45.49654006958008,
          32.521244049072266,
          -32.51301574707031,
          -45.49882888793945,
          -32.4609260559082,
          32.230918884277344,
          12.730672836303711,
          12.97451114654541,
          -54.92178726196289,
          11.881442070007324,
          7.734599590301514,
          26.055397033691406,
          -8.14743423461914,
          -38.114253997802734,
          23.562480926513672,
          37.5643310546875,
          -63.011871337890625,
          -60.04351043701172,
          -37.4262580871582,
          25.024795532226562,
          21.782590866088867,
          -7.986044406890869,
          -8.939266204833984,
          11.17545223236084,
          -7.106396675109863,
          -29.59831428527832,
          55.97395706176758,
          33.64398193359375,
          4.702668190002441,
          28.2451171875,
          31.289052963256836,
          33.64387130737305,
          27.60181999206543,
          2.136913299560547,
          -7.018479824066162,
          18.103553771972656,
          -9.222787857055664,
          -7.072319507598877,
          11.19076919555664,
          7.933902263641357,
          -9.520528793334961,
          55.49128341674805,
          34.259891510009766,
          4.912415027618408,
          28.295162200927734,
          2.253084182739258,
          -9.717218399047852,
          18.101900100708008,
          7.734285354614258,
          8.020575523376465,
          -37.47480010986328,
          18.092113494873047,
          42.12797927856445,
          -61.1619987487793,
          18.925521850585938,
          17.369461059570312,
          17.336759567260742,
          -30.96761131286621,
          19.289379119873047,
          -20.14872932434082,
          17.390382766723633,
          20.003299713134766,
          -25.459609985351562,
          -24.776042938232422,
          -26.18608283996582,
          -10.311652183532715,
          -40.68556594848633,
          36.152793884277344,
          58.43171691894531,
          -21.76875877380371,
          26.256349563598633,
          -13.980425834655762,
          -21.18006706237793,
          -38.53948974609375,
          19.585222244262695,
          -20.876110076904297,
          -21.834196090698242,
          -21.888883590698242,
          -21.668127059936523,
          19.835412979125977,
          19.85270881652832,
          18.979833602905273,
          6.963903427124023,
          40.0477294921875,
          -47.425941467285156,
          10.970266342163086,
          10.523948669433594,
          -15.636161804199219,
          -17.83484649658203,
          11.041365623474121,
          -38.84400939941406,
          -19.189517974853516,
          -22.54218864440918,
          22.37185287475586,
          -55.19692611694336,
          -1.5229169130325317,
          -2.441470146179199,
          -18.943662643432617,
          -15.589940071105957,
          6.709008693695068,
          -31.43233871459961,
          29.91685676574707,
          42.15422821044922,
          -62.551876068115234,
          30.0526180267334,
          -25.33698844909668,
          30.02618408203125,
          -27.281856536865234,
          1.304991602897644,
          -38.948097229003906,
          -1.676803708076477,
          -1.2763090133666992,
          -61.17313003540039,
          9.20300579071045,
          -19.98116683959961,
          3.7285990715026855,
          32.294776916503906,
          8.380838394165039,
          8.238545417785645,
          9.403493881225586,
          8.560232162475586,
          14.722329139709473,
          8.544950485229492,
          -41.069908142089844,
          -43.749935150146484,
          9.070284843444824,
          7.992152214050293,
          -20.855436325073242,
          -7.030238151550293,
          14.765727043151855,
          36.25002670288086,
          37.93201446533203,
          6.113250255584717,
          -30.429006576538086,
          19.453840255737305,
          -35.535404205322266,
          39.54545211791992,
          38.36724853515625,
          -63.20155334472656,
          -55.50905990600586,
          -56.68925476074219,
          45.05729675292969,
          45.016422271728516,
          -40.71144104003906,
          -42.48217010498047,
          0.8145738244056702,
          -24.996143341064453,
          -45.48296356201172,
          2.3471109867095947,
          -8.285871505737305,
          -8.396299362182617,
          32.16975784301758,
          26.894550323486328,
          -1.5802066326141357,
          -2.1293468475341797,
          45.12580871582031,
          2.2302441596984863,
          -14.378615379333496,
          34.97762680053711,
          44.879886627197266,
          -38.27863311767578,
          26.687036514282227,
          42.238372802734375,
          -64.19963073730469,
          -13.456999778747559,
          -23.169200897216797,
          -9.3303804397583,
          -29.044530868530273,
          -27.96963882446289,
          0.5804592967033386,
          30.523956298828125,
          -48.56825256347656,
          30.52399253845215,
          -56.90716552734375,
          -6.167485237121582,
          39.38079071044922,
          37.17649841308594,
          -63.92525100708008,
          -20.950042724609375,
          39.08888244628906,
          25.044498443603516,
          -14.74701976776123,
          -29.70232582092285,
          -21.952350616455078,
          7.058661460876465,
          -5.586973190307617,
          18.989408493041992,
          18.47624397277832,
          -47.92549133300781,
          -25.450773239135742,
          -29.8857364654541,
          -27.09018325805664,
          -4.978292942047119,
          9.297904014587402,
          34.323020935058594,
          -48.848915100097656,
          9.201604843139648,
          -16.5872859954834,
          36.47350311279297,
          36.93780517578125,
          55.36868667602539,
          5.926353454589844,
          9.098651885986328,
          -10.747429847717285,
          45.27042007446289,
          14.555124282836914,
          14.444907188415527,
          5.952718734741211,
          -16.498849868774414,
          2.4650213718414307,
          -57.6123046875,
          -5.978564262390137,
          -40.31558609008789,
          46.39128112792969,
          42.228431701660156,
          -48.96942901611328,
          -56.97190856933594,
          9.097196578979492,
          -0.845473051071167,
          -12.9985933303833,
          9.93103313446045,
          -29.845043182373047,
          -27.041561126708984,
          -5.650617599487305,
          61.50130844116211,
          58.30482482910156,
          -61.574913024902344,
          -57.01866149902344,
          -16.796369552612305,
          31.61869239807129,
          2.010061740875244,
          -37.631614685058594,
          -16.52771759033203,
          -1.3972512483596802,
          -27.900129318237305,
          -0.47665247321128845,
          8.298020362854004,
          5.435296058654785,
          7.44915246963501,
          -14.363847732543945,
          -17.555862426757812,
          46.46580123901367,
          61.4327278137207,
          -15.477398872375488,
          -12.938518524169922,
          7.797183036804199,
          7.702831268310547,
          -8.015666007995605,
          3.2173166275024414,
          -25.541078567504883,
          -16.14908790588379,
          -17.555862426757812,
          -7.022522449493408,
          -45.21253204345703
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Transformer-based Detection of Multiword Expressions in Flower and Plant\n  Names"
          ],
          [
           "Abstract  Multiword expression (MWE) is a sequence of words which collectively present a meaning which is not derived from its individual words."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Data"
          ],
          [
           "Methodology"
          ],
          [
           "Transformer"
          ],
          [
           "BiLSTM-CRF"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Self-Attention with Cross-Lingual Position Representation"
          ],
          [
           "Abstract  Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences."
          ],
          [
           "Introduction"
          ],
          [
           "Position Encoding"
          ],
          [
           "Self-Attention"
          ],
          [
           "Cross-Lingual Position Representation"
          ],
          [
           "Integration Strategy"
          ],
          [
           "Inputting-level XL SANs"
          ],
          [
           "Head-level XL SANs"
          ],
          [
           "Experiments"
          ],
          [
           "Effect of $\\tau $  in HeadXL SANs"
          ],
          [
           "Main Results"
          ],
          [
           "Alignment Quality"
          ],
          [
           "Gain for Context-Free Model"
          ],
          [
           "Effects of Noisy Reordering Information"
          ],
          [
           "Augmenting SANs with position representation"
          ],
          [
           "Modeling cross-lingual divergence"
          ],
          [
           "Conclusions and Future Work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "LightRNN: Memory and Computation-Efficient Recurrent Neural Networks"
          ],
          [
           "Abstract  Recurrent neural networks (RNNs) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "LightRNN"
          ],
          [
           "RNN Model with 2-Component Shared Embedding "
          ],
          [
           "Bootstrap for Word Allocation"
          ],
          [
           "Experiments"
          ],
          [
           "Settings"
          ],
          [
           "Results and Discussions"
          ],
          [
           "Conclusion and future work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "In-context Examples Selection for Machine Translation"
          ],
          [
           "Abstract  Large-scale generative models show an impressive ability to perform a wide range of Natural Language Processing (NLP) tasks using in-context learning, where a few examples are used to describe a task to the model."
          ],
          [
           "Introduction"
          ],
          [
           "Background: In-context Learning"
          ],
          [
           "Prompt Selection"
          ],
          [
           "Task-level In-context Examples"
          ],
          [
           "Example-specific In-context Examples"
          ],
          [
           "Datasets and Evaluation Metric"
          ],
          [
           "Language Model"
          ],
          [
           "Baselines and Comparisons"
          ],
          [
           "Results"
          ],
          [
           "A single task-level prompt is competitive with 16 random few-shot examples."
          ],
          [
           "Multiple example-specific prompts are required to improve translation quality over a single task-level prompt. "
          ],
          [
           "Re-ranking retreived examples improves "
          ],
          [
           "Out-of-domain Evaluation"
          ],
          [
           "Domain of few-shot in-context examples matter."
          ],
          [
           "Example-specific prompts significantly improve translation quality over task-level prompts."
          ],
          [
           "Task-level and R-prompts are complementary."
          ],
          [
           "Choice of Few-shot Examples"
          ],
          [
           "Impact of Pool Size on Task-level Prompt Selection"
          ],
          [
           "Translation direction"
          ],
          [
           "Properties of good Task-level prompts"
          ],
          [
           "Impact of Noise"
          ],
          [
           "Impact of Ordering"
          ],
          [
           "Informativeness of Example-specific Prompts "
          ],
          [
           "Output Analysis"
          ],
          [
           "Stylistic Outputs"
          ],
          [
           "Template-based "
          ],
          [
           "Size of the Datastore"
          ],
          [
           "In-context Learning for "
          ],
          [
           "Domain Adaptation for "
          ],
          [
           "Prompt Selection"
          ],
          [
           "Conclusion"
          ],
          [
           "Statistics of Datasets"
          ],
          [
           "Compute Infrastructure & Run time"
          ],
          [
           "Results using Second Metric: Comet"
          ],
          [
           "Order of Retrieved Examples "
          ],
          [
           "Choice of $\\lambda $ , Threshold"
          ],
          [
           "Example Task-Level Prompts"
          ],
          [
           "uniblock: Scoring and Filtering Corpus with Unicode Block Information"
          ],
          [
           "Abstract  The preprocessing pipelines in Natural Language Processing usually involve a step of removing sentences consisted of illegal characters."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Feature Vectors"
          ],
          [
           "Bayesian Gaussian Mixture Model"
          ],
          [
           "Scoring and Filtering"
          ],
          [
           "Experiments"
          ],
          [
           "Sentiment Analysis"
          ],
          [
           "Language Modeling"
          ],
          [
           "Machine Translation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based\n  Inference Networks"
          ],
          [
           "Abstract  Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation."
          ],
          [
           "Introduction"
          ],
          [
           "Structured Energy-Based Learning"
          ],
          [
           "Inference."
          ],
          [
           "Joint training of energy functions and inference networks."
          ],
          [
           "An Objective for Joint Learning of Inference Networks"
          ],
          [
           "Energy Functions"
          ],
          [
           "Linear Chain Energies"
          ],
          [
           "Skip-Chain Energies"
          ],
          [
           "High-Order Energies"
          ],
          [
           "Vectorized Kronecker Product (VKP):"
          ],
          [
           "CNN:"
          ],
          [
           "Tag Language Model (TLM):"
          ],
          [
           "Self-Attention (S-Att):"
          ],
          [
           "Fully-Connected Energies"
          ],
          [
           "Related Work"
          ],
          [
           "Experimental Setup"
          ],
          [
           "POS."
          ],
          [
           "NER."
          ],
          [
           "CCG."
          ],
          [
           "SRL."
          ],
          [
           "Local Classifiers."
          ],
          [
           "BiLSTM-CRF."
          ],
          [
           "Inference Networks."
          ],
          [
           "Energy Terms."
          ],
          [
           "Hyperparameters."
          ],
          [
           "Parameterizations for High-Order Energies."
          ],
          [
           "Comparing Structured Energy Terms."
          ],
          [
           "Comparison using Deeper Inference Networks."
          ],
          [
           "Results on Noisy Datasets"
          ],
          [
           "Incorporating BERT"
          ],
          [
           "Analysis of Learned Energies"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Local Interpretations for Explainable Natural Language Processing: A\n  Survey"
          ],
          [
           "Abstract  As the use of deep learning techniques has grown across various fields over the past decade, complaints about the opaqueness of the black-box models have increased, resulting in an increased focus on transparency in deep learning models."
          ],
          [
           "Introduction"
          ],
          [
           "Local and Global Interpretability"
          ],
          [
           "Post-hoc vs In-built Interpretations"
          ],
          [
           "Paper layout"
          ],
          [
           "Interpretability requirements"
          ],
          [
           "Dimensions of Interpretability"
          ],
          [
           "Faithfulness"
          ],
          [
           "Stability"
          ],
          [
           "Comprehensibility"
          ],
          [
           "Trustworthiness"
          ],
          [
           "Feature Importance"
          ],
          [
           "Input Perturbation"
          ],
          [
           "Attribution Methods"
          ],
          [
           "Attention weights"
          ],
          [
           "Datasets"
          ],
          [
           "Natural Language Explanation"
          ],
          [
           "VQA and NLE"
          ],
          [
           "Text-only NLE"
          ],
          [
           "Datasets"
          ],
          [
           "Challenges and Future work"
          ],
          [
           "Probing"
          ],
          [
           "Embedding Probes"
          ],
          [
           "Model Probes"
          ],
          [
           "Probe Considerations"
          ],
          [
           "Automatic Evaluation"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Automatic Evaluation"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Evaluation of Probing"
          ],
          [
           "Conclusion"
          ],
          [
           "Curriculum learning for language modeling"
          ],
          [
           "Abstract  Language Models like ELMo and BERT have provided robust representations of natural language, which serve as the language understanding component for a diverse range of downstream tasks.Curriculum learning is a method that employs a structured training regime instead, which has been leveraged in computer vision and machine translation to improve model training speed and model performance."
          ],
          [
           "Introduction"
          ],
          [
           "Headings: first level"
          ],
          [
           "Headings: second level"
          ],
          [
           "Headings: third level"
          ],
          [
           "Paragraph"
          ],
          [
           "Examples of citations, figures, tables, references"
          ],
          [
           "Figures"
          ],
          [
           "Tables"
          ],
          [
           "Lists"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Split and Rephrase"
          ],
          [
           "Abstract  We propose a new sentence simplification task (Split-and-Rephrase) where the aim is to split a complex sentence into a meaning preserving sequence of shorter sentences."
          ],
          [
           "Introduction"
          ],
          [
           "Contributions."
          ],
          [
           "Related Work"
          ],
          [
           "Sentence Splitting."
          ],
          [
           "Rephrasing."
          ],
          [
           "The "
          ],
          [
           "The "
          ],
          [
           "Creating the "
          ],
          [
           "Sentence segmentation"
          ],
          [
           "Pairing"
          ],
          [
           "Ordering."
          ],
          [
           "Results"
          ],
          [
           "Problem Formulation"
          ],
          [
           "Split-and-Rephrase Models"
          ],
          [
           "A Probabilistic, Semantic-Based Approach"
          ],
          [
           "A Basic Sequence-to-Sequence Approach"
          ],
          [
           "A Multi-Source Sequence-to-Sequence Approach"
          ],
          [
           "Partitioning and Generating"
          ],
          [
           "Learning to split."
          ],
          [
           "Learning to rephrase."
          ],
          [
           "Experimental Setup and Results"
          ],
          [
           "Training, Validation and Test sets"
          ],
          [
           "Implementation Details"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language\n  Processing"
          ],
          [
           "Abstract  Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained natural language processing models, we propose a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning."
          ],
          [
           "Introduction"
          ],
          [
           "SpeechT5"
          ],
          [
           "Model Architecture"
          ],
          [
           "Input/Output Representations"
          ],
          [
           "Encoder-Decoder"
          ],
          [
           "Speech Pre/Post Net"
          ],
          [
           "Text Pre/Post Net"
          ],
          [
           "Pre-training"
          ],
          [
           "Speech Learning"
          ],
          [
           "Text Learning"
          ],
          [
           "Joint Pre-training"
          ],
          [
           "Fine-tuning"
          ],
          [
           "Dataset and Evaluation Metrics"
          ],
          [
           "Pre-training"
          ],
          [
           "Fine-tuning and Inference"
          ],
          [
           "VC"
          ],
          [
           "ASR"
          ],
          [
           "TTS"
          ],
          [
           "SID"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Image Captioning using Deep Neural Architectures"
          ],
          [
           "Abstract  Automatically creating the description of an image using any natural languages sentence like English is a very challenging task."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Show & Tell Model"
          ],
          [
           "Training"
          ],
          [
           "Inference"
          ],
          [
           "Implementation"
          ],
          [
           "Datasets"
          ],
          [
           "Implementation tool and environment"
          ],
          [
           "Results"
          ],
          [
           "Evaluation Matrices"
          ],
          [
           "Conclusion"
          ],
          [
           "Interpreting Verbal Metaphors by Paraphrasing"
          ],
          [
           "Abstract  Metaphorical expressions are difficult linguistic phenomena, challenging diverse Natural Language Processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Methodology"
          ],
          [
           "Dataset"
          ],
          [
           "Baselines"
          ],
          [
           "Result"
          ],
          [
           "Conclusion"
          ],
          [
           "Leveraging Multilingual News Websites for Building a Kurdish Parallel\n  Corpus"
          ],
          [
           "Abstract  Machine translation has been a major motivation of development in natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Alphabets and Dialects"
          ],
          [
           "Vocabulary"
          ],
          [
           "Grammar"
          ],
          [
           "Methodology"
          ],
          [
           "Data Crawling"
          ],
          [
           "Corpus Filtering"
          ],
          [
           "Content Alignment"
          ],
          [
           "Evaluation"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Appendix"
          ],
          [
           "A Survey on Non-Autoregressive Generation for Neural Machine Translation\n  and Beyond"
          ],
          [
           "Abstract  Non-autoregressive (NAR) generation, which is first proposed in neural machine translation (NMT) to speed up inference, has attracted much attention in both machine learning and natural language processing communities."
          ],
          [
           "Introduction"
          ],
          [
           "Overview of AT and NAT Models"
          ],
          [
           "Comparison"
          ],
          [
           "The Main Challenge of NAT Models"
          ],
          [
           "Overview of Improving Methods"
          ],
          [
           "Knowledge Distillation"
          ],
          [
           "Data Learning Strategies"
          ],
          [
           "Modeling"
          ],
          [
           "Iteration-Based Methods"
          ],
          [
           "Latent Variable-Based Methods."
          ],
          [
           "Other Enhancements-based Methods"
          ],
          [
           "Criterion"
          ],
          [
           "Decoding"
          ],
          [
           "Length Prediction"
          ],
          [
           "Decoding Strategy"
          ],
          [
           "Benefiting from Pre-trained Models"
          ],
          [
           "AT Models"
          ],
          [
           "Pre-Trained Language Models"
          ],
          [
           "Summary of Non-Autoregressive NMT"
          ],
          [
           "Extensive Applications Beyond NMT"
          ],
          [
           "Text Generation"
          ],
          [
           "Semantic Parsing"
          ],
          [
           "Text to Speech"
          ],
          [
           "Speech Translation"
          ],
          [
           "Others"
          ],
          [
           "Conclusion and Outlooks"
          ],
          [
           "Example"
          ],
          [
           "The boundaries of meaning: a case study in neural machine translation"
          ],
          [
           "Abstract  The success of deep learning in natural language processing raises intriguing questions about the nature of linguistic meaning and ways in which it can be processed by natural and artificial systems."
          ],
          [
           "Introduction: Quine and Kaplan on the insignificance of ‘nine’ in ‘canine’"
          ],
          [
           "Yara Parser: A Fast and Accurate Dependency Parser"
          ],
          [
           "Abstract  Dependency parsers are among the most crucial tools in natural language processing as they have many important applications in downstream tasks such as information retrieval, machine translation and knowledge acquisition."
          ],
          [
           "Introduction"
          ],
          [
           "Using Yara in Practice"
          ],
          [
           "Data format"
          ],
          [
           "Training and Model Selection"
          ],
          [
           "Punctuation Files"
          ],
          [
           "Some Examples"
          ],
          [
           "Training with Brown clusters"
          ],
          [
           "Training with the fastest mode"
          ],
          [
           "Changing the number of iterations"
          ],
          [
           "Extending memory consumption"
          ],
          [
           "Using very specific options"
          ],
          [
           "Test and Evaluation"
          ],
          [
           "Parsing a CoNLL file"
          ],
          [
           "Parsing a tagged file"
          ],
          [
           "Evaluation"
          ],
          [
           "Parsing a Partial Tree"
          ],
          [
           "Yara Pipeline"
          ],
          [
           "Pipeline API usage"
          ],
          [
           "Importing libraries"
          ],
          [
           "Parsing Raw Text File"
          ],
          [
           "Parsing Raw Text"
          ],
          [
           "Parsing a Sentence"
          ],
          [
           "Parsing a Tokenized Sentence"
          ],
          [
           "Parsing a Tagged Sentence"
          ],
          [
           "Yara Technical Details "
          ],
          [
           "Arc-Eager Algorithm"
          ],
          [
           "Unshift Action"
          ],
          [
           "Online Learning"
          ],
          [
           "Beam Search and Update Methods"
          ],
          [
           "Dynamic and Static Oracles"
          ],
          [
           "Root Position"
          ],
          [
           "Features"
          ],
          [
           "Unlabeled Parsing"
          ],
          [
           "Partial Parsing"
          ],
          [
           "Multithreading"
          ],
          [
           "Model Selection"
          ],
          [
           "Tree Scoring"
          ],
          [
           "Lowercasing"
          ],
          [
           "Experiments"
          ],
          [
           "Parsing WSJ Data"
          ],
          [
           "Effect of Beam Size"
          ],
          [
           "Parsing Non-Projective Languages: Persian"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Attention-based method for categorizing different types of online\n  harassment language"
          ],
          [
           "Abstract  In the era of social media and networking platforms, Twitter has been doomed for abuse and harassment toward users specifically women."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Dataset description"
          ],
          [
           "Data augmentation"
          ],
          [
           "Text processing"
          ],
          [
           "RNN Model and Attention Mechanism"
          ],
          [
           "Model Architecture"
          ],
          [
           "Training Models"
          ],
          [
           "Evaluation and Results"
          ],
          [
           "Conclusion - Future work"
          ],
          [
           "Evaluating the Morphosyntactic Well-formedness of Generated Texts"
          ],
          [
           "Abstract  Text generation systems are ubiquitous in natural language processing applications."
          ],
          [
           "Introduction"
          ],
          [
           "In this section, we present l'ambre, a metric to gauge the morphosyntactic well-formedness of generated natural language sentences."
          ],
          [
           "Creating a Grammatical Description"
          ],
          [
           "Agreement"
          ],
          [
           "Case Assignment and Verb Form Choice"
          ],
          [
           "Human Evaluation"
          ],
          [
           "Parsing Noisy Text"
          ],
          [
           "Adding Morphology-related Noise"
          ],
          [
           "Training Robust Parsers"
          ],
          [
           "Do We Capture Grammaticality?"
          ],
          [
           "Evaluation:"
          ],
          [
           "Analysis:"
          ],
          [
           "Evaluating NLG: A Machine Translation Case Study"
          ],
          [
           "Correlation Analysis"
          ],
          [
           "Diachronic Analysis"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Comparison of UD and SUD"
          ],
          [
           "Robust parsing"
          ],
          [
           "GEC datasets"
          ],
          [
           "Comparison with other metrics"
          ],
          [
           "Contrastive evaluation on UD"
          ],
          [
           "Correlation analysis on WMT"
          ],
          [
           "Correlation analysis with Human z-scores"
          ],
          [
           "Comparison with other MT metrics"
          ],
          [
           "Diachronic analysis of WMT systems"
          ],
          [
           "Model Training"
          ],
          [
           "Resources"
          ],
          [
           "A$^3$: Accelerating Attention Mechanisms in Neural Networks with\n  Approximation"
          ],
          [
           "Abstract  With the increasing computational demands of neural networks, many hardware accelerators for the neural networks have been proposed."
          ],
          [
           "Introduction"
          ],
          [
           "Cost of Attention Mechanism"
          ],
          [
           "Opportunity for Approximation"
          ],
          [
           "Pipeline Design"
          ],
          [
           "Quantization"
          ],
          [
           "Design Details"
          ],
          [
           "Overview"
          ],
          [
           "Base Greedy Candidate Search"
          ],
          [
           "Efficient Greedy Candidate Search"
          ],
          [
           "Post-scoring Approximation"
          ],
          [
           "To efficiently implement the approximation scheme introduced in Section , we design new hardware accelerator modules for candidate selection and post-scoring approximation."
          ],
          [
           "Candidate Selection Module"
          ],
          [
           "Post-Scoring Selection Module"
          ],
          [
           "Figure REF  shows the high-level block diagram of the $A^3$  design."
          ],
          [
           "Workloads"
          ],
          [
           "Accuracy Evaluation"
          ],
          [
           "Performance Results"
          ],
          [
           "Area, Power, Energy and Test Chip"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Lexical Normalization for Code-switched Data and its Effect on\n  POS-tagging"
          ],
          [
           "Abstract  Lexical normalization, the translation of non-canonical data to standard language, has shown to improve the performance of manynatural language processing tasks on social media."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Models"
          ],
          [
           "Word-level language identification"
          ],
          [
           "Normalization"
          ],
          [
           "Monolingual"
          ],
          [
           "Fragments"
          ],
          [
           "Multilingual"
          ],
          [
           "Language-aware"
          ],
          [
           "POS tagging"
          ],
          [
           "Data"
          ],
          [
           "Turkish-German code-switched normalization corpus"
          ],
          [
           "Preprocessing for normalization"
          ],
          [
           "LID and POS alignment"
          ],
          [
           "Dataset statistics"
          ],
          [
           "Evaluation"
          ],
          [
           "Language identification"
          ],
          [
           "Normalization"
          ],
          [
           "Effect of the quality of language predictions"
          ],
          [
           "POS tagging as extrinsic evaluation"
          ],
          [
           "Test data"
          ],
          [
           "Discussion and Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Statistics on raw data collections"
          ],
          [
           "Results of in-domain pos-tagging"
          ],
          [
           "Machine Translation between Spoken Languages and Signed Languages\n  Represented in SignWriting"
          ],
          [
           "Abstract  This paper presents work on novel machine translation (MT) systems between spoken and signed languages, where signed languages are represented in SignWriting, a sign language writing system."
          ],
          [
           "Introduction"
          ],
          [
           "Sign language processing (SLP)"
          ],
          [
           "SignWriting, FSW, and SWU"
          ],
          [
           "Data and method"
          ],
          [
           "Data statistics"
          ],
          [
           "Data preprocessing"
          ],
          [
           "Multilingual models"
          ],
          [
           "Data split"
          ],
          [
           "FSW parsing"
          ],
          [
           "Factored machine translation"
          ],
          [
           "Experiments and results"
          ],
          [
           "Initial exploration with a bilingual model"
          ],
          [
           "Multilingual sign-to-spoken translation"
          ],
          [
           "Evaluating dictionary entries"
          ],
          [
           "Multilingual spoken-to-sign translation"
          ],
          [
           "FSW decoding strategies"
          ],
          [
           "Evaluation of FSW output"
          ],
          [
           "Effect of adding dictionaries, BPE, and low-resource optimizations"
          ],
          [
           "Utilizing positional numbers"
          ],
          [
           "Generating positional numbers"
          ],
          [
           "Multilingual performance"
          ],
          [
           "Multilingual transfer effects"
          ],
          [
           "Side-by-side SignWriting example"
          ],
          [
           "Conclusion"
          ],
          [
           "A word on top-n accuracy"
          ],
          [
           "Fingerspelling tokenization"
          ],
          [
           "Towards better multilingual models"
          ],
          [
           "Regression objective for positional numbers"
          ],
          [
           "Possibly flawed positional number evaluation"
          ],
          [
           "Advanced SignWriting evaluation"
          ],
          [
           "Note on reproducibility"
          ],
          [
           "Extended introduction to SignWriting"
          ],
          [
           "Formal SignWriting in ASCII (FSW)"
          ],
          [
           "SignWriting in Unicode (SWU)"
          ],
          [
           "Experimental setup"
          ],
          [
           "40k sign-to-en-us"
          ],
          [
           "100k sign-to-spoken"
          ],
          [
           "100k spoken-to-sign"
          ],
          [
           "Data"
          ],
          [
           "Towards Debiasing Translation Artifacts"
          ],
          [
           "Abstract  Cross-lingual natural language processing relies on translation, either by humans or machines, at different levels, from translating training data to translating test sets."
          ],
          [
           "Introduction"
          ],
          [
           "Debiasing Strategies"
          ],
          [
           "Translationese in Sentence Embeddings"
          ],
          [
           "Translationese in Word Embeddings"
          ],
          [
           "Application to NLI"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Experimental Setup and Hyperparameters"
          ],
          [
           "Word Analogy Tests"
          ],
          [
           "Visualisation"
          ],
          [
           "Translationese Word Lists"
          ],
          [
           "The Importance of Being Recurrent for Modeling Hierarchical Structure"
          ],
          [
           "Abstract  Recent work has shown that recurrent neural networks (RNNs) can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks such as language modeling (Linzen et al., 2016) and neural machine translation (Shi et al., 2016)."
          ],
          [
           "Introduction"
          ],
          [
           "FAN versus LSTM"
          ],
          [
           "Tasks"
          ],
          [
           "Subject-Verb Agreement"
          ],
          [
           "Logical inference"
          ],
          [
           "Models"
          ],
          [
           "Results"
          ],
          [
           "Discussion and Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Machine Translationese: Effects of Algorithmic Bias on Linguistic\n  Complexity in Machine Translation"
          ],
          [
           "Abstract  Recent studies in the field of Machine Translation (MT) and Natural Language Processing (NLP) have shown that existing models amplify biases observed in the training data."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Machine Translation Systems"
          ],
          [
           "Experiments and Results"
          ],
          [
           "Evaluation data"
          ],
          [
           "Lexical Frequency Profile"
          ],
          [
           "TTR, Yule's I and MTLD"
          ],
          [
           "Synonym Frequency Analysis"
          ],
          [
           "Grammatical Diversity"
          ],
          [
           "Shannon Entropy"
          ],
          [
           "Simpson's Diversity Index"
          ],
          [
           "Conclusions"
          ],
          [
           "Acknowledgements"
          ],
          [
           "On Dimensional Linguistic Properties of the Word Embedding Space"
          ],
          [
           "Abstract  Word embeddings have become a staple of several natural language processing tasks, yet much remains to be understood about their properties."
          ],
          [
           "Introduction"
          ],
          [
           "Dimensional Properties of the Word Embedding Space"
          ],
          [
           "Word Similarity Tasks"
          ],
          [
           "Sentence Classification Tasks"
          ],
          [
           "Variance Based Analysis"
          ],
          [
           "Dimensional Linguistic Probing Tasks"
          ],
          [
           "The Post Processing Algorithm (PPA)"
          ],
          [
           "Sentence Classification Tasks"
          ],
          [
           "Machine Translation"
          ],
          [
           "Summary and Discussion"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "An Introductory Survey on Attention Mechanisms in NLP Problems"
          ],
          [
           "Abstract  First derived from human intuition, later adapted to machine translation for automatic token alignment, attention mechanism, a simple method that can be used for encoding sequence data based on the importance score each element is assigned, has been widely applied to and attained significant improvement in various tasks in natural language processing, including sentiment classification, text summarization, question answering, dependency parsing, etc."
          ],
          [
           "Introduction"
          ],
          [
           "Formulation"
          ],
          [
           "Variation"
          ],
          [
           "Multi-dimensional Attention"
          ],
          [
           "Hierarchical Attention"
          ],
          [
           "Self Attention"
          ],
          [
           "Memory-based Attention"
          ],
          [
           "Reusability"
          ],
          [
           "Flexibility"
          ],
          [
           "Task-specific Attention"
          ],
          [
           "Application"
          ],
          [
           "Attention for Ensemble"
          ],
          [
           "Attention for Gating"
          ],
          [
           "Attention for Pre-training"
          ],
          [
           "Evaluation"
          ],
          [
           "Quantitative"
          ],
          [
           "Qualitative"
          ],
          [
           "Conclusion and Prospects"
          ],
          [
           "Unsupervised Bilingual Lexicon Induction from Mono-lingual Multimodal\n  Data"
          ],
          [
           "Abstract  Bilingual lexicon induction, translating words from the source language to the target language, is a long-standing natural language processing task."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Unsupervised Bilingual Lexicon Induction"
          ],
          [
           "Multi-lingual Image Caption Model"
          ],
          [
           "Visual-guided Word Representation"
          ],
          [
           "Word Translation Prediction"
          ],
          [
           "Datasets"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Evaluation of Multi-lingual Image Caption"
          ],
          [
           "Evaluation of Bilingual Lexicon Induction"
          ],
          [
           "Generalization to Diverse Language Pairs"
          ],
          [
           "Conclusion"
          ],
          [
           " Acknowledgments"
          ],
          [
           "On the Difficulty of Translating Free-Order Case-Marking Languages"
          ],
          [
           "Abstract  Identifying factors that make certain languages harder to model than others is essential to reach language equality in future Natural Language Processing technologies."
          ],
          [
           "Courtesy warning: Common violations of final version rules that have\nresulted in papers being returned to authors for corrections"
          ],
          [
           "Courtesy warning: Common violations of final version rules that have\nresulted in desk\nrejects"
          ],
          [
           "General instructions"
          ],
          [
           " files compliant with these instructions are available at the Author Guidelines section of the TACL website, https://www.transacl.org.Last accessed Sept. 20, 2018."
          ],
          [
           "Workarounds for problems with the hyperref package"
          ],
          [
           "Length limits"
          ],
          [
           "Fonts and text size"
          ],
          [
           "Page Layout"
          ],
          [
           "The confidentiality header and line-number ruler"
          ],
          [
           "The First Page"
          ],
          [
           "Section headings"
          ],
          [
           "Figures and Tables"
          ],
          [
           "In-text citations"
          ],
          [
           "Self-citations"
          ],
          [
           "References"
          ],
          [
           "Appendices"
          ],
          [
           "Including acknowledgments"
          ],
          [
           "Contributors to this document"
          ],
          [
           "Distilling Knowledge for Search-based Structured Prediction"
          ],
          [
           "Abstract  Many natural language processing tasks can be modeled into structured prediction and solved as a search problem."
          ],
          [
           "Introduction"
          ],
          [
           "Search-based Structured Prediction"
          ],
          [
           "Knowledge Distillation"
          ],
          [
           "Ensemble"
          ],
          [
           "Distillation from Reference"
          ],
          [
           "Distillation from Exploration"
          ],
          [
           "Distillation from Both"
          ],
          [
           "Experiments"
          ],
          [
           "Transition-based Dependency Parsing"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Transition-based Dependency Parsing"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Analysis"
          ],
          [
           "Ensemble on “Problematic” States"
          ],
          [
           "Effect of $\\alpha $"
          ],
          [
           "Learning Stability"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Learning to Copy for Automatic Post-Editing"
          ],
          [
           "Abstract  Automatic post-editing (APE), which aims to correct errors in the output of machine translation systems in a post-processing step, is an important task in natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Multi-source Sequence-to-Sequence Learning"
          ],
          [
           "CopyNet"
          ],
          [
           "Approach"
          ],
          [
           "Interactive Representation Learning"
          ],
          [
           "Predicting Words to be Copied"
          ],
          [
           "Training"
          ],
          [
           "Datasets"
          ],
          [
           "Effect of Hyper-parameters"
          ],
          [
           "Results on the PBSMT Sub-task"
          ],
          [
           "Ablation Study"
          ],
          [
           "Results on Prediction Accuracy"
          ],
          [
           "Comparison of Copying Accuracies"
          ],
          [
           "Visualization"
          ],
          [
           "Multi-source Sequence-to-Sequence Learning"
          ],
          [
           "The Copying Mechanism"
          ],
          [
           "Interactive Representation Learning"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "End-to-end Speech-to-Punctuated-Text Recognition"
          ],
          [
           "Abstract  Conventional automatic speech recognition systems do not produce punctuation marks which are important for the readability of the speech recognition results."
          ],
          [
           "Introduction"
          ],
          [
           "Punctuation prediction using acoustic features"
          ],
          [
           "Auxiliary loss in intermediate layers"
          ],
          [
           "End-to-end approach"
          ],
          [
           "Task Definition"
          ],
          [
           "Baseline Model"
          ],
          [
           "Proposed Method"
          ],
          [
           "Datasets"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Evaluation"
          ],
          [
           "Results"
          ],
          [
           "Analysis"
          ],
          [
           "Conclusions"
          ],
          [
           "Searching for fingerspelled content in American Sign Language"
          ],
          [
           "Abstract  Natural language processing for sign language video - including tasks like recognition, translation, and search - is crucial for making artificial intelligence technologies accessible to deaf individuals, and is gaining research interest in recent years."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Tasks"
          ],
          [
           "Model"
          ],
          [
           "Data"
          ],
          [
           "Baselines"
          ],
          [
           "Evaluation"
          ],
          [
           "Main Results"
          ],
          [
           "Model analysis"
          ],
          [
           "Ablation Study"
          ],
          [
           "Result analysis"
          ],
          [
           "Conclusion"
          ],
          [
           "Data"
          ],
          [
           "Implementation Details"
          ],
          [
           "Full results"
          ],
          [
           "Examples of fingerspelling localization"
          ],
          [
           "Precision-recall curve in FVS"
          ],
          [
           "Qualitative examples of pose estimation"
          ],
          [
           "Mitigating Gender Stereotypes in Hindi and Marathi"
          ],
          [
           "Abstract  As the use of natural language processing increases in our day-to-day life, the need to address gender bias inherent in these systems also amplifies."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Data"
          ],
          [
           "Bias Statement"
          ],
          [
           "Quantifying bias for Occupations and Emotions"
          ],
          [
           "For neutral occupations: $M_{neu}$"
          ],
          [
           "For gendered occupations:$M_{gen}$"
          ],
          [
           "Finding out the gender subspace"
          ],
          [
           "Debiasing methods"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Conclusion and Future work"
          ],
          [
           "FRAGE: Frequency-Agnostic Word Representation"
          ],
          [
           "Abstract  Continuous word representation (aka word embedding) is a basic building block in many neural network-based models used in natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Word Representation"
          ],
          [
           "Adversarial Training"
          ],
          [
           "Empirical Study"
          ],
          [
           "Experimental Design"
          ],
          [
           "Observation"
          ],
          [
           "Explanation"
          ],
          [
           "Discussion"
          ],
          [
           "Our Method"
          ],
          [
           "Experiment"
          ],
          [
           "Settings"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Dataset Description"
          ],
          [
           "Hyper-parameter configurations"
          ],
          [
           "Models Description"
          ],
          [
           "Additional Comparisons"
          ],
          [
           "Case Study on Original Models and Qualitative Analysis of Our Method"
          ],
          [
           "Simplifying Neural Machine Translation with Addition-Subtraction\n  Twin-Gated Recurrent Networks"
          ],
          [
           "Abstract  In this paper, we propose an additionsubtraction twin-gated recurrent network (ATR) to simplify neural machine translation."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Addition-Subtraction Twin-Gated Recurrent Network"
          ],
          [
           "Twin-Gated Mechanism"
          ],
          [
           "Computation Analysis"
          ],
          [
           "Interpretability Analysis of Hidden States"
          ],
          [
           "Setup"
          ],
          [
           "Training"
          ],
          [
           "Results on English-German Translation"
          ],
          [
           "Results on English-French Translation"
          ],
          [
           "Analysis on Twin-Gated Mechanism"
          ],
          [
           "Analysis on Speed and Model Parameters"
          ],
          [
           "Analysis on Dependency Modeling"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Neural Machine Translation with ATR"
          ],
          [
           "Experiments on Chinese-English Translation"
          ],
          [
           "Experiments on Natural Language Inference"
          ],
          [
           "Experiments on Chinese Word Segmentation"
          ],
          [
           "Reproducibility Issues for BERT-based Evaluation Metrics"
          ],
          [
           "Abstract  Reproducibility is of utmost concern in machine learning and natural language processing (NLP)."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "BERT-based Evaluation Metrics"
          ],
          [
           "Reproducibility in NLP"
          ],
          [
           "Datasets & Metrics"
          ],
          [
           "MoverScore"
          ],
          [
           "BERTScore"
          ],
          [
           "BaryScore"
          ],
          [
           "SentSim"
          ],
          [
           "Reproduction Attempts"
          ],
          [
           "Reproduction on MT"
          ],
          [
           "Results"
          ],
          [
           "Summary"
          ],
          [
           "SentSim"
          ],
          [
           "Reproduction for other tasks"
          ],
          [
           "Sensitivity Analysis"
          ],
          [
           "IDF-weighting"
          ],
          [
           "Stopwords Removal"
          ],
          [
           "Results"
          ],
          [
           "IDF-weighting"
          ],
          [
           "Results"
          ],
          [
           "Subwords & Punctuation"
          ],
          [
           "Results"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Machine Translation"
          ],
          [
           "Text Summarization"
          ],
          [
           "Image Captioning"
          ],
          [
           "Data-to-Text Generation"
          ],
          [
           "Reproduction on WMT15-16"
          ],
          [
           "Reproduction of other tasks"
          ],
          [
           "Results"
          ],
          [
           "Reproducibility problems of SentSim"
          ],
          [
           "Additional preprocessing MoverScore"
          ],
          [
           "Subword Removal"
          ],
          [
           "Stopwords Removal & Punctuation Removal"
          ],
          [
           "Default configuration of evaluation metrics"
          ],
          [
           "Stopword lists"
          ],
          [
           "Other results for stopwords"
          ],
          [
           "IDF Corpora"
          ],
          [
           "Other results for IDF-weighting"
          ],
          [
           "A Survey of Orthographic Information in Machine Translation"
          ],
          [
           "Abstract  Machine translation is one of the applications of natural language processing which has been explored in different languages."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Under-resourced Languages"
          ],
          [
           "Orthographic Information"
          ],
          [
           "Spelling and Typographical Errors"
          ],
          [
           "True-casing and Capitalization"
          ],
          [
           "Normalization"
          ],
          [
           "Tokenization and Detokenization"
          ],
          [
           "Transliteration"
          ],
          [
           "Code-Mixing"
          ],
          [
           "Orthographic Information in RBMT"
          ],
          [
           "Orthographic Information in SMT"
          ],
          [
           "Spelling and Typographical Errors "
          ],
          [
           "True-casing and Capitalization, Tokenization and Detokenization "
          ],
          [
           "Normalization"
          ],
          [
           "Transliteration (Cognate) "
          ],
          [
           "Code-Switching"
          ],
          [
           "Pivot Translation"
          ],
          [
           "Orthographic Information in NMT"
          ],
          [
           "Multilingual Neural Machine Translation"
          ],
          [
           "Spelling and Typographical Errors"
          ],
          [
           "True-casing and Capitalization, Normalization, Tokenization and Detokenization"
          ],
          [
           "Transliteration (Cognate)"
          ],
          [
           "Code-Switching"
          ],
          [
           "Orthographic Information in Unsupervised Machine Translation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Semantically Informed Slang Interpretation"
          ],
          [
           "Abstract  Slang is a predominant form of informal language making flexible and extended use of words that is notoriously hard for natural language processing systems to interpret."
          ],
          [
           "Introduction"
          ],
          [
           "Natural Language Processing for Slang"
          ],
          [
           "Generative Semantic Models of Slang"
          ],
          [
           "Computational Framework"
          ],
          [
           "Context-based Interpretation"
          ],
          [
           "LM-based interpreter."
          ],
          [
           "Dual encoder."
          ],
          [
           "Semantic Model of Slang"
          ],
          [
           "Semantically Informed Reranking"
          ],
          [
           "Datasets"
          ],
          [
           "Evaluation on Slang Interpretation"
          ],
          [
           "Zero-shot and Few-shot Interpretation"
          ],
          [
           "Evaluation on Slang Translation"
          ],
          [
           "Conclusion"
          ],
          [
           "Ethical Considerations"
          ],
          [
           "Baseline Models"
          ],
          [
           "Semantic Reranker"
          ],
          [
           "Additional Interpretation Examples"
          ],
          [
           "Effect of Context Length"
          ],
          [
           "Finetuning Dual Encoder"
          ],
          [
           "Machine Translation Examples"
          ],
          [
           "Data Permissions"
          ],
          [
           "Relphormer: Relational Graph Transformer for Knowledge Graph\n  Representations"
          ],
          [
           "Abstract  Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Translational distance KG Representation"
          ],
          [
           "Transformer for Graph Representation"
          ],
          [
           "Relphormer"
          ],
          [
           "Triple2Seq"
          ],
          [
           "Structure-enhanced Transformer"
          ],
          [
           "Masked Knowledge Modeling"
          ],
          [
           "Optimization and Inference"
          ],
          [
           "Datasets"
          ],
          [
           "Compared Baselines"
          ],
          [
           "Settings"
          ],
          [
           "Entity Prediction"
          ],
          [
           "Relation prediction"
          ],
          [
           "Inference speed comparison"
          ],
          [
           "The number of sampled contextualized sub-graph triples"
          ],
          [
           "Structure-enhanced self-attention"
          ],
          [
           "Optimization object"
          ],
          [
           "Global node"
          ],
          [
           "Discussion"
          ],
          [
           "Transformer for Graph"
          ],
          [
           "Transformer for Knowledge Graph"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Implementation Details"
          ],
          [
           "Comparison with Previous Study"
          ],
          [
           "Breeding Gender-aware Direct Speech Translation Systems"
          ],
          [
           "Abstract  In automatic speech translation (ST), traditional cascade approaches involving separate transcription and translation steps are giving ground to increasingly competitive and more robust direct solutions."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Annotation of MuST-C with Speakers' Gender Information"
          ],
          [
           "ST Systems"
          ],
          [
           "Base ST Model"
          ],
          [
           "Multi-gender Systems"
          ],
          [
           "Gender-specialized Systems"
          ],
          [
           "Gender-balanced Validation Set"
          ],
          [
           "Experiments"
          ],
          [
           "Evaluation Method"
          ],
          [
           "Overall Results"
          ],
          [
           "Cross-gender Analysis"
          ],
          [
           "Analysing Conflicts between Vocal Characteristics and Gender Tags"
          ],
          [
           "Manual Analysis"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Neural Cross-Lingual Named Entity Recognition with Minimal Resources"
          ],
          [
           "Abstract  For languages with no annotated resources, unsupervised transfer of natural language processing models such as named-entity recognition (NER) from resource-rich languages would be an appealing capability."
          ],
          [
           "Introduction"
          ],
          [
           "Approach"
          ],
          [
           "Problem Setting"
          ],
          [
           "Method"
          ],
          [
           "Learning Monolingual Embeddings"
          ],
          [
           "Learning Bilingual Embeddings"
          ],
          [
           "Learning Word Translations"
          ],
          [
           "Training the NER Model"
          ],
          [
           "Discussion"
          ],
          [
           "NER Model Architecture"
          ],
          [
           "Hierarchical Neural CRF"
          ],
          [
           "Self-Attention"
          ],
          [
           "Experiments"
          ],
          [
           "Experimental Settings"
          ],
          [
           "Results"
          ],
          [
           "Comparison with Dictionary-Based Translation"
          ],
          [
           "Why Does Translation Work Better?"
          ],
          [
           "Case Study: Uyghur"
          ],
          [
           "Related Work"
          ],
          [
           "Bilingual Word Embeddings"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "The Effect of Normalization for Bi-directional Amharic-English Neural\n  Machine Translation"
          ],
          [
           "Abstract  Machine translation (MT) is one of the main tasks in natural language processing whose objective is to translate texts automatically from one natural language to another."
          ],
          [
           "Introduction"
          ],
          [
           "Amharic language"
          ],
          [
           "Motivation"
          ],
          [
           "Related work"
          ],
          [
           "Building a Parallel Dataset"
          ],
          [
           "Data pre-processing"
          ],
          [
           "The proposed neural machine translation models"
          ],
          [
           "Pre-trained language models (PLMs)"
          ],
          [
           "Results and discussion"
          ],
          [
           "Conclusion and future work"
          ],
          [
           "Adversarial Regularization as Stackelberg Game: An Unrolled Optimization\n  Approach"
          ],
          [
           "Abstract  Adversarial regularization has been shown to improve the generalization performance of deep learning models in various natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Background and Related Works"
          ],
          [
           "Method"
          ],
          [
           "Adversarial Regularization"
          ],
          [
           "Adversarial Regularization as Stackelberg Game"
          ],
          [
           "SALT: Stackelberg Adversarial Regularization"
          ],
          [
           "Experiments"
          ],
          [
           "Baselines"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Natural Language Understanding"
          ],
          [
           "Parameter Study"
          ],
          [
           "Analysis"
          ],
          [
           "Conclusion"
          ],
          [
           "Broader Impact"
          ],
          [
           "Virtual Adversarial Training"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Natural Language Understanding"
          ],
          [
           "Model Calibration"
          ],
          [
           "UniDrop: A Simple yet Effective Technique to Improve Transformer without\n  Extra Cost"
          ],
          [
           "Abstract  Transformer architecture achieves great success in abundant natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "UniDrop"
          ],
          [
           "Feature Dropout"
          ],
          [
           "Structure Dropout"
          ],
          [
           "Data Dropout"
          ],
          [
           "Theoretical Analysis"
          ],
          [
           "Interpretation"
          ],
          [
           "UniDrop Integration"
          ],
          [
           "Experiments"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Datasets"
          ],
          [
           "Model"
          ],
          [
           "Results"
          ],
          [
           "Text Classification"
          ],
          [
           "Datasets"
          ],
          [
           "Model"
          ],
          [
           "Results"
          ],
          [
           "Analysis"
          ],
          [
           "Overfitting"
          ],
          [
           "Ablation Study"
          ],
          [
           "Effects of Different Dropout Rates"
          ],
          [
           "Dropout"
          ],
          [
           "Data Augmentation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Supplementary materials for theoretical analysis"
          ],
          [
           "Statistics of Datasets"
          ],
          [
           "Dropout Attempts"
          ],
          [
           "Loss Curves"
          ],
          [
           "Ablation Study on Text Classification"
          ],
          [
           "Compositionality as Lexical Symmetry"
          ],
          [
           "Abstract  Standard deep network models lack the inductive biases needed to generalize compositionally in tasks like semantic parsing, translation, and question answering."
          ],
          [
           "Introduction"
          ],
          [
           "Background & Approach"
          ],
          [
           "Compositionality as Lexical Symmetry"
          ],
          [
           "Discovering Symmetries Automatically"
          ],
          [
           "Inferring equivalence relations"
          ],
          [
           "Learning Alignments"
          ],
          [
           "Aside: Continous Domains"
          ],
          [
           "Inferring types"
          ],
          [
           "Constructing Homomorphisms"
          ],
          [
           "Limitations"
          ],
          [
           "Experiments"
          ],
          [
           "CLEVR-CoGenT"
          ],
          [
           "COGS"
          ],
          [
           "VQA Transformer"
          ],
          [
           "LSTM"
          ],
          [
           "Data Augmentation"
          ],
          [
           "VQA"
          ],
          [
           "Semantic Parsing"
          ],
          [
           "Lexicalized neural models"
          ],
          [
           "Data Augmentation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "VQVAE Details"
          ],
          [
           "VQA Transformer Details"
          ],
          [
           "LSTM Details"
          ],
          [
           "IBM Model Details"
          ],
          [
           "Extracted Lexicons"
          ],
          [
           "VQA"
          ],
          [
           "Semantic Parsing"
          ],
          [
           "Generalization to more complex lexicons"
          ],
          [
           "Data"
          ],
          [
           "A Tensorized Transformer for Language Modeling"
          ],
          [
           "Abstract  Latest development of neural models has connected the encoder and decoder through a self-attention mechanism."
          ],
          [
           "Introduction"
          ],
          [
           "Preliminaries"
          ],
          [
           "Tensor and Block-Term Tensor Decomposition"
          ],
          [
           "Multi-head Attention"
          ],
          [
           "Tensorized Transformer"
          ],
          [
           "Single-block Attention by Tucker Decomposition"
          ],
          [
           "Multi-Linear Attention by Block-Term Tensor Decomposition"
          ],
          [
           "Analysis of Compression and Complexity"
          ],
          [
           "Related Work"
          ],
          [
           "Experiments"
          ],
          [
           "Language Modeling"
          ],
          [
           "Results and Details"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion and Further Work"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Tensor and Tensor Slice"
          ],
          [
           "Theorem 3.1"
          ],
          [
           "Corollary 1"
          ],
          [
           "Compression Ratio about Multi-Linear Attention"
          ],
          [
           "Partial Structure about Tensorized Transformer"
          ],
          [
           "Experimental Details in Language Modeling"
          ],
          [
           "Experiment Details in Neural Machine Translation"
          ],
          [
           "Experimental comparison"
          ],
          [
           "Partial Code"
          ],
          [
           "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models"
          ],
          [
           "Abstract  Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Methods"
          ],
          [
           "Data Preprocessing"
          ],
          [
           "Model Building"
          ],
          [
           "Model Explanation"
          ],
          [
           "Model Evaluation"
          ],
          [
           "Model Performance"
          ],
          [
           "SHAP Explanation"
          ],
          [
           "Survey Results"
          ],
          [
           "DistilBERT-based NLP Models "
          ],
          [
           "SHAP-Explanations and User Trust"
          ],
          [
           "Implications"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Cross-Align: Modeling Deep Cross-lingual Interactions for Word Alignment"
          ],
          [
           "Abstract  Word alignment which aims to extract lexicon translation equivalents between source and target sentences, serves as a fundamental tool for natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "NMT based Aligner"
          ],
          [
           "LM based Aligner"
          ],
          [
           "Method"
          ],
          [
           "Model Architecture"
          ],
          [
           "Self-Attention Module."
          ],
          [
           "Cross-Attention Module."
          ],
          [
           "Alignments Extraction"
          ],
          [
           "Two-stage Training Framework"
          ],
          [
           "Stage1: Translation Language Modeling."
          ],
          [
           "Stage2: Self-Supervised Alignment."
          ],
          [
           "Experimental Settings"
          ],
          [
           "Datasets"
          ],
          [
           "Implementation Details"
          ],
          [
           "Baselines"
          ],
          [
           "Statistic based methods:"
          ],
          [
           "NMT based methods:"
          ],
          [
           "LM based methods:"
          ],
          [
           "Evaluation Measures"
          ],
          [
           "Main Results"
          ],
          [
           "Ablation Study."
          ],
          [
           "Number of Cross-Attention Layers."
          ],
          [
           "Alignment Layer."
          ],
          [
           "Case Study"
          ],
          [
           "Conclusion"
          ],
          [
           "Limitations"
          ],
          [
           "LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine\n  Translation"
          ],
          [
           "Abstract  Multimodal Machine Translation (MMT) focuses on enhancing text-only translation with visual features, which has attracted considerable attention from both natural language processing and computer vision communities."
          ],
          [
           "Introduction"
          ],
          [
           "Multimodal Machine Translation."
          ],
          [
           "Datasets"
          ],
          [
           "Multilingual MMT"
          ],
          [
           "LVP-M$^{3}$"
          ],
          [
           "Token Encoding"
          ],
          [
           "Language-aware Visual Prompt Generation"
          ],
          [
           "Language Translation"
          ],
          [
           "Experiments"
          ],
          [
           "Experimental Setting"
          ],
          [
           "Results on M$^{3}$ -Multi30K"
          ],
          [
           "Results on M$^{3}$ -AmbigCaps"
          ],
          [
           "Ablation Study"
          ],
          [
           "Effect of LVPG."
          ],
          [
           "Effect of Different Vision Backbones."
          ],
          [
           "Visualization of Different Masking Ratios."
          ],
          [
           "Qualitative Analysis."
          ],
          [
           "Discussion on  LVP-M$^{3}$"
          ],
          [
           "Conclusion"
          ],
          [
           "Limitations"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Vector Representations of Idioms in Conversational Systems"
          ],
          [
           "Abstract  We demonstrate, in this study, that an open-domain conversational system trained on idioms or figurative language generates more fitting responses to prompts containing idioms."
          ],
          [
           "1.1em"
          ],
          [
           "1.1.1em"
          ],
          [
           "1.1.1.1em colorlinks = true, allcolors = blue nlpNLPNatural Language Processing nerNERNamed Entity Recognition saSASentiment Analysis mlMLMachine Learning bowBoWbag-of-words cbowCBoWcontinuous Bag-of-Words sltcSLTCSwedish Language Technology Conference annANNartificial neural network nnNNneural network lstmLSTMLong Short Term Memory Network bilstmbiLSTMbidirectional Long Short Term Memory Network sotaSoTAstate-of-the-art nlgNLGNatural Language Generation nluNLUNatural Language Understanding mweMWEMulti-Word Expression swSWSimple Wiki mtMTMachine Translation bwBWBillion Word piePIEPotential Idiomatic Expression iaaIAAInter-Annotator Agreement rteRTERecognizing Textual Entailment irIRInformation Retrieval qaQAQuestion Answering bncBNCBritish National Corpus ukwUKWaCUK Web Pages aiAIArtificial Intelligence gdcGDCGothenburg Dialogue Corpus dialogptDialoGPTDialogue Generative Pre-trained Transformer gptGPTGenerative Pre-trained Transformer multiwozMultiWOZMulti-Domain Wizard-of-Oz t5T5Text-to-Text Transfer Transformer bartBARTBidirectional & Auto-Regressive Transformer xlmrXLM-RCross-Lingual Model-RoBERTa m2mM2MMany-to-Many multilingual translation model bertBERTBidirectional Encoder Representations from Transformers robertaRoBERTaRobustly optimized BERT pretraining Approach elmoELMoEmbeddings from Language Models piiPIIpersonally identifiable information qgQGQuestion Generation tcTCText Classification pclPCLPatronising and Condescending Language gusGUSGenial Understander System gmbGMBGroningen Meaning Bank wsdWSDWord Sense Disambiguation ccby4CC-BY4Creative Commons Attribution 4.0 ciCIconfidence interval bleuBLEUbilingual evaluation understudy gdprGDPRGeneral Data Protection Regulation svmSVMsupport vector machine vsVSvector space vsmVSMvector space model nltkNLTKnatural language toolkit tf-idftf-idfterm frequency-inverse document frequency pcaPCAPrincipal Component Analysis svdSVDSingular Value Decomposition lsiLSILatent Semantic Indexing plsiPLSIProbabilistic Latent Semantic indexing ldaLDALatent Dirichlet Allocation lmLMlanguage model bilmbiLMbidirectional language model posPoSpart of speech nnlmNNLMneural network language model bpeBPEbyte-pair encoding oovOOVout-of-vocabulary imdbIMDBInternet Movie Database lrLRlearning rate cusCUSCredibility unanimous score ieIEInformation Extraction rlRLreinforcement learning mdlMDLminimal dependency length mlmMLMmasked language model rqRQresearch questions Tosin Adewumi*, Foteini Liwicki and Marcus Liwicki ML Group, EISLAB, Luleå University of Technology, Sweden firstname.lastname@ltu.se We demonstrate, in this study, that an open-domain conversational system trained on idioms or figurative language generates more fitting responses to prompts containing idioms."
          ],
          [
           "Introduction"
          ],
          [
           "Materials and Methods"
          ],
          [
           "multiwoz dataset"
          ],
          [
           "pie-English idioms corpus"
          ],
          [
           "Classification"
          ],
          [
           "Conversation Generation"
          ],
          [
           "Evaluation"
          ],
          [
           "Credibility Unanimous Score (cus)"
          ],
          [
           "Classification"
          ],
          [
           "Error Analysis"
          ],
          [
           "Conversation generation"
          ],
          [
           "Discussion & Evaluator Feedback"
          ],
          [
           "Related Work"
          ],
          [
           "Limitation"
          ],
          [
           "Conclusions"
          ],
          [
           "Bibliographical References"
          ],
          [
           "Generalization Error in Deep Learning"
          ],
          [
           "Abstract  Deep learning models have lately shown great performance in various fields such as computer vision, speech recognition, speech translation, and natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "The learning problem"
          ],
          [
           "Deep neural networks"
          ],
          [
           "Generalization error in deep learning"
          ],
          [
           "Understanding deep learning requires rethinking generalization"
          ],
          [
           "Exploring generalization in deep learning"
          ],
          [
           "A PAC-Bayesian approach to spectrally-normalized margin bounds for neural networks"
          ],
          [
           "Stability and generalization"
          ],
          [
           "Robustness and generalization"
          ],
          [
           "Stronger generalization bounds for deep nets via a compression approach"
          ],
          [
           "Train faster, generalize better: stability of stochastic gradient descent"
          ],
          [
           "On large-batch training for deep learning: generalization gap and sharp minima"
          ],
          [
           "Sharp minima solutions to the training of DNNs can generalize for deep nets"
          ],
          [
           "Train longer, generalize better: closing the generalization gap in large batch training of neural networks"
          ],
          [
           "Generalization error of invariant classifiers"
          ],
          [
           "Generalization error and adversarial attacks"
          ],
          [
           "Open problems"
          ],
          [
           "Problem 1: Generalization and memorization"
          ],
          [
           "Problem 2: Generalization and robustness"
          ],
          [
           "Problem 3: Generalization and adversarial examples"
          ],
          [
           "Problem 4: Generalization error of generative models"
          ],
          [
           "Problem 5: Generalization error and the information bottleneck"
          ],
          [
           "Conclusions"
          ],
          [
           "ARCH: Efficient Adversarial Regularized Training with Caching"
          ],
          [
           "Abstract  Adversarial regularization can improve model generalization in many natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Method"
          ],
          [
           "Adversarial Regularization"
          ],
          [
           "Adversarial Regularization with Caching"
          ],
          [
           "Memory Saving with KNN"
          ],
          [
           "Computational Efficiency"
          ],
          [
           "Experiments"
          ],
          [
           "Baselines"
          ],
          [
           "Machine Translation"
          ],
          [
           "Natural Language Understanding"
          ],
          [
           "Parameter Study"
          ],
          [
           "Analysis"
          ],
          [
           "Conclusion"
          ],
          [
           "Broader Impact"
          ],
          [
           "Detailed Algorithm"
          ],
          [
           "Machine Translation Experiments"
          ],
          [
           "Natural Language Understanding Experiments"
          ],
          [
           "Translational NLP: A New Paradigm and General Principles for Natural\n  Language Processing Research"
          ],
          [
           "Abstract  Natural language processing (NLP) research combines the study of universal principles, through basic science, with applied science targeting specific use cases and settings."
          ],
          [
           "Introduction"
          ],
          [
           "A third type of research"
          ],
          [
           "Translation is bidirectional"
          ],
          [
           "NLP as a translational field: a historical perspective"
          ],
          [
           "A practical definition"
          ],
          [
           "The Translational NLP framework"
          ],
          [
           "Stakeholders"
          ],
          [
           "Translational NLP Checklist"
          ],
          [
           "Translating methodology advances into existing applications"
          ],
          [
           "Case Study: NLP for Disability Review"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU"
          ],
          [
           "Abstract  In this paper, we explore optimizations to run Recurrent Neural Network (RNN) models locally on mobile devices."
          ],
          [
           "2017 acmcopyright EMDL'17,June 23, 2017, Niagara Falls, NY, USA 978-1-4503-4962-8/17/06$15.00 http://dx.doi.org/10.1145/3089801.3089804 MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU  Qingqing CaoNiranjan BalasubramanianAruna Balasubramanian  Table: Conclusion"
          ],
          [
           "A Mixture of $h-1$ Heads is Better than $h$ Heads"
          ],
          [
           "Abstract  Multi-head attentive neural architectures have achieved state-of-the-art results on a variety of natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "MAE: Mixture of Attentive Experts"
          ],
          [
           "Background: Mixture of Experts"
          ],
          [
           "Multi-Head Attention: a Mixture-of-Experts Perspective"
          ],
          [
           "A mixture-of-experts perspective."
          ],
          [
           "Discussion."
          ],
          [
           "MAE: Learning to Weight Experts"
          ],
          [
           "Training MAE with Block Coordinate Descent"
          ],
          [
           "Experiments"
          ],
          [
           "Compared Models"
          ],
          [
           "Analysis"
          ],
          [
           "Does MAE Learn to Specialize the Experts?"
          ],
          [
           "MAE's Potential in Transfer Learning: A Case Study"
          ],
          [
           "Setting."
          ],
          [
           "Multi-head attention."
          ],
          [
           "Mixture of experts."
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Architectures and Implementations"
          ],
          [
           "Machine translation with WMT'14"
          ],
          [
           "Machine translation with IWSLT'14."
          ],
          [
           "Language modeling with WikiText-103."
          ],
          [
           "Learning Curve Comparison for MAE and "
          ],
          [
           "Addtional Results for §"
          ],
          [
           "Recurrent Neural Network Wave Functions"
          ],
          [
           "Abstract  A core technology that has emerged from the artificial intelligence revolution is the recurrent neural network (RNN)."
          ],
          [
           "Introduction"
          ],
          [
           "RNN wave functions"
          ],
          [
           "Ground States with RNN wave functions"
          ],
          [
           "1D transverse field Ising model"
          ],
          [
           "1D $J_1-J_2$  model"
          ],
          [
           "2D transverse field Ising model"
          ],
          [
           "Scaling of resources"
          ],
          [
           "Open-Source Code"
          ],
          [
           "Gated Recurrent Neural Networks"
          ],
          [
           "Two-dimensional Recurrent Neural Network wave functions"
          ],
          [
           "Variational Monte Carlo and Variance Reduction"
          ],
          [
           "Imposing discrete symmetries"
          ],
          [
           "Imposing zero magnetization"
          ],
          [
           "Rényi entropies"
          ],
          [
           "Tables of Results"
          ],
          [
           "Scaling of resources (continued)"
          ],
          [
           "Hyperparameters"
          ],
          [
           "xDBTagger: Explainable Natural Language Interface to Databases Using\n  Keyword Mappings and Schema Graph"
          ],
          [
           "Abstract  Translating natural language queries (NLQ) into structured query language (SQL) in interfaces to relational databases is a challenging task that has been widely studied by researchers from both the database and natural language processing communities."
          ],
          [
           "Introduction"
          ],
          [
           "System Architecture"
          ],
          [
           "Keyword Mapper - DBTagger"
          ],
          [
           "Deep Sequence Tagger Architecture"
          ],
          [
           "DBTagger Architecture"
          ],
          [
           "Annotation Scheme"
          ],
          [
           "POS Tags"
          ],
          [
           "Type Tags"
          ],
          [
           "Schema Tags"
          ],
          [
           "Explanations for Keyword Mapper"
          ],
          [
           "LIME"
          ],
          [
           "LIME Wrapper"
          ],
          [
           "SQL Translation Algorithm"
          ],
          [
           "Schema Graph Extraction"
          ],
          [
           "Join-Path Inference"
          ],
          [
           "Where Clause Completion"
          ],
          [
           "Heuristics for Aggregate Queries"
          ],
          [
           "Datasets"
          ],
          [
           "Query Translation Results"
          ],
          [
           "Explainable User Interface of xDBTagger"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "A Neural Entity Coreference Resolution Review"
          ],
          [
           "Abstract  Entity Coreference Resolution is the task of resolving all mentions in a document that refer to the same real world entity and is considered as one of the most difficult tasks in natural language understanding."
          ],
          [
           "Introduction"
          ],
          [
           "Anaphoric Types"
          ],
          [
           "Zero Anaphora:"
          ],
          [
           "One Anaphora:"
          ],
          [
           "Pronominal Anaphora:"
          ],
          [
           "Demonstratives:"
          ],
          [
           "Presuppositions:"
          ],
          [
           "Discontinuous Sets (Split Anaphora):"
          ],
          [
           "Inferrable Anaphora (Bridging Anaphora):"
          ],
          [
           "Generics:"
          ],
          [
           "Non referential terms:"
          ],
          [
           "Anaphoric Constrains"
          ],
          [
           "Gender agreement:"
          ],
          [
           "Person agreement:"
          ],
          [
           "Number agreement:"
          ],
          [
           "Binding theory:"
          ],
          [
           "Selectional Restrictions:"
          ],
          [
           "Recency:"
          ],
          [
           "Discourse structure:"
          ],
          [
           "World Knowledge:"
          ],
          [
           "Standard Datasets for Coreference Resolution"
          ],
          [
           "Entity Coreference Resolution evaluation metrics"
          ],
          [
           "MUC"
          ],
          [
           "B-cubed"
          ],
          [
           "CEAF"
          ],
          [
           "Brief history of Entity Coreference Resolution approaches"
          ],
          [
           "Deep Learning Coreference Resolution"
          ],
          [
           "Entity Coreference Resolution"
          ],
          [
           "Entity-Based models"
          ],
          [
           "Latent-Structure models"
          ],
          [
           "Language-Modelling models"
          ],
          [
           "Pronoun Resolution"
          ],
          [
           "Coreference Resolution Performance"
          ],
          [
           "Entity Coreference Resolution results"
          ],
          [
           "Pronoun Resolution"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusions and future work"
          ],
          [
           "YOLOPose: Transformer-based Multi-Object 6D Pose Estimation using\n  Keypoint Regression"
          ],
          [
           "Abstract  6D object pose estimation is a crucial prerequisite for autonomous robot manipulation applications."
          ],
          [
           "RGB Object Pose Estimation"
          ],
          [
           "Learned P"
          ],
          [
           "Multi-Object Keypoint Regression as Set Prediction"
          ],
          [
           "Keypoints Representation"
          ],
          [
           "RotEst"
          ],
          [
           "Loss Function"
          ],
          [
           "Class Probability Loss"
          ],
          [
           "Bounding Box Loss"
          ],
          [
           "Keypoint Loss"
          ],
          [
           "Pose Loss"
          ],
          [
           "Model Architecture"
          ],
          [
           "Backbone Network"
          ],
          [
           "Positional Encodings"
          ],
          [
           "Encoder"
          ],
          [
           "Decoder"
          ],
          [
           "FFN"
          ],
          [
           "Evaluation"
          ],
          [
           "Dataset"
          ],
          [
           "Metrics"
          ],
          [
           "Hyperparameters"
          ],
          [
           "Results"
          ],
          [
           "Inference Time Analysis"
          ],
          [
           "Ablation Study"
          ],
          [
           "Effectiveness of Keypoints Representations"
          ],
          [
           "Effectiveness of RotEst"
          ],
          [
           "Discussion & Conclusion"
          ],
          [
           "Acknowledgment"
          ],
          [
           "A global analysis of metrics used for measuring performance in natural\n  language processing"
          ],
          [
           "Abstract  Measuring the performance of natural language processing models is challenging."
          ],
          [
           "Introduction"
          ],
          [
           "Dataset"
          ],
          [
           "Hierarchical mapping and further curation of metric names"
          ],
          [
           "Grouping of top-level metrics"
          ],
          [
           "Analysis"
          ],
          [
           "Data basis"
          ],
          [
           "Which performance metrics are most frequently reported in NLP benchmarking?"
          ],
          [
           "Are metrics reported together with other metrics or do they stand alone?"
          ],
          [
           "Inconsistencies and ambiguities in the reporting of performance metrics"
          ],
          [
           "Discussion"
          ],
          [
           "Recommendations for reporting performance results and future considerations"
          ],
          [
           "Increasing transparency and consistency in the reporting of performance metrics"
          ],
          [
           "Maximizing the informative value in the reporting of performance results"
          ],
          [
           "Future considerations on performance metrics in the context of benchmarking"
          ],
          [
           "Limitations"
          ],
          [
           "Conclusions"
          ],
          [
           "Data and code availability"
          ],
          [
           "KinyaBERT: a Morphology-aware Kinyarwanda Language Model"
          ],
          [
           "Abstract  Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Morphology-aware Language Model"
          ],
          [
           "Morphological Analysis and Part-of-Speech Tagging"
          ],
          [
           "Morphology Encoding"
          ],
          [
           "Pre-training Objective"
          ],
          [
           "Experiments"
          ],
          [
           "Pre-training details"
          ],
          [
           "Evaluation tasks"
          ],
          [
           "Main results"
          ],
          [
           "Ablation study"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "STransE: a novel embedding model of entities and relationships in\n  knowledge bases"
          ],
          [
           "Abstract  Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Our approach"
          ],
          [
           "Related work"
          ],
          [
           "Experiments"
          ],
          [
           "Task and evaluation protocol"
          ],
          [
           "Main results"
          ],
          [
           "Conclusion and future work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "A Survey of Implicit Discourse Relation Recognition"
          ],
          [
           "Abstract  A discourse containing one or more sentences describes daily issues and events for people to communicate their thoughts and opinions."
          ],
          [
           "Introduction"
          ],
          [
           "summary of this survey"
          ],
          [
           "The PDTB Corpus"
          ],
          [
           "The CoNLL Dataset and Shared Task"
          ],
          [
           "Implicit Discourse Relation Recognition based on Machine Learning"
          ],
          [
           "Lexical features"
          ],
          [
           "Syntactic features"
          ],
          [
           "Contextual feautres"
          ],
          [
           "Implicit Connectives"
          ],
          [
           "Convolutional Neural Networks"
          ],
          [
           "Recurrent Neural Networks"
          ],
          [
           "Hybrid Neural Network Models"
          ],
          [
           "Attention Mechanism"
          ],
          [
           "Neural Learning of Argument Pair Interaction"
          ],
          [
           "Data Expansion from Explicit Discourse Relations"
          ],
          [
           "Data Expansion from Multi-Language Data"
          ],
          [
           "Joint Data Expansion and Model Training"
          ],
          [
           "Performance Comparison"
          ],
          [
           "Conclusion and Discussion"
          ],
          [
           "Interaction-boosted representation learning"
          ],
          [
           "Synthetic Implicit Corpus Refinement"
          ],
          [
           "Joint relation recognition and discourse parsing"
          ],
          [
           "Sequence-to-Sequence Lexical Normalization with Multilingual\n  Transformers"
          ],
          [
           "Abstract  Current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Data and Evaluation"
          ],
          [
           "Method"
          ],
          [
           "Results"
          ],
          [
           "Conclusions"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Sequence to sequence pretraining for a less-resourced Slovenian language"
          ],
          [
           "Abstract  Large pretrained language models have recently conquered the area of natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Slovene T5 models"
          ],
          [
           "Training data"
          ],
          [
           "Architecture and training of SloT5"
          ],
          [
           "Evaluation"
          ],
          [
           "Evaluation tasks"
          ],
          [
           "Fine-tuning T5 and compared models"
          ],
          [
           "Results"
          ],
          [
           "Discussion"
          ],
          [
           "Funding"
          ],
          [
           "NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local\n  Languages"
          ],
          [
           "Abstract  Natural language processing (NLP) has a significant impact on society via technologies such as machine translation and search engines."
          ],
          [
           "Introduction"
          ],
          [
           "Focus Languages"
          ],
          [
           "Data Construction"
          ],
          [
           "Annotator Recruitment"
          ],
          [
           "Data Filtering and Sampling"
          ],
          [
           "Human Translation"
          ],
          [
           "Human-Assisted Quality Assurance"
          ],
          [
           "Tasks"
          ],
          [
           "Sentiment Analysis"
          ],
          [
           "Machine Translation"
          ],
          [
           "Classical Machine Learning"
          ],
          [
           "Pre-trained Local Language Models"
          ],
          [
           "Pre-trained Massively Multilingual LMs"
          ],
          [
           "Sentiment Analysis"
          ],
          [
           "Machine Translation"
          ],
          [
           "Cross-lingual Capability of LMs"
          ],
          [
           "Multilingual Parallel Corpus"
          ],
          [
           "Emerging Language Benchmarks"
          ],
          [
           "Datasets for Indonesian Languages"
          ],
          [
           "Conclusion"
          ],
          [
           "Ethical Considerations"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Dataset title"
          ],
          [
           "Dataset curators"
          ],
          [
           "Dataset version"
          ],
          [
           "Dataset citation"
          ],
          [
           "Data statement author"
          ],
          [
           "Data statement version"
          ],
          [
           "Data statement citation"
          ],
          [
           "Executive Summary"
          ],
          [
           "Curation Rationale"
          ],
          [
           "Documentation for Source Datasets"
          ],
          [
           "Language Variety"
          ],
          [
           "Speaker Demographic"
          ],
          [
           "Annotator Demographic"
          ],
          [
           "Acehnese"
          ],
          [
           "Balinese"
          ],
          [
           "Banjarese"
          ],
          [
           "Buginese"
          ],
          [
           "Javanese"
          ],
          [
           "Madurese"
          ],
          [
           "Minangkabau"
          ],
          [
           "Ngaju"
          ],
          [
           "Sundanese"
          ],
          [
           "Toba Batak"
          ],
          [
           "Sentiment Analysis"
          ],
          [
           "Machine Translation"
          ],
          [
           "Examples"
          ],
          [
           "XNLI: Evaluating Cross-lingual Sentence Representations"
          ],
          [
           "Abstract  State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models."
          ],
          [
           "Introduction"
          ],
          [
           "Multilingual Word Embeddings"
          ],
          [
           "Sentence Representation Learning"
          ],
          [
           "Multilingual Sentence Representations"
          ],
          [
           "Cross-lingual Evaluation Benchmarks"
          ],
          [
           "The XNLI Corpus"
          ],
          [
           "The English Corpus"
          ],
          [
           "Translating the Corpus"
          ],
          [
           "The Resulting Corpus"
          ],
          [
           "Cross-Lingual NLI"
          ],
          [
           "Translation-Based Approaches"
          ],
          [
           "Multilingual Sentence Encoders"
          ],
          [
           "Aligning Word Embeddings"
          ],
          [
           "Universal Multilingual Sentence Embeddings"
          ],
          [
           "Aligning Sentence Embeddings"
          ],
          [
           "Training details"
          ],
          [
           "Parallel Datasets"
          ],
          [
           "Analysis"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Improving Pre-Trained Multilingual Models with Vocabulary Expansion"
          ],
          [
           "Abstract  Recently, pre-trained language models have achieved remarkable success in a broad range of natural language processing tasks."
          ],
          [
           "META-REVIEW"
          ],
          [
           "What is this paper about, what contributions does it make, what are the main strengths and weaknesses?"
          ],
          [
           "Reasons to accept"
          ],
          [
           "Reasons to reject"
          ],
          [
           "Reviewer's Scores"
          ],
          [
           "Questions and Suggestions for the Author(s)"
          ],
          [
           "What is this paper about, what contributions does it make, what are the main strengths and weaknesses?"
          ],
          [
           "Reasons to accept"
          ],
          [
           "Reasons to reject"
          ],
          [
           "Reviewer's Scores"
          ],
          [
           "Missing References"
          ],
          [
           "What is this paper about, what contributions does it make, what are the main strengths and weaknesses?"
          ],
          [
           "Reasons to accept"
          ],
          [
           "Reasons to reject"
          ],
          [
           "Reviewer's Scores"
          ],
          [
           "CIRCLE: Continual Repair across Programming Languages"
          ],
          [
           "Abstract  Automatic Program Repair (APR) aims at fixing buggy source code with less manual debugging efforts, which plays a vital role in improving software reliability and development productivity."
          ],
          [
           "Introduction"
          ],
          [
           "Continual Learning"
          ],
          [
           "Prompt for Pre-trained Model"
          ],
          [
           "Overview"
          ],
          [
           "Prompt based Data Representation"
          ],
          [
           "T5 as APR Model Skeleton"
          ],
          [
           "Difficulty-based Example Replay"
          ],
          [
           "Sampling-based EWC Regularization"
          ],
          [
           "Cross Language Re-repairing"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Research Questions"
          ],
          [
           "Datasets"
          ],
          [
           "Implementation Details"
          ],
          [
           "Benchmarks and Baselines"
          ],
          [
           "Evaluation and Results"
          ],
          [
           "RQ1: Can CIRCLE effectively learn bug fixing in “task requirements increase constantly” scenario?"
          ],
          [
           "RQ2: What is the performance of a single CIRCLE model compared to the dedicatedly trained state-of-the-art APR methods?"
          ],
          [
           "RQ3: What are the contributions of the different components of CIRCLE?"
          ],
          [
           "Impact of prompt-based data representation"
          ],
          [
           "Impact of re-repairing"
          ],
          [
           "Impact of the continual learning module"
          ],
          [
           "Case Study"
          ],
          [
           "APR"
          ],
          [
           "Continual Learning"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Neural Grammatical Error Correction with Finite State Transducers"
          ],
          [
           "Abstract  Grammatical error correction (GEC) is one of the areas in natural language processing in which purely neural models have not yet superseded more traditional symbolic models."
          ],
          [
           "Introduction"
          ],
          [
           "Constructing the set of hypotheses"
          ],
          [
           "Scoring the hypothesis space"
          ],
          [
           "Experimental setup"
          ],
          [
           "Results"
          ],
          [
           "Error type analysis"
          ],
          [
           "Oracle experiments"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "An Empirical Study of Contextual Data Augmentation for Japanese Zero\n  Anaphora Resolution"
          ],
          [
           "Abstract  One critical issue of zero anaphora resolution (ZAR) is the scarcity of labeled data."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Problem Formulation and Notation"
          ],
          [
           "Baseline Model"
          ],
          [
           "Method"
          ],
          [
           "Contextual Data Augmentation (CDA)"
          ],
          [
           "We present the [MASK]-based augmentation and simplify the integration of the original CDA into the baseline model (Section REF ) for computational efficiency."
          ],
          [
           "Linguistically-controlled Masking"
          ],
          [
           "Experiments"
          ],
          [
           "Experimental Configuration"
          ],
          [
           "Effectiveness of "
          ],
          [
           "Effectiveness of Linguistically-controlled Masking"
          ],
          [
           "Comparison with the Existing Models"
          ],
          [
           "Analysis of Augmented Data"
          ],
          [
           "Discussion"
          ],
          [
           "Word Replacement Approaches"
          ],
          [
           "Structure-Augmented Text Representation Learning for Efficient Knowledge\n  Graph Completion"
          ],
          [
           "Abstract  Human-curated knowledge graphs provide critical supportive information to various natural language processing tasks, but these graphs are usually incomplete, urging auto-completion of them."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Link Prediction."
          ],
          [
           "Pre-Trained Masked Language Model."
          ],
          [
           "KG-BERT"
          ],
          [
           "Structure-Aware Triple Encoding"
          ],
          [
           "Structure-Augmented Scoring Module"
          ],
          [
           "Deterministic Representation Learning"
          ],
          [
           "Spatial Structure Learning"
          ],
          [
           "Training Objectives and Inference Details"
          ],
          [
           "Triple Contrastive Objective."
          ],
          [
           "Training and Inference Strategies."
          ],
          [
           "Model Efficiency."
          ],
          [
           "Training Efficiency."
          ],
          [
           "Inference Efficiency."
          ],
          [
           "Self-Adaptive Ensemble Scheme"
          ],
          [
           "Compared to Prior Text-Based Approach "
          ],
          [
           "Stand-alone Embedding."
          ],
          [
           "Joint Embedding."
          ],
          [
           "Benchmark Datasets."
          ],
          [
           "Evaluation Metrics."
          ],
          [
           "Evaluation Protocol."
          ],
          [
           "Evaluations on Link Prediction"
          ],
          [
           "Comparison with KG-BERT Baseline"
          ],
          [
           "Generalization to Unseen Graph Elements"
          ],
          [
           "Ablation Study"
          ],
          [
           "Further Analyses"
          ],
          [
           "What is the effect of introducing structure learning into a textual encoding approach."
          ],
          [
           "How does StAR bring improvements."
          ],
          [
           "Why does StAR achieve better Hits@10 but worse Hits@1 than RotatE"
          ],
          [
           "How does the self-adaptive ensemble scheme bring improvements."
          ],
          [
           "Structure Learning for Link Prediction."
          ],
          [
           "Text Representation Learning."
          ],
          [
           "Jointly Learning Methods."
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Training Setups"
          ],
          [
           "Probing Tasks"
          ],
          [
           "Self-Knowledge Distillation in Natural Language Processing"
          ],
          [
           "Abstract  Since deep learning became a key player in natural language processing (NLP), many deep learning models have been showing remarkable performances in a variety of NLP tasks, and in some cases, they are even outperforming humans."
          ],
          [
           "Introduction"
          ],
          [
           "Background"
          ],
          [
           "Cross Entropy"
          ],
          [
           "Knowledge Distillation"
          ],
          [
           "Word Embedding"
          ],
          [
           "Self-Knowledge Distillation"
          ],
          [
           "SKD Equations"
          ],
          [
           "SKD Algorithm"
          ],
          [
           "NLP Tasks"
          ],
          [
           "Experiments"
          ],
          [
           "Dataset"
          ],
          [
           "Language Modeling"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Towards a robust out-of-the-box neural network model for genomic data"
          ],
          [
           "Abstract  The accurate prediction of biological features from genomic data is paramount for precision medicine and sustainable agriculture."
          ],
          [
           "Introduction"
          ],
          [
           "Methods"
          ],
          [
           "Available Datasets"
          ],
          [
           "Convolutional Neural Networks"
          ],
          [
           "CNN-Nguyen {{cite:8e1762df642a6add900fbca08858e99e90695e7c}}"
          ],
          [
           "CNN-Zeng {{cite:3c71e43ef24f1f4669f33a18df83784895733a46}}"
          ],
          [
           "DeepDBP {{cite:dd49f233931b392ea4a7054be93e058d27684513}}"
          ],
          [
           "DeepRAM {{cite:31086e06923f1471de3b7f712e6671ae51b89ee6}}"
          ],
          [
           "Natural Language Processing Neural Networks"
          ],
          [
           "LSTM-layer"
          ],
          [
           "doc2vec+NN {{cite:f67a1ca0ef071524500dd7f48f549770987d9dfd}}"
          ],
          [
           "LSTM-AE+NN {{cite:62c347d3f326ba85bb9592513fdbf18b07d56e07}}"
          ],
          [
           "Replication of Results"
          ],
          [
           "The Role of Convolutional Layers and Dimension."
          ],
          [
           "Robustness across Datasets"
          ],
          [
           "The Role of Data Encoding"
          ],
          [
           "The Role of Sparsity in Overfitting"
          ],
          [
           "Comparison of Classification Accuracy"
          ],
          [
           "The Role of the Embedding Size on Classification Accuracy of doc2vec+NN"
          ],
          [
           "The Role of the Optimizer in the Classification Accuracy of the LSTM-layer Model"
          ],
          [
           "The Role of the Batch Size in the Classification Accuracy of the LSTM-AE+NN Model"
          ],
          [
           "Comparison of Sequence Embedding in doc2vec and LSTM-AE"
          ],
          [
           "Discussion"
          ],
          [
           "Reproducibility"
          ],
          [
           "Reproducible Julia Script for Random Order of First Authors"
          ],
          [
           "Hidden Backdoors in Human-Centric Language Models"
          ],
          [
           "Abstract  Natural language processing (NLP) systems have been proven to be vulnerable to backdoor attacks, whereby hidden features (backdoors) are trained into a language model and may only be activated by specific inputs (called triggers), to trick the model into producing unexpected behaviors."
          ],
          [
           "Introduction"
          ],
          [
           "Template Overview"
          ],
          [
           "Template Styles"
          ],
          [
           "Template Parameters"
          ],
          [
           "Modifications"
          ],
          [
           "Typefaces"
          ],
          [
           "Title Information"
          ],
          [
           "Authors and Affiliations"
          ],
          [
           "Rights Information"
          ],
          [
           "CCS Concepts and User-Defined Keywords"
          ],
          [
           "Sectioning Commands"
          ],
          [
           "Tables"
          ],
          [
           "Math Equations"
          ],
          [
           "Inline (In-text) Equations"
          ],
          [
           "Display Equations"
          ],
          [
           "Figures"
          ],
          [
           "The “Teaser Figure”"
          ],
          [
           "Citations and Bibliographies"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Appendices"
          ],
          [
           "SIGCHI Extended Abstracts"
          ],
          [
           "Part One"
          ],
          [
           "Part Two"
          ],
          [
           "Online Resources"
          ],
          [
           "When Word Embeddings Become Endangered"
          ],
          [
           "Abstract  Big languages such as English and Finnish have many natural language processing (NLP) resources and models, but this is not the case for low-resourced and endangered languages as such resources are so scarce despite the great advantages they would provide for the language communities."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Linguistic resources"
          ],
          [
           "Translation dictionaries"
          ],
          [
           "Universal dependencies"
          ],
          [
           "Finite-state transducers"
          ],
          [
           "Word embeddings of resource-rich languages"
          ],
          [
           "Sentiment analysis"
          ],
          [
           "Discussion and Conclusions"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Leap-LSTM: Enhancing Long Short-Term Memory for Text Categorization"
          ],
          [
           "Abstract  Recurrent Neural Networks (RNNs) are widely used in the field of natural language processing (NLP), ranging from text categorization to question answering and machine translation."
          ],
          [
           "Introduction"
          ],
          [
           "Related Works"
          ],
          [
           "Methodology"
          ],
          [
           "Model Overview"
          ],
          [
           "Efficient Feature Encoders"
          ],
          [
           "Relaxation of Discrete Variables"
          ],
          [
           "Differences with Related Models"
          ],
          [
           "Experiments"
          ],
          [
           "Data"
          ],
          [
           "Model Settings"
          ],
          [
           "Model Performances"
          ],
          [
           "Schedule-Training"
          ],
          [
           "Ablation Tests"
          ],
          [
           "Skipping Analysis"
          ],
          [
           "Top-5 keep-rate words."
          ],
          [
           "Case study. "
          ],
          [
           "Conclusions"
          ],
          [
           "Acknowledgements"
          ],
          [
           "XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and\n  Question Answering"
          ],
          [
           "Abstract  While natural language processing systems often focus on a single language, multilingual transfer learning has the potential to improve performance, especially for low-resource languages."
          ],
          [
           "Introduction"
          ],
          [
           "Multilingual Methods."
          ],
          [
           "Natural Language Inference."
          ],
          [
           "Question Answering."
          ],
          [
           "Unsupervised Language Models."
          ],
          [
           "Back-translation."
          ],
          [
           "XLDA: Cross-Lingual Data Augmentation"
          ],
          [
           "Experiments and Results"
          ],
          [
           "Cross-lingual Data"
          ],
          [
           "Models"
          ],
          [
           "Pairwise Evaluation"
          ],
          [
           "There exists a cross-lingual augmentor that improves over the monolingual approach."
          ],
          [
           "Most languages are effective augmentors."
          ],
          [
           "Lower resource languages are less effective augmentors, but benefit greatly from XLDA."
          ],
          [
           "XLDA is robust to translation quality."
          ],
          [
           "A Greedy Algorithm for XLDA"
          ],
          [
           "Greedy XLDA always improves over using the single best cross-lingual augmentor."
          ],
          [
           "Targeted XLDA"
          ],
          [
           "The `cross' in cross-lingual is crucial."
          ],
          [
           "XLDA without BERT"
          ],
          [
           "XLDA is equally effective for randomly initialized and pretrained models."
          ],
          [
           "Greedy XLDA is more effective for randomly initialized models than pretrained models."
          ],
          [
           "XLDA for SQuAD"
          ],
          [
           "Conclusion"
          ],
          [
           "Bad Characters: Imperceptible NLP Attacks"
          ],
          [
           "Abstract  Several years of research have shown that machine-learning systems are vulnerable to adversarial examples, both in theory and in practice."
          ],
          [
           "Introduction"
          ],
          [
           "Motivation"
          ],
          [
           "Adversarial Examples"
          ],
          [
           "NLP Models"
          ],
          [
           "Adversarial NLP"
          ],
          [
           "Unicode"
          ],
          [
           "Unicode Security"
          ],
          [
           "Attack Taxonomy"
          ],
          [
           "NLP Pipeline"
          ],
          [
           "Attack Methodology"
          ],
          [
           "Invisible Characters"
          ],
          [
           "Homoglyphs"
          ],
          [
           "Reorderings"
          ],
          [
           "Deletions"
          ],
          [
           "Integrity Attack"
          ],
          [
           "Availability Attack"
          ],
          [
           "Experiment Setup"
          ],
          [
           "Machine Translation: Integrity"
          ],
          [
           "Machine Translation: Availability"
          ],
          [
           "Machine Translation: MLaaS"
          ],
          [
           "Toxic Content Detection"
          ],
          [
           "Toxic Content Detection: MLaaS"
          ],
          [
           "Textual Entailment: Untargeted"
          ],
          [
           "Textual Entailment: Targeted"
          ],
          [
           "Ethics"
          ],
          [
           "Attack Potential"
          ],
          [
           "Search Engine Attack"
          ],
          [
           "Defences"
          ],
          [
           "Invisible Character Defences"
          ],
          [
           "Homoglyph Defences"
          ],
          [
           "Reordering Defences"
          ],
          [
           "Deletion Defences"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgment"
          ],
          [
           "Self-Attentional Models for Lattice Inputs"
          ],
          [
           "Abstract  Lattices are an efficient and effective method to encode ambiguity of upstream systems in natural language processing tasks, for example to compactly capture multiple speech recognition hypotheses, or to represent multiple linguistic analyses."
          ],
          [
           "Introduction"
          ],
          [
           "Masked Self-Attention"
          ],
          [
           "Lattices"
          ],
          [
           "Baseline Model"
          ],
          [
           "Lattice-Biased Attentional Decoder"
          ],
          [
           "Multi-Head Transformer Layers"
          ],
          [
           "Self-Attentional Lattice Encoders"
          ],
          [
           "Lattice Reachability Masks"
          ],
          [
           "Binary Masks"
          ],
          [
           "Probabilistic Masks"
          ],
          [
           "Directional and Non-Directional Masks"
          ],
          [
           "Lattice Positional Encoding"
          ],
          [
           "Computational Complexity"
          ],
          [
           "Experiments"
          ],
          [
           "Settings"
          ],
          [
           "Main Results"
          ],
          [
           "Computation Speed"
          ],
          [
           "Feature Ablation"
          ],
          [
           "Behavior At Test Time"
          ],
          [
           "Effect of Pretraining and Finetuning"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Path Duplication Invariance"
          ],
          [
           "Qualitative Analysis"
          ],
          [
           "Example 1"
          ],
          [
           "Example 2"
          ],
          [
           "Example 3"
          ],
          [
           "Counter Example"
          ],
          [
           "A Continuous Space Neural Language Model for Bengali Language"
          ],
          [
           "Abstract  Language models are generally employed to estimate the probability distribution of various linguistic units, making them one of the fundamental parts of natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "On Language Models"
          ],
          [
           "Count-based language models"
          ],
          [
           "Continuous-space language models"
          ],
          [
           "On Neural Network Architectures"
          ],
          [
           "On Training Neural Networks"
          ],
          [
           "Corpus"
          ],
          [
           "Proposed Architecture"
          ],
          [
           "Training the language model"
          ],
          [
           "Experiments"
          ],
          [
           "Bi-gram language model"
          ],
          [
           "LSTM and CNN language models"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Product Market Demand Analysis Using NLP in Banglish Text with Sentiment\n  Analysis and Named Entity Recognition"
          ],
          [
           "Abstract  Product market demand analysis plays a significant role for originating business strategies due to its noticeable impact on the competitive business field."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Methodology"
          ],
          [
           "Dataset"
          ],
          [
           "Data Collection"
          ],
          [
           "Data Prepossessing"
          ],
          [
           "Spell Correction Algorithm for Entities"
          ],
          [
           "Train and Validation set"
          ],
          [
           "Amazon Comprehend Custom NER Model"
          ],
          [
           "SpaCy NER Model"
          ],
          [
           "Gender Prediction"
          ],
          [
           "Sentiment Analysis"
          ],
          [
           "Spacy Custom NER Accuracy"
          ],
          [
           "Amazon Comprehend Accuracy"
          ],
          [
           "Sequential Model Sentiment Analysis"
          ],
          [
           "Demand Analysis"
          ],
          [
           "Conclusion and future work"
          ],
          [
           "Word2rate: training and evaluating multiple word embeddings as\n  statistical transitions"
          ],
          [
           "Abstract  Using pretrained word embeddings has been shown to be a very effective way in improving the performance of natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Word2rate"
          ],
          [
           "Word2rate First Order Series(FOS)"
          ],
          [
           "Word2rate First Order Product(FOP)"
          ],
          [
           "Left-Right Context Split"
          ],
          [
           "Hybrid Embeddings"
          ],
          [
           "Word2rate Second Order Series"
          ],
          [
           "Experiments"
          ],
          [
           "Word2rate FOS"
          ],
          [
           "Word2rate FOP"
          ],
          [
           "Comparison with CMOW"
          ],
          [
           "Comparison with CBOW"
          ],
          [
           "Left-Right Context Split"
          ],
          [
           "Hybrid FOS-FOP"
          ],
          [
           "Word2rate Second Order Series"
          ],
          [
           "Comparison with CBOW"
          ],
          [
           "Comparison with CMOW"
          ],
          [
           "Conclusion"
          ],
          [
           "Explaining Queries over Web Tables to Non-Experts"
          ],
          [
           "Abstract  Designing a reliable natural language (NL) interface for querying tables has been a longtime goal of researchers in both the data management and natural language processing (NLP) communities."
          ],
          [
           "Introduction"
          ],
          [
           "Setting"
          ],
          [
           "System Overview"
          ],
          [
           "Semantic Parser"
          ],
          [
           "Preliminaries"
          ],
          [
           "Data Model"
          ],
          [
           "Query Language"
          ],
          [
           "Language Operators"
          ],
          [
           "Provenance"
          ],
          [
           "Model Definitions"
          ],
          [
           "Query Operators"
          ],
          [
           "Explaining Queries"
          ],
          [
           "Query to Utterance"
          ],
          [
           "Provenance to Highlights"
          ],
          [
           "Scaling to Large Tables"
          ],
          [
           "Concrete Applications"
          ],
          [
           "Deployment"
          ],
          [
           "Implementation"
          ],
          [
           "WikiTableQuestions Dataset"
          ],
          [
           "Training on Feedback"
          ],
          [
           "Semantic Parsing"
          ],
          [
           "Deployment"
          ],
          [
           "Experiments"
          ],
          [
           "Evaluation Metrics"
          ],
          [
           "Interactive Parsing at Deployment"
          ],
          [
           "User Study"
          ],
          [
           "Training on User Feedback"
          ],
          [
           "NL interfaces"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Future Work"
          ],
          [
           "Confusion2Vec: Towards Enriching Vector Space Word Representations with\n  Representational Ambiguities"
          ],
          [
           "Abstract  Word vector representations are a crucial part of Natural Language Processing (NLP) and Human Computer Interaction."
          ],
          [
           "fit,calc Table: Similarity Task Results: Model concatenation and joint optimizationC2V-1: Top-Confusion, C2V-a: Intra-Confusion, C2V-c: Inter-Confusion, C2V-*: Hybrid Intra-InterSimilarity in terms of Spearman's correlation.All the models are of 556 dimensions.Numbers inside parenthesis indicate correlation p-valuep-value for similarity tasks.Good correlations are observed for both the word similarity and acoustic similarity with model concatenation with and without joint optimization."
          ],
          [
           "That Slepen Al the Nyght with Open Ye! Cross-era Sequence Segmentation\n  with Switch-memory"
          ],
          [
           "Abstract  The evolution of language follows the rule of gradual change."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "BERT-CRF model for Chinese word Segmentation"
          ],
          [
           "Switch-memory mechanism"
          ],
          [
           "Memory cells"
          ],
          [
           "Switcher"
          ],
          [
           "Objective"
          ],
          [
           "Datasets"
          ],
          [
           "Experimental configurations"
          ],
          [
           "Overall results"
          ],
          [
           "Ablation study"
          ],
          [
           "Mode selection"
          ],
          [
           "Case study"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Incorporating Dictionaries into Deep Neural Networks for the Chinese\n  Clinical Named Entity Recognition"
          ],
          [
           "Abstract  Clinical Named Entity Recognition (CNER) aims to identify and classify clinical terms such as diseases, symptoms, treatments, exams, and body parts in electronic health records, which is a fundamental and crucial task for clinical and translational research."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Bi-LSTM-CRF model"
          ],
          [
           "Pretrained Models for Multilingual Federated Learning"
          ],
          [
           "Abstract  Since the advent of Federated Learning (FL), research has applied these methods to natural language processing (NLP) tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Background and Related Work"
          ],
          [
           "Federated Learning Methods"
          ],
          [
           "Client Partitioning"
          ],
          [
           "Data"
          ],
          [
           "Europarl"
          ],
          [
           "MTNT"
          ],
          [
           "UN Corpus"
          ],
          [
           "NC Corpus"
          ],
          [
           "Modeling"
          ],
          [
           "Training"
          ],
          [
           "Language Modeling"
          ],
          [
           "Machine Translation"
          ],
          [
           "Text Classification"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Hyperparameters"
          ],
          [
           "Randomly Initialized MT"
          ],
          [
           "MTNT Data Preprocessing for M2M-100"
          ],
          [
           "Full LM Results"
          ],
          [
           "Image Synthesis with Adversarial Networks: a Comprehensive Survey and\n  Case Studies"
          ],
          [
           "Abstract  Generative Adversarial Networks (GANs) have been extremely successful in various application domains such as computer vision, medicine, and natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Convolution GANs"
          ],
          [
           "Conditional GANs"
          ],
          [
           "Auto-Encoders GAN"
          ],
          [
           "Progressive and Auxiliary Classifier GAN "
          ],
          [
           "Adversarial Domain Adaptation"
          ],
          [
           "GANs and Loss-Variants"
          ],
          [
           "Datasets"
          ],
          [
           "Synthetic Image Generation Methods"
          ],
          [
           "Single-stage methods:"
          ],
          [
           "Multi-stage methods:"
          ],
          [
           "Applications to medical imaging:"
          ],
          [
           "Generative phase"
          ],
          [
           "Discriminative phase"
          ],
          [
           "Applications to 3D Reconstruction"
          ],
          [
           "Image fusion"
          ],
          [
           "Image Completion"
          ],
          [
           "Supervised Translation"
          ],
          [
           "Unsupervised translation"
          ],
          [
           "Conclusion and Discussion"
          ],
          [
           "Topic-Centric Unsupervised Multi-Document Summarization of Scientific\n  and News Articles"
          ],
          [
           "Abstract  Recent advances in natural language processing have enabled automation of a wide range of tasks, including machine translation, named entity recognition, and sentiment analysis."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Data Collection"
          ],
          [
           "Extractive Phase"
          ],
          [
           "Topical Hierarchical Agglomerative Clustering"
          ],
          [
           "Core and Peripheral Articles Identification"
          ],
          [
           "Centroid based Clustering"
          ],
          [
           "Multi-Sentence Compression"
          ],
          [
           "Topical Coverage Formulation"
          ],
          [
           "Path Relevance Formulation"
          ],
          [
           "Cumulative Score"
          ],
          [
           "Abstractive Phase"
          ],
          [
           "Abstractive Language Unit (ALU) Generation"
          ],
          [
           "Multi-Sentence Compression"
          ],
          [
           "Extractive Evaluation"
          ],
          [
           "Abstractive Evaluation"
          ],
          [
           "DUC-2004 Abstractive Evaluation"
          ],
          [
           "MAG-20 Abstractive Evaluation"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgment"
          ],
          [
           "Explicit Sparse Transformer: Concentrated Attention Through Explicit\n  Selection"
          ],
          [
           "Abstract  Self-attention based Transformer has demonstrated the state-of-the-art performances in a number of natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Explicit Sparse Transformer"
          ],
          [
           "Results"
          ],
          [
           "Dataset"
          ],
          [
           "Result"
          ],
          [
           "Dataset"
          ],
          [
           "Result"
          ],
          [
           "Dataset"
          ],
          [
           "Result"
          ],
          [
           "Discussion"
          ],
          [
           "Comparison with other Sparse Attention Methods"
          ],
          [
           "How to Select a Proper k?"
          ],
          [
           "Do the proposed sparse attention method helps training?"
          ],
          [
           "Do the Explicit Sparse Transformer Attend better?"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Attention Mechanism"
          ],
          [
           "Transformer"
          ],
          [
           "Experimental Details"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Image Captioning"
          ],
          [
           "Language Models"
          ],
          [
           "The Back-propagation Process of Top-k Selection"
          ],
          [
           "Implementation"
          ],
          [
           "Global memory transformer for processing long documents"
          ],
          [
           "Abstract  Transformer variants dominate the state-of-the-art in different natural language processing tasks such as translation, reading comprehension and summarization."
          ],
          [
           "Introduction"
          ],
          [
           "Global slot memory augmented Transformer with hierarchical attention "
          ],
          [
           "Masked language modeling"
          ],
          [
           "Experiments setup"
          ],
          [
           "Experimental MLM task results"
          ],
          [
           "FlexiBO: A Decoupled Cost-Aware Multi-Objective Optimization Approach\n  for Deep Neural Networks"
          ],
          [
           "Abstract  The design of machine learning systems often requires trading off different objectives, for example, prediction error and energy consumption for deep neural networks (DNNs)."
          ],
          [
           "Introduction"
          ],
          [
           "Surrogate Models"
          ],
          [
           "Gaussian Processes"
          ],
          [
           "Random Forests"
          ],
          [
           "Multi-Objective Optimization"
          ],
          [
           "Pareto-optimality"
          ],
          [
           "Pareto region"
          ],
          [
           "Metrics"
          ],
          [
           "Cost Metrics"
          ],
          [
           "Objective evaluation cost"
          ],
          [
           "Prediction Quality Metrics"
          ],
          [
           "Pareto volume reduction"
          ],
          [
           "Contribution rate indicator"
          ],
          [
           "Diversity measure"
          ],
          [
           "FlexiBO: Flexible Bayesian Multi-Objective Optimization"
          ],
          [
           "Modeling"
          ],
          [
           "Pareto Region Construction"
          ],
          [
           "Sampling"
          ],
          [
           "Implementation and Workflow"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Results"
          ],
          [
           "FlexiBO Finds Better Configurations"
          ],
          [
           "FlexiBO Produces Superior Pareto Fronts"
          ],
          [
           "FlexiBO Discovers Optimal Configurations at Lower Cost"
          ],
          [
           "Threats to Validity"
          ],
          [
           "Multi-objective optimization with preferences."
          ],
          [
           "Multi-objective optimization with scalarizations."
          ],
          [
           "Multi-objective optimization with Pareto front approximation."
          ],
          [
           "Multi-objective, cross-layer, and hardware-aware optimization of DNNs."
          ],
          [
           "Conclusion"
          ],
          [
           "A Survey of Paraphrasing and Textual Entailment Methods"
          ],
          [
           "Abstract  Paraphrasing methods recognize, generate, or extract phrases, sentences, or longer natural language expressions that convey almost the same information."
          ],
          [
           "Introduction"
          ],
          [
           "Paraphrase and Textual Entailment Recognition"
          ],
          [
           "Logic-based Approaches to Recognition"
          ],
          [
           "Recognition Approaches that Use Vector Space Models of Semantics"
          ],
          [
           "Paraphrase and Textual Entailment Generation"
          ],
          [
           "Generation Methods Inspired by Statistical Machine Translation"
          ],
          [
           "Generation Methods that Use Bootstrapping"
          ],
          [
           "Paraphrase and Textual Entailment Extraction"
          ],
          [
           "Extraction Methods Based on the Distributional Hypothesis"
          ],
          [
           "Conclusions"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Bibliographic Resources, Portals, Tutorials"
          ],
          [
           "Corpora, Challenges, and their Datasets"
          ],
          [
           "Implementations of Machine Learning Algorithms"
          ],
          [
           "Implementations of Similarity Measures"
          ],
          [
           "Parsers, POS Taggers, Named Entity Recognizers, Stemmers"
          ],
          [
           "Statistical Machine Translation Tools and Resources"
          ],
          [
           "Lexical Resources, Paraphrasing and Textual Entailment Rules"
          ],
          [
           "On the Linguistic Representational Power of Neural Machine Translation\n  Models"
          ],
          [
           "Abstract  Despite the recent success of deep neural networks in natural language processing (NLP), their interpretability remains a challenge."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Analysis of Neural Networks"
          ],
          [
           "Subword Units"
          ],
          [
           "Linguistic Properties"
          ],
          [
           "Morphology"
          ],
          [
           "Syntax"
          ],
          [
           "Semantics"
          ],
          [
           "Methodology"
          ],
          [
           "Generating representations with subword and character units"
          ],
          [
           "NMT Training Data"
          ],
          [
           "Model Training"
          ],
          [
           "Classifier Settings"
          ],
          [
           "Supervised Data and Annotations"
          ],
          [
           "Morphology Results"
          ],
          [
           "Impact of Translation Unit on Learning Morphology"
          ],
          [
           "Encoder versus Decoder Representations"
          ],
          [
           "Effect of Network Depth"
          ],
          [
           "Effect of Target Language"
          ],
          [
           "Syntax Results"
          ],
          [
           "Impact of Translation Unit on Learning Syntax"
          ],
          [
           "Effect of Network Depth"
          ],
          [
           "Analysis"
          ],
          [
           "Effect of Relation Type"
          ],
          [
           "Effect of Relation Distance"
          ],
          [
           "Semantics Results"
          ],
          [
           "Impact of Translation Unit on Learning Semantics"
          ],
          [
           "Effect of Network Depth"
          ],
          [
           "Analysis of Lexical Semantics"
          ],
          [
           "Semantic Tag Level Analysis"
          ],
          [
           "Analyzing Discourse Relations"
          ],
          [
           "Effect of Target Language"
          ],
          [
           "Analysis of Semantic Dependencies"
          ],
          [
           "Comparison Against Multilingual Models"
          ],
          [
           "Discussion"
          ],
          [
           "Assessing Representation Quality"
          ],
          [
           "Contextualized Word Representations"
          ],
          [
           "On the Impact of Language Representation on Translation Output"
          ],
          [
           "Why Analyze?"
          ],
          [
           "Other NMT Architectures"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Character-based Models"
          ],
          [
           "Effect of Target Language"
          ],
          [
           "Three Layered Character-based Models"
          ],
          [
           "Layer-wise Experiments Using CCG Tags"
          ],
          [
           "Statistical Significance Results"
          ],
          [
           "MLE-guided parameter search for task loss minimization in neural\n  sequence modeling"
          ],
          [
           "Abstract  Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses."
          ],
          [
           "Introduction"
          ],
          [
           "Sequence generation."
          ],
          [
           "Method."
          ],
          [
           "Comparison with policy gradient."
          ],
          [
           "Comparison with minimum risk training."
          ],
          [
           "Pooled task losses."
          ],
          [
           "Sequence-level training for NLP."
          ],
          [
           "Drawbacks of MLE in NLP."
          ],
          [
           "Black-box optimization."
          ],
          [
           "Text Completion with GPT-2"
          ],
          [
           "Experimental setup."
          ],
          [
           "Task losses."
          ],
          [
           "Metrics."
          ],
          [
           "Effect on sequence-level task loss."
          ],
          [
           "PG & MRT comparison."
          ],
          [
           "MGS candidate analysis."
          ],
          [
           "Experimental setup."
          ],
          [
           "Results."
          ],
          [
           "Conclusion"
          ],
          [
           "Broader Impact"
          ],
          [
           "Self-normalized Importance Sampling"
          ],
          [
           "Minimum risk gradient."
          ],
          [
           "Computation."
          ],
          [
           "Text completion."
          ],
          [
           "Machine translation."
          ],
          [
           "Text completion."
          ],
          [
           "A Panoramic Survey of Natural Language Processing in the Arab World"
          ],
          [
           "Abstract  The term natural language refers to any system of symbolic communication (spoken, signed or written) without intentional human planning and design."
          ],
          [
           "Natural Language and its Processing"
          ],
          [
           "Arabic and its Challenges"
          ],
          [
           "Morphological Richness"
          ],
          [
           "Orthographic Ambiguity"
          ],
          [
           "Dialectal Variation"
          ],
          [
           "Orthographic Inconsistency"
          ],
          [
           "Resource Poverty"
          ],
          [
           "A Brief History of NLP in the Arab World"
          ],
          [
           "Arabic Tools and Resources"
          ],
          [
           "Corpora and Lexical Resources"
          ],
          [
           "Corpora"
          ],
          [
           "Lexical Resources"
          ],
          [
           "Morphological Processing"
          ],
          [
           "Syntactic Processing"
          ],
          [
           "Named Entity Recognition"
          ],
          [
           "Dialect Identification"
          ],
          [
           "Infrastructure"
          ],
          [
           "Machine Translation"
          ],
          [
           "Pedagogical Applications"
          ],
          [
           "Information Retrieval and Question Answering"
          ],
          [
           "Dialogue Systems"
          ],
          [
           "Sentiment and Emotion Analysis"
          ],
          [
           "Content Moderation on Social Media"
          ],
          [
           "Future Outlook"
          ],
          [
           "Modeling Local Dependence in Natural Language with Multi-channel\n  Recurrent Neural Networks"
          ],
          [
           "Abstract  Recurrent Neural Networks (RNNs) have been widely used in processing natural language tasks and achieve huge success."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Model Description"
          ],
          [
           "Capturing Rich Patterns with Multiple Channels"
          ],
          [
           "Aggregating Patterns by an Attention Module"
          ],
          [
           "Experiments"
          ],
          [
           "Experimental Setups"
          ],
          [
           "Experimental Results"
          ],
          [
           "Experimental Setups"
          ],
          [
           "Experimental Results"
          ],
          [
           "Experimental Setups"
          ],
          [
           "Experimental Results"
          ],
          [
           "Analysis"
          ],
          [
           "Case Studies and Visualization"
          ],
          [
           "Performance on Long Sentences"
          ],
          [
           "Impact of Model Size and Time Cost"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Improving Word Embedding Factorization for Compression Using Distilled\n  Nonlinear Neural Decomposition"
          ],
          [
           "Abstract  Word-embeddings are vital components of Natural Language Processing (NLP) models and have been extensively explored."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Low-rank Factorization"
          ],
          [
           "GroupReduce"
          ],
          [
           "Product Quantization"
          ],
          [
           "Tensor Decomposition"
          ],
          [
           "Knowledge Distillation"
          ],
          [
           "Funneling Decomposition and Embedding Distillation"
          ],
          [
           "Datasets and Evaluation"
          ],
          [
           "Hyper-Parameters"
          ],
          [
           "Hardware Details"
          ],
          [
           "Machine Translation"
          ],
          [
           "Ablation Study"
          ],
          [
           "Initialization"
          ],
          [
           "Embedding Distillation"
          ],
          [
           "Compression Rate"
          ],
          [
           "Re-training"
          ],
          [
           "Extension"
          ],
          [
           "Importance of Non-linearity"
          ],
          [
           "Importance Reconstruction Loss"
          ],
          [
           "Conclusion and future work"
          ],
          [
           "WMT En-Fr"
          ],
          [
           "WMT En-De"
          ],
          [
           "IWSLT Pt-En"
          ],
          [
           "Stabilizing Transformers for Reinforcement Learning"
          ],
          [
           "Abstract  Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP), achieving state-of-the-art results in domains such as language modeling and machine translation."
          ],
          [
           "Introduction"
          ],
          [
           "Transformer Architecture and Variants"
          ],
          [
           "Gated Transformer Architectures"
          ],
          [
           "Identity Map Reordering"
          ],
          [
           "Gating Layers"
          ],
          [
           "Experiments"
          ],
          [
           "Transformer as Effective RL Memory Architecture"
          ],
          [
           "Scaling with Memory Horizon"
          ],
          [
           "Gating Variants + Identity Map Reordering"
          ],
          [
           "Performance Ablation"
          ],
          [
           "Hyperparameter and Seed Sensitivity"
          ],
          [
           "Parameter Count-Controlled Comparisons"
          ],
          [
           "Gated Identity Initialization Ablation"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Environment Details"
          ],
          [
           "Experimental details"
          ],
          [
           "Training setup"
          ],
          [
           "Multi-Head Attention"
          ],
          [
           "Relative Multi-Head Attention"
          ],
          [
           "Identity Map Reordering"
          ],
          [
           "PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation"
          ],
          [
           "Abstract  Chinese word segmentation (CWS) is a fundamental step of Chinese natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           " Implementation"
          ],
          [
           "Conditional Random Field"
          ],
          [
           "ADF Algorithm"
          ],
          [
           "Pre-training"
          ],
          [
           "A Large-Scale Vocabulary"
          ],
          [
           "Usage"
          ],
          [
           "Installation"
          ],
          [
           "Segmentation"
          ],
          [
           "Domain-specific Segmentation"
          ],
          [
           "Experiment"
          ],
          [
           "MSRA & PKU."
          ],
          [
           "CTB8."
          ],
          [
           "Weibo."
          ],
          [
           "Medicine & News & Tourism."
          ],
          [
           "Out-of-domain Results"
          ],
          [
           "Pre-training Results"
          ],
          [
           "Default Performance"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Considerations for meaningful sign language machine translation based on\n  glosses"
          ],
          [
           "Abstract  Automatic sign language processing is gaining popularity in Natural Language Processing (NLP) research (Yin et al., 2021)."
          ],
          [
           "Introduction"
          ],
          [
           "Related work"
          ],
          [
           "Awareness of limitations of gloss approach"
          ],
          [
           "Choice of dataset"
          ],
          [
           "Glossing"
          ],
          [
           "Live interpretation and translationese effects"
          ],
          [
           "Preprocessing of spoken language"
          ],
          [
           "Evaluation"
          ],
          [
           "Non-standard metrics"
          ],
          [
           "Tokenization"
          ],
          [
           "Spurious gains"
          ],
          [
           "Further observations"
          ],
          [
           "Preprocessing glosses"
          ],
          [
           "Modeling and training decisions"
          ],
          [
           "Limitations of sentence-level systems"
          ],
          [
           "Recommendations for gloss translation"
          ],
          [
           "Conclusion"
          ],
          [
           "Data licensing"
          ],
          [
           "Impact of internal tokenization when computing BLEU on gloss sequences"
          ],
          [
           "Example for corpus-specific gloss preprocessing"
          ],
          [
           "The first large scale collection of diverse Hausa language datasets"
          ],
          [
           "Abstract  Hausa language belongs to the Afroasiatic phylum, and with more first-language speakers than any other sub-Saharan African language."
          ],
          [
           "Introduction"
          ],
          [
           "Contributions"
          ],
          [
           "Existing Corpus"
          ],
          [
           "Language Models"
          ],
          [
           "Downstream tasks in low resource languages"
          ],
          [
           "Datasets"
          ],
          [
           "Social Stream Category"
          ],
          [
           "Getting the hydrated tweets"
          ],
          [
           "Website and Blog Category"
          ],
          [
           "Parallel Data"
          ],
          [
           "Preprocessing and meta-analysis"
          ],
          [
           "Preprocessing"
          ],
          [
           "Meta-analysis"
          ],
          [
           "Utility of the datasets"
          ],
          [
           "Conclusion"
          ],
          [
           "Future work"
          ],
          [
           "Appendix"
          ],
          [
           "Embedding-Enhanced Giza++: Improving Alignment in Low- and High-\n  Resource Scenarios Using Embedding Space Geometry"
          ],
          [
           "Abstract  A popular natural language processing task decades ago, word alignment has been dominated until recently by GIZA++, a statistical method based on the 30-year-old IBM models."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Alignment Task"
          ],
          [
           "Giza++"
          ],
          [
           "Monolingual Embedding Space Mapping"
          ],
          [
           "Cross-domain similarity local scaling"
          ],
          [
           "Method"
          ],
          [
           "Word Embedding Space Mapping"
          ],
          [
           "Geometrically-Aware Translation Probability Distribution"
          ],
          [
           "Integration with Giza++"
          ],
          [
           "Symmetrization & Alignment Extraction"
          ],
          [
           "Data"
          ],
          [
           "Performance in Low-Resource Scenarios"
          ],
          [
           "Comparison to the Literature in High-Resource Scenarios"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Style-transfer and Paraphrase: Looking for a Sensible Semantic\n  Similarity Metric"
          ],
          [
           "Abstract  The rapid development of such natural language processing tasks as style transfer, paraphrase, and machine translation often calls for the use of semantic similarity metrics."
          ],
          [
           "Introduction"
          ],
          [
           "Measuring semantic preservation"
          ],
          [
           "Data"
          ],
          [
           "Assessment"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Evolving Attention with Residual Convolutions"
          ],
          [
           "Abstract  Transformer is a ubiquitous model for natural language processing and has attracted wide attentions in computer vision."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Overview"
          ],
          [
           "Attention Map Generation"
          ],
          [
           "Attention Map Convolution"
          ],
          [
           "Value Projection and Feed-Forward Layers"
          ],
          [
           "Convolution for Decoders"
          ],
          [
           "Image Classification"
          ],
          [
           "Natural Language Understanding"
          ],
          [
           "Machine Translation"
          ],
          [
           "Quality of Attention Maps"
          ],
          [
           "Interpretability"
          ],
          [
           "Learning Curve Comparison"
          ],
          [
           "Conclusion"
          ],
          [
           "Image classification"
          ],
          [
           "Natural language understanding"
          ],
          [
           "Machine Translation"
          ],
          [
           "Quality of Image Attention"
          ],
          [
           "Interpretability"
          ],
          [
           "Case Study"
          ],
          [
           "Image attention"
          ],
          [
           "Text Attention"
          ],
          [
           "Pre-training Polish Transformer-based Language Models at Scale"
          ],
          [
           "Abstract  Transformer-based language models are now widely used in Natural Language Processing (NLP)."
          ],
          [
           "Introduction"
          ],
          [
           "Language-specific and multilingual transformer-based models"
          ],
          [
           "Contributions"
          ],
          [
           "Language model pre-training"
          ],
          [
           "Training corpus"
          ],
          [
           "Training procedure"
          ],
          [
           "Evaluation"
          ],
          [
           "Task descriptions"
          ],
          [
           "Task-specific fine-tuning"
          ],
          [
           "Results and discussion"
          ],
          [
           "Conclusions"
          ],
          [
           "Top-Rank Enhanced Listwise Optimization for Statistical Machine\n  Translation"
          ],
          [
           "Abstract  Pairwise ranking methods are the basis of many widely used discriminative training approaches for structure prediction problems in natural language processing(NLP)."
          ],
          [
           "Introduction"
          ],
          [
           "Log-linear models"
          ],
          [
           "SMT Features"
          ],
          [
           "Tuning via Pairwise Ranking"
          ],
          [
           "Listwise Learning Framework"
          ],
          [
           "The Permutation Probability Model"
          ],
          [
           "Loss Functions"
          ],
          [
           "Training with Instance Aggregating"
          ],
          [
           "Top-Rank Enhanced Losses"
          ],
          [
           "Data and Preparation"
          ],
          [
           "Tuning Settings"
          ],
          [
           "Experiments of Listwise Learning Framework"
          ],
          [
           "Effect of Top-rank Enhanced Losses"
          ],
          [
           "Impact of the Size of Candidate Lists"
          ],
          [
           "Performance on Basic Feature Set"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "An Exploratory Study on Utilising the Web of Linked Data for Product\n  Data Mining"
          ],
          [
           "Abstract  The Linked Open Data practice has led to a significant growth of structured data on the Web in the last decade."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Semantic markup data as language resources"
          ],
          [
           "Product classification"
          ],
          [
           "Product linking"
          ],
          [
           "Entity classification and linking using LOD"
          ],
          [
           "Reflection"
          ],
          [
           "Methodology"
          ],
          [
           "Data sources"
          ],
          [
           "Building language resources for product data mining"
          ],
          [
           "Training word embedding models"
          ],
          [
           "Continued Pre-training of BERT language models"
          ],
          [
           "Training machine translation models"
          ],
          [
           "Product classification"
          ],
          [
           "Product linking"
          ],
          [
           "Experiment"
          ],
          [
           "Product classification"
          ],
          [
           "Product linking"
          ],
          [
           "Product classification"
          ],
          [
           "Product linking"
          ],
          [
           "Results"
          ],
          [
           "Product classification results"
          ],
          [
           "Product linking results"
          ],
          [
           "Discussion and analysis"
          ],
          [
           "Data provenance"
          ],
          [
           "Vocabulary coverage"
          ],
          [
           "Product keywords analysis"
          ],
          [
           "Algorithmic considerations"
          ],
          [
           "Conclusion"
          ],
          [
           "Product classification: word frequency analysis for word embedding model training"
          ],
          [
           "No More Fine-Tuning? An Experimental Evaluation of Prompt Tuning in Code\n  Intelligence"
          ],
          [
           "Abstract  Pre-trained models have been shown effective in many code intelligence tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Prompt Tuning"
          ],
          [
           "Hard Prompt"
          ],
          [
           "Soft Prompt"
          ],
          [
           "Research Questions"
          ],
          [
           "Code Intelligence Tasks with Prompt Tuning"
          ],
          [
           "Pre-trained Models"
          ],
          [
           "Defect Detection"
          ],
          [
           "Code summarization"
          ],
          [
           "Code Translation"
          ],
          [
           "Evaluation Datasets"
          ],
          [
           "Defect Detection"
          ],
          [
           "Code Summarization"
          ],
          [
           "Code translation"
          ],
          [
           "Defect Detection:"
          ],
          [
           "Code Summarization:"
          ],
          [
           "Code Translation:"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Fine-tuning Baselines"
          ],
          [
           "RQ1: Effectiveness of Prompt Tuning"
          ],
          [
           "RQ2: Capability of Prompt Tuning in Different Data Scarcity Scenarios"
          ],
          [
           "RQ3: Impact of Different Prompts"
          ],
          [
           "Different Hard Prompt Templates."
          ],
          [
           "Hard Prompt vs. Vanilla Soft Prompt."
          ],
          [
           "Different Lengths of Prefix Soft Prompts."
          ],
          [
           "Implication on the Utilization of Pre-trained Models"
          ],
          [
           "Implication on the Utilization of Prompts"
          ],
          [
           "Future Directions"
          ],
          [
           "Threats To Validity"
          ],
          [
           "Pre-training on Programming language"
          ],
          [
           "Prompt Tuning"
          ],
          [
           "Conclusion"
          ],
          [
           "GERNERMED -- An Open German Medical NER Model"
          ],
          [
           "Abstract  The current state of adoption of well-structured electronic health records and integration of digital methods for storing medical patient data in structured formats can often considered as inferior compared to the use of traditional, unstructured text based patient data documentation."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Custom Dataset Creation"
          ],
          [
           "NLP Model for NER Training"
          ],
          [
           "Custom Dataset Creation"
          ],
          [
           "NLP Model for NER Training"
          ],
          [
           "Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgment"
          ],
          [
           "On the Explainability of Natural Language Processing Deep Models"
          ],
          [
           "Abstract  While there has been a recent explosion of work on ExplainableAI ExAI on deep models that operate on imagery and tabular data, textual datasets present new challenges to the ExAI community."
          ],
          [
           "Introduction"
          ],
          [
           "Challenges in ExAI on NLP Models"
          ],
          [
           "Related Surveys"
          ],
          [
           "Terminology"
          ],
          [
           "Interpreting Word Embeddings"
          ],
          [
           "Sparsification of Embedding Spaces"
          ],
          [
           "Rotation of Embedding Spaces"
          ],
          [
           "Integrating External Knowledge"
          ],
          [
           "Contextualized Embeddings"
          ],
          [
           "Evaluating Embeddings Interpretability"
          ],
          [
           "Discussion"
          ],
          [
           "Most of the post-hoc interpretation methods try to dissect hidden knowledge in trained deep networks from syntax and semantic lens."
          ],
          [
           "Inherently interpretable RNNs are trained in an explainable way by adding transparency constraints [118] and exploring tree and graph-like structures [106], [59]."
          ],
          [
           "Discussion"
          ],
          [
           "What do Transformers Learn?"
          ],
          [
           "Visualization of Transformers"
          ],
          [
           "Is the Attention Mechanism "
          ],
          [
           "Interpretability of BERT"
          ],
          [
           "Discussion"
          ],
          [
           "Explaining Model's Decisions"
          ],
          [
           "These methods, consider a pre-trained model and analyze how such a model process a textual input before producing a decision."
          ],
          [
           "Instead of considering black-box models, Kádár et al."
          ],
          [
           "As an extension to the previously discussed “rationalization” attempts [124], [125], Lei et al."
          ],
          [
           "Liu et al."
          ],
          [
           "Discussion"
          ],
          [
           "Discussion and Future Directions"
          ],
          [
           "Conclusion"
          ],
          [
           "Mapping Supervised Bilingual Word Embeddings from English to\n  low-resource languages"
          ],
          [
           "Abstract  It is very challenging to work with low-resource languages due to the inadequate availability of data."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Method"
          ],
          [
           "Experiment"
          ],
          [
           "Data"
          ],
          [
           "Preprocessing"
          ],
          [
           "Word Embeddings"
          ],
          [
           "Translation"
          ],
          [
           "Training and testing"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Future Work"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Exploiting Linguistic Resources for Neural Machine Translation Using\n  Multi-task Learning"
          ],
          [
           "Abstract  Linguistic resources such as part-of-speech (POS) tags have been extensively used in statistical machine translation (SMT) frameworks and have yielded better performances."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Attention Models"
          ],
          [
           "Multi-task Learning"
          ],
          [
           "Architecture"
          ],
          [
           "Shared encoder "
          ],
          [
           "Shared attention "
          ],
          [
           "Shared decoder "
          ],
          [
           "Training Schedule"
          ],
          [
           "Target Length"
          ],
          [
           "Experimental Setup"
          ],
          [
           "Data"
          ],
          [
           "System Architecture"
          ],
          [
           "Evaluation"
          ],
          [
           "Results"
          ],
          [
           "Initial experiments on the architecture"
          ],
          [
           "Impact of design decisions"
          ],
          [
           "POS Tagging Performance"
          ],
          [
           "Analysis and Examples"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "Towards Making the Most of BERT in Neural Machine Translation"
          ],
          [
           "Abstract  GPT-2 and BERT demonstrate the effectiveness of using pre-trained language models (LMs) on various natural language processing tasks."
          ],
          [
           "Introduction"
          ],
          [
           "The Proposed "
          ],
          [
           "Background"
          ],
          [
           "Asymptotic Distillation"
          ],
          [
           "Dynamic Switch"
          ],
          [
           "Rate-scheduled learning"
          ],
          [
           "Datasets"
          ],
          [
           "Training details"
          ],
          [
           "Results and Analysis"
          ],
          [
           "Encoder v.s. Decoder"
          ],
          [
           "BERT v.s. GPT-2"
          ],
          [
           "About asymptotic distillation"
          ],
          [
           "About dynamic switch"
          ],
          [
           "About rate-scheduled learning"
          ],
          [
           "About BERT layers"
          ],
          [
           "Unsupervised pre-training of LMs"
          ],
          [
           "Pre-training for NMT"
          ],
          [
           "Conclusion"
          ],
          [
           "Gamified Crowdsourcing for Idiom Corpora Construction"
          ],
          [
           "Abstract  Learning idiomatic expressions is seen as one of the most challenging stages in second language learning because of their unpredictable meaning."
          ],
          [
           "Introduction"
          ],
          [
           "Background & Related Work"
          ],
          [
           "Game Design"
          ],
          [
           "Main Interactions and Gameplay"
          ],
          [
           "Gamification affordances & Additional incentives"
          ],
          [
           "Game implementation"
          ],
          [
           "Analysis & Discussions"
          ],
          [
           "Methodology & Participants"
          ],
          [
           "Data Analysis"
          ],
          [
           "Comparison with Parseme Annotations"
          ],
          [
           "Motivational & Behavioral Outcomes"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "BERT(s) to Detect Multiword Expressions"
          ],
          [
           "Abstract  Multiword expressions (MWEs) present groups of words in which the meaning of the whole is not derived from the meaning of its parts."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Data"
          ],
          [
           "Methodology"
          ],
          [
           "Transformer"
          ],
          [
           "BiLSTM-CRF"
          ],
          [
           "Results"
          ],
          [
           "Conclusion"
          ],
          [
           "Few-Shot Learning for Clinical Natural Language Processing Using Siamese\n  Neural Networks"
          ],
          [
           "Abstract  Clinical Natural Language Processing (NLP) has become an emerging technology in healthcare that leverages a large amount of free-text data in electronic health records (EHRs) to improve patient care, support clinical decisions, and facilitate clinical and translational science research."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "SNN-Based Models"
          ],
          [
           "Model Architecture"
          ],
          [
           "Pre-trained SNN (PT-SNN)"
          ],
          [
           "SNN With Second-Order Embeddings (SOE-SNN)"
          ],
          [
           "Text Embeddings"
          ],
          [
           "Sentence-Level Embeddings"
          ],
          [
           "Word-Level Embeddings"
          ],
          [
           "FSL Model Evaluation"
          ],
          [
           "Baseline Models"
          ],
          [
           "Classification Tasks and Datasets"
          ],
          [
           "2006 i2b2 De-Identification Challenge Dataset"
          ],
          [
           "Few-Shot Clinical Text Classification"
          ],
          [
           "Few-Shot Clinical Named Entity Recognition"
          ],
          [
           "Limitations and Future Work"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Convolution-enhanced Evolving Attention Networks"
          ],
          [
           "Abstract  Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Convolution-enhanced Evolving Attention Networks"
          ],
          [
           "The Evolving Attention Mechanism"
          ],
          [
           "Evolving Attention Transformer"
          ],
          [
           "Evolving Attention-enhanced Dilated Convolutional Transformer for Time-Series Representation"
          ],
          [
           "Network Architecture"
          ],
          [
           "Optimization"
          ],
          [
           "Extension to other Attention Networks"
          ],
          [
           "Time-Series Representation"
          ],
          [
           "Natural Language Understanding"
          ],
          [
           "Machine Translation"
          ],
          [
           "Image Classification"
          ],
          [
           "Learned Representations"
          ],
          [
           "Quality of Attention Maps"
          ],
          [
           "Interpretability"
          ],
          [
           "Learning Curve Comparison"
          ],
          [
           "Case Study"
          ],
          [
           "Hyper-parameter Analysis"
          ],
          [
           "Limitations"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgment"
          ],
          [
           "Dynamic Context-guided Capsule Network for Multimodal Machine\n  Translation"
          ],
          [
           "Abstract  Multimodal machine translation (MMT), which mainly focuses on enhancing text-only translation with visual features, has attracted considerable attention from both computer vision and natural language processing communities."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Our Model"
          ],
          [
           "Encoder"
          ],
          [
           "Decoder"
          ],
          [
           "Visual Features"
          ],
          [
           "Dynamic Context-guided Capsule Network"
          ],
          [
           "Dataset"
          ],
          [
           "Setup"
          ],
          [
           "Baselines"
          ],
          [
           "Results on the EN$\\Rightarrow $ DE Translation Task."
          ],
          [
           "Ablation Study"
          ],
          [
           "Case Study"
          ],
          [
           "Results on the EN$\\Rightarrow $ FR Translation Task"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgments"
          ],
          [
           "IOT: Instance-wise Layer Reordering for Transformer Structures"
          ],
          [
           "Abstract  With sequentially stacked self-attention, (optional) encoder-decoder attention, and feed-forward layers, Transformer achieves big success in natural language processing (NLP), and many variants have been proposed."
          ],
          [
           "Introduction"
          ],
          [
           "Related Work"
          ],
          [
           "Instance-wise Ordered Transformer"
          ],
          [
           "Instance-wise Encoder/Decoder"
          ],
          [
           "Auxiliary Losses"
          ],
          [
           "Experiments"
          ],
          [
           "Dataset"
          ],
          [
           "Model and Optimization"
          ],
          [
           "Evaluation"
          ],
          [
           "Main Results"
          ],
          [
           "Inference/Training Cost"
          ],
          [
           "Case Verification"
          ],
          [
           "Apply on Another Structure (DynamicConv)"
          ],
          [
           "Discussions"
          ],
          [
           "Conclusion"
          ],
          [
           "Detailed Data Settings"
          ],
          [
           "Detailed Model/Training Configurations"
          ],
          [
           "Results of Order Combinations"
          ],
          [
           "Results of Different Number of Decoders"
          ],
          [
           "Impact of Weighted Auxiliary Losses"
          ],
          [
           "Data Examples Verification"
          ],
          [
           "Regularization"
          ],
          [
           "Robustness"
          ],
          [
           "Visualization"
          ],
          [
           "A Combined CNN and LSTM Model for Arabic Sentiment Analysis"
          ],
          [
           "Abstract  Deep neural networks have shown good data modelling capabilities when dealing with challenging and large datasets from a wide range of application areas."
          ],
          [
           "1. Introduction"
          ],
          [
           "2. Background and Related Work"
          ],
          [
           "3. Datasets"
          ],
          [
           "Arabic Health Services Dataset (Main-AHS and Sub-AHS)"
          ],
          [
           "Twitter Data Set (Ar-Twitter)"
          ],
          [
           "Arabic Sentiment Tweets Dataset (ASTD)"
          ],
          [
           "3. CNN-LSTM Arabic Sentiment Analysis Model"
          ],
          [
           "Input Layer"
          ],
          [
           "Convolutional Layer"
          ],
          [
           "Max-Pooling Layer"
          ],
          [
           "LSTM Layer"
          ],
          [
           "Fully Connected Layer"
          ],
          [
           "6. Conclusions and Future Work"
          ],
          [
           "XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning"
          ],
          [
           "Abstract  In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects."
          ],
          [
           "Introduction"
          ],
          [
           "Annotation Design"
          ],
          [
           "Qualitative Analysis"
          ],
          [
           "Experiments and Results"
          ],
          [
           "Baselines"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Adversarial Variants"
          ],
          [
           "Adaptation to Unseen Languages"
          ],
          [
           "Related Work"
          ],
          [
           "Conclusion and Future Work"
          ],
          [
           "Acknowledgements"
          ],
          [
           "Detailed Translation Guidelines"
          ],
          [
           "Why is Grammatical Tense Problematic for XCOPA?"
          ],
          [
           "Hyper-Parameter Search"
          ],
          [
           "Full Results (Per Language)"
          ],
          [
           "Code and Dependencies"
          ],
          [
           "ESPnet-SLU: Advancing Spoken Language Understanding through ESPnet"
          ],
          [
           "Abstract  As Automatic Speech Processing (ASR) systems are getting better, there is an increasing interest of using the ASR output to do downstream Natural Language Processing (NLP) tasks."
          ],
          [
           "Introduction"
          ],
          [
           "Design"
          ],
          [
           "Example Models"
          ],
          [
           "Experiments"
          ],
          [
           "Intent Classification (IC) and Slot Filling (SF)"
          ],
          [
           "Emotion Recognition (ER)"
          ],
          [
           "Dialogue Act Classification (DA)"
          ],
          [
           "Noisy Intent Classification (IC) with Speech Enhancement"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ],
          [
           "References"
          ],
          [
           "A Subword Level Language Model for Bangla Language"
          ],
          [
           "Abstract  Language models are at the core of natural language processing."
          ],
          [
           "Introduction"
          ],
          [
           "On Language Models"
          ],
          [
           "Count-based language models"
          ],
          [
           "Continuous-space language models"
          ],
          [
           "On Neural Network Architectures"
          ],
          [
           "On Training Neural Networks"
          ],
          [
           "Corpus"
          ],
          [
           "Proposed Architecture"
          ],
          [
           "Subword Tokenization"
          ],
          [
           "Training the language model"
          ],
          [
           "Experiments"
          ],
          [
           "Bi-gram language model"
          ],
          [
           "LSTM and CNN language models"
          ],
          [
           "AWD-LSTM word-level language model"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgement"
          ],
          [
           "Parallelizing Word2Vec in Shared and Distributed Memory"
          ],
          [
           "Abstract  Word2Vec is a widely used algorithm for extracting low-dimensional vector representations of words."
          ],
          [
           "Introduction"
          ],
          [
           "The Word2Vec Model"
          ],
          [
           "Word2vec Algorithm and improvements"
          ],
          [
           "Latent Alignment and Variational Attention"
          ],
          [
           "Abstract  Neural attention has become central to many state-of-the-art models in natural language processing and related domains."
          ],
          [
           "Introduction"
          ],
          [
           "Background: Latent Alignment and Neural Attention"
          ],
          [
           "Latent Alignment"
          ],
          [
           "Attention Models: Soft and Hard"
          ],
          [
           "Soft Attention"
          ],
          [
           "Hard Attention"
          ],
          [
           "Variational Attention for Latent Alignment Models"
          ],
          [
           "Algorithm 1: Categorical Alignments"
          ],
          [
           "Algorithm 2: Relaxed Alignments"
          ],
          [
           "Models and Methods"
          ],
          [
           "Neural Machine Translation"
          ],
          [
           "Visual Question Answering"
          ],
          [
           "Inference Alternatives"
          ],
          [
           "Predictive Inference"
          ],
          [
           "Setup"
          ],
          [
           "Results and Discussion"
          ],
          [
           "Potential Limitations"
          ],
          [
           "Conclusion"
          ],
          [
           "Acknowledgements"
          ]
         ],
         "hovertemplate": "type=Academic<br>x=%{x}<br>y=%{y}<br>section_name=%{customdata[0]}<extra></extra>",
         "legendgroup": "Academic",
         "marker": {
          "color": "#4ECDC4",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Academic",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -13.835834503173828,
          -21.271177291870117,
          14.359872817993164,
          -20.0672550201416,
          -3.3644797801971436,
          5.634024620056152,
          46.30269241333008,
          -29.17262840270996,
          -21.83378028869629,
          -46.71633529663086,
          28.984375,
          28.59190559387207,
          13.528094291687012,
          13.769549369812012,
          35.41350555419922,
          7.508463382720947,
          4.418471336364746,
          4.2760090827941895,
          4.284657955169678,
          42.37507247924805,
          5.0176100730896,
          -21.015361785888672,
          12.592622756958008,
          29.819246292114258,
          -12.561588287353516,
          4.855686187744141,
          6.353969573974609,
          -57.2408561706543,
          -54.63146209716797,
          23.020008087158203,
          21.660358428955078,
          16.476402282714844,
          -18.264694213867188,
          -26.600187301635742,
          19.13536262512207,
          17.371814727783203,
          44.397891998291016,
          42.445396423339844,
          -35.2714729309082,
          -59.17958450317383,
          -53.7535285949707,
          -1.2974342107772827,
          20.21666717529297,
          17.093481063842773,
          10.907774925231934,
          -17.343669891357422,
          -27.047651290893555,
          -27.04220962524414,
          1.3799070119857788,
          1.2375261783599854,
          22.374759674072266,
          -23.075477600097656,
          -18.233415603637695,
          -19.478012084960938,
          -23.09125328063965,
          -11.023778915405273,
          -27.21847152709961,
          -19.509305953979492,
          -17.67637062072754,
          -27.217952728271484,
          -17.042924880981445,
          -8.502350807189941,
          -17.585050582885742,
          13.63476848602295,
          -12.875697135925293,
          -18.035398483276367,
          -5.964513778686523,
          -16.453372955322266,
          28.300655364990234,
          -0.6399818658828735,
          10.901971817016602,
          23.70590591430664,
          -17.343669891357422,
          -47.22688293457031,
          1.4723436832427979,
          8.821211814880371,
          3.949709415435791,
          -13.751444816589355,
          34.588558197021484,
          -17.89854621887207,
          -12.546051979064941,
          -8.888867378234863,
          15.715624809265137,
          -20.951887130737305,
          13.668058395385742,
          21.3604736328125,
          -5.465769290924072,
          41.81105422973633,
          -37.23435974121094,
          2.2596893310546875,
          -4.110325813293457,
          -47.972450256347656,
          -36.41200256347656,
          14.205385208129883,
          -3.1682043075561523,
          16.190853118896484,
          31.24986457824707,
          -27.555910110473633,
          30.98880386352539,
          30.72797393798828,
          29.72201156616211,
          29.67795753479004,
          29.698810577392578,
          30.620014190673828,
          39.460880279541016,
          30.45265007019043,
          0.6195520758628845,
          35.136863708496094,
          30.384401321411133,
          -17.506763458251953,
          47.72180938720703,
          -23.325334548950195,
          -24.488149642944336,
          -26.93300437927246,
          -27.3681583404541,
          15.096136093139648,
          -29.172452926635742,
          30.279199600219727,
          28.772018432617188,
          32.06988525390625,
          30.74180030822754,
          28.837617874145508,
          29.78643035888672,
          8.511001586914062,
          -1.276353120803833,
          30.88022804260254,
          -46.930419921875,
          -55.75393295288086,
          -31.333499908447266,
          28.854930877685547,
          1.2873966693878174,
          -31.536081314086914,
          -29.99149513244629,
          4.433635234832764,
          -31.894060134887695,
          -32.074241638183594,
          -37.12991714477539,
          31.567604064941406,
          -38.49714279174805,
          -37.130802154541016,
          13.491589546203613,
          48.53550720214844,
          6.9042510986328125,
          34.527976989746094,
          4.653219223022461,
          -23.33518409729004,
          -31.465532302856445,
          -5.234083652496338,
          4.705292701721191,
          -55.67563247680664,
          39.63456726074219,
          20.358522415161133,
          39.24796676635742,
          39.50355911254883,
          -4.3920111656188965,
          -6.54495096206665,
          -4.392011642456055,
          -6.545045852661133,
          39.62129592895508,
          -47.81416320800781,
          5.464639186859131,
          6.167981147766113,
          0.698822021484375,
          17.356658935546875,
          17.3629093170166,
          17.36341094970703,
          -38.943233489990234,
          -17.50821304321289,
          -8.320903778076172,
          -7.219079494476318,
          -2.7270054817199707,
          -56.24153137207031,
          -53.83548355102539,
          -28.93111801147461,
          -28.740461349487305,
          15.674108505249023,
          -25.04717445373535,
          -27.39289665222168,
          -28.04383659362793,
          -31.06633758544922,
          10.91193962097168,
          10.911931991577148,
          11.07327651977539,
          -19.801103591918945,
          -18.04503631591797,
          -12.626797676086426,
          -19.946163177490234,
          16.095979690551758,
          -29.4598331451416,
          -22.873376846313477,
          13.492076873779297,
          13.494372367858887,
          12.095768928527832,
          0.6327500343322754,
          -31.036867141723633,
          47.472503662109375,
          40.411231994628906,
          17.717355728149414,
          -20.11772918701172,
          -45.843326568603516,
          -35.946720123291016,
          10.098397254943848,
          10.098136901855469,
          11.692127227783203,
          -3.3266453742980957,
          29.1011905670166,
          19.576629638671875,
          16.944229125976562,
          -3.1578476428985596,
          -3.0793232917785645,
          43.69981002807617,
          -2.728612184524536,
          9.123427391052246,
          42.975852966308594,
          25.817087173461914,
          1.3853322267532349,
          43.7009391784668,
          25.838726043701172,
          -30.088537216186523,
          -24.39044952392578,
          -24.354358673095703,
          -28.23130226135254,
          -23.228336334228516,
          -59.847415924072266,
          11.349698066711426,
          11.935236930847168,
          14.06860637664795,
          -19.701404571533203,
          25.827089309692383,
          40.21330642700195,
          -27.226224899291992,
          16.890762329101562,
          4.5982255935668945,
          17.78131675720215,
          -20.659687042236328,
          -4.803362846374512,
          -47.71830749511719,
          -24.676725387573242,
          -24.137027740478516,
          15.01382064819336,
          -19.91236114501953,
          5.801113128662109,
          3.9197514057159424,
          23.374622344970703,
          -24.49738121032715,
          -47.32493209838867,
          4.507976531982422,
          -4.078314304351807,
          11.403786659240723,
          -17.944459915161133,
          -4.593732833862305,
          -18.466209411621094,
          -19.10186195373535,
          5.801113128662109,
          -6.651978969573975,
          -13.018136024475098,
          12.848440170288086,
          -4.606535911560059,
          -58.211238861083984,
          -26.707950592041016,
          6.376911640167236,
          6.403805255889893,
          12.458209991455078,
          34.29478073120117,
          1.8532357215881348,
          34.295799255371094,
          8.772733688354492,
          52.80030822753906,
          0.4535307288169861,
          27.922555923461914,
          11.393909454345703,
          20.16608428955078,
          8.76616096496582,
          -47.797733306884766,
          15.333613395690918,
          -35.844459533691406,
          14.772544860839844,
          42.53862762451172,
          26.732868194580078,
          6.213254451751709,
          48.19423294067383,
          47.62618637084961,
          -7.946710109710693,
          -23.139827728271484,
          -3.33642578125,
          -6.882906913757324,
          -39.66386413574219,
          -48.26241683959961,
          -16.700395584106445,
          2.1270036697387695,
          19.228845596313477,
          -48.53137969970703,
          -26.132469177246094,
          -26.258832931518555,
          11.43110179901123,
          22.29836654663086,
          -2.1888790130615234,
          36.393611907958984,
          -6.627065181732178,
          -16.632614135742188,
          37.771854400634766,
          41.02747344970703,
          11.63978385925293,
          41.91637420654297,
          32.28885269165039,
          -3.0492961406707764,
          -20.37689971923828,
          -20.942270278930664,
          -4.151925086975098,
          -23.578588485717773,
          22.33405876159668,
          24.006484985351562,
          -28.77550506591797,
          -20.664222717285156,
          -20.802913665771484,
          -21.691011428833008,
          -21.5794734954834,
          -21.528249740600586,
          22.304725646972656,
          13.668152809143066,
          -22.942171096801758,
          36.50957489013672,
          36.40080261230469,
          38.787986755371094,
          12.85245418548584,
          13.341861724853516,
          -23.140262603759766,
          -23.48035430908203,
          8.471376419067383,
          27.713451385498047,
          -6.265544891357422,
          23.533472061157227,
          44.2041130065918,
          -21.42033576965332,
          36.241546630859375,
          -24.441286087036133,
          -59.05654525756836,
          -37.13983154296875,
          -41.021141052246094,
          -41.1484260559082,
          10.893281936645508,
          -20.844654083251953,
          1.205444097518921,
          3.6951992511749268,
          -19.04212760925293,
          32.644283294677734,
          29.103696823120117,
          37.38179016113281,
          -3.6001672744750977,
          -57.97846221923828,
          -10.035630226135254,
          -8.118890762329102,
          10.451364517211914,
          -10.029258728027344,
          -20.354368209838867,
          -46.7331428527832,
          -44.5328369140625,
          -6.545179843902588,
          -19.571063995361328,
          -6.930001735687256,
          -24.244430541992188,
          -18.844926834106445,
          -5.209487438201904,
          -5.017114162445068,
          -2.0896623134613037,
          -3.8013312816619873,
          14.477310180664062,
          -58.211238861083984,
          -55.04598617553711,
          7.244704723358154,
          -24.036962509155273,
          4.641066551208496,
          3.071493625640869,
          7.546387195587158,
          14.134690284729004,
          -3.701097249984741,
          3.1417338848114014,
          14.312126159667969,
          37.328025817871094,
          -17.334260940551758,
          33.162384033203125,
          31.16162109375,
          10.384149551391602,
          34.50735092163086,
          15.154995918273926,
          24.014217376708984,
          19.203737258911133,
          22.703384399414062,
          15.680294036865234,
          9.376175880432129,
          9.388143539428711,
          -5.61213493347168,
          11.156583786010742,
          -4.63327169418335,
          -4.981470108032227,
          23.219392776489258,
          -13.651524543762207,
          -2.0252108573913574,
          4.584754467010498,
          25.089540481567383,
          -22.829710006713867,
          -46.21957778930664,
          -53.23118209838867,
          -10.10664176940918,
          -0.039504777640104294,
          10.477118492126465,
          -23.1727237701416,
          25.850584030151367,
          -3.202101707458496,
          22.367887496948242,
          6.2570481300354,
          5.751613140106201,
          5.869421005249023,
          2.9685568809509277,
          -22.8842830657959,
          -3.7726895809173584,
          -10.066649436950684,
          21.90028953552246,
          13.315994262695312,
          1.5576027631759644,
          -4.466880798339844,
          -3.3015618324279785,
          22.367218017578125,
          4.345421314239502,
          -22.780061721801758,
          -4.519248962402344,
          -46.60872268676758,
          -36.52114486694336,
          0.8638808131217957,
          -22.771207809448242,
          -13.906426429748535,
          -13.904560089111328,
          12.219274520874023,
          -15.10302734375,
          -11.301997184753418,
          -3.6449830532073975,
          1.226977825164795,
          -2.828777551651001,
          5.1545796394348145,
          0.45287543535232544,
          -22.59067153930664,
          -5.257890224456787,
          44.85693359375,
          6.600528240203857,
          -12.979256629943848,
          -9.520280838012695,
          -13.013614654541016,
          14.405559539794922,
          20.24761199951172,
          -9.955628395080566,
          11.864747047424316,
          11.968753814697266,
          5.071807384490967,
          4.5698628425598145,
          -11.842251777648926,
          -59.38813400268555,
          -2.092637300491333,
          -16.59059715270996,
          5.109989166259766,
          12.026238441467285,
          11.394925117492676,
          -11.821932792663574,
          2.6845521926879883,
          -11.809694290161133,
          -11.41861629486084,
          -10.73764419555664,
          48.153316497802734,
          -52.87474822998047,
          -52.8853759765625,
          -52.88408279418945,
          -3.164456605911255,
          -2.5729010105133057,
          4.923593521118164,
          9.856767654418945,
          7.9999871253967285,
          10.16379165649414,
          10.210208892822266,
          -5.774135589599609,
          -61.138267517089844,
          -52.847042083740234,
          33.17718505859375,
          -16.814363479614258,
          -7.492996692657471,
          -7.565954208374023,
          27.92823028564453,
          21.05031394958496,
          18.25274658203125,
          18.912675857543945,
          -14.646072387695312,
          -45.97417068481445,
          -27.471281051635742,
          25.848068237304688,
          -20.65445327758789,
          -46.608707427978516,
          -55.413631439208984,
          -0.11739441752433777,
          0.054935991764068604,
          17.835399627685547,
          -23.455673217773438,
          -2.5315277576446533,
          44.85667419433594,
          -1.6649720668792725,
          -16.338760375976562,
          -24.27076530456543,
          -16.21232795715332,
          -18.321308135986328,
          22.321758270263672,
          -32.763877868652344,
          -49.08319091796875,
          -35.90812301635742,
          17.041603088378906,
          15.429634094238281,
          14.927592277526855,
          17.140535354614258,
          -16.46146583557129,
          -11.440964698791504,
          11.83627986907959,
          -20.004573822021484,
          12.376879692077637,
          -11.440889358520508,
          -3.9871060848236084,
          -43.6164665222168,
          -18.46108627319336,
          -59.00655746459961,
          30.380775451660156,
          -4.268835067749023,
          15.910032272338867,
          15.98026180267334,
          8.595697402954102,
          35.93967819213867,
          35.5146369934082,
          35.569129943847656,
          35.703731536865234,
          -11.056268692016602,
          32.21602249145508,
          34.92148971557617,
          6.846900463104248,
          38.9917106628418,
          36.59389877319336,
          44.4481201171875,
          -3.930781841278076,
          -8.772177696228027,
          -10.046390533447266,
          -60.10959243774414,
          7.711429119110107,
          7.274087429046631,
          14.466658592224121,
          -19.4360294342041,
          7.553256988525391,
          9.503366470336914,
          15.461518287658691,
          -5.27417516708374,
          5.218263149261475,
          48.465171813964844,
          9.499242782592773,
          7.4370880126953125,
          -17.90749168395996,
          -58.641319274902344,
          -54.74363327026367,
          -6.126917362213135,
          -1.0367554426193237,
          -55.49948501586914,
          -55.49134826660156,
          -1.8620707988739014,
          -8.137609481811523,
          31.272232055664062,
          -35.88954544067383,
          -20.642818450927734,
          4.59429407119751,
          -48.000938415527344,
          5.015925884246826,
          17.726181030273438,
          -7.486933708190918,
          -17.824766159057617,
          -17.8734073638916,
          -15.964075088500977,
          -27.283552169799805,
          -83.22456359863281,
          -24.69163703918457,
          0.4850323498249054,
          -2.9887776374816895,
          11.025592803955078,
          0.4542061686515808,
          52.801387786865234,
          21.05466079711914,
          51.75184631347656,
          51.807735443115234,
          51.64423751831055,
          42.07551193237305,
          -26.321796417236328,
          3.451460838317871,
          -26.321792602539062,
          3.2594146728515625,
          -4.267796516418457,
          20.946393966674805,
          8.084497451782227,
          31.9394588470459,
          -21.09255599975586,
          -46.14775085449219,
          -55.72907638549805,
          -5.628372669219971,
          -4.380166530609131,
          11.1182861328125,
          13.566673278808594,
          -4.549661636352539,
          8.699094772338867,
          20.997177124023438,
          -5.8027567863464355,
          40.21323013305664,
          4.921313285827637,
          31.868473052978516,
          6.062443256378174,
          61.64140701293945,
          -1.9215965270996094,
          -4.456221103668213,
          -7.498573303222656,
          13.566298484802246,
          -4.491363525390625,
          20.997196197509766,
          -46.6618766784668,
          -55.72907638549805,
          -5.484684944152832,
          -6.278293609619141,
          15.782421112060547,
          -6.372483253479004,
          27.582128524780273,
          8.087772369384766,
          -14.628275871276855,
          24.127172470092773,
          10.215302467346191,
          4.4872002601623535,
          47.73910903930664,
          -3.7811925411224365,
          -22.084001541137695,
          -4.262235164642334,
          -49.329471588134766,
          -15.824692726135254,
          -15.473767280578613,
          11.287854194641113,
          -20.025676727294922,
          -14.646283149719238,
          26.30384063720703,
          -3.6913578510284424,
          23.29622459411621,
          -4.20382022857666,
          -21.028697967529297,
          24.18267059326172,
          61.64140701293945,
          -6.883882522583008,
          -58.32750701904297,
          -3.2000279426574707,
          17.717973709106445,
          -18.273263931274414,
          -16.52553367614746,
          22.552627563476562,
          24.625904083251953,
          -43.93871307373047,
          -43.40874099731445,
          10.933377265930176,
          -19.276453018188477,
          -2.9880237579345703,
          -40.20371627807617,
          -40.39110565185547,
          -41.823604583740234,
          -41.84408950805664,
          -45.519954681396484,
          8.009482383728027,
          -34.51294708251953,
          -59.835655212402344,
          14.359439849853516,
          16.21645164489746,
          13.770722389221191,
          14.823904037475586,
          25.87411880493164,
          -7.3387770652771,
          48.27809143066406,
          48.233970642089844,
          -42.15190887451172,
          -41.01477813720703,
          9.920652389526367,
          46.570396423339844,
          42.4456901550293,
          -22.51844024658203,
          -58.51750564575195,
          1.205552101135254,
          31.9041748046875,
          26.398143768310547,
          1.9112496376037598,
          -10.805420875549316,
          4.533337593078613,
          4.447575569152832,
          13.833243370056152,
          -17.54157257080078,
          4.7206525802612305,
          54.922977447509766,
          11.269308090209961,
          -31.9631290435791,
          46.45939254760742,
          40.21299743652344,
          -8.526313781738281,
          -8.536843299865723,
          54.922149658203125,
          25.350793838500977,
          -27.90108299255371,
          -59.48495864868164,
          -55.75393295288086,
          3.930036783218384,
          -1.6752336025238037,
          -24.591365814208984,
          2.15594482421875,
          -2.9095401763916016,
          -5.339659214019775,
          14.937068939208984,
          -19.3187255859375,
          -2.8710145950317383,
          -5.5132927894592285,
          2.201812744140625,
          -20.55028533935547,
          -1.1833339929580688,
          -20.888713836669922,
          -25.91461753845215,
          36.697330474853516,
          36.58393478393555,
          -22.83397102355957,
          -43.3694953918457,
          -25.91461753845215,
          -13.238070487976074,
          10.778721809387207,
          -13.488391876220703,
          -14.3264741897583,
          -21.835845947265625,
          -13.48798942565918,
          -21.972564697265625,
          -14.581404685974121,
          -21.908817291259766,
          -41.183616638183594,
          -59.196022033691406,
          -3.56632924079895,
          -38.11808395385742,
          10.852316856384277,
          -7.89854621887207,
          35.485557556152344,
          -13.245195388793945,
          -22.726911544799805,
          2.2811901569366455,
          -20.408174514770508,
          -14.490020751953125,
          -14.329866409301758,
          0.3616877794265747,
          -14.184381484985352,
          -14.19176959991455,
          -14.175301551818848,
          -13.487192153930664,
          -6.154471397399902,
          -3.9316141605377197,
          10.374521255493164,
          -15.278255462646484,
          -2.094468355178833,
          6.664060115814209,
          -20.821331024169922,
          -15.285290718078613,
          22.367887496948242,
          -14.394668579101562,
          -12.19321346282959,
          -8.790979385375977,
          6.5468668937683105,
          6.796436786651611,
          -20.821247100830078,
          -15.077784538269043,
          22.36782455444336,
          -12.205619812011719,
          -8.163070678710938,
          -5.048131465911865,
          6.854409694671631,
          3.512704849243164,
          -20.821331024169922,
          -15.082619667053223,
          -12.205850601196289,
          -8.16319751739502,
          -6.191061973571777,
          -45.590538024902344,
          -55.1003303527832,
          -22.707685470581055,
          -22.207672119140625,
          1.61575186252594,
          -22.673677444458008,
          -22.92022132873535,
          11.63305377960205,
          -29.4223575592041,
          9.41697883605957,
          16.864967346191406,
          -22.844453811645508,
          -22.940258026123047,
          5.250504970550537,
          -22.4448299407959,
          -27.279090881347656,
          -22.355831146240234,
          -45.0627555847168,
          -9.572846412658691,
          24.053909301757812,
          -22.958045959472656,
          -29.740983963012695,
          -27.6837215423584,
          16.772764205932617,
          -2.088512420654297,
          -5.311789512634277,
          3.2440736293792725,
          25.745086669921875,
          12.305750846862793,
          -15.278255462646484,
          0.5605754256248474,
          46.13112258911133,
          -32.74440002441406,
          -17.103668212890625,
          45.19236373901367,
          4.277023792266846,
          28.233505249023438,
          3.742223024368286,
          22.361997604370117,
          42.445823669433594,
          -21.25688934326172,
          -24.241661071777344,
          -25.938053131103516,
          12.95163345336914,
          34.5274772644043,
          29.041614532470703,
          -2.263490676879883,
          -41.44333267211914,
          46.17402267456055,
          3.23173451423645,
          -59.05654525756836,
          17.717254638671875,
          2.1222949028015137,
          -44.008697509765625,
          -2.360389232635498,
          11.172114372253418,
          -15.278255462646484,
          -44.0184326171875,
          28.283266067504883,
          28.20047378540039,
          -44.83878707885742,
          -44.81730651855469,
          -44.74440383911133,
          41.74292755126953,
          -2.533022165298462,
          -19.034446716308594,
          -44.651466369628906,
          -44.09214782714844,
          -2.5917418003082275,
          -46.450843811035156,
          -37.262630462646484,
          6.307618618011475,
          2.0224833488464355,
          2.2719614505767822,
          8.698956489562988,
          43.236175537109375,
          9.748382568359375,
          11.827820777893066,
          11.107397079467773,
          -5.35144567489624,
          18.683998107910156,
          -41.81577682495117,
          18.6678524017334,
          28.0206298828125,
          35.41352081298828,
          42.87312698364258,
          44.17950439453125,
          -21.970991134643555,
          -8.857226371765137,
          -0.4042538106441498,
          -12.144204139709473,
          -26.608596801757812,
          10.97343635559082,
          -46.88365173339844,
          -53.10539245605469,
          2.759514093399048,
          -3.840824842453003,
          17.753124237060547,
          3.337029457092285,
          -3.9833858013153076,
          -26.449508666992188,
          7.752527713775635,
          -3.0548906326293945,
          2.4520742893218994,
          5.449001789093018,
          -34.709712982177734,
          -58.785743713378906,
          26.743854522705078,
          27.667476654052734,
          16.91350746154785,
          -17.639158248901367,
          9.198168754577637,
          26.10910987854004,
          26.703096389770508,
          26.527324676513672,
          42.272003173828125,
          23.296894073486328,
          3.348421812057495,
          -23.56005096435547,
          29.75021743774414,
          -4.551618576049805,
          -44.92621612548828,
          -6.435641765594482,
          25.643224716186523,
          3.3689398765563965,
          -23.56096649169922,
          28.215682983398438,
          45.48297119140625,
          25.567676544189453,
          1.1517720222473145,
          -15.147489547729492,
          -23.1539306640625,
          42.51518249511719,
          41.97247314453125,
          42.38042449951172,
          -3.863415002822876,
          -29.7447452545166,
          -23.278644561767578,
          42.077964782714844,
          3.1052589416503906,
          4.938852787017822,
          26.304073333740234,
          -22.874521255493164,
          -10.912216186523438,
          4.136974811553955,
          26.303829193115234,
          -23.08926010131836,
          -4.612027645111084,
          35.95158004760742,
          62.07468795776367,
          41.25429916381836,
          42.085445404052734,
          3.695953845977783,
          -60.759002685546875,
          -53.100440979003906,
          -4.29297399520874,
          1.4723666906356812,
          41.87685012817383,
          25.652484893798828,
          60.300880432128906,
          -20.59779167175293,
          20.2482852935791,
          16.4539794921875,
          -16.67069435119629,
          -20.598186492919922,
          11.663368225097656,
          -24.57976531982422,
          11.767725944519043,
          -11.791598320007324,
          -22.048784255981445,
          -6.848725318908691,
          -36.0052375793457,
          44.135414123535156,
          -26.42212677001953,
          -26.722017288208008,
          47.79495620727539,
          19.22385597229004,
          3.695011854171753,
          -31.14198112487793,
          -23.139875411987305,
          -18.147157669067383,
          3.6947007179260254,
          -59.375789642333984,
          -37.262630462646484,
          -31.393735885620117,
          47.85859680175781,
          19.305908203125,
          27.14564323425293,
          -16.85106658935547,
          -31.141111373901367,
          -23.139875411987305,
          -17.77412986755371,
          -2.7778666019439697,
          4.803289413452148,
          31.474380493164062,
          17.291858673095703,
          22.551279067993164,
          40.0471076965332,
          38.10668182373047,
          43.175819396972656,
          35.54939651489258,
          35.55734634399414,
          15.620523452758789,
          -19.3804931640625,
          43.272438049316406,
          2.25923228263855,
          -18.698936462402344,
          2.8378124237060547,
          -41.97126770019531,
          -61.029972076416016,
          -36.10735321044922,
          40.143089294433594,
          -53.50996398925781,
          -53.52762985229492,
          35.71358108520508,
          43.15199661254883,
          1.6817775964736938,
          1.7113789319992065,
          43.91583251953125,
          -10.407803535461426,
          -32.49745559692383,
          -32.606956481933594,
          0.4092155396938324,
          -27.1824893951416,
          8.961647033691406,
          -2.8289408683776855,
          28.652368545532227,
          25.1971492767334,
          23.007396697998047,
          24.92586326599121,
          -5.981627941131592,
          -26.168851852416992,
          -6.639828205108643,
          -6.010045528411865,
          -50.032100677490234,
          -59.17958450317383,
          8.532027244567871,
          -2.9996941089630127,
          0.42266562581062317,
          48.372772216796875,
          18.40705680847168,
          9.631083488464355,
          29.103696823120117,
          36.248741149902344,
          36.40195846557617,
          11.749488830566406,
          38.96847915649414,
          -2.4145262241363525,
          11.430947303771973,
          44.179161071777344,
          3.814636468887329,
          17.71771240234375,
          23.297426223754883,
          1.2601226568222046,
          47.80543518066406,
          10.19619369506836,
          -2.3952457904815674,
          -21.0805606842041,
          61.592529296875,
          37.09054183959961,
          12.876224517822266,
          -11.498069763183594,
          -60.30768966674805,
          -36.005306243896484,
          0.5033526420593262,
          1.121278166770935,
          12.232373237609863,
          -0.01778949797153473,
          4.63145637512207,
          6.227176666259766,
          16.191251754760742,
          -13.858990669250488,
          -17.483545303344727,
          -7.566822052001953,
          42.62031173706055,
          44.70109176635742,
          -14.906290054321289,
          -14.895004272460938,
          62.30998229980469,
          15.940298080444336,
          39.387203216552734,
          9.222970008850098,
          -10.08956527709961,
          16.155454635620117,
          -60.348567962646484,
          -36.005470275878906,
          -55.006046295166016,
          -24.43720245361328,
          -24.424657821655273,
          -4.603940963745117,
          -4.599350929260254,
          -14.831676483154297,
          13.167069435119629,
          11.77548885345459,
          6.013573169708252,
          -23.425907135009766,
          14.701810836791992,
          -34.73459243774414,
          -4.596710205078125,
          -6.3591718673706055,
          14.70306396484375,
          -1.3544273376464844,
          -34.73459243774414,
          -35.95424270629883,
          -20.261198043823242,
          -36.11832809448242,
          -49.257118225097656,
          -17.504892349243164,
          29.814775466918945,
          29.16075325012207,
          13.005373001098633,
          36.29150390625,
          28.354902267456055,
          29.815288543701172,
          30.097414016723633,
          30.173372268676758,
          32.24620819091797,
          31.118370056152344,
          29.640174865722656,
          31.463346481323242,
          32.090389251708984,
          31.164094924926758,
          30.835620880126953,
          31.1728572845459,
          29.42746925354004,
          28.25322151184082,
          -20.53666114807129,
          30.551401138305664,
          29.67373275756836,
          28.021791458129883,
          29.254844665527344,
          30.34421157836914,
          -49.318790435791016,
          25.32764434814453,
          27.635631561279297,
          11.463289260864258,
          -14.972355842590332,
          9.748382568359375,
          26.109127044677734,
          25.38458251953125,
          42.373409271240234,
          10.974475860595703,
          42.292381286621094,
          23.374622344970703,
          -4.028775691986084,
          -23.558462142944336,
          29.750200271606445,
          -4.212551593780518,
          -60.741302490234375,
          -6.435641765594482,
          14.045269966125488,
          -2.164320945739746,
          -24.02202606201172,
          -6.548553466796875,
          -5.9476494789123535,
          10.582791328430176,
          -13.59791374206543,
          -8.760960578918457,
          -7.165365695953369,
          5.898293495178223,
          -7.21056604385376,
          -9.819286346435547,
          -7.559298515319824,
          5.164223670959473,
          -7.907726287841797,
          -42.325862884521484,
          -60.28443908691406,
          -54.41133117675781,
          24.389944076538086,
          24.23613929748535,
          24.44186019897461,
          39.67665100097656,
          25.63409996032715,
          11.496856689453125,
          19.211788177490234,
          18.33534049987793,
          38.64924240112305,
          18.199665069580078,
          -43.023643493652344,
          19.6007080078125,
          21.06517219543457,
          42.077964782714844,
          23.074827194213867,
          -4.159925937652588,
          19.71978759765625,
          19.906808853149414,
          43.08362579345703,
          38.16682815551758,
          18.253612518310547,
          -59.52346420288086,
          -53.66303253173828,
          31.601707458496094,
          -3.1089766025543213,
          -3.31977915763855,
          3.249455451965332,
          21.249975204467773,
          -21.22237205505371,
          23.996734619140625,
          22.184186935424805,
          0.7973875999450684,
          24.304492950439453,
          24.420421600341797,
          45.76602554321289,
          24.07002067565918,
          45.76666259765625,
          -9.390016555786133,
          -8.136367797851562,
          22.851455688476562,
          23.93409538269043,
          26.442102432250977,
          11.664292335510254,
          42.3962287902832,
          20.47121810913086,
          -7.174354553222656,
          -9.3557710647583,
          32.239070892333984,
          -17.712589263916016,
          -16.50117301940918,
          1.5776337385177612,
          32.12336730957031,
          -18.708620071411133,
          12.462814331054688,
          -18.64310073852539,
          -41.46531295776367,
          -23.040117263793945,
          -21.322328567504883,
          -19.938879013061523,
          -18.684314727783203,
          -29.697696685791016,
          -29.71054458618164,
          -5.813625335693359,
          -19.77783966064453,
          -24.428348541259766,
          -14.431951522827148,
          -10.284486770629883,
          5.360671043395996,
          -5.934642314910889,
          -18.504741668701172,
          -26.92680549621582,
          -59.849365234375,
          -32.23550796508789,
          -31.557615280151367,
          12.26659870147705,
          -33.34836959838867,
          -32.546852111816406,
          -32.54191970825195,
          -32.527801513671875,
          -18.201385498046875,
          22.113203048706055,
          -32.06950378417969,
          -32.568607330322266,
          -21.79799461364746,
          -13.71063232421875,
          -33.359249114990234,
          -44.70625686645508,
          -46.67723083496094,
          -47.34218215942383,
          -3.3381876945495605,
          -34.72467041015625,
          -33.560882568359375,
          -29.18399429321289,
          -0.3605198264122009,
          -31.92660903930664,
          -31.80951499938965,
          -26.669374465942383,
          -17.355358123779297,
          -28.99842643737793,
          -31.694087982177734,
          -32.33634567260742,
          -31.668132781982422,
          -21.172382354736328,
          20.216827392578125,
          1.8354949951171875,
          -30.35367202758789,
          -31.901283264160156,
          -31.62791633605957,
          -30.353425979614258,
          -41.31724166870117,
          -57.237396240234375,
          23.712894439697266,
          23.654857635498047,
          24.222000122070312,
          37.034889221191406,
          23.1870174407959,
          23.253780364990234,
          -34.612674713134766,
          26.143064498901367,
          26.171897888183594,
          26.448606491088867,
          24.474489212036133,
          25.282529830932617,
          29.103275299072266,
          35.25699996948242,
          13.82544231414795,
          17.176942825317383,
          15.503863334655762,
          -26.591838836669922,
          -4.430333614349365,
          3.2538607120513916,
          2.733470916748047,
          32.239341735839844,
          -20.07236671447754,
          -26.031057357788086,
          62.07468795776367,
          23.221969604492188,
          -34.63959503173828,
          -46.6301383972168,
          -55.23356628417969,
          -1.071866512298584,
          -1.130906581878662,
          10.705946922302246,
          3.5299792289733887,
          3.304962396621704,
          3.2391045093536377,
          -4.051828384399414,
          -1.0554859638214111,
          2.029202461242676,
          3.6575655937194824,
          2.6185615062713623,
          -41.97126770019531,
          2.563291549682617,
          2.632855176925659,
          2.43530535697937,
          4.518411159515381,
          -36.005584716796875,
          -48.96467590332031,
          -5.2693400382995605,
          -1.5798234939575195,
          7.869927883148193,
          11.571593284606934,
          -1.4857966899871826,
          -8.105584144592285,
          -6.785929203033447,
          43.91920471191406,
          42.86806869506836,
          43.336334228515625,
          -6.641659736633301,
          -21.015361785888672,
          61.64140701293945,
          -22.69823455810547,
          -45.59629440307617,
          -36.583580017089844,
          3.848787784576416,
          -3.6704516410827637,
          14.12524700164795,
          9.982316970825195,
          -18.85365867614746,
          42.06718826293945,
          -7.4970316886901855,
          -21.048612594604492,
          -58.564056396484375,
          -54.41133117675781,
          -28.04115867614746,
          -29.770597457885742,
          14.85750675201416,
          -26.112943649291992,
          -13.670539855957031,
          7.278417587280273,
          -28.028888702392578,
          -17.75937271118164,
          -19.61850929260254,
          -27.65228843688965,
          -16.028188705444336,
          27.263900756835938,
          22.90696144104004,
          29.940340042114258,
          34.056644439697266,
          -28.296491622924805,
          -28.63130760192871,
          2.8521711826324463,
          33.719669342041016,
          4.497501850128174,
          -47.089271545410156,
          21.067712783813477,
          -15.166775703430176,
          -27.774505615234375,
          0.4509202241897583,
          -1.178214430809021,
          17.18338966369629,
          -20.231021881103516,
          -1.5869373083114624,
          9.197710990905762,
          -19.958892822265625,
          -49.087745666503906,
          -54.199127197265625,
          6.236990928649902,
          8.04977798461914,
          11.178608894348145,
          -22.997915267944336,
          22.941837310791016,
          -0.29333826899528503,
          33.75933074951172,
          -3.7903592586517334,
          -6.641266822814941,
          23.16843032836914,
          -19.98311424255371,
          -40.8325309753418,
          -24.355548858642578,
          3.9429640769958496,
          -5.52223014831543,
          14.01864242553711,
          1.10600745677948,
          -4.233386993408203,
          -42.077613830566406,
          5.391984939575195,
          -7.304686069488525,
          -7.868232727050781,
          -14.646135330200195,
          -37.23451614379883,
          -3.857063055038452,
          17.97161102294922,
          6.262425422668457,
          8.315892219543457,
          -37.23359298706055,
          -3.395742416381836,
          8.217947006225586,
          4.62768030166626,
          3.4163010120391846,
          3.5869357585906982,
          -56.36090087890625,
          -9.572747230529785,
          -53.754234313964844,
          1.9554200172424316,
          5.653957366943359,
          2.9626832008361816,
          -2.594688653945923,
          -3.4200823307037354,
          -3.4585371017456055,
          -3.002195358276367,
          -43.331546783447266,
          -38.574737548828125,
          1.5416646003723145,
          0.22363774478435516,
          -43.174861907958984,
          -42.161136627197266,
          -29.861196517944336,
          -29.521587371826172,
          -29.25836181640625,
          -24.840986251831055,
          -29.422834396362305,
          -24.73573112487793,
          -27.927032470703125,
          -28.102073669433594,
          -29.56183433532715,
          -27.758670806884766,
          -37.23359298706055,
          -3.2823405265808105,
          -16.66716766357422,
          9.111239433288574,
          0.17548702657222748,
          14.917778015136719,
          11.083052635192871,
          9.367673873901367,
          10.110983848571777,
          4.696995735168457,
          -12.612223625183105,
          -14.1908540725708,
          -7.520504951477051,
          -13.826321601867676,
          6.500649929046631,
          -4.39876127243042,
          10.198081016540527,
          16.852890014648438,
          10.612178802490234,
          16.93280601501465,
          40.46149826049805,
          7.718141555786133,
          -4.119128704071045,
          -55.27696228027344,
          -54.199127197265625,
          6.614726543426514,
          8.077906608581543,
          -42.3843879699707,
          6.168207168579102,
          -42.434814453125,
          -43.45408630371094,
          -7.4997076988220215,
          -24.310176849365234,
          6.168274879455566,
          -42.43485641479492,
          -43.45408630371094,
          -7.4997076988220215,
          -16.1727294921875,
          6.168204307556152,
          -42.434814453125,
          -43.453819274902344,
          -7.4997076988220215,
          -10.434959411621094,
          -10.331558227539062,
          2.5806922912597656,
          36.660789489746094,
          42.7518310546875,
          15.680591583251953,
          -16.072694778442383,
          22.987680435180664,
          8.864178657531738,
          24.299745559692383,
          8.590636253356934,
          48.167762756347656,
          -12.967243194580078,
          5.396116256713867,
          17.717355728149414,
          22.053325653076172,
          -3.6002235412597656,
          -13.315159797668457,
          -12.878055572509766,
          -12.86207103729248,
          -16.061681747436523,
          -11.035840034484863,
          36.85050582885742,
          -11.498078346252441,
          -29.760080337524414,
          36.66073989868164,
          -55.1203498840332,
          -35.2857666015625,
          12.936898231506348,
          13.043621063232422,
          10.953179359436035,
          -28.913297653198242,
          -28.97254180908203,
          47.94584655761719,
          -22.050514221191406,
          -1.3276300430297852,
          39.36850357055664,
          -55.68182373046875,
          -36.17540740966797,
          -32.53807830810547,
          -32.54547882080078,
          14.858945846557617,
          -19.721590042114258,
          16.110233306884766,
          24.126964569091797,
          9.748382568359375,
          3.1958649158477783,
          2.918766736984253,
          3.161717653274536,
          41.74292755126953,
          46.318199157714844,
          -3.364506959915161,
          3.118905544281006,
          23.082263946533203,
          2.8721208572387695,
          -41.01477813720703,
          -17.980134963989258,
          2.2769765853881836,
          2.1839284896850586,
          15.703364372253418,
          -15.278255462646484,
          -22.830150604248047,
          3.697319746017456,
          -1.6752426624298096,
          14.433524131774902,
          -5.33644437789917,
          20.86600112915039,
          32.340087890625,
          35.020896911621094,
          7.853991985321045,
          35.00707244873047,
          25.212955474853516,
          39.70083236694336,
          -26.409055709838867,
          22.227197647094727,
          -4.735217094421387,
          19.44447898864746,
          19.336742401123047,
          6.83574104309082,
          -0.44290876388549805,
          -7.3302483558654785,
          -22.75030517578125,
          -2.2166497707366943,
          13.664433479309082,
          61.64140701293945,
          -6.2939605712890625,
          8.827266693115234,
          20.68646240234375,
          20.68865203857422,
          22.24592399597168,
          -22.75716781616211,
          9.271480560302734,
          33.38114929199219,
          -55.179691314697266,
          -36.10735321044922,
          40.003501892089844,
          39.621036529541016,
          53.64720916748047,
          19.25082015991211,
          0.5638226270675659,
          -15.147486686706543,
          22.32595443725586,
          52.80180740356445,
          15.856049537658691,
          53.11625289916992,
          15.145655632019043,
          15.09776496887207,
          -7.60228157043457,
          42.87571716308594,
          3.152283191680908,
          2.2579894065856934,
          3.1996402740478516,
          -56.50226593017578,
          -35.086856842041016,
          9.918704986572266,
          9.874643325805664,
          1.2439712285995483,
          8.961647033691406,
          2.459271192550659,
          27.26435661315918,
          30.582904815673828,
          30.60518455505371,
          24.3203125,
          24.432199478149414,
          21.399335861206055,
          19.835693359375,
          23.70684242248535,
          23.83077621459961,
          -15.200319290161133,
          26.459613800048828,
          8.991806030273438,
          13.555155754089355,
          35.94819641113281,
          -1.878983497619629,
          20.702608108520508,
          19.738956451416016,
          19.693626403808594,
          20.746278762817383,
          -41.58999252319336,
          2.6739377975463867,
          -14.388021469116211,
          0.8880470395088196,
          0.7798119187355042,
          11.316777229309082,
          28.288545608520508,
          28.34515380859375,
          28.557771682739258,
          12.940837860107422,
          -21.366540908813477,
          -19.513851165771484,
          -24.582759857177734,
          -19.53676986694336,
          -17.531557083129883,
          17.945619583129883,
          -7.219079971313477,
          14.826050758361816,
          14.829246520996094,
          14.828899383544922,
          -8.320903778076172,
          -8.614119529724121,
          -17.688566207885742,
          -53.100440979003906,
          -27.284135818481445,
          -20.545177459716797,
          -27.85738754272461,
          -27.861249923706055,
          -17.475053787231445,
          15.498639106750488,
          -1.597743034362793,
          11.948486328125,
          -23.392620086669922,
          -16.651731491088867,
          -8.704560279846191,
          -28.247915267944336,
          12.798722267150879,
          13.607778549194336,
          -37.234100341796875,
          -46.05369186401367,
          -35.253108978271484,
          17.25337791442871,
          21.575937271118164,
          12.819926261901855,
          -23.885452270507812,
          5.627311706542969,
          26.30640983581543,
          17.90179443359375,
          16.51695442199707,
          22.590511322021484,
          44.51795196533203,
          -2.788936138153076,
          41.447044372558594,
          24.826379776000977,
          41.98701858520508,
          61.124813079833984,
          -2.934799909591675,
          -15.004206657409668,
          -12.137094497680664,
          -49.087745666503906,
          -37.570960998535156,
          7.619518280029297,
          4.069507122039795,
          14.990819931030273,
          5.744446754455566,
          -24.666296005249023,
          -9.88061237335205,
          1.7842199802398682,
          -8.202890396118164,
          7.288028240203857,
          44.856285095214844,
          6.347322463989258,
          25.85030746459961,
          -5.539944648742676,
          7.892762660980225,
          7.968482971191406,
          2.330491542816162,
          1.6257984638214111,
          0.9796479344367981,
          2.3054418563842773,
          0.7963066101074219,
          6.592865943908691,
          0.09503757208585739,
          1.8709570169448853,
          1.9385390281677246,
          0.565579891204834,
          -60.32978057861328,
          0.6180287003517151,
          26.858430862426758,
          14.009754180908203,
          -3.9834742546081543,
          26.652490615844727,
          -6.876673221588135,
          25.934375762939453,
          -8.775663375854492,
          -8.76711654663086,
          0.5103948712348938,
          -8.179553031921387,
          0.6109312772750854,
          -4.531716823577881,
          -6.768643856048584,
          -12.54322624206543,
          -22.25255012512207,
          0.363527774810791,
          0.39333975315093994,
          49.44879150390625,
          -4.712455749511719,
          -4.133205413818359,
          -5.195988178253174,
          -35.31027603149414,
          -35.31057357788086,
          -26.58427619934082,
          -26.49726104736328,
          -9.524295806884766,
          0.5288192629814148,
          -7.590672492980957,
          -1.0600038766860962,
          -4.534255504608154,
          -6.725456237792969,
          -1.156628131866455,
          -1.1951639652252197,
          -47.799598693847656,
          -55.23356628417969,
          30.61246681213379,
          11.148622512817383,
          1.9250106811523438,
          35.503562927246094,
          13.098397254943848,
          24.12533950805664,
          30.559894561767578,
          46.59508514404297,
          30.65850067138672,
          13.044486045837402,
          9.505742073059082,
          9.40987491607666,
          9.313667297363281,
          13.667337417602539,
          11.233652114868164,
          43.83325958251953,
          42.44583511352539,
          -21.02821922302246,
          10.80965518951416,
          62.46665573120117,
          39.80459976196289,
          44.036773681640625,
          -26.876224517822266,
          -59.588134765625,
          -53.846397399902344,
          -23.91891860961914,
          -10.095251083374023,
          -17.589540481567383,
          -17.593481063842773,
          -17.61081314086914,
          -16.676015853881836,
          -0.03938351199030876,
          -2.032883882522583,
          1.148975133895874,
          0.9130441546440125,
          2.803755044937134,
          0.47881993651390076,
          30.190643310546875,
          29.359067916870117,
          -13.57243537902832,
          32.47187042236328,
          4.71157693862915,
          43.90312576293945,
          2.1186587810516357,
          15.787834167480469,
          -34.789703369140625,
          -60.00711441040039,
          -35.288299560546875,
          -18.729816436767578,
          -0.5045427083969116,
          14.417981147766113,
          -18.307174682617188,
          6.034042835235596,
          3.8569698333740234,
          -0.47467947006225586,
          -3.2418789863586426,
          -20.527254104614258,
          40.422874450683594,
          18.06285858154297,
          18.1906681060791,
          -44.7343864440918,
          -37.233306884765625,
          17.928770065307617,
          17.646055221557617,
          -37.82379913330078,
          -0.6745060086250305,
          -59.56962966918945,
          14.66800308227539,
          15.038778305053711,
          13.463727951049805,
          -20.535764694213867,
          19.02892303466797,
          19.87953758239746,
          19.518632888793945,
          -26.668590545654297,
          19.018285751342773,
          20.129499435424805,
          42.016990661621094,
          19.146930694580078,
          19.125873565673828,
          5.043026924133301,
          4.5175461769104,
          -26.668588638305664,
          32.56717300415039,
          20.129383087158203,
          4.517163276672363,
          5.0431227684021,
          -59.851444244384766,
          -15.627411842346191,
          -16.569984436035156,
          13.548087120056152,
          43.00509262084961,
          16.236164093017578,
          -23.278501510620117,
          22.550363540649414,
          -2.187002182006836,
          -15.272162437438965,
          -0.2812567949295044,
          -44.278717041015625,
          27.291704177856445,
          -14.899998664855957,
          -15.510897636413574,
          -14.984739303588867,
          -44.27135467529297,
          -8.381240844726562,
          13.315831184387207,
          47.161476135253906,
          16.890636444091797,
          2.054842233657837,
          -11.618912696838379,
          -23.139892578125,
          47.161006927490234,
          44.77915954589844,
          -0.34935125708580017,
          -24.69329261779785,
          -10.549092292785645,
          -11.633785247802734,
          -5.800787448883057,
          -59.847415924072266,
          -54.95945358276367,
          16.977415084838867,
          15.82158088684082,
          9.739853858947754,
          12.787355422973633,
          -0.5829800367355347,
          15.14868450164795,
          -19.776002883911133,
          2.179363965988159,
          41.624839782714844,
          40.87285232543945,
          49.99677658081055,
          0.9939808249473572,
          5.12598991394043,
          46.2134895324707,
          -19.03444480895996,
          61.64140701293945,
          37.42379379272461,
          -11.49808120727539,
          -58.96541976928711,
          -54.608604431152344,
          -10.459046363830566,
          -10.125568389892578,
          12.56482982635498,
          -18.844892501831055,
          20.139543533325195,
          10.97725772857666,
          11.19921875,
          10.373495101928711,
          -17.720882415771484,
          11.144686698913574,
          11.91675090789795,
          -3.5472607612609863,
          -23.621538162231445,
          -5.715714931488037,
          -13.8056001663208,
          -13.052020072937012,
          27.922386169433594,
          40.213069915771484,
          2.258876085281372,
          -3.605682373046875,
          -10.912182807922363,
          -41.97126770019531,
          -58.959407806396484,
          32.239280700683594,
          37.15614318847656,
          -5.696697235107422,
          -18.388750076293945,
          24.00979995727539,
          24.305662155151367,
          0.4915698170661926,
          -27.56669807434082,
          24.562013626098633,
          24.44708824157715,
          24.38007926940918,
          25.05189323425293,
          24.179759979248047,
          24.717975616455078,
          3.861236572265625,
          18.97258186340332,
          9.956993103027344,
          9.960455894470215,
          51.087547302246094,
          17.586294174194336,
          17.60222816467285,
          50.808719635009766,
          17.992229461669922,
          17.587398529052734,
          -3.502638101577759,
          -6.81714391708374,
          -47.088905334472656,
          -38.23653030395508,
          -4.596602439880371,
          1.8017276525497437,
          -27.41249656677246,
          -0.47462862730026245,
          17.456787109375,
          -24.150474548339844,
          -30.66636085510254,
          -16.850942611694336,
          -12.17124080657959,
          15.941133499145508,
          -24.287776947021484,
          -6.200214862823486,
          17.465484619140625,
          -8.439279556274414,
          -12.171218872070312,
          -3.8545899391174316,
          -6.146727561950684,
          -6.188286304473877,
          -6.2322869300842285,
          -59.02342224121094,
          -55.23356628417969,
          43.22479248046875,
          27.047508239746094,
          15.527149200439453,
          43.42976760864258,
          -22.618267059326172,
          3.0855863094329834,
          -24.49585723876953,
          3.6675913333892822,
          -24.49738121032715,
          3.9393863677978516,
          -24.49738121032715,
          -42.10578918457031,
          36.80205535888672,
          30.74199867248535,
          36.883304595947266,
          43.48492431640625,
          -26.534400939941406,
          -59.66246795654297,
          34.05650329589844,
          46.30257797241211,
          46.89916229248047,
          2.837984323501587,
          10.852320671081543,
          1.4349833726882935,
          30.534351348876953,
          16.89141845703125,
          44.34196853637695,
          25.051557540893555,
          2.3038170337677,
          44.17452621459961,
          3.8538153171539307,
          49.447509765625,
          45.9388313293457,
          31.2248592376709,
          30.82160758972168,
          1.8017784357070923,
          26.258527755737305,
          21.293996810913086,
          14.07835865020752,
          31.210922241210938,
          33.174522399902344,
          33.75830078125,
          2.7334649562835693,
          1.6804090738296509,
          -0.8886969685554504,
          -0.10093231499195099,
          33.729461669921875,
          -26.05885124206543,
          -32.72709274291992,
          31.291643142700195,
          27.922513961791992,
          33.72666931152344,
          5.526542663574219,
          17.96982765197754,
          48.604278564453125,
          -22.36126136779785,
          35.076820373535156,
          34.943111419677734,
          35.045597076416016,
          -39.53068923950195,
          31.25054168701172,
          31.14126205444336,
          31.757108688354492,
          31.013540267944336,
          -46.520267486572266,
          -25.482812881469727,
          -24.525146484375,
          15.67465877532959,
          -25.73894500732422,
          9.343311309814453,
          17.119483947753906,
          -25.735639572143555,
          -3.1999690532684326,
          -29.613576889038086,
          -25.748371124267578,
          -9.658187866210938,
          -49.621543884277344,
          -53.93527603149414,
          -17.695877075195312,
          -14.769368171691895,
          17.902719497680664,
          10.011544227600098,
          -22.921512603759766,
          -1.8455559015274048,
          -25.730466842651367,
          1.828262209892273,
          19.031002044677734,
          14.786399841308594,
          -20.69793128967285,
          29.559598922729492,
          13.777132034301758,
          -19.26360511779785,
          -6.991456508636475,
          -17.88664436340332,
          -22.279895782470703,
          6.034042835235596,
          13.949010848999023,
          47.11817932128906,
          37.32784652709961,
          40.62031555175781,
          -41.264732360839844,
          -6.994891166687012,
          0.1797802746295929,
          17.703054428100586,
          38.8680534362793,
          0.9342132210731506,
          -17.76459503173828,
          0.2083989977836609,
          38.86817169189453,
          -4.630582332611084,
          -25.335220336914062,
          -25.345125198364258,
          -22.258506774902344,
          0.2046048492193222,
          38.868282318115234,
          -18.023826599121094,
          -21.367319107055664,
          -28.95988655090332,
          0.9342097640037537,
          -27.879310607910156,
          5.0606231689453125,
          -41.19819641113281,
          -8.059501647949219,
          15.594940185546875,
          -0.17227233946323395,
          -4.9507904052734375,
          47.56608581542969,
          -58.32391357421875,
          -36.81571960449219,
          7.41084098815918,
          0.9341030120849609,
          7.422537326812744,
          5.624643325805664,
          -9.185806274414062,
          16.400789260864258,
          16.69275665283203,
          15.203951835632324,
          13.420693397521973,
          8.99110221862793,
          33.942535400390625,
          34.79652404785156,
          -16.5286808013916,
          11.798318862915039,
          -5.174417972564697,
          29.35871124267578,
          -2.2593307495117188,
          48.69839859008789,
          -16.50974464416504,
          2.5918242931365967,
          -16.5312557220459,
          2.7138545513153076,
          -6.286519527435303,
          48.69878387451172,
          -21.153396606445312,
          -61.011070251464844,
          -6.435641765594482,
          23.688270568847656,
          34.66956329345703,
          11.234461784362793,
          -2.3930130004882812,
          -5.115601539611816,
          -2.392927646636963,
          -7.865614414215088,
          -22.098697662353516,
          -22.396135330200195,
          -8.171170234680176,
          -7.087818622589111,
          6.536017417907715,
          -4.6718621253967285,
          6.544088840484619,
          -10.50633430480957,
          -7.848680019378662,
          -8.188865661621094,
          -15.951250076293945,
          -14.571637153625488,
          -16.722755432128906,
          -7.366335391998291,
          -19.687152862548828,
          -10.588386535644531,
          -4.504744052886963,
          8.65336799621582,
          -3.273933172225952,
          6.824692726135254,
          -10.012154579162598,
          -33.80614471435547,
          -36.96302795410156,
          -38.3958740234375,
          -55.06562042236328,
          16.27594757080078,
          21.646596908569336,
          14.607904434204102,
          -19.048824310302734,
          26.38364601135254,
          16.459497451782227,
          36.40392303466797,
          44.06952667236328,
          47.410457611083984,
          45.008121490478516,
          47.410457611083984,
          45.00807571411133,
          47.410457611083984,
          45.00826644897461,
          -4.537472248077393,
          -9.535240173339844,
          -11.299349784851074,
          25.358993530273438,
          -59.58756637573242,
          -35.713531494140625,
          15.434514999389648,
          15.547096252441406,
          10.897878646850586,
          -19.26757049560547,
          24.872129440307617,
          -17.84934425354004,
          19.326332092285156,
          40.01027297973633,
          52.80030822753906,
          51.81997299194336,
          1.2862021923065186,
          31.765323638916016,
          24.823680877685547,
          -3.3510854244232178,
          62.30998229980469,
          42.188209533691406,
          51.867767333984375,
          15.666707992553711,
          41.17923355102539,
          13.563277244567871,
          21.83356475830078,
          23.745906829833984,
          -58.32391357421875,
          -14.140542030334473,
          -14.137137413024902,
          -24.04222297668457,
          32.76301956176758,
          27.749439239501953,
          11.81617546081543,
          45.739681243896484,
          45.37576675415039,
          8.455265045166016,
          41.53169631958008,
          42.4937629699707,
          44.867347717285156,
          9.590156555175781,
          8.460906028747559,
          62.84092330932617,
          33.21202850341797,
          28.844173431396484,
          62.82651138305664,
          -22.672910690307617,
          -47.52803039550781,
          -53.23118209838867,
          17.824892044067383,
          46.90185546875,
          40.03618240356445,
          38.10681915283203,
          38.23873519897461,
          8.455248832702637,
          2.155503511428833,
          2.1475586891174316,
          12.673935890197754,
          16.891145706176758,
          23.603158950805664,
          14.725724220275879,
          43.70077896118164,
          -18.374128341674805,
          -16.867321014404297,
          46.8251838684082,
          12.153743743896484,
          12.117947578430176,
          46.57040023803711,
          -26.742544174194336,
          -26.339391708374023,
          -12.241928100585938,
          -26.752500534057617,
          -11.122117042541504,
          44.04878616333008,
          5.363451957702637,
          -59.02342224121094,
          -14.277054786682129,
          -15.33967399597168,
          10.559646606445312,
          -18.410791397094727,
          -14.113201141357422,
          5.008322238922119,
          -14.124347686767578,
          -0.8320968151092529,
          -0.9437617659568787,
          -4.027570724487305,
          3.4060089588165283,
          -14.293635368347168,
          -3.485286235809326,
          48.30596923828125,
          -14.485405921936035,
          37.236629486083984,
          -17.234867095947266,
          -13.617446899414062,
          -47.147098541259766,
          -5.356821060180664,
          -15.0706148147583,
          -14.665535926818848,
          3.5027015209198,
          3.331455945968628,
          12.000842094421387,
          -25.187108993530273,
          -13.521331787109375,
          1.4350628852844238,
          -2.186166286468506,
          4.286792755126953,
          -37.56021499633789,
          -38.39505386352539,
          -37.121952056884766,
          7.959308624267578,
          -42.22919464111328,
          -3.115839719772339,
          -42.25270462036133,
          7.122705459594727,
          -60.35084915161133,
          -54.95952606201172,
          -26.706798553466797,
          20.517032623291016,
          -2.522536039352417,
          13.396803855895996,
          -17.321290969848633,
          12.534624099731445,
          -25.97737693786621,
          12.099979400634766,
          10.07863998413086,
          9.198168754577637,
          16.426902770996094,
          -3.847778081893921,
          -25.938880920410156,
          11.623228073120117,
          -3.188371181488037,
          -10.215563774108887,
          -10.262618064880371,
          -59.58756637573242,
          -37.55697250366211,
          -15.886653900146484,
          -15.77553939819336,
          11.510812759399414,
          -22.055706024169922,
          -2.686702251434326,
          -4.690088748931885,
          -40.673282623291016,
          -47.26445770263672,
          32.11317825317383,
          25.766836166381836,
          11.165318489074707,
          -23.456924438476562,
          15.680469512939453,
          37.29188537597656,
          37.167808532714844,
          38.90237808227539,
          16.219480514526367,
          15.087455749511719,
          -23.56170082092285,
          -3.671370506286621,
          37.571563720703125,
          -31.729673385620117,
          21.725515365600586,
          -46.727134704589844,
          15.087570190429688,
          -23.56085205078125,
          -3.3834385871887207,
          37.02833938598633,
          -31.72966766357422,
          -11.495418548583984,
          36.74260711669922,
          35.33000183105469,
          5.259458541870117,
          -3.1751046180725098,
          17.012859344482422,
          4.763331890106201,
          -25.187183380126953,
          6.106355667114258,
          -13.137839317321777,
          41.03771209716797,
          -3.818531036376953,
          -14.725110054016113,
          -14.165056228637695,
          -34.512081146240234,
          -49.621543884277344,
          -1.2817741632461548,
          -2.693056583404541,
          11.8971529006958,
          24.562532424926758,
          12.64541244506836,
          -11.35880184173584,
          18.281959533691406,
          19.62342643737793,
          26.146921157836914,
          37.146270751953125,
          29.096742630004883,
          -3.135640859603882,
          40.74098205566406,
          18.287254333496094,
          29.07093048095703,
          -2.7643849849700928,
          13.15031909942627,
          -20.21993064880371,
          -55.8597412109375,
          -55.006046295166016,
          -19.885135650634766,
          -20.220561981201172,
          17.964622497558594,
          -18.708585739135742,
          -19.028648376464844,
          -17.449190139770508,
          -19.90298843383789,
          -20.99485206604004,
          -39.597537994384766,
          5.801113128662109,
          1.3490753173828125,
          -18.79026985168457,
          15.241615295410156,
          7.574587345123291,
          -0.6234490871429443,
          -17.4493465423584,
          -19.902908325195312,
          46.57040023803711,
          -17.44968605041504,
          -19.902986526489258,
          -17.44913673400879,
          -19.90298843383789,
          -20.743303298950195,
          -17.288171768188477,
          -19.93983268737793,
          -37.05009460449219,
          -44.25399398803711,
          -17.93657684326172,
          -17.917268753051758,
          13.105175971984863,
          -55.75267028808594,
          14.850558280944824,
          -13.69860553741455,
          -13.227250099182129,
          16.35149574279785,
          -15.992449760437012,
          -18.343002319335938,
          -18.324995040893555,
          -12.96731185913086,
          -13.669904708862305,
          42.54845428466797,
          35.44452667236328,
          -10.261506080627441,
          -9.738648414611816,
          1.226535439491272,
          35.444332122802734,
          -10.261725425720215,
          -9.73875904083252,
          35.44670867919922,
          -10.280824661254883,
          -9.771587371826172,
          48.293548583984375,
          22.719327926635742,
          -15.341450691223145,
          -14.855378150939941,
          -15.62028694152832,
          -18.811439514160156,
          -18.660696029663086,
          -19.309185028076172,
          42.53083038330078,
          -17.311113357543945,
          -51.16880416870117,
          -39.53069305419922,
          -2.2956457138061523,
          -15.992476463317871,
          -46.045005798339844,
          19.23154067993164,
          -9.6820068359375,
          16.768102645874023,
          -18.329532623291016,
          3.1608173847198486,
          1.1141613721847534,
          3.1608173847198486,
          1.1141849756240845,
          -41.44685363769531,
          -56.25931167602539,
          -55.23356628417969,
          18.552230834960938,
          18.393461227416992,
          15.840357780456543,
          -6.575126647949219,
          -26.372692108154297,
          5.741919994354248,
          16.321044921875,
          19.37765884399414,
          19.396957397460938,
          -0.3307528495788574,
          17.944988250732422,
          -32.75148010253906,
          -42.41200637817383,
          18.916845321655273,
          19.041667938232422,
          -41.525753021240234,
          47.50822067260742,
          47.2698974609375,
          34.11024856567383,
          -2.478926420211792,
          -41.82268142700195,
          24.836772918701172,
          7.457096576690674,
          27.058237075805664,
          -38.80554962158203,
          -35.08503341674805,
          -40.71312713623047,
          -51.00745391845703,
          -45.573360443115234,
          10.808103561401367,
          -2.1409878730773926,
          11.935148239135742,
          -23.115123748779297,
          9.631083488464355,
          46.57040023803711,
          -3.771073579788208,
          -3.115839719772339,
          15.839692115783691,
          -7.841819763183594,
          39.33674240112305,
          -34.711273193359375,
          -45.477848052978516,
          -54.95956039428711,
          -53.83548355102539,
          3.887132406234741,
          -1.7144638299942017,
          0.9490359425544739,
          -26.714126586914062,
          35.20417404174805,
          45.51582717895508,
          32.79229736328125,
          16.48468589782715,
          35.9514045715332,
          15.469305992126465,
          41.918914794921875,
          -35.81205368041992,
          48.60400390625,
          -3.549194574356079,
          32.12286376953125,
          -4.62044095993042,
          -20.481971740722656,
          33.11431121826172,
          22.042152404785156,
          -22.765104293823242,
          -5.879018306732178,
          -45.932621002197266,
          -54.74363327026367,
          5.046964645385742,
          7.952969551086426,
          14.062222480773926,
          10.981823921203613,
          -15.278255462646484,
          50.15288543701172,
          49.43177032470703,
          34.86392593383789,
          3.8387303352355957,
          40.4608154296875,
          -6.868020534515381,
          16.966718673706055,
          -1.6204687356948853,
          50.135318756103516,
          49.36942672729492,
          34.87360763549805,
          -1.515098214149475,
          8.456138610839844,
          46.747711181640625,
          -56.203121185302734,
          -23.534759521484375,
          -23.818836212158203,
          12.562810897827148,
          -17.721403121948242,
          21.48929786682129,
          21.476579666137695,
          -5.207967281341553,
          20.65239143371582,
          -37.04779815673828,
          4.738780975341797,
          -4.039763450622559,
          -24.248390197753906,
          -4.329941749572754,
          -56.5126953125,
          -54.74363327026367,
          -13.817116737365723,
          -21.291475296020508,
          2.46842622756958,
          -18.78354263305664,
          -2.6800904273986816,
          6.085046768188477,
          46.30267333984375,
          -29.172639846801758,
          -20.6212158203125,
          -55.69710159301758,
          -11.277168273925781,
          -9.71280288696289,
          13.300436973571777,
          -17.878780364990234,
          28.801488876342773,
          29.103267669677734,
          44.568214416503906,
          28.749046325683594,
          17.4924373626709,
          16.038150787353516,
          15.902655601501465,
          21.7673282623291,
          24.054119110107422,
          6.865011215209961,
          4.139399528503418,
          -11.240117073059082,
          -11.081901550292969,
          -55.51472473144531,
          -46.04156494140625,
          -36.793914794921875,
          32.01851272583008,
          27.276586532592773,
          13.132247924804688,
          -18.888805389404297,
          32.0189094543457,
          33.59126281738281,
          31.532289505004883,
          30.864717483520508,
          35.11737060546875,
          28.91042709350586,
          34.62158966064453,
          26.353179931640625,
          -23.560840606689453,
          -4.058882236480713,
          15.087773323059082,
          20.675216674804688,
          37.57109451293945,
          -31.72966766357422,
          21.725509643554688,
          -11.498076438903809,
          31.485719680786133,
          -36.00539016723633,
          -55.659786224365234,
          -55.23356628417969,
          4.669592380523682,
          1.111895203590393,
          1.9528642892837524,
          -27.332372665405273,
          25.581693649291992,
          17.17714500427246,
          15.50413703918457,
          13.518105506896973,
          4.7109174728393555,
          3.1583595275878906,
          46.45949935913086,
          23.374622344970703,
          -8.196907997131348,
          62.07468795776367,
          -11.498078346252441,
          -8.197800636291504,
          -55.207969665527344,
          -53.83548355102539,
          46.792396545410156,
          27.444623947143555,
          13.080775260925293,
          -17.516511917114258,
          46.652099609375,
          17.232126235961914,
          27.613386154174805,
          44.40604782104492,
          3.158346652984619,
          28.561683654785156,
          -4.4392876625061035,
          -21.015361785888672,
          34.76618194580078,
          -12.80190658569336,
          48.746192932128906,
          -39.80117416381836,
          -60.99651336669922,
          -0.3385315239429474,
          38.565494537353516,
          -13.69248104095459,
          15.190930366516113,
          27.95988655090332,
          -4.734635353088379,
          24.093442916870117,
          29.551883697509766,
          -7.499274253845215,
          14.36693286895752,
          29.727909088134766,
          10.55709171295166,
          -17.730030059814453,
          6.063424110412598,
          5.959004878997803,
          -38.26105880737305,
          -9.438920021057129,
          14.351468086242676,
          40.056602478027344,
          26.524356842041016,
          40.97710418701172,
          19.815359115600586,
          40.67139434814453,
          -57.4577522277832,
          7.8714447021484375,
          -1.790158987045288,
          14.175110816955566,
          -41.474510192871094,
          -10.095251083374023,
          44.85605239868164,
          23.3759765625,
          -34.79729080200195,
          26.153472900390625,
          2.259485960006714,
          -27.50131607055664,
          -58.60040283203125,
          -37.45097732543945,
          -8.309428215026855,
          -19.348888397216797,
          31.49871253967285,
          2.4587748050689697,
          -28.28740882873535,
          3.5965654850006104,
          -4.9527788162231445,
          2.4293978214263916,
          22.265552520751953,
          25.277429580688477,
          42.70216751098633,
          7.090126991271973,
          -36.73777389526367,
          -33.16641616821289,
          7.077577114105225,
          -60.52250671386719,
          -36.917930603027344,
          -15.964091300964355,
          0.025658002123236656,
          -2.8244986534118652,
          16.081281661987305,
          0.9126191735267639,
          2.8037548065185547,
          0.4787820875644684,
          30.19024658203125,
          29.359140396118164,
          -13.571920394897461,
          32.47187805175781,
          -14.54177474975586,
          4.711338520050049,
          42.484619140625,
          2.1186585426330566,
          15.787339210510254,
          3.791877269744873,
          -34.79533767700195,
          -48.05498504638672,
          -35.713531494140625,
          18.86516761779785,
          18.50307273864746,
          17.902807235717773,
          18.64991569519043,
          18.577150344848633,
          33.79118728637695,
          29.637638092041016,
          16.896974563598633,
          33.82515335083008,
          13.891075134277344,
          35.060970306396484,
          36.595558166503906,
          36.76150131225586,
          33.78422546386719,
          10.819866180419922,
          11.14240550994873,
          25.322948455810547,
          2.835908889770508,
          13.620034217834473,
          -26.75850486755371,
          -26.388826370239258,
          46.45941162109375,
          -34.718162536621094,
          -35.85786056518555,
          -61.13168716430664,
          -37.18174362182617
         ],
         "xaxis": "x",
         "y": [
          32.972511291503906,
          44.18050765991211,
          -65.60662078857422,
          -54.38529968261719,
          1.9542169570922852,
          -38.15747833251953,
          24.17183494567871,
          -5.2488203048706055,
          -27.40348243713379,
          -8.543301582336426,
          40.0860595703125,
          39.27714157104492,
          -65.75494384765625,
          19.604516983032227,
          38.65635299682617,
          43.68366241455078,
          -34.8414306640625,
          18.83442497253418,
          18.841249465942383,
          -40.592525482177734,
          19.161121368408203,
          -21.907672882080078,
          13.461373329162598,
          -14.354848861694336,
          -24.468547821044922,
          19.040664672851562,
          44.01251220703125,
          -21.179414749145508,
          -40.31558609008789,
          29.912500381469727,
          36.738590240478516,
          -61.986270904541016,
          -55.48191452026367,
          -17.921483993530273,
          43.93065643310547,
          52.641422271728516,
          -38.6153450012207,
          -24.26051902770996,
          -23.480323791503906,
          -22.294328689575195,
          -41.69050598144531,
          55.920570373535156,
          39.27155685424805,
          -62.49387741088867,
          24.386066436767578,
          -0.002625466324388981,
          15.23912525177002,
          15.192900657653809,
          -12.456183433532715,
          34.210235595703125,
          -26.538414001464844,
          -26.795011520385742,
          -2.366610527038574,
          -1.9721087217330933,
          13.432051658630371,
          -19.781049728393555,
          12.781120300292969,
          -1.9743722677230835,
          -1.9867380857467651,
          12.709351539611816,
          -2.3062713146209717,
          56.4298210144043,
          -1.9259741306304932,
          -10.320239067077637,
          -24.63166046142578,
          -1.2142866849899292,
          -26.787532806396484,
          33.7846794128418,
          -34.326515197753906,
          -0.9192866683006287,
          24.3979549407959,
          12.216337203979492,
          -0.0026254744734615088,
          -7.680667877197266,
          -6.207326412200928,
          -27.382917404174805,
          -16.352691650390625,
          -24.492826461791992,
          -6.992032051086426,
          -1.8715206384658813,
          36.897220611572266,
          39.50776672363281,
          -63.93023681640625,
          -55.89461135864258,
          0.3765375018119812,
          17.16660499572754,
          -11.663026809692383,
          -41.05270004272461,
          27.367889404296875,
          34.25932312011719,
          55.72785568237305,
          -7.667361736297607,
          -38.0241584777832,
          29.448381423950195,
          43.77978515625,
          -64.57942962646484,
          3.716357707977295,
          1.9546527862548828,
          4.441890239715576,
          4.889406681060791,
          2.2450342178344727,
          1.1075927019119263,
          1.102643370628357,
          1.4835001230239868,
          24.853858947753906,
          25.779104232788086,
          33.616695404052734,
          38.7528190612793,
          2.0904617309570312,
          -54.479698181152344,
          -29.61127281188965,
          21.26569366455078,
          -14.46533203125,
          -15.434212684631348,
          -15.711493492126465,
          3.333528518676758,
          -5.261756420135498,
          5.328299522399902,
          2.478602409362793,
          -30.06249237060547,
          1.3792006969451904,
          2.4635376930236816,
          5.776005268096924,
          -1.3245606422424316,
          16.977081298828125,
          3.1199495792388916,
          -7.38032341003418,
          -41.27562713623047,
          20.2753849029541,
          16.963178634643555,
          -46.68501663208008,
          18.702056884765625,
          17.37321662902832,
          -59.82324981689453,
          17.880748748779297,
          18.141756057739258,
          -32.98387908935547,
          8.71667766571045,
          -4.505646228790283,
          -32.939971923828125,
          -0.38642871379852295,
          10.76655387878418,
          -35.41546630859375,
          34.97452163696289,
          -0.8325276970863342,
          33.17156982421875,
          -15.10754680633545,
          38.58278274536133,
          -0.19145838916301727,
          -23.07487678527832,
          -34.84068298339844,
          46.3023796081543,
          -33.715843200683594,
          -34.0185661315918,
          -16.148971557617188,
          -17.555862426757812,
          -16.148971557617188,
          -17.552316665649414,
          -34.77603530883789,
          -7.232671737670898,
          32.7769775390625,
          32.4661750793457,
          -47.05591583251953,
          -54.08311462402344,
          -54.08859634399414,
          -54.074581146240234,
          4.195364475250244,
          -44.051734924316406,
          -2.337287187576294,
          -4.3768086433410645,
          -7.161021709442139,
          0.2786102592945099,
          -42.8449821472168,
          36.93776321411133,
          37.38334274291992,
          -65.70767974853516,
          -40.662899017333984,
          -57.94253158569336,
          36.53777313232422,
          37.60590744018555,
          -42.90410232543945,
          -42.903839111328125,
          -43.105735778808594,
          29.939220428466797,
          -14.931492805480957,
          -25.251874923706055,
          -26.797260284423828,
          -30.162612915039062,
          37.12398147583008,
          30.56138801574707,
          27.803138732910156,
          28.432659149169922,
          -6.141547679901123,
          5.764552593231201,
          37.606449127197266,
          -30.567279815673828,
          -3.9017462730407715,
          -38.03306198120117,
          -27.450708389282227,
          -8.090482711791992,
          -38.66561508178711,
          33.417449951171875,
          33.43306350708008,
          -51.178951263427734,
          27.18882179260254,
          -17.986284255981445,
          23.640546798706055,
          21.7287540435791,
          26.305065155029297,
          25.833066940307617,
          1.2685682773590088,
          27.263179779052734,
          29.347412109375,
          1.2975558042526245,
          -7.447850704193115,
          -12.48419189453125,
          1.2678136825561523,
          -7.541089057922363,
          -15.281638145446777,
          -14.545465469360352,
          -16.81992530822754,
          -11.889936447143555,
          -59.94437026977539,
          -22.3811092376709,
          61.12382507324219,
          58.43230056762695,
          -62.236812591552734,
          -54.03509521484375,
          -19.70231056213379,
          0.7889693379402161,
          2.0100464820861816,
          -37.12030792236328,
          -0.12613968551158905,
          -39.79924011230469,
          -26.69426727294922,
          -21.1240177154541,
          -8.997528076171875,
          43.501373291015625,
          44.12470245361328,
          -66.11849212646484,
          -54.937870025634766,
          -37.78160858154297,
          -2.883653402328491,
          -26.619583129882812,
          -24.939210891723633,
          -8.059808731079102,
          45.45913314819336,
          47.259403228759766,
          -62.32728576660156,
          -56.456573486328125,
          34.333412170410156,
          43.08759689331055,
          34.68948745727539,
          -37.78160858154297,
          3.1593217849731445,
          37.516658782958984,
          13.470666885375977,
          -19.264198303222656,
          -22.519542694091797,
          -50.820579528808594,
          56.211814880371094,
          56.20472717285156,
          -62.04039001464844,
          -15.635933876037598,
          -23.22120475769043,
          -15.627861022949219,
          -34.371307373046875,
          10.52412223815918,
          2.976038694381714,
          -16.084959030151367,
          -34.33987808227539,
          -9.043839454650879,
          -34.27033233642578,
          -0.4896312654018402,
          22.439590454101562,
          1.1334742307662964,
          22.511451721191406,
          4.5096611976623535,
          -15.593583106994629,
          34.58180236816406,
          -2.0787546634674072,
          -2.7888283729553223,
          35.95374298095703,
          29.064807891845703,
          26.843212127685547,
          55.94771957397461,
          -24.554704666137695,
          -16.275419235229492,
          -31.38620948791504,
          56.53201675415039,
          38.365299224853516,
          7.100322723388672,
          26.85837173461914,
          27.272741317749023,
          -63.22160720825195,
          -43.257469177246094,
          2.905229091644287,
          -1.1849619150161743,
          27.468555450439453,
          -31.197362899780273,
          0.6077654957771301,
          2.079206705093384,
          -34.232200622558594,
          31.609220504760742,
          -5.646757125854492,
          -20.546897888183594,
          26.913841247558594,
          27.503015518188477,
          -18.863018035888672,
          26.827011108398438,
          -43.213706970214844,
          -33.87030029296875,
          24.46040153503418,
          26.830516815185547,
          26.811267852783203,
          28.87446403503418,
          28.99070930480957,
          28.25003433227539,
          -43.25535202026367,
          -24.558727264404297,
          -6.285068035125732,
          5.017289161682129,
          -24.870981216430664,
          -39.78494644165039,
          -17.244590759277344,
          -0.14133203029632568,
          27.845184326171875,
          27.5623722076416,
          -5.232265472412109,
          -12.288980484008789,
          -11.580267906188965,
          -28.062986373901367,
          -39.90675735473633,
          26.28087615966797,
          -25.572677612304688,
          27.102027893066406,
          -23.243215560913086,
          -38.78413772583008,
          18.16939353942871,
          18.14026641845703,
          -63.80373001098633,
          -54.330772399902344,
          -2.3343114852905273,
          8.484342575073242,
          28.2828369140625,
          36.4543571472168,
          -17.986278533935547,
          -0.5694277882575989,
          -21.041818618774414,
          -23.31098747253418,
          36.09557342529297,
          36.4564094543457,
          -50.1801643371582,
          36.11936950683594,
          34.533470153808594,
          12.182116508483887,
          11.114889144897461,
          -17.55268669128418,
          28.110750198364258,
          31.432767868041992,
          27.931154251098633,
          35.337120056152344,
          -19.161705017089844,
          -29.907487869262695,
          54.768287658691406,
          -27.124521255493164,
          -14.591421127319336,
          -22.519542694091797,
          -42.03372573852539,
          -15.998013496398926,
          27.929214477539062,
          1.3140641450881958,
          -16.407564163208008,
          -15.768780708312988,
          -14.471391677856445,
          -26.376907348632812,
          -16.644441604614258,
          -14.520211219787598,
          -0.7810084819793701,
          -46.472347259521484,
          34.837196350097656,
          21.134183883666992,
          -50.367027282714844,
          36.8302116394043,
          -26.559688568115234,
          -33.87211608886719,
          16.764480590820312,
          -37.492061614990234,
          -47.73456954956055,
          -9.263980865478516,
          -9.274089813232422,
          -12.117935180664062,
          -22.63840675354004,
          -10.744404792785645,
          -11.159255027770996,
          -37.317813873291016,
          -8.859552383422852,
          -13.258034706115723,
          -20.445594787597656,
          -38.227691650390625,
          -60.013484954833984,
          -7.977915287017822,
          -40.94364929199219,
          19.797027587890625,
          45.87846374511719,
          -50.954410552978516,
          -59.91904830932617,
          -15.874860763549805,
          34.83805465698242,
          8.525618553161621,
          41.716983795166016,
          -27.603931427001953,
          41.5281982421875,
          31.994688034057617,
          21.959897994995117,
          1.3501887321472168,
          19.773679733276367,
          8.526362419128418,
          14.239150047302246,
          -6.261200904846191,
          -18.99492073059082,
          34.814857482910156,
          8.525609970092773,
          32.81278991699219,
          22.246118545532227,
          0.06132126227021217,
          -16.261396408081055,
          -37.973182678222656,
          -5.773283958435059,
          22.307579040527344,
          55.3657341003418,
          55.33538818359375,
          -60.80317306518555,
          55.58617401123047,
          23.564159393310547,
          -0.3131428360939026,
          -6.887763023376465,
          5.941041469573975,
          39.49971389770508,
          5.549635410308838,
          26.80007553100586,
          54.52632141113281,
          -43.74760818481445,
          39.068214416503906,
          55.7730827331543,
          52.723941802978516,
          55.768821716308594,
          22.539295196533203,
          -16.018497467041016,
          -9.17668342590332,
          -18.428802490234375,
          -18.46799659729004,
          41.933082580566406,
          41.473175048828125,
          23.044723510742188,
          -7.746549129486084,
          -12.14852237701416,
          53.749778747558594,
          39.51808166503906,
          -18.554542541503906,
          -18.3687744140625,
          23.030290603637695,
          -28.530506134033203,
          23.049230575561523,
          23.870920181274414,
          23.888635635375977,
          -29.09745216369629,
          18.156431198120117,
          18.15508460998535,
          18.154964447021484,
          1.939305067062378,
          53.508548736572266,
          43.61199951171875,
          -63.77467727661133,
          -12.36635684967041,
          49.11295700073242,
          49.064186096191406,
          37.51070022583008,
          -6.168350696563721,
          -41.529361724853516,
          -30.276050567626953,
          44.91844940185547,
          -34.55409622192383,
          51.815792083740234,
          29.57223129272461,
          36.55000686645508,
          -60.88249969482422,
          31.436443328857422,
          -8.210823059082031,
          11.98361873626709,
          2.775164842605591,
          -15.875268936157227,
          -26.715375900268555,
          -16.261423110961914,
          -40.525047302246094,
          53.82994842529297,
          54.78132247924805,
          -62.168270111083984,
          -60.41774368286133,
          56.20674514770508,
          -43.74779510498047,
          -20.687788009643555,
          38.716976165771484,
          -16.799884796142578,
          38.593467712402344,
          36.534542083740234,
          20.257295608520508,
          6.275121212005615,
          -1.1506446599960327,
          -38.62018966674805,
          47.90217208862305,
          42.720951080322266,
          -61.64844512939453,
          47.87129211425781,
          45.20467758178711,
          32.16576385498047,
          -11.660372734069824,
          38.30947494506836,
          -24.55592918395996,
          32.16590118408203,
          55.992919921875,
          -16.768659591674805,
          -53.486724853515625,
          -22.484941482543945,
          37.93401336669922,
          45.143924713134766,
          -63.29521179199219,
          -31.084835052490234,
          -19.885208129882812,
          34.27204895019531,
          34.2202033996582,
          38.624691009521484,
          34.842899322509766,
          6.092411518096924,
          -1.5416501760482788,
          35.908164978027344,
          -44.895206451416016,
          34.645774841308594,
          39.42829895019531,
          1.532132863998413,
          -18.914270401000977,
          -30.47245216369629,
          -31.622207641601562,
          -20.291898727416992,
          48.642601013183594,
          48.75535202026367,
          -64.73271942138672,
          -54.873046875,
          48.701690673828125,
          60.7311897277832,
          49.76714324951172,
          52.40284729003906,
          -0.4377194941043854,
          -29.681116104125977,
          60.732601165771484,
          48.71379089355469,
          37.532066345214844,
          -7.2171173095703125,
          -42.790283203125,
          53.855857849121094,
          40.57417678833008,
          -31.29981231689453,
          -31.30779457092285,
          -31.391939163208008,
          12.737082481384277,
          -27.391618728637695,
          0.5807374715805054,
          17.60552978515625,
          -59.87704086303711,
          11.881497383117676,
          -60.04548263549805,
          -53.460243225097656,
          -3.5927021503448486,
          -43.20578384399414,
          -43.133155822753906,
          -45.38538360595703,
          -50.02699661254883,
          -50.24573516845703,
          -42.04377746582031,
          21.334531784057617,
          43.74996566772461,
          -49.8682861328125,
          21.330018997192383,
          10.524153709411621,
          3.4657676219940186,
          10.686485290527344,
          10.419622421264648,
          10.691487312316895,
          -39.3700065612793,
          26.850095748901367,
          55.18239974975586,
          26.85042953491211,
          54.917694091796875,
          -29.703327178955078,
          3.7130863666534424,
          -23.974605560302734,
          8.907052040100098,
          -54.86784362792969,
          -6.411532878875732,
          -42.11336898803711,
          50.30760955810547,
          50.327537536621094,
          -50.43467330932617,
          29.291255950927734,
          12.853118896484375,
          -39.9611701965332,
          24.790855407714844,
          50.366336822509766,
          0.7889687418937683,
          -1.678092122077942,
          -28.15686798095703,
          13.239208221435547,
          -29.745792388916016,
          -13.255960464477539,
          12.419259071350098,
          -34.56061935424805,
          29.291414260864258,
          12.555994987487793,
          24.790884017944336,
          -6.418154239654541,
          -42.11336898803711,
          27.263628005981445,
          27.432283401489258,
          -60.43717575073242,
          27.4439754486084,
          -1.9874367713928223,
          -40.4339485168457,
          -7.622591972351074,
          -24.795177459716797,
          -35.9605712890625,
          -1.4739567041397095,
          -29.543621063232422,
          -19.541973114013672,
          -26.005157470703125,
          -29.701736450195312,
          -1.0531091690063477,
          54.79072570800781,
          55.77562713623047,
          -60.39136505126953,
          -53.48907470703125,
          -8.211004257202148,
          -16.796472549438477,
          1.709120750427246,
          -26.308162689208984,
          -19.831546783447266,
          -21.752471923828125,
          -15.708060264587402,
          -29.745792388916016,
          -27.274328231811523,
          -6.440239906311035,
          0.916865885257721,
          -38.03359603881836,
          -20.27865219116211,
          53.860565185546875,
          -5.120028495788574,
          0.6915380954742432,
          18.263132095336914,
          18.007871627807617,
          -51.343711853027344,
          -57.20554733276367,
          1.8945660591125488,
          12.25832462310791,
          12.517863273620605,
          13.986212730407715,
          14.021300315856934,
          17.606807708740234,
          -12.376352310180664,
          -23.520612716674805,
          -21.892385482788086,
          49.400508880615234,
          42.58659744262695,
          -63.988121032714844,
          49.46723937988281,
          12.682135581970215,
          -28.47957420349121,
          -31.173097610473633,
          -39.1609001159668,
          -18.085289001464844,
          -20.48379135131836,
          -39.41018295288086,
          -41.411109924316406,
          -24.26052474975586,
          -26.047361373901367,
          -6.854062080383301,
          -2.3342599868774414,
          -28.22908592224121,
          -18.687347412109375,
          -23.302480697631836,
          -33.76772689819336,
          58.07390213012695,
          57.93031311035156,
          -65.05130004882812,
          -56.14678955078125,
          58.28866958618164,
          -2.0058162212371826,
          -27.204410552978516,
          17.14528465270996,
          -24.38803482055664,
          0.7889308929443359,
          59.41750717163086,
          59.433284759521484,
          -2.0052521228790283,
          -11.93558120727539,
          25.772581100463867,
          -21.648178100585938,
          -41.27562713623047,
          56.799156188964844,
          53.33761215209961,
          35.70262145996094,
          66.56047821044922,
          17.475595474243164,
          41.21300506591797,
          -65.19400787353516,
          -53.320396423339844,
          17.442035675048828,
          41.06134796142578,
          -12.285616874694824,
          -8.980696678161621,
          16.555147171020508,
          -9.202413558959961,
          -21.38001823425293,
          -43.42856979370117,
          -43.71231460571289,
          -26.489072799682617,
          -16.478891372680664,
          -21.38001823425293,
          -53.2841911315918,
          -14.378630638122559,
          42.94150924682617,
          29.802949905395508,
          -27.403121948242188,
          42.9415168762207,
          -26.586820602416992,
          28.473186492919922,
          -26.9598388671875,
          -22.22983169555664,
          -6.894667625427246,
          55.27177429199219,
          5.250115394592285,
          60.37297058105469,
          35.87908935546875,
          -43.38304138183594,
          -53.2794303894043,
          -26.442371368408203,
          -27.67512321472168,
          -8.865897178649902,
          29.17847442626953,
          29.698026657104492,
          -16.748672485351562,
          30.578035354614258,
          30.512510299682617,
          41.6416015625,
          42.94895935058594,
          58.25945281982422,
          47.4371223449707,
          -50.718414306640625,
          -63.22354507446289,
          37.69626235961914,
          15.022979736328125,
          54.80685806274414,
          24.477874755859375,
          8.525618553161621,
          25.861230850219727,
          59.37184524536133,
          16.455827713012695,
          14.362848281860352,
          14.797124862670898,
          54.80669021606445,
          24.76565170288086,
          8.525572776794434,
          59.38655090332031,
          16.677841186523438,
          59.700042724609375,
          14.660987854003906,
          53.64145278930664,
          54.80685806274414,
          24.73564338684082,
          59.38642120361328,
          16.677749633789062,
          58.178314208984375,
          -6.63856840133667,
          -41.682857513427734,
          49.24469757080078,
          49.043094635009766,
          -46.84254455566406,
          49.12371063232422,
          49.032867431640625,
          -28.47604751586914,
          18.213342666625977,
          37.926753997802734,
          20.744922637939453,
          49.05976104736328,
          13.829739570617676,
          -1.487130045890808,
          49.76736068725586,
          12.673356056213379,
          49.96400833129883,
          -8.663797378540039,
          -43.58076858520508,
          -24.801355361938477,
          13.81155776977539,
          18.909975051879883,
          17.96610450744629,
          20.56707000732422,
          55.75035095214844,
          0.933136522769928,
          22.911571502685547,
          36.78343200683594,
          -66.89248657226562,
          -63.22354507446289,
          51.59091567993164,
          22.103836059570312,
          -9.410773277282715,
          -16.58479118347168,
          24.600210189819336,
          27.672048568725586,
          -9.217111587524414,
          -0.7870458364486694,
          -26.49883270263672,
          -24.260530471801758,
          6.269908905029297,
          7.366094589233398,
          0.6280274987220764,
          8.218505859375,
          38.6929817199707,
          -9.632798194885254,
          10.913006782531738,
          -22.34355354309082,
          22.237239837646484,
          22.856149673461914,
          -23.243215560913086,
          -38.03376388549805,
          -23.893701553344727,
          19.370168685913086,
          60.836387634277344,
          -51.333744049072266,
          -63.22354507446289,
          19.324308395385742,
          -21.874042510986328,
          -21.663774490356445,
          17.55994987487793,
          17.61784553527832,
          16.9659481048584,
          -40.658058166503906,
          -19.341947555541992,
          -23.66543197631836,
          17.271657943725586,
          18.921001434326172,
          -30.805652618408203,
          -8.867355346679688,
          -37.29983139038086,
          46.176490783691406,
          40.857025146484375,
          -47.02847671508789,
          -39.96122360229492,
          -23.831628799438477,
          -37.25276565551758,
          46.83097839355469,
          47.12834548950195,
          52.452354431152344,
          -12.844399452209473,
          -20.4674072265625,
          -12.95617389678955,
          29.573184967041016,
          38.656349182128906,
          -41.165382385253906,
          -29.702360153198242,
          -26.69338607788086,
          53.01225280761719,
          51.4859619140625,
          -36.508995056152344,
          -57.89731216430664,
          47.073978424072266,
          -9.413124084472656,
          -41.77540588378906,
          52.84901428222656,
          48.057472229003906,
          -63.922733306884766,
          49.50004959106445,
          -53.35784149169922,
          -57.66236877441406,
          -4.6706013679504395,
          5.1491289138793945,
          54.21665954589844,
          34.59670639038086,
          -23.257278442382812,
          -21.84561538696289,
          10.796768188476562,
          14.612180709838867,
          -64.44257354736328,
          -61.69839096069336,
          -37.13890075683594,
          11.674737930297852,
          10.86728286743164,
          11.025062561035156,
          -41.376590728759766,
          -26.307802200317383,
          54.971595764160156,
          33.801536560058594,
          -30.010276794433594,
          -29.169755935668945,
          -7.57209587097168,
          -38.53948974609375,
          12.66601848602295,
          55.41600036621094,
          33.802581787109375,
          -15.06786823272705,
          23.83344078063965,
          37.49384307861328,
          -48.90229797363281,
          -62.891090393066406,
          -6.304126262664795,
          -9.746447563171387,
          -9.06906509399414,
          -9.73089599609375,
          -32.35106658935547,
          18.878442764282227,
          -6.285964012145996,
          -39.36962890625,
          54.89691162109375,
          -1.6760456562042236,
          -16.796062469482422,
          -27.705394744873047,
          30.965444564819336,
          -0.2585529386997223,
          -16.796531677246094,
          -27.458818435668945,
          -29.251527786254883,
          11.602478981018066,
          -30.413835525512695,
          -9.686537742614746,
          -9.640326499938965,
          8.4843111038208,
          -5.327448844909668,
          -42.39653778076172,
          -32.78356170654297,
          -6.207386016845703,
          -9.615104675292969,
          -2.8026983737945557,
          -28.48780632019043,
          40.55040740966797,
          36.61708068847656,
          -63.77021789550781,
          -62.363739013671875,
          40.55022048950195,
          10.347870826721191,
          7.042802810668945,
          13.486530303955078,
          -19.506534576416016,
          17.478185653686523,
          22.104663848876953,
          -1.5692954063415527,
          -39.873992919921875,
          -14.32007122039795,
          -14.917542457580566,
          24.738628387451172,
          31.327871322631836,
          8.484116554260254,
          -15.120217323303223,
          29.06473159790039,
          39.954978942871094,
          8.483830451965332,
          -5.042240142822266,
          -37.29983139038086,
          -15.42244815826416,
          24.75647735595703,
          31.30325698852539,
          -19.61356544494629,
          40.24183654785156,
          -15.120519638061523,
          29.06473731994629,
          38.73915481567383,
          1.7663884162902832,
          37.011146545410156,
          36.428497314453125,
          -65.39815521240234,
          -56.68337631225586,
          25.1009578704834,
          36.46321487426758,
          24.710458755493164,
          32.09739303588867,
          32.063175201416016,
          -4.9323248863220215,
          -56.268917083740234,
          -37.73609924316406,
          34.26019287109375,
          -27.415096282958984,
          55.161102294921875,
          -21.97752571105957,
          -22.97574806213379,
          -36.6331672668457,
          25.093908309936523,
          -8.579339981079102,
          -8.676054000854492,
          32.80946350097656,
          24.749534606933594,
          33.11845779418945,
          55.32150650024414,
          -45.61014938354492,
          16.528217315673828,
          23.45330238342285,
          23.434871673583984,
          -48.02927017211914,
          -58.17842102050781,
          -36.239295959472656,
          5.941394805908203,
          -16.66689682006836,
          -18.46368408203125,
          -15.588058471679688,
          -12.583113670349121,
          -47.37268829345703,
          -31.264554977416992,
          40.384098052978516,
          -47.361083984375,
          -2.4964585304260254,
          -22.294328689575195,
          44.971954345703125,
          47.22637176513672,
          -47.746604919433594,
          -2.6283628940582275,
          -6.657016277313232,
          -36.898101806640625,
          -17.98628044128418,
          36.653907775878906,
          36.35429763793945,
          12.951217651367188,
          -0.6366444826126099,
          50.6596794128418,
          14.235629081726074,
          -29.702510833740234,
          -1.0744448900222778,
          -38.03282928466797,
          -26.307693481445312,
          -7.662199974060059,
          -2.5620477199554443,
          -32.46687698364258,
          -17.507944107055664,
          -21.745752334594727,
          -30.5874080657959,
          35.6519775390625,
          13.659273147583008,
          -35.535377502441406,
          -5.0551838874816895,
          -1.569272518157959,
          59.749595642089844,
          60.49654769897461,
          -64.81905364990234,
          59.12851333618164,
          -0.8186777830123901,
          41.08659362792969,
          -8.517032623291016,
          26.014394760131836,
          1.7973790168762207,
          56.01532745361328,
          -41.31698989868164,
          -30.429052352905273,
          -16.747100830078125,
          -16.739850997924805,
          -29.952634811401367,
          -8.85411262512207,
          39.0858268737793,
          20.292644500732422,
          -31.938005447387695,
          -8.570636749267578,
          -6.518503665924072,
          -1.5688427686691284,
          -41.00739669799805,
          46.26740264892578,
          46.238182067871094,
          -43.06265640258789,
          -43.06855392456055,
          46.449886322021484,
          -66.40042877197266,
          -36.47296142578125,
          -4.047745227813721,
          46.073509216308594,
          3.630337715148926,
          32.99918746948242,
          -19.662370681762695,
          -13.204181671142578,
          3.630506992340088,
          -26.096189498901367,
          32.9991455078125,
          -22.782482147216797,
          -56.880889892578125,
          -1.2722561359405518,
          -1.6627963781356812,
          -44.118160247802734,
          12.956952095031738,
          17.232934951782227,
          -65.10200500488281,
          4.450407981872559,
          19.358779907226562,
          12.956877708435059,
          13.946996688842773,
          13.785552024841309,
          14.533567428588867,
          9.021305084228516,
          9.256631851196289,
          14.406657218933105,
          9.80803394317627,
          13.591203689575195,
          14.840576171875,
          13.470282554626465,
          12.327454566955566,
          12.366048812866211,
          -32.80521011352539,
          11.454777717590332,
          9.458605766296387,
          12.196051597595215,
          11.451775550842285,
          11.63417911529541,
          -1.0530787706375122,
          11.014595985412598,
          14.60500717163086,
          -64.4198226928711,
          -63.0749397277832,
          -37.25276565551758,
          11.674556732177734,
          11.0390043258667,
          31.680099487304688,
          -26.27070426940918,
          -40.59752655029297,
          -26.619583129882812,
          55.94243240356445,
          33.8007926940918,
          -30.01025390625,
          -29.68792152404785,
          -7.4284892082214355,
          -38.539146423339844,
          -25.368131637573242,
          54.16737365722656,
          34.8795166015625,
          43.412296295166016,
          43.19768524169922,
          -64.84224700927734,
          -40.820281982421875,
          56.434104919433594,
          43.49089813232422,
          -31.27808952331543,
          43.336952209472656,
          -38.768070220947266,
          51.40558624267578,
          -39.27214431762695,
          42.1273307800293,
          -20.845380783081055,
          -5.808839797973633,
          -41.97964096069336,
          28.342853546142578,
          28.605331420898438,
          28.279151916503906,
          36.808231353759766,
          39.16461181640625,
          -65.24503326416016,
          -1.3392281532287598,
          -1.1491683721542358,
          36.62432098388672,
          -1.1585768461227417,
          -22.261005401611328,
          -1.0529234409332275,
          -3.7427423000335693,
          -39.36962890625,
          -13.955668449401855,
          -29.201366424560547,
          -2.2325894832611084,
          -2.4521994590759277,
          -24.556034088134766,
          36.70462417602539,
          -1.1494674682617188,
          -5.625092029571533,
          -40.48884582519531,
          -20.318334579467773,
          57.799652099609375,
          57.662200927734375,
          33.72578430175781,
          -4.178196430206299,
          -20.327573776245117,
          31.67455291748047,
          35.42746353149414,
          -48.71027755737305,
          32.02351760864258,
          32.15928649902344,
          16.912429809570312,
          -17.324045181274414,
          16.908418655395508,
          -7.018992900848389,
          15.096667289733887,
          30.057743072509766,
          31.64500617980957,
          6.112773895263672,
          10.341732025146484,
          21.160573959350586,
          20.7940673828125,
          -4.6753435134887695,
          -6.970796585083008,
          -29.84586524963379,
          20.473419189453125,
          19.926164627075195,
          -48.39933776855469,
          -19.329036712646484,
          22.083303451538086,
          30.82301139831543,
          21.419967651367188,
          23.550357818603516,
          21.693344116210938,
          18.950942993164062,
          19.90582275390625,
          22.33462142944336,
          -18.66189956665039,
          -18.616214752197266,
          60.295135498046875,
          19.83474349975586,
          3.028965950012207,
          18.840665817260742,
          9.30726146697998,
          -1.2701470851898193,
          60.32975769042969,
          21.248497009277344,
          -58.18022537231445,
          -6.242323875427246,
          50.54008102416992,
          50.24810028076172,
          -63.358428955078125,
          42.1176643371582,
          43.35911560058594,
          43.07120895385742,
          43.14630126953125,
          35.19334411621094,
          -56.700252532958984,
          42.2861328125,
          42.914710998535156,
          17.689741134643555,
          11.748126983642578,
          42.09854507446289,
          16.53858757019043,
          12.262236595153809,
          12.062777519226074,
          -33.05702590942383,
          -2.1869699954986572,
          -35.41720962524414,
          30.79930877685547,
          10.509845733642578,
          51.23603057861328,
          50.64535140991211,
          -20.173521041870117,
          -16.996793746948242,
          -11.608071327209473,
          50.434234619140625,
          51.08834457397461,
          50.48291015625,
          6.064304828643799,
          -9.059225082397461,
          34.81563949584961,
          47.017181396484375,
          51.17718505859375,
          50.478755950927734,
          47.01755142211914,
          -21.33785057067871,
          -21.181743621826172,
          0.7278069853782654,
          0.9208502769470215,
          0.8304665684700012,
          3.9541056156158447,
          -0.1744316965341568,
          -1.430166482925415,
          -9.749192237854004,
          -2.501880645751953,
          -2.001486301422119,
          -3.290865898132324,
          -1.8311198949813843,
          -0.7479804754257202,
          -17.98655891418457,
          -18.170503616333008,
          19.589935302734375,
          21.089393615722656,
          22.404272079467773,
          -17.92696189880371,
          -18.97517967224121,
          -3.091557025909424,
          -15.47740364074707,
          -29.845964431762695,
          -26.19047737121582,
          0.7437911629676819,
          -30.413835525512695,
          -1.4217357635498047,
          -9.761873245239258,
          -16.274478912353516,
          -45.21253204345703,
          42.42448425292969,
          42.25795364379883,
          -49.93489074707031,
          -3.2221195697784424,
          -14.0101957321167,
          -14.105280876159668,
          -29.476106643676758,
          1.3360087871551514,
          42.910186767578125,
          -15.148947715759277,
          -19.097475051879883,
          -21.97752571105957,
          -19.63213539123535,
          -19.158937454223633,
          -19.56092071533203,
          -19.465423583984375,
          -1.5688602924346924,
          -1.3464981317520142,
          4.893725395202637,
          33.898468017578125,
          33.275787353515625,
          -49.85051345825195,
          33.89662170410156,
          32.90863037109375,
          32.27369689941406,
          1.8243627548217773,
          -38.18954849243164,
          0.7895461320877075,
          -19.385467529296875,
          -21.907672882080078,
          -29.745792388916016,
          -60.496337890625,
          -8.719780921936035,
          -38.99027633666992,
          23.479066848754883,
          40.44648742675781,
          -61.6443977355957,
          -39.95983123779297,
          -56.473777770996094,
          -39.361488342285156,
          -20.204875946044922,
          -21.753414154052734,
          -22.853755950927734,
          -41.97964096069336,
          31.671358108520508,
          30.665699005126953,
          -62.23379898071289,
          -31.142616271972656,
          37.73038101196289,
          0.5197954177856445,
          31.710966110229492,
          39.56766128540039,
          32.891475677490234,
          16.661800384521484,
          35.5887565612793,
          19.539262771606445,
          30.07808494567871,
          20.947206497192383,
          36.74530792236328,
          32.70802307128906,
          30.95085334777832,
          44.666744232177734,
          2.5073001384735107,
          -20.459943771362305,
          -15.996086120605469,
          25.217124938964844,
          36.49104309082031,
          31.48663902282715,
          45.95840835571289,
          43.19847106933594,
          -61.36342239379883,
          -56.048397064208984,
          -20.807207107543945,
          -37.13966369628906,
          -26.440698623657227,
          -1.599465250968933,
          -41.05915832519531,
          35.774723052978516,
          34.224178314208984,
          -50.71604919433594,
          -60.70654296875,
          -11.037708282470703,
          2.7404141426086426,
          -19.731578826904297,
          -19.566585540771484,
          -19.385473251342773,
          -11.055939674377441,
          -27.084474563598633,
          -22.070659637451172,
          -40.17809295654297,
          46.51161575317383,
          43.34429168701172,
          -60.257972717285156,
          30.958921432495117,
          3.1509151458740234,
          23.020275115966797,
          -7.926578998565674,
          56.27296829223633,
          -17.451683044433594,
          -8.210969924926758,
          27.367294311523438,
          55.291839599609375,
          4.548783302307129,
          34.74729919433594,
          37.535247802734375,
          27.368078231811523,
          55.359291076660156,
          38.48991012573242,
          45.40987014770508,
          43.02278518676758,
          46.95425033569336,
          1.1571887731552124,
          -43.58174514770508,
          -41.486717224121094,
          -3.5097947120666504,
          0.9273143410682678,
          -4.1989665031433105,
          -3.223940372467041,
          -2.4910264015197754,
          -2.4390411376953125,
          -2.9254753589630127,
          -16.017860412597656,
          -16.051551818847656,
          0.4594346582889557,
          32.11445617675781,
          21.561046600341797,
          22.891162872314453,
          -10.322761535644531,
          -9.634825706481934,
          -10.255294799804688,
          -11.755209922790527,
          -9.739202499389648,
          -11.745675086975098,
          -10.28431510925293,
          -10.257508277893066,
          -10.454272270202637,
          -10.135854721069336,
          27.368078231811523,
          55.509063720703125,
          -31.257308959960938,
          45.03370666503906,
          41.906436920166016,
          -60.32497024536133,
          46.279998779296875,
          30.38909149169922,
          45.21482467651367,
          43.23026657104492,
          38.295433044433594,
          38.432918548583984,
          54.55409622192383,
          38.24357223510742,
          43.360836029052734,
          53.88805389404297,
          45.15443420410156,
          45.658199310302734,
          45.61186981201172,
          45.38214111328125,
          -0.47797688841819763,
          -4.652259826660156,
          -29.246347427368164,
          0.33903998136520386,
          -41.05915832519531,
          37.08928298950195,
          34.056636810302734,
          -2.515315294265747,
          -54.5423698425293,
          -29.952930450439453,
          -29.175209045410156,
          -13.438833236694336,
          -42.64572525024414,
          -54.5424690246582,
          -29.952590942382812,
          -29.175209045410156,
          -13.438834190368652,
          -44.84518051147461,
          -54.54225158691406,
          -29.952930450439453,
          -29.175119400024414,
          -13.438834190368652,
          12.41020393371582,
          12.832698822021484,
          -48.28328323364258,
          7.121510028839111,
          4.756263256072998,
          -47.73584747314453,
          1.2444431781768799,
          -11.019347190856934,
          -22.13368034362793,
          8.694724082946777,
          41.41102600097656,
          -29.087278366088867,
          -40.90712356567383,
          -0.9011258482933044,
          -38.03306198120117,
          -25.588199615478516,
          -21.041709899902344,
          -1.8123401403427124,
          -2.7497808933258057,
          -2.7979445457458496,
          1.18387770652771,
          6.133779048919678,
          7.157501697540283,
          -35.5354118347168,
          -19.966753005981445,
          7.121127605438232,
          0.8381136655807495,
          -37.62331008911133,
          38.93545913696289,
          39.03363800048828,
          -66.1024398803711,
          0.6057268381118774,
          0.5576624870300293,
          -29.8701114654541,
          -26.056102752685547,
          -26.07918930053711,
          -39.79303741455078,
          1.4157882928848267,
          -38.262088775634766,
          45.1321907043457,
          45.105342864990234,
          -61.021541595458984,
          -55.56333541870117,
          -30.180063247680664,
          -24.794979095458984,
          -37.25276565551758,
          9.551835060119629,
          10.115697860717773,
          28.125869750976562,
          -40.658058166503906,
          -29.106515884399414,
          -22.299007415771484,
          28.123647689819336,
          -13.847635269165039,
          7.645988464355469,
          -20.48379135131836,
          45.9896125793457,
          23.7390079498291,
          23.74709701538086,
          -61.96418762207031,
          -63.22354507446289,
          8.578093528747559,
          29.201444625854492,
          16.794273376464844,
          19.5120849609375,
          -11.459980010986328,
          24.061508178710938,
          4.444145679473877,
          0.6484473347663879,
          -15.61642074584961,
          0.6993164420127869,
          -13.127923965454102,
          2.2125940322875977,
          1.1578515768051147,
          4.094538688659668,
          24.55656623840332,
          45.6779899597168,
          45.889530181884766,
          -1.77998685836792,
          -16.60357666015625,
          -20.320524215698242,
          8.63335132598877,
          17.177141189575195,
          8.68712329864502,
          -29.745792388916016,
          -28.33958625793457,
          28.754514694213867,
          -32.070411682128906,
          -32.05747985839844,
          4.0817484855651855,
          8.678491592407227,
          29.7155704498291,
          2.862780809402466,
          0.5207618474960327,
          -36.6331672668457,
          -1.6618764400482178,
          -35.10122299194336,
          10.40321159362793,
          38.43705368041992,
          -48.41252517700195,
          -62.89109420776367,
          20.264423370361328,
          10.523659706115723,
          46.96274948120117,
          10.467768669128418,
          -22.773754119873047,
          -23.002864837646484,
          40.68766403198242,
          -38.18756866455078,
          -2.467715263366699,
          34.259639739990234,
          55.49276351928711,
          0.7785950303077698,
          -37.21698760986328,
          2.410196304321289,
          2.3780252933502197,
          -48.23701858520508,
          -36.23929214477539,
          -0.15512120723724365,
          19.539134979248047,
          26.26873016357422,
          26.34359359741211,
          51.647239685058594,
          51.667381286621094,
          37.8304328918457,
          31.087392807006836,
          51.57140350341797,
          51.45718002319336,
          -27.092771530151367,
          19.7584171295166,
          -1.218214750289917,
          20.268375396728516,
          11.616239547729492,
          -13.19771671295166,
          51.35833740234375,
          30.359237670898438,
          30.226957321166992,
          51.32304382324219,
          -21.39579200744629,
          -28.5390682220459,
          -25.817792892456055,
          27.26268196105957,
          27.080230712890625,
          -49.80588150024414,
          -34.378944396972656,
          -34.26600646972656,
          -33.87334060668945,
          -40.29292678833008,
          17.991106033325195,
          -37.636592864990234,
          -42.3695182800293,
          -37.64118194580078,
          14.492271423339844,
          -53.12510299682617,
          -4.376809120178223,
          -20.853059768676758,
          -20.631221771240234,
          -20.74420738220215,
          -2.337287187576294,
          -2.2433254718780518,
          -43.570987701416016,
          -42.39653778076172,
          -50.027320861816406,
          -18.407608032226562,
          -26.943235397338867,
          -26.945476531982422,
          -46.408199310302734,
          47.6130256652832,
          38.98358154296875,
          -50.71623611450195,
          -60.55317306518555,
          40.920204162597656,
          53.03272247314453,
          25.15445899963379,
          38.771087646484375,
          46.844600677490234,
          27.369422912597656,
          -16.728174209594727,
          -36.87020492553711,
          31.572629928588867,
          36.75716018676758,
          -62.5836181640625,
          -55.196712493896484,
          -38.141353607177734,
          -18.219316482543945,
          20.56228256225586,
          -28.61726951599121,
          -17.536508560180664,
          -39.85109329223633,
          1.1864475011825562,
          -24.23969268798828,
          -12.538920402526855,
          -1.354375958442688,
          -30.461563110351562,
          -29.119447708129883,
          31.729881286621094,
          -35.605323791503906,
          -1.599465250968933,
          -38.11651611328125,
          45.4490966796875,
          41.927154541015625,
          -63.666996002197266,
          41.32882308959961,
          35.73762893676758,
          28.112503051757812,
          35.664615631103516,
          57.17995834350586,
          44.99440383911133,
          -43.74763870239258,
          43.8575325012207,
          -15.874804496765137,
          -20.693443298339844,
          41.882022857666016,
          41.82052993774414,
          15.917637825012207,
          15.24045181274414,
          14.04300308227539,
          15.856648445129395,
          14.435883522033691,
          43.31513977050781,
          15.45114517211914,
          14.336636543273926,
          14.240133285522461,
          14.445435523986816,
          -7.702641487121582,
          26.825542449951172,
          12.837952613830566,
          -62.96907424926758,
          -53.35645294189453,
          12.721893310546875,
          40.356693267822266,
          13.20236587524414,
          24.329057693481445,
          24.333995819091797,
          -37.89830017089844,
          40.348026275634766,
          -37.781131744384766,
          21.242786407470703,
          22.245563507080078,
          -24.869672775268555,
          -31.48442840576172,
          -36.755001068115234,
          -36.63525390625,
          -29.972427368164062,
          57.296749114990234,
          57.12297439575195,
          56.472835540771484,
          13.799276351928711,
          13.806640625,
          42.062564849853516,
          42.04819869995117,
          -43.64975357055664,
          -37.94313430786133,
          3.398730993270874,
          -38.6475944519043,
          21.21866226196289,
          22.25017738342285,
          -38.6087646484375,
          -38.62732696533203,
          -8.516343116760254,
          -45.21253204345703,
          35.22255325317383,
          40.48456573486328,
          -47.794158935546875,
          39.14301300048828,
          17.87866973876953,
          -24.797103881835938,
          35.16482162475586,
          24.94093132019043,
          35.28813552856445,
          17.873056411743164,
          20.192150115966797,
          20.249649047851562,
          20.3251895904541,
          18.921825408935547,
          -26.488351821899414,
          -39.54677200317383,
          -24.26053237915039,
          -21.75274085998535,
          -26.453001022338867,
          -28.90897560119629,
          -37.64969253540039,
          0.21130266785621643,
          -57.057979583740234,
          -7.14106559753418,
          -42.081844329833984,
          2.997518301010132,
          -31.903610229492188,
          -31.397459030151367,
          -31.403440475463867,
          -31.382017135620117,
          -31.920984268188477,
          36.4859733581543,
          41.583343505859375,
          -47.588417053222656,
          35.14216232299805,
          36.274436950683594,
          36.57872772216797,
          20.22524642944336,
          19.831024169921875,
          38.563594818115234,
          -21.10213851928711,
          33.7958869934082,
          -39.0711669921875,
          38.06565475463867,
          33.739356994628906,
          -23.699132919311523,
          -7.126617908477783,
          -37.62419509887695,
          14.019783020019531,
          -29.597658157348633,
          -63.51568603515625,
          -54.24654006958008,
          -38.19586944580078,
          -3.1215009689331055,
          -3.7764360904693604,
          5.50975227355957,
          54.23784637451172,
          -3.921170711517334,
          -12.17656421661377,
          -13.487424850463867,
          17.28424072265625,
          27.368152618408203,
          -13.705280303955078,
          -11.570759773254395,
          28.108787536621094,
          -29.55336570739746,
          -21.66383171081543,
          46.41122055053711,
          43.41126251220703,
          -62.47606658935547,
          -53.88453674316406,
          56.40858459472656,
          56.385414123535156,
          56.794898986816406,
          19.711097717285156,
          46.09327697753906,
          56.142112731933594,
          -41.27040100097656,
          56.52978515625,
          56.60679626464844,
          -23.93718910217285,
          -24.311811447143555,
          19.711008071899414,
          -13.8886079788208,
          56.14228820800781,
          -24.311796188354492,
          -23.937360763549805,
          -7.799031734466553,
          17.70905876159668,
          19.960378646850586,
          -63.29542922973633,
          -24.163087844848633,
          -46.70262145996094,
          28.97116470336914,
          -56.68965530395508,
          0.12501157820224762,
          19.41202163696289,
          34.78559494018555,
          3.135300874710083,
          -18.507558822631836,
          18.746112823486328,
          17.834270477294922,
          19.798934936523438,
          3.1508967876434326,
          -5.7336015701293945,
          -36.28786087036133,
          -21.62749481201172,
          -37.1203727722168,
          -0.759864091873169,
          3.146531105041504,
          29.064760208129883,
          -21.62739372253418,
          -39.08736038208008,
          -16.528179168701172,
          28.782922744750977,
          -36.38211441040039,
          3.149057626724243,
          37.45143508911133,
          -22.3811092376709,
          -23.5345516204834,
          49.80271911621094,
          41.85245132446289,
          7.910989761352539,
          30.64134979248047,
          31.64248275756836,
          -64.29393768310547,
          -56.232940673828125,
          66.5623779296875,
          30.928653717041016,
          31.83050537109375,
          -8.807167053222656,
          -41.92464828491211,
          -0.37004581093788147,
          -29.041927337646484,
          -23.665430068969727,
          -29.745792388916016,
          -23.100088119506836,
          -35.535404205322266,
          -7.5594353675842285,
          -41.49496841430664,
          44.390953063964844,
          44.05134963989258,
          -65.622314453125,
          -56.02265167236328,
          32.33721923828125,
          36.21501541137695,
          36.366661071777344,
          -62.05129623413086,
          -61.63398361206055,
          36.205841064453125,
          -6.140352249145508,
          0.9994665384292603,
          -11.531929969787598,
          -7.337538719177246,
          39.09790802001953,
          39.278785705566406,
          -16.0849609375,
          0.7889315485954285,
          34.261810302734375,
          56.13758087158203,
          30.965534210205078,
          -21.97752571105957,
          -5.242763042449951,
          -29.846134185791016,
          -44.6854133605957,
          -7.321005344390869,
          -20.498394012451172,
          13.721227645874023,
          14.574274063110352,
          -47.3609619140625,
          -57.45378875732422,
          15.505826950073242,
          15.4857177734375,
          15.220589637756348,
          15.673979759216309,
          12.371195793151855,
          15.065149307250977,
          -1.139557957649231,
          9.414379119873047,
          -33.208152770996094,
          -33.19796371459961,
          -15.158834457397461,
          14.092059135437012,
          14.157800674438477,
          -15.27520751953125,
          8.487010955810547,
          8.520874977111816,
          54.03636932373047,
          57.21393585205078,
          -15.99610424041748,
          5.8299760818481445,
          44.97807693481445,
          -48.1370849609375,
          -57.16795349121094,
          -3.7764859199523926,
          14.084439277648926,
          16.115262985229492,
          51.066688537597656,
          -12.391873359680176,
          34.54633331298828,
          -31.578041076660156,
          3.1495985984802246,
          -12.491883277893066,
          14.070390701293945,
          36.82765197753906,
          34.54680252075195,
          -16.597654342651367,
          -22.495346069335938,
          -22.570537567138672,
          -23.00893783569336,
          -21.37343406677246,
          -45.21253204345703,
          22.974210739135742,
          37.83003616333008,
          -64.86686706542969,
          22.948158264160156,
          -27.921842575073242,
          -2.900195360183716,
          -24.93470001220703,
          -2.6300926208496094,
          -24.939210891723633,
          -2.922607898712158,
          -24.939210891723633,
          -20.578855514526367,
          31.255220413208008,
          -4.630190849304199,
          31.201887130737305,
          22.9848690032959,
          -57.40658187866211,
          -6.61176872253418,
          36.750457763671875,
          24.171863555908203,
          -36.495445251464844,
          55.20150375366211,
          60.374114990234375,
          34.8988037109375,
          -4.519362926483154,
          -37.12019348144531,
          27.33302116394043,
          37.58854675292969,
          -48.63066101074219,
          27.434616088867188,
          28.877368927001953,
          -30.02232551574707,
          -45.9600830078125,
          -8.1013765335083,
          16.285438537597656,
          -47.463104248046875,
          -14.745636940002441,
          17.17804527282715,
          3.1894707679748535,
          -9.04659366607666,
          -9.480239868164062,
          -9.978156089782715,
          -15.477313995361328,
          -15.750494956970215,
          -18.186256408691406,
          -14.973871231079102,
          -9.673325538635254,
          -40.167518615722656,
          6.3269500732421875,
          -8.677291870117188,
          -16.0849609375,
          -9.941228866577148,
          -8.005026817321777,
          -36.90304946899414,
          -29.2530574798584,
          -28.04753875732422,
          -11.608209609985352,
          -11.419384956359863,
          -11.603913307189941,
          -5.392578125,
          -9.101868629455566,
          -8.99209976196289,
          -9.1907377243042,
          16.262004852294922,
          -7.669066905975342,
          42.048301696777344,
          42.18619155883789,
          -61.22578811645508,
          41.632469177246094,
          17.232627868652344,
          49.93722915649414,
          41.700042724609375,
          52.42795944213867,
          8.873089790344238,
          41.63641357421875,
          0.7439944744110107,
          -1.3019157648086548,
          -40.32328796386719,
          -44.76480484008789,
          40.78842544555664,
          4.511865139007568,
          6.935394287109375,
          24.15854263305664,
          57.97047805786133,
          42.07565689086914,
          53.99463653564453,
          37.49610137939453,
          -59.46702575683594,
          -56.4235725402832,
          20.17266082763672,
          51.07041549682617,
          38.346195220947266,
          32.19062805175781,
          33.4365348815918,
          37.42192077636719,
          -38.19586944580078,
          50.79378890991211,
          -2.0305798053741455,
          -0.780604362487793,
          -24.861465454101562,
          23.70829963684082,
          32.167701721191406,
          48.63007354736328,
          21.946491241455078,
          -15.182723045349121,
          30.09673500061035,
          33.371219635009766,
          49.02643966674805,
          -15.182807922363281,
          -29.425647735595703,
          7.2159647941589355,
          7.229001045227051,
          37.42353820800781,
          49.01353073120117,
          -15.182806968688965,
          39.59965133666992,
          24.019268035888672,
          30.8790340423584,
          30.096742630004883,
          25.80820083618164,
          39.6568603515625,
          -21.707544326782227,
          -16.10723304748535,
          49.17634201049805,
          51.421791076660156,
          -30.81387710571289,
          -2.919295072555542,
          -22.062496185302734,
          -37.48623275756836,
          25.81402015686035,
          30.09687614440918,
          25.798015594482422,
          -11.028511047363281,
          -26.44065284729004,
          37.627628326416016,
          37.64460754394531,
          -63.08277130126953,
          27.64521598815918,
          -37.83911895751953,
          8.164735794067383,
          -3.5233137607574463,
          -6.527177333831787,
          31.164587020874023,
          38.7373161315918,
          -9.362683296203613,
          23.466106414794922,
          -27.80239486694336,
          -6.494636058807373,
          -15.451167106628418,
          -6.224303245544434,
          -22.451353073120117,
          -24.359779357910156,
          -27.80279541015625,
          -29.28007698059082,
          -5.716671466827393,
          -38.53948974609375,
          6.96173095703125,
          -3.6235005855560303,
          -27.227304458618164,
          23.633808135986328,
          55.64599609375,
          23.633699417114258,
          45.851985931396484,
          34.369224548339844,
          34.07373046875,
          47.19252395629883,
          32.05785369873047,
          15.59677791595459,
          34.308650970458984,
          15.556625366210938,
          -7.920361042022705,
          45.702430725097656,
          47.222904205322266,
          40.63490676879883,
          41.070220947265625,
          40.61454391479492,
          32.44504928588867,
          32.831993103027344,
          41.83625411987305,
          34.38761520385742,
          -27.500566482543945,
          55.53907775878906,
          -44.85913848876953,
          28.190444946289062,
          33.25844955444336,
          26.602445602416992,
          -16.159093856811523,
          -21.02900505065918,
          34.164608001708984,
          36.735233306884766,
          -62.777503967285156,
          -53.7358512878418,
          -18.916061401367188,
          17.636096954345703,
          35.9340934753418,
          -38.895145416259766,
          -28.631427764892578,
          -45.48368835449219,
          -28.631427764892578,
          -45.481956481933594,
          -28.631427764892578,
          -45.481964111328125,
          -29.15720558166504,
          -35.12635040283203,
          34.048072814941406,
          -12.885921478271484,
          -22.958288192749023,
          -37.146270751953125,
          44.73895263671875,
          42.404876708984375,
          -61.298126220703125,
          -54.43157196044922,
          4.515262603759766,
          -12.664957046508789,
          16.791996002197266,
          25.05077362060547,
          10.52412223815918,
          11.673237800598145,
          -11.170953750610352,
          -28.370487213134766,
          -38.17226791381836,
          55.96113586425781,
          -29.952634811401367,
          14.835298538208008,
          11.510089874267578,
          -4.832553386688232,
          0.8531694412231445,
          -39.96455001831055,
          -7.470273494720459,
          6.772777080535889,
          -22.062496185302734,
          14.577032089233398,
          14.577388763427734,
          -9.751054763793945,
          8.621787071228027,
          38.16542053222656,
          -50.118595123291016,
          24.996646881103516,
          25.409696578979492,
          10.41801643371582,
          13.241066932678223,
          -37.97895431518555,
          26.380077362060547,
          5.625420570373535,
          10.384169578552246,
          -29.720962524414062,
          -29.887699127197266,
          -29.595767974853516,
          -28.394527435302734,
          -60.429813385009766,
          -6.907137393951416,
          -40.94364929199219,
          -40.341575622558594,
          -36.495662689208984,
          -1.631196141242981,
          36.4632682800293,
          36.31100845336914,
          10.417840003967285,
          66.56420135498047,
          66.57880401611328,
          -64.2583236694336,
          -37.12057113647461,
          17.02271270751953,
          -24.608734130859375,
          1.2685775756835938,
          43.00814437866211,
          -25.334552764892578,
          -24.164905548095703,
          4.8690361976623535,
          4.894158363342285,
          -41.411109924316406,
          -8.84512710571289,
          -16.050464630126953,
          -26.60938835144043,
          -32.04653549194336,
          -19.849512100219727,
          0.9621286392211914,
          -20.528514862060547,
          -21.37343406677246,
          55.487125396728516,
          55.64411544799805,
          -62.8912353515625,
          -54.90781784057617,
          50.2919921875,
          -3.5394339561462402,
          50.26640319824219,
          50.84671401977539,
          28.791881561279297,
          -19.762651443481445,
          -15.496045112609863,
          26.129674911499023,
          -53.825889587402344,
          -39.155601501464844,
          49.97663497924805,
          -1.4276427030563354,
          30.862884521484375,
          50.68961715698242,
          -8.58367919921875,
          1.538811445236206,
          49.86494064331055,
          49.819950103759766,
          47.16728591918945,
          48.292484283447266,
          -62.63844680786133,
          -40.7312126159668,
          38.50852584838867,
          34.89875411987305,
          37.665348052978516,
          -1.2484493255615234,
          18.53678321838379,
          18.21624755859375,
          18.72740936279297,
          -4.832748889923096,
          -2.0113751888275146,
          7.582187175750732,
          -2.082224130630493,
          -0.5831251740455627,
          -6.89569091796875,
          -23.535140991210938,
          -50.821319580078125,
          47.73091506958008,
          46.78703308105469,
          -64.5535888671875,
          -55.17295837402344,
          13.478446960449219,
          -7.1987128257751465,
          46.827911376953125,
          6.673051357269287,
          -37.13890075683594,
          47.63901901245117,
          53.36408996582031,
          -7.126863956451416,
          12.569013595581055,
          0.9149863123893738,
          -8.64323902130127,
          -8.517573356628418,
          -22.958288192749023,
          -37.814170837402344,
          46.40126419067383,
          46.381675720214844,
          -51.24414825439453,
          37.88093185424805,
          1.5644738674163818,
          -17.739160537719727,
          -21.438217163085938,
          -9.28432846069336,
          32.55474090576172,
          37.25634002685547,
          -50.51919937133789,
          -60.17666244506836,
          -47.73660659790039,
          33.45030975341797,
          33.29563522338867,
          13.529888153076172,
          23.01470947265625,
          4.896081924438477,
          33.80376434326172,
          56.137821197509766,
          33.91728210449219,
          17.99295425415039,
          -4.784492015838623,
          -8.130743026733398,
          4.895833969116211,
          33.801177978515625,
          55.993370056152344,
          34.52833557128906,
          17.993118286132812,
          -35.534488677978516,
          34.607295989990234,
          36.38192367553711,
          36.3258171081543,
          41.91126251220703,
          -63.36243438720703,
          38.243221282958984,
          -40.731082916259766,
          34.62024688720703,
          38.59524154663086,
          -0.34632954001426697,
          -19.01521873474121,
          -7.3261260986328125,
          -5.525881290435791,
          -23.50433921813965,
          -1.3019157648086548,
          57.1892204284668,
          43.605228424072266,
          -50.78953552246094,
          -15.26486587524414,
          -0.14884653687477112,
          -14.080890655517578,
          2.5669679641723633,
          -19.572357177734375,
          -2.5163943767547607,
          1.1385611295700073,
          -3.8918402194976807,
          3.494896411895752,
          -22.842926025390625,
          2.577497959136963,
          -3.868698835372925,
          -7.661509990692139,
          -1.443076729774475,
          -55.472652435302734,
          1.3510030508041382,
          -41.00739669799805,
          11.115159034729004,
          11.436891555786133,
          -63.11988830566406,
          -57.055397033691406,
          24.992162704467773,
          12.014758110046387,
          9.432907104492188,
          7.000799179077148,
          -10.290583610534668,
          -37.78160858154297,
          0.6683504581451416,
          12.092500686645508,
          46.26107406616211,
          33.12612533569336,
          55.1362419128418,
          12.014912605285645,
          9.432765007019043,
          -41.41110610961914,
          12.014870643615723,
          9.432907104492188,
          12.014779090881348,
          9.432907104492188,
          -25.920013427734375,
          11.871319770812988,
          9.633617401123047,
          -21.289703369140625,
          3.162776231765747,
          42.96437072753906,
          13.361654281616211,
          -25.745134353637695,
          0.1421317607164383,
          45.75288391113281,
          0.780015230178833,
          1.234580397605896,
          -62.75736618041992,
          -0.30636727809906006,
          0.3499947786331177,
          0.34148848056793213,
          -40.90700912475586,
          0.8101037740707397,
          4.596333980560303,
          -38.231754302978516,
          15.156609535217285,
          17.538793563842773,
          -11.23826789855957,
          -38.23165512084961,
          15.15734577178955,
          17.538488388061523,
          -38.232173919677734,
          15.143157958984375,
          17.606019973754883,
          -29.885021209716797,
          -25.59090232849121,
          -0.9595116376876831,
          -1.0147719383239746,
          -1.2616010904312134,
          0.10470651835203171,
          0.3693961501121521,
          0.19836881756782532,
          4.481331825256348,
          -0.9586219787597656,
          -22.199609756469727,
          -5.392554759979248,
          30.245746612548828,
          -0.3063720762729645,
          -7.393115997314453,
          -13.067292213439941,
          43.57986831665039,
          -60.25834655761719,
          -55.90243148803711,
          2.9197399616241455,
          39.97296905517578,
          2.9197399616241455,
          39.97284698486328,
          -20.905506134033203,
          1.2181737422943115,
          -45.21253204345703,
          36.93544387817383,
          36.69887924194336,
          -59.54523849487305,
          39.88093185424805,
          -31.550796508789062,
          -30.76560401916504,
          47.140892028808594,
          47.13867950439453,
          47.415016174316406,
          10.513154029846191,
          46.49114227294922,
          18.370159149169922,
          -21.28373908996582,
          35.45748519897461,
          35.648006439208984,
          -20.320232391357422,
          23.1343994140625,
          23.101232528686523,
          36.87278366088867,
          17.927698135375977,
          -21.13449478149414,
          -18.832368850708008,
          31.058080673217773,
          -13.572846412658691,
          -15.855672836303711,
          10.25662612915039,
          -21.12276268005371,
          -22.16535758972168,
          -7.39127254486084,
          47.33926010131836,
          37.74007797241211,
          -50.29104232788086,
          -60.70962905883789,
          -36.898101806640625,
          -41.411109924316406,
          1.475022554397583,
          7.582187175750732,
          46.89457321166992,
          56.48314666748047,
          0.5907781720161438,
          -23.256690979003906,
          -9.208076477050781,
          -23.53462791442871,
          -42.8449821472168,
          53.29867172241211,
          58.5872688293457,
          -46.914794921875,
          -58.002323150634766,
          34.37160110473633,
          2.947730779647827,
          -20.178171157836914,
          20.946046829223633,
          37.82229232788086,
          21.909921646118164,
          -1.297912359237671,
          0.964321494102478,
          -29.25212287902832,
          1.8273802995681763,
          -19.328929901123047,
          -19.62140464782715,
          -27.62691879272461,
          -20.65547752380371,
          -36.82462692260742,
          22.143970489501953,
          -29.817903518676758,
          -9.382579803466797,
          -42.790283203125,
          53.39662170410156,
          33.1867790222168,
          -60.984004974365234,
          -40.84935760498047,
          -63.22354507446289,
          10.737140655517578,
          -9.116642951965332,
          5.895208358764648,
          -0.5548164248466492,
          -0.4766521453857422,
          -27.636119842529297,
          21.70445442199707,
          16.485836029052734,
          10.736435890197754,
          -9.150400161743164,
          5.87607479095459,
          18.018199920654297,
          37.21215057373047,
          -1.7189668416976929,
          0.2465660274028778,
          46.28895950317383,
          44.442665100097656,
          -61.40604782104492,
          -61.63410949707031,
          -38.135616302490234,
          -38.69933319091797,
          -52.857418060302734,
          -38.05870819091797,
          -21.265108108520508,
          -37.79389572143555,
          -28.15757179260254,
          29.55140495300293,
          -53.173221588134766,
          0.6655555367469788,
          -42.790283203125,
          32.928688049316406,
          44.159305572509766,
          -47.297977447509766,
          -54.28814697265625,
          1.4188975095748901,
          -37.924312591552734,
          24.171730041503906,
          -5.248820781707764,
          -27.073871612548828,
          0.7128059267997742,
          45.35514831542969,
          43.77192306518555,
          -61.843257904052734,
          -53.9521369934082,
          22.87637710571289,
          -17.986562728881836,
          4.5404486656188965,
          23.067007064819336,
          46.38727569580078,
          45.788631439208984,
          46.378482818603516,
          -15.622179985046387,
          -24.801410675048828,
          0.6353419423103333,
          -4.763087749481201,
          45.24457550048828,
          45.06462097167969,
          -22.390012741088867,
          -8.589700698852539,
          -37.50469207763672,
          32.50904846191406,
          36.680442810058594,
          -60.4946174621582,
          -55.456539154052734,
          32.50905990600586,
          37.157230377197266,
          32.68413162231445,
          32.53875732421875,
          -18.34122657775879,
          -9.607476234436035,
          33.67863082885742,
          32.22697830200195,
          33.801170349121094,
          55.46942138671875,
          4.895968437194824,
          23.819557189941406,
          33.91728973388672,
          17.993118286132812,
          -4.784491539001465,
          -35.5354118347168,
          -28.38089370727539,
          -1.5692824125289917,
          0.09066127985715866,
          -45.21253204345703,
          61.668609619140625,
          60.485382080078125,
          -46.74759292602539,
          -57.09721374511719,
          -17.210535049438477,
          21.089384078979492,
          22.4042911529541,
          0.13232573866844177,
          61.70616912841797,
          -2.4648025035858154,
          -24.38813591003418,
          -26.619583129882812,
          61.61965560913086,
          -30.413835525512695,
          -35.5354118347168,
          61.63279342651367,
          1.1311479806900024,
          -42.8449821472168,
          26.215410232543945,
          38.133445739746094,
          -63.84220504760742,
          -55.64204025268555,
          25.933513641357422,
          22.068971633911133,
          -2.3140039443969727,
          -38.6358757019043,
          -2.4648046493530273,
          -9.885690689086914,
          -19.80585479736328,
          -21.907672882080078,
          0.6504577398300171,
          -34.792320251464844,
          -9.385830879211426,
          -21.062585830688477,
          -7.049339771270752,
          -0.9538052678108215,
          -2.175089120864868,
          -24.89952850341797,
          23.026878356933594,
          -2.473287343978882,
          2.8558294773101807,
          9.017898559570312,
          9.038068771362305,
          -34.55989074707031,
          35.02650451660156,
          17.106884002685547,
          -48.77994918823242,
          -61.634395599365234,
          -2.638552188873291,
          3.0406994819641113,
          18.26343536376953,
          47.90825271606445,
          35.03044891357422,
          13.55615520477295,
          19.7396240234375,
          12.406471252441406,
          31.091108322143555,
          12.957148551940918,
          -20.27398109436035,
          46.06357955932617,
          40.70313262939453,
          -66.36658477783203,
          23.54486656188965,
          -31.903636932373047,
          -43.74776077270508,
          -26.619115829467773,
          -23.69749641418457,
          12.706104278564453,
          30.86127281188965,
          -57.96889114379883,
          -21.591957092285156,
          -38.553958892822266,
          55.3107795715332,
          35.22554397583008,
          -28.88198471069336,
          44.703033447265625,
          25.080942153930664,
          31.610660552978516,
          43.5129508972168,
          -47.99768829345703,
          -37.473785400390625,
          -16.040912628173828,
          -37.69108200073242,
          22.899778366088867,
          25.999570846557617,
          33.48112487792969,
          22.9155330657959,
          -6.207664966583252,
          -38.856834411621094,
          -45.38562774658203,
          35.64436340332031,
          41.77467346191406,
          -66.56497192382812,
          35.141822814941406,
          36.27442932128906,
          36.578712463378906,
          20.22633171081543,
          19.83091163635254,
          38.563133239746094,
          -21.10213851928711,
          27.92001724243164,
          33.79578399658203,
          -37.977108001708984,
          38.06565856933594,
          33.738590240478516,
          35.10893249511719,
          -23.696788787841797,
          -8.181259155273438,
          -37.146270751953125,
          52.672855377197266,
          51.834468841552734,
          -64.78060150146484,
          52.28797149658203,
          52.323402404785156,
          31.007596969604492,
          37.93856430053711,
          -66.2229232788086,
          31.10027313232422,
          12.637423515319824,
          34.19232940673828,
          38.38393783569336,
          38.496360778808594,
          30.99110984802246,
          13.123472213745117,
          13.105862617492676,
          -15.126641273498535,
          55.207332611083984,
          57.07081604003906,
          1.7867497205734253,
          2.6407365798950195,
          -24.388118743896484,
          -23.2569580078125,
          -2.0405795574188232,
          -6.634222507476807,
          -38.157501220703125
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "hoverlabel": {
         "bgcolor": "white"
        },
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "t-SNE visualization of section names"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract section names\n",
    "industry_section_names = [\n",
    "    section[0]\n",
    "    for text in industry_papers[\"text\"][2:]\n",
    "    for section in text\n",
    "    if len(section) > 0\n",
    "]\n",
    "academic_section_names = [\n",
    "    section[0]\n",
    "    for text in academic_papers[\"text\"][2:]\n",
    "    for section in text\n",
    "    if len(section) > 0\n",
    "]\n",
    "\n",
    "# Create labels\n",
    "labels = [\"Industry\"] * len(industry_section_names) + [\"Academic\"] * len(\n",
    "    academic_section_names\n",
    ")\n",
    "all_sections = industry_section_names + academic_section_names\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(all_sections, show_progress_bar=True)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "plot_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": tsne_results[:, 0],\n",
    "        \"y\": tsne_results[:, 1],\n",
    "        \"type\": labels,\n",
    "        \"section_name\": all_sections,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "fig = px.scatter(\n",
    "    plot_data,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"type\",\n",
    "    hover_data=[\"section_name\"],\n",
    "    title=\"t-SNE visualization of section names\",\n",
    "    color_discrete_map={\"Industry\": \"#FF6B6B\", \"Academic\": \"#4ECDC4\"},\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(hoverlabel=dict(bgcolor=\"white\"), width=1000, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:04<00:00,  1.07it/s]\n",
      "/Users/omar/Library/Caches/pypoetry/virtualenvs/streem-wind-prod-forecast-jFLq_jOy-py3.9/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning:\n",
      "\n",
      "The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "\n",
      "/Users/omar/Library/Caches/pypoetry/virtualenvs/streem-wind-prod-forecast-jFLq_jOy-py3.9/lib/python3.9/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning:\n",
      "\n",
      "The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Introduction | Related Work | Model Architecture | Emergent Communication Pretraining | NMT Fine-Tuning and Adapters | Regularisation with Annealing | Experimental Setup | Results and Analysis | Conclusion and Future Work | Acknowledgements | Regulariser without Annealing"
          ],
          [
           "Introduction | Background | Language-Family Adapters for NMT | Adapter Architecture | Embedding-layer Adapter | Model Architecture | Experimental Setup | Main results | Computational cost | Embedding-layer adapter | Automatic clustering of languages | Performance according to language family | Performance on seen  | Conclusion | Limitations and Risks | Acknowledgements | Dataset statistics | Training details | Evaluation of main results using 2 metrics | Hyperparameters | Embedding-layer results | Position of adapter in the encoder layer | Results using GMM, random clustering and language families"
          ],
          [
           "Introduction | Summary of Research Contributions | Shared Task: Document-level Generation and Translation | Evaluation Measures | Data | Baseline Systems | Submitted Systems | Team EdiNLG | Team FIT-Monash | Team Microsoft | Team Naver Labs Europe | Team SYSTRAN-AI | Results | Shared Task: Efficient NMT | Evaluation Measures | Data | Baseline Systems | Submitted Systems | Team Marian | Team Notre Dame | Results | Conclusion | Acknowledgments | Full Shared Task Results"
          ],
          [
           "Introduction | Product Quantization (PQ) | Methodology | Random Word Embeddings (RWE) | Gaussian Product Quantization (GPQ) | Structured Partitioning | Unified Partitioning | Experiments | Evaluation | Model and Training Details | Random Word Embeddings | Gaussian Product Quantization | Experiments for Discrete Space Approximation | Experiments for Compression Analysis | Cluster and Group Size Analysis | Compression Analysis | Importance of Variance | Related Work | Conclusion"
          ],
          [
           "Introduction | Related Work | Problem Formulation | Grounded Communication Environment | Policy Learning with Backpropagation | Discrete Communication and Gumbel-Softmax Estimator | Policy Architecture | Auxiliary Prediction Reward | Compositionality and Vocabulary Size | Experiments | Syntactic Structure | Symbol Vocabulary Usage | Generalization to Unseen Configurations | Non-verbal Communication and Other Strategies | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Active Memory Models | The Markovian Neural GPU | The Extended Neural GPU | Related Models | Experiments | Parsing. | Discussion"
          ],
          [
           "Introduction | Related Work | Model | LSTM-based Sentence Generator | Training | Inference | Experiments | Evaluation Metrics | Datasets | Results | Training Details | Generation Results | Transfer Learning, Data Size and Label Quality | Generation Diversity Discussion | Ranking Results | Human Evaluation | Analysis of Embeddings | Conclusion | Acknowledgement"
          ],
          [
           "Introduction | NLP for “Network Language” Processing | Configuration Verification | Configuration Synthesis | Configuration Translation | Current State of the Art in Network Configuration | Configuration Verification | Configuration Synthesis | Configuration Explanation | NLP for “Computer Language” Processing | Code Verification | Code Synthesis | Code Translation | Other software-related tasks | Automated code documentation | Automated code completion/repair | Transfer from programming to configuration languages: a reality check | Lessons from computer language field | Impact on network configuration | Lessons from computer language field | Impact on network configuration | Lessons from computer language field | Impact on network configuration | Lessons from computer language field | Impact on network configuration | Lessons from computer language field | Impact on network configuration | Conclusion and recommendations"
          ],
          [
           "Introduction | Problems | Problems related to subtitle creation guidelines | Problems related to textual translation | Machine Translation adaptability Problems | Subtitle Validation Experiment | Conclusion"
          ],
          [
           "Introduction | Link Prediction | Language Model Pre-training | Overall Framework | Multi-task Pre-training | Mask Entity Modeling(MEM) | Mask Relation Modeling(MRM) | Mask Language Modeling(MLM) | Pre-traning Loss Designing | Knowledge Representation | Contrastive Learning | Triple Augmentation | Mixed Precision | Fine-tuning Loss Designing | Experiments | Experiment Settings and Datasets | Experimental Results | Ablation Study | Conclusion and Future Work"
          ],
          [
           "Introduction | Related work | Defining semantic coherence | Evaluating semantic coherence: paraphrase coherence | Model structure | Objective | Vocabulary expansion | Experimental settings | P-coherence | STS Benchmark task | Conclusion"
          ],
          [
           "Introduction | Direct Product of Graphs (PoG) | Dependency Tree | Direct Product of Graphs | Abstraction | Sub-graphs of PoG as Matching Patterns | Mining of Matching Patterns | Speeding-up the Mining Process | Mining without Abstraction | Mining with Abstraction | Advantage of Tree Pattern Mining | The Deep Matching Model | Model Description | Learning | Architecture Learning | The Selection of Overall Architecture | Parameter Learning | Experiments | Datasets and Evaluation Metric | Original-vs-Random: | Retrieval-based Conversation: | Competitor Methods | Results on Original-vs-Random | Comparison to Competitor Models | Results on Conversation Data | Deep vs. Shallow Patterns | The effect of abstraction | Related Work | Deep Matching Models | Graph-based Kernel | String-Rewriting Kernel | Conclusion | Acknowledge"
          ],
          [
           "Introduction | Related Work | Method | The Transformer Architecture | Training Transformers with Random Structured Pruning | Randomly Dropping Structures at Training Time | Random Structured Dropout. | Selecting Layers to Prune | Setting the drop rate for optimal pruning. | Experimental Setup | Neural Machine Translation. | Language Modeling. | Summarization. | Long Form Question Answering. | Sentence representation Pre-training. | Language Modeling. | Sequence to sequence modeling. | Bi-Directional Pre-training. | Pruning Generation Tasks. | Pruning BERT-like Models. | Comparison of Structured Dropout | Comparison of Various Pruning Strategies. | Choosing which Layers to Prune. | Relationship between LayerDrop at Training Time and Pruning at Inference Time. | Conclusion | Neural Machine Translation | Language Modeling | Summarization | Long Form Question Answering | Bi-Directional Pre-Training | IWSLT | Pruning BERT Models | Impact of LayerDrop on training time. | BERT: Relationship between LayerDrop at Training Time and Pruning at Inference Time | Impact of Finetuning."
          ],
          [
           "Introduction | Low-Rank Softmax (Softmax Bottleneck) | Unargmaxable Classes | Detecting Unargmaxable Classes | Definitions | Softmax | Discretising the Output Space into Permutations | How Can Unargmaxable Classes Arise? | Effect of Softmax Bias Term | Exact Algorithm | Chebyshev Center Linear Programme | Approximate Algorithm | Braid Reflect | Experiments | Language Models (0/7 Unargmaxable) | Machine Translation (13/143 Unargmaxable) | Discussion | Infrequent Tokens Are the Victims | Some Models Are Easier to Verify | Conclusions and Future Work | Broader Impact | Halfspace interpretation | Hyperplane Arrangements | Braid Arrangement | Restricting the Braid Arrangement to Lower Dimensions | Number of Regions (Feasible Permutations) of the Restricted Braid Arrangement | Softmax with no Bias Term | Softmax with Bias Term | Activation Range of Softmax Layer Inputs"
          ],
          [
           "Introduction | Latent Space Directions of a Factor of Variation | Latent Space Trajectories of an Image transformation  | Choice of the reconstruction error $\\mathcal {L}$ | Recursive Estimation of the Trajectory | Encoding Model of the Factor of Variation in the Latent Space. | Experiments | Quantitative evaluation method | Results on BigGAN | The importance of disentangled representations | Related works | Conclusions | Penalty on the amplitude of frequencies due to MSE | $\\beta $ -VAE architecture | Qualitative and quantitative experiments with our reconstruction error | On the difficulty of optimization on the natural image manifold. | Additional qualitative examples"
          ],
          [
           "Introduction | Discourse information for completing incomplete parses | Algorithm | Step 1: Inspecting each partial parse and restructuring\nit on the basis of the discourse information | Results | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Term-based queries on cbma databases | plp | CP-Logic | Syntactic restrictions and probabilistic databases | Probabilistic cbma databases | Encoding a cbma database as a probabilistic logic program | Equivalence between the program of fig:program and the\ncbma approach of sec:term-based-queries | Solving queries on probabilistic cbma databases | kc approaches do not scale to the size of neuroimaging data\n | Lifted processing of ucq on probabilistic cbma\ndatabases | Relating terms and studies probabilistically | Experiments and results | Gain of statistical power when solving two-term cq\n$\\textbf {P}\\left[A_k|T_i \\wedge T_j\\right]$  on smaller simulated\ncbma databases\n | Gain of activation consistency on a real cbma database | Discussion | Conclusion | Free software"
          ],
          [
           "Dataset Preprocessing | Experimental Setting | Binarization Statistics | Case Study"
          ],
          [
           "Introduction | Related Work | Preliminaries | Bochner Time Embedding | Mercer Time Embedding | Time-event Interaction | Experiment and Result | Data Sets | Baselines and Model configurations | Experimental results | Conlusion | Proof of Claim 1 | Proof of Proposition 1 | Fourier series under truncation | Flow-based distribution learning | Dataset details | Training and model configuration | Initialization for time embedding methods | Training efficiency | Sensitivity analysis | Cases study for attention weights | Visualization of time embeddings and time kernel functions | Reference implementation"
          ],
          [
           "Introduction | Measuring Intrinsic Uncertainty | Mode-seeking Search | $N$ -best Search | Experimental Setup | Results | Finding the Most Likely Hypothesis | Sentence-level uncertainty | The Spread of Probability Mass | Sentence-level uncertainty | Related Work | Conclusion"
          ],
          [
           "Introduction | Proposed Architectures | GSA: Gaussian-weighted Self-Attention | Extension to Complex Transformer Architecture | End-to-End Metric Optimization | Experimental Settings | Main Result | Comparison with Generative Models | Conclusion"
          ],
          [
           "Introduction | Proposed Algorithm | Experimental Setup | Results | Conclusion"
          ],
          [
           "Introduction | Models and Pre-trained Checkpoints | Investigated Model Variants | Sentence Fusion | Split and Rephrase | Machine Translation | Abstractive Summarization | Combining Different Checkpoints. | Tuning GPT-2 Based Models. | Initializing only Embeddings. | Initializing only Layers. | Initializing a Subset of Layers. | Analysis of Abstractive Summaries | Human Assessment of Summary Quality. | Summary Lengths and Repetitions. | Related Work | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Data Augmentation via Backtranslation | Datasets | NER Model | Backtranslation Models | Hyperparameters | Results | Conclusion"
          ],
          [
           "Introduction | Related Work | Model | LSTM-based Sentence Generator | Inference | Experiments | Evaluation Metrics | Datasets | Results | Training Details | Generation Results | Transfer Learning, Data Size and Label Quality | Generation Diversity Discussion | Ranking Results | Human Evaluation | Analysis of Embeddings | The MS COCO Image Captioning Challenge | Metrics | Improvements Over Our CVPR15 Model | Image Model Improvement | Image Model Fine Tuning | Scheduled Sampling | Ensembling | Beam Size Reduction | Automatic Evaluation | Human Evaluation | Conclusion | Acknowledgment"
          ]
         ],
         "hovertemplate": "type=Industry<br>x=%{x}<br>y=%{y}<br>sections=%{customdata[0]}<extra></extra>",
         "legendgroup": "Industry",
         "marker": {
          "color": "#FF6B6B",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Industry",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          11.168964385986328,
          10.716375350952148,
          -3.204932689666748,
          3.836099147796631,
          4.170039653778076,
          0.25362929701805115,
          3.1251003742218018,
          -0.6811175346374512,
          1.815194010734558,
          6.74862003326416,
          8.412315368652344,
          10.402185440063477,
          5.668465614318848,
          5.144052982330322,
          -2.598306894302368,
          9.518242835998535,
          -7.863697052001953,
          -4.847606658935547,
          -0.3403991758823395,
          -7.197749614715576,
          6.898618221282959,
          -5.814840316772461,
          6.616451263427734,
          0.29763856530189514,
          2.721059560775757
         ],
         "xaxis": "x",
         "y": [
          4.433716773986816,
          4.1032280921936035,
          1.4867005348205566,
          -5.140344142913818,
          -3.310447931289673,
          -7.412130355834961,
          -0.5554718971252441,
          4.0901570320129395,
          3.8551087379455566,
          5.886292457580566,
          -0.5896950364112854,
          -3.9208452701568604,
          -0.5118281245231628,
          -3.825995445251465,
          -5.449199199676514,
          0.8994996547698975,
          4.868252754211426,
          4.776266098022461,
          -4.216434001922607,
          2.972940683364868,
          -8.401885986328125,
          3.830613374710083,
          -0.3302164673805237,
          -2.8833508491516113,
          -0.5277451872825623
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Introduction | Proposed Approaches | Design Space | Arbitrary Encoder-Decoder Attention. | Heterogeneous Transformer Layers. | SuperTransformer | Evolutionary Search for SubTransformer | Datasets | Baselines. | Evaluation Metrics. | SuperTransformer Setups. | Hardware-Aware Evolutionary Search Setups. | Training Settings. | HAT Performance Comparisons | Design Insights. | Ablation Study. | SubTransformer Performance Proxy. | Low Search Cost. | Finetuning Inherited SubTransformers | Quantization Friendly. | Knowledge Distillation Friendly. | Transformer. | Neural Architecture Search. | Conclusion | Acknowledgment | SubTransformer Performance Proxy | Visualizations of Searched Models on WMT'14 En-De Task | Latency, BLEU and SacreBLEU of searched HAT models."
          ],
          [
           "Introduction | Data Creation | Scene Graphs | Modified MSCOCO and GCC for Graph Modification | We randomly select a node from $\\mathcal {G}$  (denoting the source graph $\\mathbf {x}$ ), and then remove this node and its associated edges. | We treat insertion as the inversion of deletion. | We replace a randomly selected node from the source graph $\\mathcal {G}$  with a semantically similar node to get the target graph. | Crowd-sourcing User Data | Extension: Multiple Operations | Methodology | Notations. | Problem Formulation | Graph-based Encoder-Decoder Model | Graph Encoder: Sparsely Connected Transformer  | Query Encoder |  Information Fusion of Encoders | Late Fusion via Gating. | Early Fusion via Cross-Attention. | Node-level Decoder | Edge-level Decoder | Baselines. | Our Model Configurations. | Evaluation Metrics. | Data Splits. | Experimental Results | Multi-Operation Performance | Quantitative Analysis | Related Work | Conclusion | Acknowledgments | Training Details | Performance on validation set | Data Statistics | Data Creation for Multi-operation Graph Modification | Mixing Synthetic and User-generated Data | Templates | Examples from User-generated Dataset | Alignments between Different Components"
          ],
          [
           "Introduction | Related Work | Data | Methodology | Transformer | BiLSTM-CRF | Results | Conclusion"
          ],
          [
           "Introduction | Position Encoding | Self-Attention | Cross-Lingual Position Representation | Integration Strategy | Inputting-level XL SANs | Head-level XL SANs | Experiments | Effect of $\\tau $  in HeadXL SANs | Main Results | Alignment Quality | Gain for Context-Free Model | Effects of Noisy Reordering Information | Augmenting SANs with position representation | Modeling cross-lingual divergence | Conclusions and Future Work | Acknowledgments"
          ],
          [
           "Introduction | Related work | LightRNN | RNN Model with 2-Component Shared Embedding  | Bootstrap for Word Allocation | Experiments | Settings | Results and Discussions | Conclusion and future work | Acknowledgments"
          ],
          [
           "Introduction | Background: In-context Learning | Prompt Selection | Task-level In-context Examples | Example-specific In-context Examples | Datasets and Evaluation Metric | Language Model | Baselines and Comparisons | Results | A single task-level prompt is competitive with 16 random few-shot examples. | Multiple example-specific prompts are required to improve translation quality over a single task-level prompt.  | Re-ranking retreived examples improves  | Out-of-domain Evaluation | Domain of few-shot in-context examples matter. | Example-specific prompts significantly improve translation quality over task-level prompts. | Task-level and R-prompts are complementary. | Choice of Few-shot Examples | Impact of Pool Size on Task-level Prompt Selection | Translation direction | Properties of good Task-level prompts | Impact of Noise | Impact of Ordering | Informativeness of Example-specific Prompts  | Output Analysis | Stylistic Outputs | Template-based  | Size of the Datastore | In-context Learning for  | Domain Adaptation for  | Prompt Selection | Conclusion | Statistics of Datasets | Compute Infrastructure & Run time | Results using Second Metric: Comet | Order of Retrieved Examples  | Choice of $\\lambda $ , Threshold | Example Task-Level Prompts"
          ],
          [
           "Introduction | Related Work | Feature Vectors | Bayesian Gaussian Mixture Model | Scoring and Filtering | Experiments | Sentiment Analysis | Language Modeling | Machine Translation | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Structured Energy-Based Learning | Inference. | Joint training of energy functions and inference networks. | An Objective for Joint Learning of Inference Networks | Energy Functions | Linear Chain Energies | Skip-Chain Energies | High-Order Energies | Vectorized Kronecker Product (VKP): | CNN: | Tag Language Model (TLM): | Self-Attention (S-Att): | Fully-Connected Energies | Related Work | Experimental Setup | POS. | NER. | CCG. | SRL. | Local Classifiers. | BiLSTM-CRF. | Inference Networks. | Energy Terms. | Hyperparameters. | Parameterizations for High-Order Energies. | Comparing Structured Energy Terms. | Comparison using Deeper Inference Networks. | Results on Noisy Datasets | Incorporating BERT | Analysis of Learned Energies | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Local and Global Interpretability | Post-hoc vs In-built Interpretations | Paper layout | Interpretability requirements | Dimensions of Interpretability | Faithfulness | Stability | Comprehensibility | Trustworthiness | Feature Importance | Input Perturbation | Attribution Methods | Attention weights | Datasets | Natural Language Explanation | VQA and NLE | Text-only NLE | Datasets | Challenges and Future work | Probing | Embedding Probes | Model Probes | Probe Considerations | Automatic Evaluation | Human Evaluation | Automatic Evaluation | Human Evaluation | Evaluation of Probing | Conclusion"
          ],
          [
           "Introduction | Headings: first level | Headings: second level | Headings: third level | Paragraph | Examples of citations, figures, tables, references | Figures | Tables | Lists | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Contributions. | Related Work | Sentence Splitting. | Rephrasing. | The  | The  | Creating the  | Sentence segmentation | Pairing | Ordering. | Results | Problem Formulation | Split-and-Rephrase Models | A Probabilistic, Semantic-Based Approach | A Basic Sequence-to-Sequence Approach | A Multi-Source Sequence-to-Sequence Approach | Partitioning and Generating | Learning to split. | Learning to rephrase. | Experimental Setup and Results | Training, Validation and Test sets | Implementation Details | Results | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | SpeechT5 | Model Architecture | Input/Output Representations | Encoder-Decoder | Speech Pre/Post Net | Text Pre/Post Net | Pre-training | Speech Learning | Text Learning | Joint Pre-training | Fine-tuning | Dataset and Evaluation Metrics | Pre-training | Fine-tuning and Inference | VC | ASR | TTS | SID | Related Work | Conclusion and Future Work"
          ],
          [
           "Introduction | Related work | Show & Tell Model | Training | Inference | Implementation | Datasets | Implementation tool and environment | Results | Evaluation Matrices | Conclusion"
          ],
          [
           "Introduction | Related work | Methodology | Dataset | Baselines | Result | Conclusion"
          ],
          [
           "Introduction | Related Work | Alphabets and Dialects | Vocabulary | Grammar | Methodology | Data Crawling | Corpus Filtering | Content Alignment | Evaluation | Conclusion and Future Work | Appendix"
          ],
          [
           "Introduction | Overview of AT and NAT Models | Comparison | The Main Challenge of NAT Models | Overview of Improving Methods | Knowledge Distillation | Data Learning Strategies | Modeling | Iteration-Based Methods | Latent Variable-Based Methods. | Other Enhancements-based Methods | Criterion | Decoding | Length Prediction | Decoding Strategy | Benefiting from Pre-trained Models | AT Models | Pre-Trained Language Models | Summary of Non-Autoregressive NMT | Extensive Applications Beyond NMT | Text Generation | Semantic Parsing | Text to Speech | Speech Translation | Others | Conclusion and Outlooks | Example"
          ],
          [
           "Introduction: Quine and Kaplan on the insignificance of ‘nine’ in ‘canine’"
          ],
          [
           "Introduction | Using Yara in Practice | Data format | Training and Model Selection | Punctuation Files | Some Examples | Training with Brown clusters | Training with the fastest mode | Changing the number of iterations | Extending memory consumption | Using very specific options | Test and Evaluation | Parsing a CoNLL file | Parsing a tagged file | Evaluation | Parsing a Partial Tree | Yara Pipeline | Pipeline API usage | Importing libraries | Parsing Raw Text File | Parsing Raw Text | Parsing a Sentence | Parsing a Tokenized Sentence | Parsing a Tagged Sentence | Yara Technical Details  | Arc-Eager Algorithm | Unshift Action | Online Learning | Beam Search and Update Methods | Dynamic and Static Oracles | Root Position | Features | Unlabeled Parsing | Partial Parsing | Multithreading | Model Selection | Tree Scoring | Lowercasing | Experiments | Parsing WSJ Data | Effect of Beam Size | Parsing Non-Projective Languages: Persian | Conclusion and Future Work | Acknowledgements"
          ],
          [
           "Introduction | Related Work | Dataset description | Data augmentation | Text processing | RNN Model and Attention Mechanism | Model Architecture | Training Models | Evaluation and Results | Conclusion - Future work"
          ],
          [
           "Introduction | In this section, we present l'ambre, a metric to gauge the morphosyntactic well-formedness of generated natural language sentences. | Creating a Grammatical Description | Agreement | Case Assignment and Verb Form Choice | Human Evaluation | Parsing Noisy Text | Adding Morphology-related Noise | Training Robust Parsers | Do We Capture Grammaticality? | Evaluation: | Analysis: | Evaluating NLG: A Machine Translation Case Study | Correlation Analysis | Diachronic Analysis | Conclusion and Future Work | Acknowledgments | Comparison of UD and SUD | Robust parsing | GEC datasets | Comparison with other metrics | Contrastive evaluation on UD | Correlation analysis on WMT | Correlation analysis with Human z-scores | Comparison with other MT metrics | Diachronic analysis of WMT systems | Model Training | Resources"
          ],
          [
           "Introduction | Cost of Attention Mechanism | Opportunity for Approximation | Pipeline Design | Quantization | Design Details | Overview | Base Greedy Candidate Search | Efficient Greedy Candidate Search | Post-scoring Approximation | To efficiently implement the approximation scheme introduced in Section , we design new hardware accelerator modules for candidate selection and post-scoring approximation. | Candidate Selection Module | Post-Scoring Selection Module | Figure REF  shows the high-level block diagram of the $A^3$  design. | Workloads | Accuracy Evaluation | Performance Results | Area, Power, Energy and Test Chip | Related Work | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Models | Word-level language identification | Normalization | Monolingual | Fragments | Multilingual | Language-aware | POS tagging | Data | Turkish-German code-switched normalization corpus | Preprocessing for normalization | LID and POS alignment | Dataset statistics | Evaluation | Language identification | Normalization | Effect of the quality of language predictions | POS tagging as extrinsic evaluation | Test data | Discussion and Conclusion | Acknowledgements | Statistics on raw data collections | Results of in-domain pos-tagging"
          ],
          [
           "Introduction | Sign language processing (SLP) | SignWriting, FSW, and SWU | Data and method | Data statistics | Data preprocessing | Multilingual models | Data split | FSW parsing | Factored machine translation | Experiments and results | Initial exploration with a bilingual model | Multilingual sign-to-spoken translation | Evaluating dictionary entries | Multilingual spoken-to-sign translation | FSW decoding strategies | Evaluation of FSW output | Effect of adding dictionaries, BPE, and low-resource optimizations | Utilizing positional numbers | Generating positional numbers | Multilingual performance | Multilingual transfer effects | Side-by-side SignWriting example | Conclusion | A word on top-n accuracy | Fingerspelling tokenization | Towards better multilingual models | Regression objective for positional numbers | Possibly flawed positional number evaluation | Advanced SignWriting evaluation | Note on reproducibility | Extended introduction to SignWriting | Formal SignWriting in ASCII (FSW) | SignWriting in Unicode (SWU) | Experimental setup | 40k sign-to-en-us | 100k sign-to-spoken | 100k spoken-to-sign | Data"
          ],
          [
           "Introduction | Debiasing Strategies | Translationese in Sentence Embeddings | Translationese in Word Embeddings | Application to NLI | Conclusion | Acknowledgments | Experimental Setup and Hyperparameters | Word Analogy Tests | Visualisation | Translationese Word Lists"
          ],
          [
           "Introduction | FAN versus LSTM | Tasks | Subject-Verb Agreement | Logical inference | Models | Results | Discussion and Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Machine Translation Systems | Experiments and Results | Evaluation data | Lexical Frequency Profile | TTR, Yule's I and MTLD | Synonym Frequency Analysis | Grammatical Diversity | Shannon Entropy | Simpson's Diversity Index | Conclusions | Acknowledgements"
          ],
          [
           "Introduction | Dimensional Properties of the Word Embedding Space | Word Similarity Tasks | Sentence Classification Tasks | Variance Based Analysis | Dimensional Linguistic Probing Tasks | The Post Processing Algorithm (PPA) | Sentence Classification Tasks | Machine Translation | Summary and Discussion | Related Work | Conclusion and Future Work"
          ],
          [
           "Introduction | Formulation | Variation | Multi-dimensional Attention | Hierarchical Attention | Self Attention | Memory-based Attention | Reusability | Flexibility | Task-specific Attention | Application | Attention for Ensemble | Attention for Gating | Attention for Pre-training | Evaluation | Quantitative | Qualitative | Conclusion and Prospects"
          ],
          [
           "Introduction | Related Work | Unsupervised Bilingual Lexicon Induction | Multi-lingual Image Caption Model | Visual-guided Word Representation | Word Translation Prediction | Datasets | Experimental Setup | Evaluation of Multi-lingual Image Caption | Evaluation of Bilingual Lexicon Induction | Generalization to Diverse Language Pairs | Conclusion |  Acknowledgments"
          ],
          [
           "Courtesy warning: Common violations of final version rules that have\nresulted in papers being returned to authors for corrections | Courtesy warning: Common violations of final version rules that have\nresulted in desk\nrejects | General instructions |  files compliant with these instructions are available at the Author Guidelines section of the TACL website, https://www.transacl.org.Last accessed Sept. 20, 2018. | Workarounds for problems with the hyperref package | Length limits | Fonts and text size | Page Layout | The confidentiality header and line-number ruler | The First Page | Section headings | Figures and Tables | In-text citations | Self-citations | References | Appendices | Including acknowledgments | Contributors to this document"
          ],
          [
           "Introduction | Search-based Structured Prediction | Knowledge Distillation | Ensemble | Distillation from Reference | Distillation from Exploration | Distillation from Both | Experiments | Transition-based Dependency Parsing | Neural Machine Translation | Transition-based Dependency Parsing | Neural Machine Translation | Analysis | Ensemble on “Problematic” States | Effect of $\\alpha $ | Learning Stability | Related Work | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Multi-source Sequence-to-Sequence Learning | CopyNet | Approach | Interactive Representation Learning | Predicting Words to be Copied | Training | Datasets | Effect of Hyper-parameters | Results on the PBSMT Sub-task | Ablation Study | Results on Prediction Accuracy | Comparison of Copying Accuracies | Visualization | Multi-source Sequence-to-Sequence Learning | The Copying Mechanism | Interactive Representation Learning | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Punctuation prediction using acoustic features | Auxiliary loss in intermediate layers | End-to-end approach | Task Definition | Baseline Model | Proposed Method | Datasets | Experimental Setup | Evaluation | Results | Analysis | Conclusions"
          ],
          [
           "Introduction | Related Work | Tasks | Model | Data | Baselines | Evaluation | Main Results | Model analysis | Ablation Study | Result analysis | Conclusion | Data | Implementation Details | Full results | Examples of fingerspelling localization | Precision-recall curve in FVS | Qualitative examples of pose estimation"
          ],
          [
           "Introduction | Related work | Data | Bias Statement | Quantifying bias for Occupations and Emotions | For neutral occupations: $M_{neu}$ | For gendered occupations:$M_{gen}$ | Finding out the gender subspace | Debiasing methods | Results and Discussion | Conclusion and Future work"
          ],
          [
           "Introduction | Word Representation | Adversarial Training | Empirical Study | Experimental Design | Observation | Explanation | Discussion | Our Method | Experiment | Settings | Results | Conclusion | Dataset Description | Hyper-parameter configurations | Models Description | Additional Comparisons | Case Study on Original Models and Qualitative Analysis of Our Method"
          ],
          [
           "Introduction | Related Work | Addition-Subtraction Twin-Gated Recurrent Network | Twin-Gated Mechanism | Computation Analysis | Interpretability Analysis of Hidden States | Setup | Training | Results on English-German Translation | Results on English-French Translation | Analysis on Twin-Gated Mechanism | Analysis on Speed and Model Parameters | Analysis on Dependency Modeling | Conclusion and Future Work | Acknowledgments | Neural Machine Translation with ATR | Experiments on Chinese-English Translation | Experiments on Natural Language Inference | Experiments on Chinese Word Segmentation"
          ],
          [
           "Introduction | Related Work | BERT-based Evaluation Metrics | Reproducibility in NLP | Datasets & Metrics | MoverScore | BERTScore | BaryScore | SentSim | Reproduction Attempts | Reproduction on MT | Results | Summary | SentSim | Reproduction for other tasks | Sensitivity Analysis | IDF-weighting | Stopwords Removal | Results | IDF-weighting | Results | Subwords & Punctuation | Results | Discussion | Conclusion | Machine Translation | Text Summarization | Image Captioning | Data-to-Text Generation | Reproduction on WMT15-16 | Reproduction of other tasks | Results | Reproducibility problems of SentSim | Additional preprocessing MoverScore | Subword Removal | Stopwords Removal & Punctuation Removal | Default configuration of evaluation metrics | Stopword lists | Other results for stopwords | IDF Corpora | Other results for IDF-weighting"
          ],
          [
           "Introduction | Background | Under-resourced Languages | Orthographic Information | Spelling and Typographical Errors | True-casing and Capitalization | Normalization | Tokenization and Detokenization | Transliteration | Code-Mixing | Orthographic Information in RBMT | Orthographic Information in SMT | Spelling and Typographical Errors  | True-casing and Capitalization, Tokenization and Detokenization  | Normalization | Transliteration (Cognate)  | Code-Switching | Pivot Translation | Orthographic Information in NMT | Multilingual Neural Machine Translation | Spelling and Typographical Errors | True-casing and Capitalization, Normalization, Tokenization and Detokenization | Transliteration (Cognate) | Code-Switching | Orthographic Information in Unsupervised Machine Translation | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Natural Language Processing for Slang | Generative Semantic Models of Slang | Computational Framework | Context-based Interpretation | LM-based interpreter. | Dual encoder. | Semantic Model of Slang | Semantically Informed Reranking | Datasets | Evaluation on Slang Interpretation | Zero-shot and Few-shot Interpretation | Evaluation on Slang Translation | Conclusion | Ethical Considerations | Baseline Models | Semantic Reranker | Additional Interpretation Examples | Effect of Context Length | Finetuning Dual Encoder | Machine Translation Examples | Data Permissions"
          ],
          [
           "Introduction | Background | Translational distance KG Representation | Transformer for Graph Representation | Relphormer | Triple2Seq | Structure-enhanced Transformer | Masked Knowledge Modeling | Optimization and Inference | Datasets | Compared Baselines | Settings | Entity Prediction | Relation prediction | Inference speed comparison | The number of sampled contextualized sub-graph triples | Structure-enhanced self-attention | Optimization object | Global node | Discussion | Transformer for Graph | Transformer for Knowledge Graph | Conclusion and Future Work | Implementation Details | Comparison with Previous Study"
          ],
          [
           "Introduction | Background | Annotation of MuST-C with Speakers' Gender Information | ST Systems | Base ST Model | Multi-gender Systems | Gender-specialized Systems | Gender-balanced Validation Set | Experiments | Evaluation Method | Overall Results | Cross-gender Analysis | Analysing Conflicts between Vocal Characteristics and Gender Tags | Manual Analysis | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Approach | Problem Setting | Method | Learning Monolingual Embeddings | Learning Bilingual Embeddings | Learning Word Translations | Training the NER Model | Discussion | NER Model Architecture | Hierarchical Neural CRF | Self-Attention | Experiments | Experimental Settings | Results | Comparison with Dictionary-Based Translation | Why Does Translation Work Better? | Case Study: Uyghur | Related Work | Bilingual Word Embeddings | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Amharic language | Motivation | Related work | Building a Parallel Dataset | Data pre-processing | The proposed neural machine translation models | Pre-trained language models (PLMs) | Results and discussion | Conclusion and future work"
          ],
          [
           "Introduction | Background and Related Works | Method | Adversarial Regularization | Adversarial Regularization as Stackelberg Game | SALT: Stackelberg Adversarial Regularization | Experiments | Baselines | Neural Machine Translation | Natural Language Understanding | Parameter Study | Analysis | Conclusion | Broader Impact | Virtual Adversarial Training | Neural Machine Translation | Natural Language Understanding | Model Calibration"
          ],
          [
           "Introduction | Background | UniDrop | Feature Dropout | Structure Dropout | Data Dropout | Theoretical Analysis | Interpretation | UniDrop Integration | Experiments | Neural Machine Translation | Datasets | Model | Results | Text Classification | Datasets | Model | Results | Analysis | Overfitting | Ablation Study | Effects of Different Dropout Rates | Dropout | Data Augmentation | Conclusion | Acknowledgments | Supplementary materials for theoretical analysis | Statistics of Datasets | Dropout Attempts | Loss Curves | Ablation Study on Text Classification"
          ],
          [
           "Introduction | Background & Approach | Compositionality as Lexical Symmetry | Discovering Symmetries Automatically | Inferring equivalence relations | Learning Alignments | Aside: Continous Domains | Inferring types | Constructing Homomorphisms | Limitations | Experiments | CLEVR-CoGenT | COGS | VQA Transformer | LSTM | Data Augmentation | VQA | Semantic Parsing | Lexicalized neural models | Data Augmentation | Conclusion | Acknowledgements | VQVAE Details | VQA Transformer Details | LSTM Details | IBM Model Details | Extracted Lexicons | VQA | Semantic Parsing | Generalization to more complex lexicons | Data"
          ],
          [
           "Introduction | Preliminaries | Tensor and Block-Term Tensor Decomposition | Multi-head Attention | Tensorized Transformer | Single-block Attention by Tucker Decomposition | Multi-Linear Attention by Block-Term Tensor Decomposition | Analysis of Compression and Complexity | Related Work | Experiments | Language Modeling | Results and Details | Neural Machine Translation | Discussion | Conclusion and Further Work | Acknowledgement | Tensor and Tensor Slice | Theorem 3.1 | Corollary 1 | Compression Ratio about Multi-Linear Attention | Partial Structure about Tensorized Transformer | Experimental Details in Language Modeling | Experiment Details in Neural Machine Translation | Experimental comparison | Partial Code"
          ],
          [
           "Introduction | Related work | Methods | Data Preprocessing | Model Building | Model Explanation | Model Evaluation | Model Performance | SHAP Explanation | Survey Results | DistilBERT-based NLP Models  | SHAP-Explanations and User Trust | Implications | Conclusion and Future Work"
          ],
          [
           "Introduction | NMT based Aligner | LM based Aligner | Method | Model Architecture | Self-Attention Module. | Cross-Attention Module. | Alignments Extraction | Two-stage Training Framework | Stage1: Translation Language Modeling. | Stage2: Self-Supervised Alignment. | Experimental Settings | Datasets | Implementation Details | Baselines | Statistic based methods: | NMT based methods: | LM based methods: | Evaluation Measures | Main Results | Ablation Study. | Number of Cross-Attention Layers. | Alignment Layer. | Case Study | Conclusion | Limitations"
          ],
          [
           "Introduction | Multimodal Machine Translation. | Datasets | Multilingual MMT | LVP-M$^{3}$ | Token Encoding | Language-aware Visual Prompt Generation | Language Translation | Experiments | Experimental Setting | Results on M$^{3}$ -Multi30K | Results on M$^{3}$ -AmbigCaps | Ablation Study | Effect of LVPG. | Effect of Different Vision Backbones. | Visualization of Different Masking Ratios. | Qualitative Analysis. | Discussion on  LVP-M$^{3}$ | Conclusion | Limitations | Acknowledgments"
          ],
          [
           "1.1em | 1.1.1em | 1.1.1.1em colorlinks = true, allcolors = blue nlpNLPNatural Language Processing nerNERNamed Entity Recognition saSASentiment Analysis mlMLMachine Learning bowBoWbag-of-words cbowCBoWcontinuous Bag-of-Words sltcSLTCSwedish Language Technology Conference annANNartificial neural network nnNNneural network lstmLSTMLong Short Term Memory Network bilstmbiLSTMbidirectional Long Short Term Memory Network sotaSoTAstate-of-the-art nlgNLGNatural Language Generation nluNLUNatural Language Understanding mweMWEMulti-Word Expression swSWSimple Wiki mtMTMachine Translation bwBWBillion Word piePIEPotential Idiomatic Expression iaaIAAInter-Annotator Agreement rteRTERecognizing Textual Entailment irIRInformation Retrieval qaQAQuestion Answering bncBNCBritish National Corpus ukwUKWaCUK Web Pages aiAIArtificial Intelligence gdcGDCGothenburg Dialogue Corpus dialogptDialoGPTDialogue Generative Pre-trained Transformer gptGPTGenerative Pre-trained Transformer multiwozMultiWOZMulti-Domain Wizard-of-Oz t5T5Text-to-Text Transfer Transformer bartBARTBidirectional & Auto-Regressive Transformer xlmrXLM-RCross-Lingual Model-RoBERTa m2mM2MMany-to-Many multilingual translation model bertBERTBidirectional Encoder Representations from Transformers robertaRoBERTaRobustly optimized BERT pretraining Approach elmoELMoEmbeddings from Language Models piiPIIpersonally identifiable information qgQGQuestion Generation tcTCText Classification pclPCLPatronising and Condescending Language gusGUSGenial Understander System gmbGMBGroningen Meaning Bank wsdWSDWord Sense Disambiguation ccby4CC-BY4Creative Commons Attribution 4.0 ciCIconfidence interval bleuBLEUbilingual evaluation understudy gdprGDPRGeneral Data Protection Regulation svmSVMsupport vector machine vsVSvector space vsmVSMvector space model nltkNLTKnatural language toolkit tf-idftf-idfterm frequency-inverse document frequency pcaPCAPrincipal Component Analysis svdSVDSingular Value Decomposition lsiLSILatent Semantic Indexing plsiPLSIProbabilistic Latent Semantic indexing ldaLDALatent Dirichlet Allocation lmLMlanguage model bilmbiLMbidirectional language model posPoSpart of speech nnlmNNLMneural network language model bpeBPEbyte-pair encoding oovOOVout-of-vocabulary imdbIMDBInternet Movie Database lrLRlearning rate cusCUSCredibility unanimous score ieIEInformation Extraction rlRLreinforcement learning mdlMDLminimal dependency length mlmMLMmasked language model rqRQresearch questions Tosin Adewumi*, Foteini Liwicki and Marcus Liwicki ML Group, EISLAB, Luleå University of Technology, Sweden firstname.lastname@ltu.se We demonstrate, in this study, that an open-domain conversational system trained on idioms or figurative language generates more fitting responses to prompts containing idioms. | Introduction | Materials and Methods | multiwoz dataset | pie-English idioms corpus | Classification | Conversation Generation | Evaluation | Credibility Unanimous Score (cus) | Classification | Error Analysis | Conversation generation | Discussion & Evaluator Feedback | Related Work | Limitation | Conclusions | Bibliographical References"
          ],
          [
           "Introduction | The learning problem | Deep neural networks | Generalization error in deep learning | Understanding deep learning requires rethinking generalization | Exploring generalization in deep learning | A PAC-Bayesian approach to spectrally-normalized margin bounds for neural networks | Stability and generalization | Robustness and generalization | Stronger generalization bounds for deep nets via a compression approach | Train faster, generalize better: stability of stochastic gradient descent | On large-batch training for deep learning: generalization gap and sharp minima | Sharp minima solutions to the training of DNNs can generalize for deep nets | Train longer, generalize better: closing the generalization gap in large batch training of neural networks | Generalization error of invariant classifiers | Generalization error and adversarial attacks | Open problems | Problem 1: Generalization and memorization | Problem 2: Generalization and robustness | Problem 3: Generalization and adversarial examples | Problem 4: Generalization error of generative models | Problem 5: Generalization error and the information bottleneck | Conclusions"
          ],
          [
           "Introduction | Background | Method | Adversarial Regularization | Adversarial Regularization with Caching | Memory Saving with KNN | Computational Efficiency | Experiments | Baselines | Machine Translation | Natural Language Understanding | Parameter Study | Analysis | Conclusion | Broader Impact | Detailed Algorithm | Machine Translation Experiments | Natural Language Understanding Experiments"
          ],
          [
           "Introduction | A third type of research | Translation is bidirectional | NLP as a translational field: a historical perspective | A practical definition | The Translational NLP framework | Stakeholders | Translational NLP Checklist | Translating methodology advances into existing applications | Case Study: NLP for Disability Review | Discussion | Conclusion | Acknowledgments"
          ],
          [
           "2017 acmcopyright EMDL'17,June 23, 2017, Niagara Falls, NY, USA 978-1-4503-4962-8/17/06$15.00 http://dx.doi.org/10.1145/3089801.3089804 MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU  Qingqing CaoNiranjan BalasubramanianAruna Balasubramanian  Table: Conclusion"
          ],
          [
           "Introduction | MAE: Mixture of Attentive Experts | Background: Mixture of Experts | Multi-Head Attention: a Mixture-of-Experts Perspective | A mixture-of-experts perspective. | Discussion. | MAE: Learning to Weight Experts | Training MAE with Block Coordinate Descent | Experiments | Compared Models | Analysis | Does MAE Learn to Specialize the Experts? | MAE's Potential in Transfer Learning: A Case Study | Setting. | Multi-head attention. | Mixture of experts. | Conclusion | Acknowledgments | Architectures and Implementations | Machine translation with WMT'14 | Machine translation with IWSLT'14. | Language modeling with WikiText-103. | Learning Curve Comparison for MAE and  | Addtional Results for §"
          ],
          [
           "Introduction | RNN wave functions | Ground States with RNN wave functions | 1D transverse field Ising model | 1D $J_1-J_2$  model | 2D transverse field Ising model | Scaling of resources | Open-Source Code | Gated Recurrent Neural Networks | Two-dimensional Recurrent Neural Network wave functions | Variational Monte Carlo and Variance Reduction | Imposing discrete symmetries | Imposing zero magnetization | Rényi entropies | Tables of Results | Scaling of resources (continued) | Hyperparameters"
          ],
          [
           "Introduction | System Architecture | Keyword Mapper - DBTagger | Deep Sequence Tagger Architecture | DBTagger Architecture | Annotation Scheme | POS Tags | Type Tags | Schema Tags | Explanations for Keyword Mapper | LIME | LIME Wrapper | SQL Translation Algorithm | Schema Graph Extraction | Join-Path Inference | Where Clause Completion | Heuristics for Aggregate Queries | Datasets | Query Translation Results | Explainable User Interface of xDBTagger | Related Work | Conclusion"
          ],
          [
           "Introduction | Anaphoric Types | Zero Anaphora: | One Anaphora: | Pronominal Anaphora: | Demonstratives: | Presuppositions: | Discontinuous Sets (Split Anaphora): | Inferrable Anaphora (Bridging Anaphora): | Generics: | Non referential terms: | Anaphoric Constrains | Gender agreement: | Person agreement: | Number agreement: | Binding theory: | Selectional Restrictions: | Recency: | Discourse structure: | World Knowledge: | Standard Datasets for Coreference Resolution | Entity Coreference Resolution evaluation metrics | MUC | B-cubed | CEAF | Brief history of Entity Coreference Resolution approaches | Deep Learning Coreference Resolution | Entity Coreference Resolution | Entity-Based models | Latent-Structure models | Language-Modelling models | Pronoun Resolution | Coreference Resolution Performance | Entity Coreference Resolution results | Pronoun Resolution | Discussion | Conclusions and future work"
          ],
          [
           "RGB Object Pose Estimation | Learned P | Multi-Object Keypoint Regression as Set Prediction | Keypoints Representation | RotEst | Loss Function | Class Probability Loss | Bounding Box Loss | Keypoint Loss | Pose Loss | Model Architecture | Backbone Network | Positional Encodings | Encoder | Decoder | FFN | Evaluation | Dataset | Metrics | Hyperparameters | Results | Inference Time Analysis | Ablation Study | Effectiveness of Keypoints Representations | Effectiveness of RotEst | Discussion & Conclusion | Acknowledgment"
          ],
          [
           "Introduction | Dataset | Hierarchical mapping and further curation of metric names | Grouping of top-level metrics | Analysis | Data basis | Which performance metrics are most frequently reported in NLP benchmarking? | Are metrics reported together with other metrics or do they stand alone? | Inconsistencies and ambiguities in the reporting of performance metrics | Discussion | Recommendations for reporting performance results and future considerations | Increasing transparency and consistency in the reporting of performance metrics | Maximizing the informative value in the reporting of performance results | Future considerations on performance metrics in the context of benchmarking | Limitations | Conclusions | Data and code availability"
          ],
          [
           "Introduction | Morphology-aware Language Model | Morphological Analysis and Part-of-Speech Tagging | Morphology Encoding | Pre-training Objective | Experiments | Pre-training details | Evaluation tasks | Main results | Ablation study | Related Work | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Our approach | Related work | Experiments | Task and evaluation protocol | Main results | Conclusion and future work | Acknowledgments"
          ],
          [
           "Introduction | summary of this survey | The PDTB Corpus | The CoNLL Dataset and Shared Task | Implicit Discourse Relation Recognition based on Machine Learning | Lexical features | Syntactic features | Contextual feautres | Implicit Connectives | Convolutional Neural Networks | Recurrent Neural Networks | Hybrid Neural Network Models | Attention Mechanism | Neural Learning of Argument Pair Interaction | Data Expansion from Explicit Discourse Relations | Data Expansion from Multi-Language Data | Joint Data Expansion and Model Training | Performance Comparison | Conclusion and Discussion | Interaction-boosted representation learning | Synthetic Implicit Corpus Refinement | Joint relation recognition and discourse parsing"
          ],
          [
           "Introduction | Related Work | Data and Evaluation | Method | Results | Conclusions | Acknowledgments"
          ],
          [
           "Introduction | Related work | Slovene T5 models | Training data | Architecture and training of SloT5 | Evaluation | Evaluation tasks | Fine-tuning T5 and compared models | Results | Discussion | Funding"
          ],
          [
           "Introduction | Focus Languages | Data Construction | Annotator Recruitment | Data Filtering and Sampling | Human Translation | Human-Assisted Quality Assurance | Tasks | Sentiment Analysis | Machine Translation | Classical Machine Learning | Pre-trained Local Language Models | Pre-trained Massively Multilingual LMs | Sentiment Analysis | Machine Translation | Cross-lingual Capability of LMs | Multilingual Parallel Corpus | Emerging Language Benchmarks | Datasets for Indonesian Languages | Conclusion | Ethical Considerations | Acknowledgments | Dataset title | Dataset curators | Dataset version | Dataset citation | Data statement author | Data statement version | Data statement citation | Executive Summary | Curation Rationale | Documentation for Source Datasets | Language Variety | Speaker Demographic | Annotator Demographic | Acehnese | Balinese | Banjarese | Buginese | Javanese | Madurese | Minangkabau | Ngaju | Sundanese | Toba Batak | Sentiment Analysis | Machine Translation | Examples"
          ],
          [
           "Introduction | Multilingual Word Embeddings | Sentence Representation Learning | Multilingual Sentence Representations | Cross-lingual Evaluation Benchmarks | The XNLI Corpus | The English Corpus | Translating the Corpus | The Resulting Corpus | Cross-Lingual NLI | Translation-Based Approaches | Multilingual Sentence Encoders | Aligning Word Embeddings | Universal Multilingual Sentence Embeddings | Aligning Sentence Embeddings | Training details | Parallel Datasets | Analysis | Conclusion | Acknowledgments"
          ],
          [
           "META-REVIEW | What is this paper about, what contributions does it make, what are the main strengths and weaknesses? | Reasons to accept | Reasons to reject | Reviewer's Scores | Questions and Suggestions for the Author(s) | What is this paper about, what contributions does it make, what are the main strengths and weaknesses? | Reasons to accept | Reasons to reject | Reviewer's Scores | Missing References | What is this paper about, what contributions does it make, what are the main strengths and weaknesses? | Reasons to accept | Reasons to reject | Reviewer's Scores"
          ],
          [
           "Introduction | Continual Learning | Prompt for Pre-trained Model | Overview | Prompt based Data Representation | T5 as APR Model Skeleton | Difficulty-based Example Replay | Sampling-based EWC Regularization | Cross Language Re-repairing | Experimental Setup | Research Questions | Datasets | Implementation Details | Benchmarks and Baselines | Evaluation and Results | RQ1: Can CIRCLE effectively learn bug fixing in “task requirements increase constantly” scenario? | RQ2: What is the performance of a single CIRCLE model compared to the dedicatedly trained state-of-the-art APR methods? | RQ3: What are the contributions of the different components of CIRCLE? | Impact of prompt-based data representation | Impact of re-repairing | Impact of the continual learning module | Case Study | APR | Continual Learning | Conclusion | Acknowledgement"
          ],
          [
           "Introduction | Constructing the set of hypotheses | Scoring the hypothesis space | Experimental setup | Results | Error type analysis | Oracle experiments | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Related Work | Problem Formulation and Notation | Baseline Model | Method | Contextual Data Augmentation (CDA) | We present the [MASK]-based augmentation and simplify the integration of the original CDA into the baseline model (Section REF ) for computational efficiency. | Linguistically-controlled Masking | Experiments | Experimental Configuration | Effectiveness of  | Effectiveness of Linguistically-controlled Masking | Comparison with the Existing Models | Analysis of Augmented Data | Discussion | Word Replacement Approaches"
          ],
          [
           "Introduction | Background | Link Prediction. | Pre-Trained Masked Language Model. | KG-BERT | Structure-Aware Triple Encoding | Structure-Augmented Scoring Module | Deterministic Representation Learning | Spatial Structure Learning | Training Objectives and Inference Details | Triple Contrastive Objective. | Training and Inference Strategies. | Model Efficiency. | Training Efficiency. | Inference Efficiency. | Self-Adaptive Ensemble Scheme | Compared to Prior Text-Based Approach  | Stand-alone Embedding. | Joint Embedding. | Benchmark Datasets. | Evaluation Metrics. | Evaluation Protocol. | Evaluations on Link Prediction | Comparison with KG-BERT Baseline | Generalization to Unseen Graph Elements | Ablation Study | Further Analyses | What is the effect of introducing structure learning into a textual encoding approach. | How does StAR bring improvements. | Why does StAR achieve better Hits@10 but worse Hits@1 than RotatE | How does the self-adaptive ensemble scheme bring improvements. | Structure Learning for Link Prediction. | Text Representation Learning. | Jointly Learning Methods. | Conclusion | Acknowledgement | Training Setups | Probing Tasks"
          ],
          [
           "Introduction | Background | Cross Entropy | Knowledge Distillation | Word Embedding | Self-Knowledge Distillation | SKD Equations | SKD Algorithm | NLP Tasks | Experiments | Dataset | Language Modeling | Neural Machine Translation | Conclusion | Acknowledgement"
          ],
          [
           "Introduction | Methods | Available Datasets | Convolutional Neural Networks | CNN-Nguyen {{cite:8e1762df642a6add900fbca08858e99e90695e7c}} | CNN-Zeng {{cite:3c71e43ef24f1f4669f33a18df83784895733a46}} | DeepDBP {{cite:dd49f233931b392ea4a7054be93e058d27684513}} | DeepRAM {{cite:31086e06923f1471de3b7f712e6671ae51b89ee6}} | Natural Language Processing Neural Networks | LSTM-layer | doc2vec+NN {{cite:f67a1ca0ef071524500dd7f48f549770987d9dfd}} | LSTM-AE+NN {{cite:62c347d3f326ba85bb9592513fdbf18b07d56e07}} | Replication of Results | The Role of Convolutional Layers and Dimension. | Robustness across Datasets | The Role of Data Encoding | The Role of Sparsity in Overfitting | Comparison of Classification Accuracy | The Role of the Embedding Size on Classification Accuracy of doc2vec+NN | The Role of the Optimizer in the Classification Accuracy of the LSTM-layer Model | The Role of the Batch Size in the Classification Accuracy of the LSTM-AE+NN Model | Comparison of Sequence Embedding in doc2vec and LSTM-AE | Discussion | Reproducibility | Reproducible Julia Script for Random Order of First Authors"
          ],
          [
           "Introduction | Template Overview | Template Styles | Template Parameters | Modifications | Typefaces | Title Information | Authors and Affiliations | Rights Information | CCS Concepts and User-Defined Keywords | Sectioning Commands | Tables | Math Equations | Inline (In-text) Equations | Display Equations | Figures | The “Teaser Figure” | Citations and Bibliographies | Acknowledgments | Appendices | SIGCHI Extended Abstracts | Part One | Part Two | Online Resources"
          ],
          [
           "Introduction | Related work | Linguistic resources | Translation dictionaries | Universal dependencies | Finite-state transducers | Word embeddings of resource-rich languages | Sentiment analysis | Discussion and Conclusions | Acknowledgement"
          ],
          [
           "Introduction | Related Works | Methodology | Model Overview | Efficient Feature Encoders | Relaxation of Discrete Variables | Differences with Related Models | Experiments | Data | Model Settings | Model Performances | Schedule-Training | Ablation Tests | Skipping Analysis | Top-5 keep-rate words. | Case study.  | Conclusions | Acknowledgements"
          ],
          [
           "Introduction | Multilingual Methods. | Natural Language Inference. | Question Answering. | Unsupervised Language Models. | Back-translation. | XLDA: Cross-Lingual Data Augmentation | Experiments and Results | Cross-lingual Data | Models | Pairwise Evaluation | There exists a cross-lingual augmentor that improves over the monolingual approach. | Most languages are effective augmentors. | Lower resource languages are less effective augmentors, but benefit greatly from XLDA. | XLDA is robust to translation quality. | A Greedy Algorithm for XLDA | Greedy XLDA always improves over using the single best cross-lingual augmentor. | Targeted XLDA | The `cross' in cross-lingual is crucial. | XLDA without BERT | XLDA is equally effective for randomly initialized and pretrained models. | Greedy XLDA is more effective for randomly initialized models than pretrained models. | XLDA for SQuAD | Conclusion"
          ],
          [
           "Introduction | Motivation | Adversarial Examples | NLP Models | Adversarial NLP | Unicode | Unicode Security | Attack Taxonomy | NLP Pipeline | Attack Methodology | Invisible Characters | Homoglyphs | Reorderings | Deletions | Integrity Attack | Availability Attack | Experiment Setup | Machine Translation: Integrity | Machine Translation: Availability | Machine Translation: MLaaS | Toxic Content Detection | Toxic Content Detection: MLaaS | Textual Entailment: Untargeted | Textual Entailment: Targeted | Ethics | Attack Potential | Search Engine Attack | Defences | Invisible Character Defences | Homoglyph Defences | Reordering Defences | Deletion Defences | Conclusion | Acknowledgment"
          ],
          [
           "Introduction | Masked Self-Attention | Lattices | Baseline Model | Lattice-Biased Attentional Decoder | Multi-Head Transformer Layers | Self-Attentional Lattice Encoders | Lattice Reachability Masks | Binary Masks | Probabilistic Masks | Directional and Non-Directional Masks | Lattice Positional Encoding | Computational Complexity | Experiments | Settings | Main Results | Computation Speed | Feature Ablation | Behavior At Test Time | Effect of Pretraining and Finetuning | Related Work | Conclusion | Acknowledgments | Path Duplication Invariance | Qualitative Analysis | Example 1 | Example 2 | Example 3 | Counter Example"
          ],
          [
           "Introduction | On Language Models | Count-based language models | Continuous-space language models | On Neural Network Architectures | On Training Neural Networks | Corpus | Proposed Architecture | Training the language model | Experiments | Bi-gram language model | LSTM and CNN language models | Results and Discussion | Conclusion | Acknowledgement"
          ],
          [
           "Introduction | Related Work | Methodology | Dataset | Data Collection | Data Prepossessing | Spell Correction Algorithm for Entities | Train and Validation set | Amazon Comprehend Custom NER Model | SpaCy NER Model | Gender Prediction | Sentiment Analysis | Spacy Custom NER Accuracy | Amazon Comprehend Accuracy | Sequential Model Sentiment Analysis | Demand Analysis | Conclusion and future work"
          ],
          [
           "Introduction | Related Work | Word2rate | Word2rate First Order Series(FOS) | Word2rate First Order Product(FOP) | Left-Right Context Split | Hybrid Embeddings | Word2rate Second Order Series | Experiments | Word2rate FOS | Word2rate FOP | Comparison with CMOW | Comparison with CBOW | Left-Right Context Split | Hybrid FOS-FOP | Word2rate Second Order Series | Comparison with CBOW | Comparison with CMOW | Conclusion"
          ],
          [
           "Introduction | Setting | System Overview | Semantic Parser | Preliminaries | Data Model | Query Language | Language Operators | Provenance | Model Definitions | Query Operators | Explaining Queries | Query to Utterance | Provenance to Highlights | Scaling to Large Tables | Concrete Applications | Deployment | Implementation | WikiTableQuestions Dataset | Training on Feedback | Semantic Parsing | Deployment | Experiments | Evaluation Metrics | Interactive Parsing at Deployment | User Study | Training on User Feedback | NL interfaces | Conclusion and Future Work | Future Work"
          ],
          [
           "fit,calc Table: Similarity Task Results: Model concatenation and joint optimizationC2V-1: Top-Confusion, C2V-a: Intra-Confusion, C2V-c: Inter-Confusion, C2V-*: Hybrid Intra-InterSimilarity in terms of Spearman's correlation.All the models are of 556 dimensions.Numbers inside parenthesis indicate correlation p-valuep-value for similarity tasks.Good correlations are observed for both the word similarity and acoustic similarity with model concatenation with and without joint optimization."
          ],
          [
           "Introduction | Related Work | BERT-CRF model for Chinese word Segmentation | Switch-memory mechanism | Memory cells | Switcher | Objective | Datasets | Experimental configurations | Overall results | Ablation study | Mode selection | Case study | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related work | Bi-LSTM-CRF model"
          ],
          [
           "Introduction | Background and Related Work | Federated Learning Methods | Client Partitioning | Data | Europarl | MTNT | UN Corpus | NC Corpus | Modeling | Training | Language Modeling | Machine Translation | Text Classification | Discussion | Conclusion | Hyperparameters | Randomly Initialized MT | MTNT Data Preprocessing for M2M-100 | Full LM Results"
          ],
          [
           "Introduction | Related Work | Convolution GANs | Conditional GANs | Auto-Encoders GAN | Progressive and Auxiliary Classifier GAN  | Adversarial Domain Adaptation | GANs and Loss-Variants | Datasets | Synthetic Image Generation Methods | Single-stage methods: | Multi-stage methods: | Applications to medical imaging: | Generative phase | Discriminative phase | Applications to 3D Reconstruction | Image fusion | Image Completion | Supervised Translation | Unsupervised translation | Conclusion and Discussion"
          ],
          [
           "Introduction | Related Work | Data Collection | Extractive Phase | Topical Hierarchical Agglomerative Clustering | Core and Peripheral Articles Identification | Centroid based Clustering | Multi-Sentence Compression | Topical Coverage Formulation | Path Relevance Formulation | Cumulative Score | Abstractive Phase | Abstractive Language Unit (ALU) Generation | Multi-Sentence Compression | Extractive Evaluation | Abstractive Evaluation | DUC-2004 Abstractive Evaluation | MAG-20 Abstractive Evaluation | Conclusion and Future Work | Acknowledgment"
          ],
          [
           "Introduction | Explicit Sparse Transformer | Results | Dataset | Result | Dataset | Result | Dataset | Result | Discussion | Comparison with other Sparse Attention Methods | How to Select a Proper k? | Do the proposed sparse attention method helps training? | Do the Explicit Sparse Transformer Attend better? | Related Work | Conclusion | Attention Mechanism | Transformer | Experimental Details | Neural Machine Translation | Image Captioning | Language Models | The Back-propagation Process of Top-k Selection | Implementation"
          ],
          [
           "Introduction | Global slot memory augmented Transformer with hierarchical attention  | Masked language modeling | Experiments setup | Experimental MLM task results"
          ],
          [
           "Introduction | Surrogate Models | Gaussian Processes | Random Forests | Multi-Objective Optimization | Pareto-optimality | Pareto region | Metrics | Cost Metrics | Objective evaluation cost | Prediction Quality Metrics | Pareto volume reduction | Contribution rate indicator | Diversity measure | FlexiBO: Flexible Bayesian Multi-Objective Optimization | Modeling | Pareto Region Construction | Sampling | Implementation and Workflow | Experimental Setup | Results | FlexiBO Finds Better Configurations | FlexiBO Produces Superior Pareto Fronts | FlexiBO Discovers Optimal Configurations at Lower Cost | Threats to Validity | Multi-objective optimization with preferences. | Multi-objective optimization with scalarizations. | Multi-objective optimization with Pareto front approximation. | Multi-objective, cross-layer, and hardware-aware optimization of DNNs. | Conclusion"
          ],
          [
           "Introduction | Paraphrase and Textual Entailment Recognition | Logic-based Approaches to Recognition | Recognition Approaches that Use Vector Space Models of Semantics | Paraphrase and Textual Entailment Generation | Generation Methods Inspired by Statistical Machine Translation | Generation Methods that Use Bootstrapping | Paraphrase and Textual Entailment Extraction | Extraction Methods Based on the Distributional Hypothesis | Conclusions | Acknowledgments | Bibliographic Resources, Portals, Tutorials | Corpora, Challenges, and their Datasets | Implementations of Machine Learning Algorithms | Implementations of Similarity Measures | Parsers, POS Taggers, Named Entity Recognizers, Stemmers | Statistical Machine Translation Tools and Resources | Lexical Resources, Paraphrasing and Textual Entailment Rules"
          ],
          [
           "Introduction | Related Work | Analysis of Neural Networks | Subword Units | Linguistic Properties | Morphology | Syntax | Semantics | Methodology | Generating representations with subword and character units | NMT Training Data | Model Training | Classifier Settings | Supervised Data and Annotations | Morphology Results | Impact of Translation Unit on Learning Morphology | Encoder versus Decoder Representations | Effect of Network Depth | Effect of Target Language | Syntax Results | Impact of Translation Unit on Learning Syntax | Effect of Network Depth | Analysis | Effect of Relation Type | Effect of Relation Distance | Semantics Results | Impact of Translation Unit on Learning Semantics | Effect of Network Depth | Analysis of Lexical Semantics | Semantic Tag Level Analysis | Analyzing Discourse Relations | Effect of Target Language | Analysis of Semantic Dependencies | Comparison Against Multilingual Models | Discussion | Assessing Representation Quality | Contextualized Word Representations | On the Impact of Language Representation on Translation Output | Why Analyze? | Other NMT Architectures | Conclusion and Future Work | Acknowledgements | Character-based Models | Effect of Target Language | Three Layered Character-based Models | Layer-wise Experiments Using CCG Tags | Statistical Significance Results"
          ],
          [
           "Introduction | Sequence generation. | Method. | Comparison with policy gradient. | Comparison with minimum risk training. | Pooled task losses. | Sequence-level training for NLP. | Drawbacks of MLE in NLP. | Black-box optimization. | Text Completion with GPT-2 | Experimental setup. | Task losses. | Metrics. | Effect on sequence-level task loss. | PG & MRT comparison. | MGS candidate analysis. | Experimental setup. | Results. | Conclusion | Broader Impact | Self-normalized Importance Sampling | Minimum risk gradient. | Computation. | Text completion. | Machine translation. | Text completion."
          ],
          [
           "Natural Language and its Processing | Arabic and its Challenges | Morphological Richness | Orthographic Ambiguity | Dialectal Variation | Orthographic Inconsistency | Resource Poverty | A Brief History of NLP in the Arab World | Arabic Tools and Resources | Corpora and Lexical Resources | Corpora | Lexical Resources | Morphological Processing | Syntactic Processing | Named Entity Recognition | Dialect Identification | Infrastructure | Machine Translation | Pedagogical Applications | Information Retrieval and Question Answering | Dialogue Systems | Sentiment and Emotion Analysis | Content Moderation on Social Media | Future Outlook"
          ],
          [
           "Introduction | Related Work | Model Description | Capturing Rich Patterns with Multiple Channels | Aggregating Patterns by an Attention Module | Experiments | Experimental Setups | Experimental Results | Experimental Setups | Experimental Results | Experimental Setups | Experimental Results | Analysis | Case Studies and Visualization | Performance on Long Sentences | Impact of Model Size and Time Cost | Conclusion and Future Work | Acknowledgement"
          ],
          [
           "Introduction | Related Work | Low-rank Factorization | GroupReduce | Product Quantization | Tensor Decomposition | Knowledge Distillation | Funneling Decomposition and Embedding Distillation | Datasets and Evaluation | Hyper-Parameters | Hardware Details | Machine Translation | Ablation Study | Initialization | Embedding Distillation | Compression Rate | Re-training | Extension | Importance of Non-linearity | Importance Reconstruction Loss | Conclusion and future work | WMT En-Fr | WMT En-De | IWSLT Pt-En"
          ],
          [
           "Introduction | Transformer Architecture and Variants | Gated Transformer Architectures | Identity Map Reordering | Gating Layers | Experiments | Transformer as Effective RL Memory Architecture | Scaling with Memory Horizon | Gating Variants + Identity Map Reordering | Performance Ablation | Hyperparameter and Seed Sensitivity | Parameter Count-Controlled Comparisons | Gated Identity Initialization Ablation | Related Work | Conclusion | Acknowledgments | Environment Details | Experimental details | Training setup | Multi-Head Attention | Relative Multi-Head Attention | Identity Map Reordering"
          ],
          [
           "Introduction |  Implementation | Conditional Random Field | ADF Algorithm | Pre-training | A Large-Scale Vocabulary | Usage | Installation | Segmentation | Domain-specific Segmentation | Experiment | MSRA & PKU. | CTB8. | Weibo. | Medicine & News & Tourism. | Out-of-domain Results | Pre-training Results | Default Performance | Conclusion and Future Work"
          ],
          [
           "Introduction | Related work | Awareness of limitations of gloss approach | Choice of dataset | Glossing | Live interpretation and translationese effects | Preprocessing of spoken language | Evaluation | Non-standard metrics | Tokenization | Spurious gains | Further observations | Preprocessing glosses | Modeling and training decisions | Limitations of sentence-level systems | Recommendations for gloss translation | Conclusion | Data licensing | Impact of internal tokenization when computing BLEU on gloss sequences | Example for corpus-specific gloss preprocessing"
          ],
          [
           "Introduction | Contributions | Existing Corpus | Language Models | Downstream tasks in low resource languages | Datasets | Social Stream Category | Getting the hydrated tweets | Website and Blog Category | Parallel Data | Preprocessing and meta-analysis | Preprocessing | Meta-analysis | Utility of the datasets | Conclusion | Future work | Appendix"
          ],
          [
           "Introduction | Related Work | Alignment Task | Giza++ | Monolingual Embedding Space Mapping | Cross-domain similarity local scaling | Method | Word Embedding Space Mapping | Geometrically-Aware Translation Probability Distribution | Integration with Giza++ | Symmetrization & Alignment Extraction | Data | Performance in Low-Resource Scenarios | Comparison to the Literature in High-Resource Scenarios | Conclusion and Future Work | Acknowledgements"
          ],
          [
           "Introduction | Measuring semantic preservation | Data | Assessment | Discussion | Conclusion"
          ],
          [
           "Introduction | Related Work | Overview | Attention Map Generation | Attention Map Convolution | Value Projection and Feed-Forward Layers | Convolution for Decoders | Image Classification | Natural Language Understanding | Machine Translation | Quality of Attention Maps | Interpretability | Learning Curve Comparison | Conclusion | Image classification | Natural language understanding | Machine Translation | Quality of Image Attention | Interpretability | Case Study | Image attention | Text Attention"
          ],
          [
           "Introduction | Language-specific and multilingual transformer-based models | Contributions | Language model pre-training | Training corpus | Training procedure | Evaluation | Task descriptions | Task-specific fine-tuning | Results and discussion | Conclusions"
          ],
          [
           "Introduction | Log-linear models | SMT Features | Tuning via Pairwise Ranking | Listwise Learning Framework | The Permutation Probability Model | Loss Functions | Training with Instance Aggregating | Top-Rank Enhanced Losses | Data and Preparation | Tuning Settings | Experiments of Listwise Learning Framework | Effect of Top-rank Enhanced Losses | Impact of the Size of Candidate Lists | Performance on Basic Feature Set | Related Work | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Semantic markup data as language resources | Product classification | Product linking | Entity classification and linking using LOD | Reflection | Methodology | Data sources | Building language resources for product data mining | Training word embedding models | Continued Pre-training of BERT language models | Training machine translation models | Product classification | Product linking | Experiment | Product classification | Product linking | Product classification | Product linking | Results | Product classification results | Product linking results | Discussion and analysis | Data provenance | Vocabulary coverage | Product keywords analysis | Algorithmic considerations | Conclusion | Product classification: word frequency analysis for word embedding model training"
          ],
          [
           "Introduction | Prompt Tuning | Hard Prompt | Soft Prompt | Research Questions | Code Intelligence Tasks with Prompt Tuning | Pre-trained Models | Defect Detection | Code summarization | Code Translation | Evaluation Datasets | Defect Detection | Code Summarization | Code translation | Defect Detection: | Code Summarization: | Code Translation: | Experimental Setup | Fine-tuning Baselines | RQ1: Effectiveness of Prompt Tuning | RQ2: Capability of Prompt Tuning in Different Data Scarcity Scenarios | RQ3: Impact of Different Prompts | Different Hard Prompt Templates. | Hard Prompt vs. Vanilla Soft Prompt. | Different Lengths of Prefix Soft Prompts. | Implication on the Utilization of Pre-trained Models | Implication on the Utilization of Prompts | Future Directions | Threats To Validity | Pre-training on Programming language | Prompt Tuning | Conclusion"
          ],
          [
           "Introduction | Related Work | Custom Dataset Creation | NLP Model for NER Training | Custom Dataset Creation | NLP Model for NER Training | Discussion | Conclusion | Acknowledgment"
          ],
          [
           "Introduction | Challenges in ExAI on NLP Models | Related Surveys | Terminology | Interpreting Word Embeddings | Sparsification of Embedding Spaces | Rotation of Embedding Spaces | Integrating External Knowledge | Contextualized Embeddings | Evaluating Embeddings Interpretability | Discussion | Most of the post-hoc interpretation methods try to dissect hidden knowledge in trained deep networks from syntax and semantic lens. | Inherently interpretable RNNs are trained in an explainable way by adding transparency constraints [118] and exploring tree and graph-like structures [106], [59]. | Discussion | What do Transformers Learn? | Visualization of Transformers | Is the Attention Mechanism  | Interpretability of BERT | Discussion | Explaining Model's Decisions | These methods, consider a pre-trained model and analyze how such a model process a textual input before producing a decision. | Instead of considering black-box models, Kádár et al. | As an extension to the previously discussed “rationalization” attempts [124], [125], Lei et al. | Liu et al. | Discussion | Discussion and Future Directions | Conclusion"
          ],
          [
           "Introduction | Related Work | Method | Experiment | Data | Preprocessing | Word Embeddings | Translation | Training and testing | Results and Discussion | Conclusion | Future Work | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Attention Models | Multi-task Learning | Architecture | Shared encoder  | Shared attention  | Shared decoder  | Training Schedule | Target Length | Experimental Setup | Data | System Architecture | Evaluation | Results | Initial experiments on the architecture | Impact of design decisions | POS Tagging Performance | Analysis and Examples | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | The Proposed  | Background | Asymptotic Distillation | Dynamic Switch | Rate-scheduled learning | Datasets | Training details | Results and Analysis | Encoder v.s. Decoder | BERT v.s. GPT-2 | About asymptotic distillation | About dynamic switch | About rate-scheduled learning | About BERT layers | Unsupervised pre-training of LMs | Pre-training for NMT | Conclusion"
          ],
          [
           "Introduction | Background & Related Work | Game Design | Main Interactions and Gameplay | Gamification affordances & Additional incentives | Game implementation | Analysis & Discussions | Methodology & Participants | Data Analysis | Comparison with Parseme Annotations | Motivational & Behavioral Outcomes | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Data | Methodology | Transformer | BiLSTM-CRF | Results | Conclusion"
          ],
          [
           "Introduction | Related Work | SNN-Based Models | Model Architecture | Pre-trained SNN (PT-SNN) | SNN With Second-Order Embeddings (SOE-SNN) | Text Embeddings | Sentence-Level Embeddings | Word-Level Embeddings | FSL Model Evaluation | Baseline Models | Classification Tasks and Datasets | 2006 i2b2 De-Identification Challenge Dataset | Few-Shot Clinical Text Classification | Few-Shot Clinical Named Entity Recognition | Limitations and Future Work | Conclusion | Acknowledgements"
          ],
          [
           "Introduction | Related Work | Convolution-enhanced Evolving Attention Networks | The Evolving Attention Mechanism | Evolving Attention Transformer | Evolving Attention-enhanced Dilated Convolutional Transformer for Time-Series Representation | Network Architecture | Optimization | Extension to other Attention Networks | Time-Series Representation | Natural Language Understanding | Machine Translation | Image Classification | Learned Representations | Quality of Attention Maps | Interpretability | Learning Curve Comparison | Case Study | Hyper-parameter Analysis | Limitations | Conclusion | Acknowledgment"
          ],
          [
           "Introduction | Related Work | Our Model | Encoder | Decoder | Visual Features | Dynamic Context-guided Capsule Network | Dataset | Setup | Baselines | Results on the EN$\\Rightarrow $ DE Translation Task. | Ablation Study | Case Study | Results on the EN$\\Rightarrow $ FR Translation Task | Conclusion | Acknowledgments"
          ],
          [
           "Introduction | Related Work | Instance-wise Ordered Transformer | Instance-wise Encoder/Decoder | Auxiliary Losses | Experiments | Dataset | Model and Optimization | Evaluation | Main Results | Inference/Training Cost | Case Verification | Apply on Another Structure (DynamicConv) | Discussions | Conclusion | Detailed Data Settings | Detailed Model/Training Configurations | Results of Order Combinations | Results of Different Number of Decoders | Impact of Weighted Auxiliary Losses | Data Examples Verification | Regularization | Robustness | Visualization"
          ],
          [
           "1. Introduction | 2. Background and Related Work | 3. Datasets | Arabic Health Services Dataset (Main-AHS and Sub-AHS) | Twitter Data Set (Ar-Twitter) | Arabic Sentiment Tweets Dataset (ASTD) | 3. CNN-LSTM Arabic Sentiment Analysis Model | Input Layer | Convolutional Layer | Max-Pooling Layer | LSTM Layer | Fully Connected Layer | 6. Conclusions and Future Work"
          ],
          [
           "Introduction | Annotation Design | Qualitative Analysis | Experiments and Results | Baselines | Results and Discussion | Adversarial Variants | Adaptation to Unseen Languages | Related Work | Conclusion and Future Work | Acknowledgements | Detailed Translation Guidelines | Why is Grammatical Tense Problematic for XCOPA? | Hyper-Parameter Search | Full Results (Per Language) | Code and Dependencies"
          ],
          [
           "Introduction | Design | Example Models | Experiments | Intent Classification (IC) and Slot Filling (SF) | Emotion Recognition (ER) | Dialogue Act Classification (DA) | Noisy Intent Classification (IC) with Speech Enhancement | Conclusion | Acknowledgements | References"
          ],
          [
           "Introduction | On Language Models | Count-based language models | Continuous-space language models | On Neural Network Architectures | On Training Neural Networks | Corpus | Proposed Architecture | Subword Tokenization | Training the language model | Experiments | Bi-gram language model | LSTM and CNN language models | AWD-LSTM word-level language model | Results and Discussion | Conclusion | Acknowledgement"
          ],
          [
           "Introduction | The Word2Vec Model | Word2vec Algorithm and improvements"
          ],
          [
           "Introduction | Background: Latent Alignment and Neural Attention | Latent Alignment | Attention Models: Soft and Hard | Soft Attention | Hard Attention | Variational Attention for Latent Alignment Models | Algorithm 1: Categorical Alignments | Algorithm 2: Relaxed Alignments | Models and Methods | Neural Machine Translation | Visual Question Answering | Inference Alternatives | Predictive Inference | Setup | Results and Discussion | Potential Limitations | Conclusion | Acknowledgements"
          ]
         ],
         "hovertemplate": "type=Academic<br>x=%{x}<br>y=%{y}<br>sections=%{customdata[0]}<extra></extra>",
         "legendgroup": "Academic",
         "marker": {
          "color": "#4ECDC4",
          "opacity": 0.7,
          "size": 8,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Academic",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          7.611329555511475,
          10.104516983032227,
          -4.358004570007324,
          2.9735841751098633,
          2.6961944103240967,
          -0.21835778653621674,
          2.142336130142212,
          0.8319594860076904,
          5.5952606201171875,
          -7.701146125793457,
          6.803594589233398,
          9.054078102111816,
          -4.160151481628418,
          -4.574517250061035,
          3.3523643016815186,
          8.754911422729492,
          3.3787810802459717,
          10.075651168823242,
          0.3811526894569397,
          6.459758281707764,
          8.69120979309082,
          4.764118194580078,
          5.817843437194824,
          3.22574782371521,
          3.2954423427581787,
          4.437432289123535,
          3.385986089706421,
          -1.8441084623336792,
          2.5126395225524902,
          -7.724465847015381,
          2.2612125873565674,
          1.9867571592330933,
          9.28602123260498,
          -3.6331584453582764,
          -0.3971589505672455,
          5.968281269073486,
          1.7254705429077148,
          5.140225410461426,
          6.598295211791992,
          -4.8152923583984375,
          10.142762184143066,
          0.9256772994995117,
          2.6265110969543457,
          6.1459174156188965,
          6.691807746887207,
          1.1173944473266602,
          7.551951885223389,
          -0.87477046251297,
          -2.0393002033233643,
          9.928991317749023,
          0.8667556643486023,
          7.062020301818848,
          6.571293830871582,
          6.6482834815979,
          0.9978940486907959,
          -0.12105552107095718,
          -0.6646708250045776,
          -0.2118719071149826,
          10.642868995666504,
          7.794839382171631,
          -3.4472897052764893,
          5.642797946929932,
          5.863604545593262,
          -4.2652740478515625,
          8.979172706604004,
          -4.585923671722412,
          -3.0282204151153564,
          4.653144836425781,
          2.997163772583008,
          -6.957364559173584,
          -1.6582586765289307,
          -5.7546796798706055,
          4.498525142669678,
          4.557529926300049,
          2.567070722579956,
          2.193140983581543,
          -7.790384769439697,
          2.789095401763916,
          0.735759973526001,
          3.673767566680908,
          6.53431510925293,
          -2.325676441192627,
          5.075648307800293,
          -0.7389744520187378,
          3.31296706199646,
          10.419231414794922,
          4.421579360961914,
          4.641526222229004,
          -3.830383539199829,
          7.324337482452393,
          -2.8922178745269775,
          0.8393304347991943,
          -1.1432536840438843,
          6.596344947814941,
          8.603686332702637,
          8.433300018310547,
          7.224153995513916,
          6.296816349029541,
          3.3527519702911377,
          -3.997637987136841,
          1.0140392780303955,
          6.89880895614624,
          7.501284599304199,
          5.545662879943848,
          4.2438249588012695,
          2.4900760650634766,
          11.424599647521973,
          -0.8009897470474243,
          4.424448490142822,
          8.114937782287598,
          4.624675273895264,
          -1.3053730726242065,
          -0.7113673686981201,
          4.888351917266846,
          3.4670963287353516,
          -2.8760969638824463,
          0.9019384384155273,
          -5.330377578735352,
          -4.357624053955078,
          2.132777452468872,
          -0.9714437127113342,
          0.6998084187507629,
          6.9369635581970215,
          3.627357006072998,
          7.095261096954346,
          9.794219017028809,
          5.058715343475342,
          3.721581220626831,
          10.015613555908203
         ],
         "xaxis": "x",
         "y": [
          -8.244890213012695,
          -4.851460933685303,
          7.679910182952881,
          -8.52846622467041,
          -4.903861999511719,
          2.076730251312256,
          6.057035446166992,
          -6.153814792633057,
          -1.8791769742965698,
          -0.2005215585231781,
          0.07049883902072906,
          5.536480903625488,
          3.3271896839141846,
          3.075144052505493,
          4.6686882972717285,
          4.730751991271973,
          -2.067737340927124,
          -1.0907846689224243,
          -2.6544137001037598,
          1.398730754852295,
          -8.813831329345703,
          4.18847131729126,
          3.7546427249908447,
          2.0109171867370605,
          -1.182302713394165,
          2.888576030731201,
          1.2852376699447632,
          -1.9952921867370605,
          3.1147937774658203,
          -1.6221288442611694,
          -3.6726796627044678,
          -0.3093159794807434,
          5.9124274253845215,
          -3.343477487564087,
          8.645209312438965,
          -3.0823240280151367,
          2.087782144546509,
          1.6762348413467407,
          3.4140167236328125,
          -1.6851431131362915,
          -4.771717548370361,
          8.619450569152832,
          2.671830415725708,
          6.005863189697266,
          -3.9956247806549072,
          -1.9970643520355225,
          1.099967122077942,
          -0.21228229999542236,
          5.715511322021484,
          3.0664243698120117,
          0.5393632054328918,
          2.0493323802948,
          -5.0179243087768555,
          -3.9216835498809814,
          4.940558910369873,
          -7.4864678382873535,
          0.4679959714412689,
          -5.828364849090576,
          -2.028346300125122,
          2.96238374710083,
          -3.8858678340911865,
          1.8888119459152222,
          4.831879615783691,
          1.8961634635925293,
          1.212906837463379,
          2.7482926845550537,
          4.406371593475342,
          4.772546768188477,
          2.8921709060668945,
          0.6322575211524963,
          3.026350259780884,
          3.019559383392334,
          0.19833062589168549,
          -1.2244899272918701,
          -3.3894314765930176,
          -5.804662227630615,
          -0.34882688522338867,
          5.68317174911499,
          -1.1072622537612915,
          3.5278491973876953,
          -2.339245557785034,
          -1.3822808265686035,
          7.74307918548584,
          6.65576171875,
          -7.541196346282959,
          -1.4078645706176758,
          -7.2052764892578125,
          0.5282986164093018,
          8.413844108581543,
          5.557778358459473,
          -5.004393577575684,
          3.2642879486083984,
          -0.8675451874732971,
          -9.253740310668945,
          -6.6525959968566895,
          -0.37414756417274475,
          2.7123215198516846,
          -0.5693711638450623,
          7.013689994812012,
          1.222436785697937,
          -4.51291561126709,
          -8.779772758483887,
          7.062495231628418,
          3.2422971725463867,
          5.412480354309082,
          1.2385001182556152,
          -0.45166683197021484,
          -2.083846092224121,
          3.8010592460632324,
          9.122056007385254,
          1.4909172058105469,
          3.2561750411987305,
          6.595883369445801,
          -2.097792387008667,
          1.7751853466033936,
          0.08599929511547089,
          -5.449265003204346,
          1.2897613048553467,
          7.679870128631592,
          -2.0016837120056152,
          -2.385580062866211,
          -0.7559773921966553,
          -7.738763809204102,
          7.878195285797119,
          -2.355543375015259,
          6.576793193817139,
          7.705896854400635,
          -7.112006187438965,
          2.705448627471924
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 600,
        "hoverlabel": {
         "bgcolor": "white"
        },
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "t-SNE visualization of papers based on section structure"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get section names for each paper\n",
    "def get_paper_sections(text):\n",
    "    # Skip title and abstract (first 2 elements)\n",
    "    return [section[0] for section in text[2:] if len(section) > 0]\n",
    "\n",
    "\n",
    "industry_papers_sections = [\n",
    "    get_paper_sections(text) for text in industry_papers[\"text\"]\n",
    "]\n",
    "academic_papers_sections = [\n",
    "    get_paper_sections(text) for text in academic_papers[\"text\"]\n",
    "]\n",
    "\n",
    "# Convert lists of sections to string representation\n",
    "industry_sections_text = [\" | \".join(sections) for sections in industry_papers_sections]\n",
    "academic_sections_text = [\" | \".join(sections) for sections in academic_papers_sections]\n",
    "\n",
    "# Combine all papers\n",
    "all_papers_sections = industry_sections_text + academic_sections_text\n",
    "labels = [\"Industry\"] * len(industry_sections_text) + [\"Academic\"] * len(\n",
    "    academic_sections_text\n",
    ")\n",
    "\n",
    "# Generate embeddings\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(all_papers_sections, show_progress_bar=True)\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "plot_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": tsne_results[:, 0],\n",
    "        \"y\": tsne_results[:, 1],\n",
    "        \"type\": labels,\n",
    "        \"sections\": all_papers_sections,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create interactive plot\n",
    "fig = px.scatter(\n",
    "    plot_data,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"type\",\n",
    "    hover_data=[\"sections\"],\n",
    "    title=\"t-SNE visualization of papers based on section structure\",\n",
    "    color_discrete_map={\"Industry\": \"#FF6B6B\", \"Academic\": \"#4ECDC4\"},\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "fig.update_layout(hoverlabel=dict(bgcolor=\"white\"), width=1000, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/omar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/omar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'learning':\n",
      "[('model', 0.9876201748847961), ('translation', 0.9850051999092102), ('language', 0.9834638237953186), ('tasks', 0.9829775094985962), ('models', 0.9828003644943237), ('proposed', 0.981328547000885), ('using', 0.9809401035308838), ('neural', 0.9809185862541199), ('languages', 0.9805827736854553), ('results', 0.9804854989051819)]\n",
      "\n",
      "Similarity between 'quantum' and 'computing':\n",
      "0.30829513\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between academic and industry embeddings: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# Download NLTK stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(texts):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_texts = []\n",
    "    for text in texts:\n",
    "        # Tokenize and lowercase\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Remove punctuation and stopwords\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts\n",
    "\n",
    "# Preprocess the abstracts\n",
    "academic_tokens = preprocess(academic_abstracts)\n",
    "industry_tokens = preprocess(industry_abstracts)\n",
    "\n",
    "# Combine tokens for training Word2Vec\n",
    "all_tokens = academic_tokens + industry_tokens\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model (optional)\n",
    "word2vec_model.save(\"word2vec.model\")\n",
    "\n",
    "# Load the model (if saved)\n",
    "# word2vec_model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# Explore the model\n",
    "print(\"Most similar words to 'learning':\")\n",
    "print(word2vec_model.wv.most_similar(\"learning\"))\n",
    "\n",
    "print(\"\\nSimilarity between 'quantum' and 'computing':\")\n",
    "print(word2vec_model.wv.similarity(\"quantum\", \"computing\"))\n",
    "\n",
    "# Visualize word embeddings in 2D using PCA\n",
    "def plot_embeddings(model, words):\n",
    "    # Get embeddings for the words\n",
    "    word_vectors = np.array([model.wv[word] for word in words])\n",
    "\n",
    "    # Reduce dimensionality to 2D using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    word_vectors_2d = pca.fit_transform(word_vectors)\n",
    "\n",
    "    # Plot the words\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, word in enumerate(words):\n",
    "        plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])\n",
    "        plt.annotate(word, xy=(word_vectors_2d[i, 0], word_vectors_2d[i, 1]), fontsize=12)\n",
    "    plt.title(\"Word Embeddings Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "# Words to visualize\n",
    "words_to_plot = [\"learning\", \"ai\", \"algorithm\", \"neural\", \"computing\", \"deep\", \"nlp\", \"translation\"]\n",
    "plot_embeddings(word2vec_model, words_to_plot)\n",
    "\n",
    "# Compare academic vs. industry embeddings\n",
    "def compare_domains(model, academic_tokens, industry_tokens):\n",
    "    # Get average embeddings for academic and industry abstracts\n",
    "    academic_embeddings = np.array([model.wv[word] for tokens in academic_tokens for word in tokens])\n",
    "    industry_embeddings = np.array([model.wv[word] for tokens in industry_tokens for word in tokens])\n",
    "\n",
    "    # Compute average embedding for each domain\n",
    "    academic_avg = np.mean(academic_embeddings, axis=0)\n",
    "    industry_avg = np.mean(industry_embeddings, axis=0)\n",
    "\n",
    "    # Compute cosine similarity between the two domains\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = cosine_similarity([academic_avg], [industry_avg])[0][0]\n",
    "    print(f\"Cosine similarity between academic and industry embeddings: {similarity:.4f}\")\n",
    "\n",
    "# Compare academic and industry embeddings\n",
    "compare_domains(word2vec_model, academic_tokens, industry_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfenv_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
