{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scholarly\n",
      "  Downloading scholarly-1.7.11-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pandas in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (4.12.3)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: arrow in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from scholarly) (1.3.0)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting free-proxy\n",
      "  Downloading free_proxy-1.1.3.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bibtexparser\n",
      "  Downloading bibtexparser-1.4.3.tar.gz (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from scholarly) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from scholarly) (4.12.2)\n",
      "Collecting deprecated\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from arrow->scholarly) (2.9.0.20241206)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from bibtexparser->scholarly) (3.2.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from deprecated->scholarly) (1.17.2)\n",
      "Collecting lxml\n",
      "  Downloading lxml-5.3.1-cp310-cp310-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from httpx->scholarly) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from httpx->scholarly) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from selenium->scholarly) (1.8.0)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Collecting docutils<0.22,>0.18\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sphinx<9,>=6\n",
      "  Downloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sphinxcontrib-jquery<5,>=4\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pygments>=2.17 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.19.1)\n",
      "Requirement already satisfied: Jinja2>=3.1 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (3.1.5)\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting snowballstemmer>=2.2\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tomli>=2 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.2.1)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sphinxcontrib-jsmath>=1.0.1\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: babel>=2.13 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.16.0)\n",
      "Requirement already satisfied: packaging>=23.0 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (24.2)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imagesize>=1.3\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting alabaster>=0.7.14\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio>=1.3.0 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from trio~=0.17->selenium->scholarly) (1.3.1)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from trio~=0.17->selenium->scholarly) (24.3.0)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: exceptiongroup in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from trio~=0.17->selenium->scholarly) (1.2.2)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/lib/python3.10/site-packages (from Jinja2>=3.1->sphinx<9,>=6->sphinx-rtd-theme->scholarly) (3.0.2)\n",
      "Building wheels for collected packages: bibtexparser, free-proxy\n",
      "  Building wheel for bibtexparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bibtexparser: filename=bibtexparser-1.4.3-py3-none-any.whl size=43566 sha256=d8c136f527ebfce8456c6412b495473e60c1acd87441360bc9eca1844d3b9c20\n",
      "  Stored in directory: /Users/omar/Library/Caches/pip/wheels/31/9c/e2/471fa4752a2d99ddca152d75b53a2eaf38675145ba1d26ac0f\n",
      "  Building wheel for free-proxy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for free-proxy: filename=free_proxy-1.1.3-py3-none-any.whl size=6113 sha256=e22563675770f2ee05fd216fe05bf7189af2e3ed4e2a1c57b488dd9a531db07a\n",
      "  Stored in directory: /Users/omar/Library/Caches/pip/wheels/95/45/0e/36fc27d383f76ec4e6f876c6584102b5ab6146ae535735a1ea\n",
      "Successfully built bibtexparser free-proxy\n",
      "Installing collected packages: sortedcontainers, snowballstemmer, wsproto, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, python-dotenv, PySocks, outcome, lxml, imagesize, fake-useragent, docutils, deprecated, bibtexparser, alabaster, trio, sphinx, free-proxy, trio-websocket, sphinxcontrib-jquery, sphinx-rtd-theme, selenium, scholarly\n",
      "Successfully installed PySocks-1.7.1 alabaster-1.0.0 bibtexparser-1.4.3 deprecated-1.2.18 docutils-0.21.2 fake-useragent-2.0.3 free-proxy-1.1.3 imagesize-1.4.1 lxml-5.3.1 outcome-1.3.0.post0 python-dotenv-1.0.1 scholarly-1.7.11 selenium-4.29.0 snowballstemmer-2.2.0 sortedcontainers-2.4.0 sphinx-8.1.3 sphinx-rtd-theme-3.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Users/omar/.pyenv/versions/3.10.4/envs/pfenv_pyenv/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install scholarly pandas tqdm requests beautifulsoup4\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scholarly import scholarly\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Create a directory to store the results\n",
    "os.makedirs('extracted_papers', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying arXiv API with: cat:cs.CL\n",
      "Retrieved 100 papers from API.\n",
      "Added academic paper: Linear Segmentation and Segment Significance... (1/300)\n",
      "Added academic paper: Modelling Users, Intentions, and Structure in Spok... (2/300)\n",
      "Added academic paper: A Lexicalized Tree Adjoining Grammar for English... (3/300)\n",
      "Added academic paper: Prefix Probabilities from Stochastic Tree Adjoinin... (4/300)\n",
      "Added academic paper: Conditions on Consistency of Probabilistic Tree Ad... (5/300)\n",
      "Added academic paper: Separating Dependency from Constituency in a Tree ... (6/300)\n",
      "Added academic paper: Incremental Parser Generation for Tree Adjoining G... (7/300)\n",
      "Added academic paper: A Freely Available Morphological Analyzer, Disambi... (8/300)\n",
      "Added academic paper: Processing Unknown Words in HPSG... (9/300)\n",
      "Added academic paper: Computing Declarative Prosodic Morphology... (10/300)\n",
      "Added academic paper: On the Evaluation and Comparison of Taggers: The E... (11/300)\n",
      "Added academic paper: Improving Tagging Performance by Using Voting Tagg... (12/300)\n",
      "Added academic paper: Resources for Evaluation of Summarization Techniqu... (13/300)\n",
      "Added academic paper: Restrictions on Tree Adjoining Languages... (14/300)\n",
      "Added academic paper: Translating near-synonyms: Possibilities and prefe... (15/300)\n",
      "Added academic paper: Choosing the Word Most Typical in Context Using a ... (16/300)\n",
      "Added academic paper: Comparing a statistical and a rule-based tagger fo... (17/300)\n",
      "Added academic paper: Expoiting Syntactic Structure for Language Modelin... (18/300)\n",
      "Added academic paper: A Structured Language Model... (19/300)\n",
      "Added academic paper: A Probabilistic Approach to Lexical Semantic Knowl... (20/300)\n",
      "Added academic paper: Optimal Multi-Paragraph Text Segmentation by Dynam... (21/300)\n",
      "Added academic paper: A Flexible Shallow Approach to Text Generation... (22/300)\n",
      "Added academic paper: An Empirical Approach to Temporal Reference Resolu... (23/300)\n",
      "Added academic paper: Compacting the Penn Treebank Grammar... (24/300)\n",
      "Added academic paper: The \"Fodor\"-FODOR fallacy bites back... (25/300)\n",
      "Added academic paper: Is Word Sense Disambiguation just one more NLP tas... (26/300)\n",
      "Added academic paper: A Formal Framework for Linguistic Annotation... (27/300)\n",
      "Added academic paper: Empirically Evaluating an Adaptable Spoken Dialogu... (28/300)\n",
      "Added academic paper: Transducers from Rewrite Rules with Backreferences... (29/300)\n",
      "Added academic paper: An ascription-based approach to speech acts... (30/300)\n",
      "Added academic paper: A Computational Memory and Processing Model for Pr... (31/300)\n",
      "Added academic paper: Supervised Grammar Induction Using Training Data w... (32/300)\n",
      "Added academic paper: The syntactic processing of particles in Japanese ... (33/300)\n",
      "Added academic paper: Cascaded Markov Models... (34/300)\n",
      "Added academic paper: Evaluation of the NLP Components of the OVIS2 Spok... (35/300)\n",
      "Added academic paper: Learning Transformation Rules to Find Grammatical ... (36/300)\n",
      "Added academic paper: Temporal Meaning Representations in a Natural Lang... (37/300)\n",
      "Added academic paper: Mapping Multilingual Hierarchies Using Relaxation ... (38/300)\n",
      "Added academic paper: Robust Grammatical Analysis for Spoken Dialogue Sy... (39/300)\n",
      "Added academic paper: A Unified Example-Based and Lexicalist Approach to... (40/300)\n",
      "Added academic paper: Annotation graphs as a framework for multidimensio... (41/300)\n",
      "Added academic paper: Representing Text Chunks... (42/300)\n",
      "Added academic paper: Cross-Language Information Retrieval for Technical... (43/300)\n",
      "Added academic paper: Explanation-based Learning for Machine Translation... (44/300)\n",
      "Added academic paper: Language Identification With Confidence Limits... (45/300)\n",
      "Added academic paper: Selective Magic HPSG Parsing... (46/300)\n",
      "Added academic paper: Corpus Annotation for Parser Evaluation... (47/300)\n",
      "Added academic paper: A Bootstrap Approach to Automatically Generating L... (48/300)\n",
      "Added academic paper: Architectural Considerations for Conversational Sy... (49/300)\n",
      "Added academic paper: Detecting Sub-Topic Correspondence through Biparti... (50/300)\n",
      "Added academic paper: Semantic robust parsing for noun extraction from n... (51/300)\n",
      "Added academic paper: Selective Sampling for Example-based Word Sense Di... (52/300)\n",
      "Added academic paper: Practical experiments with regular approximation o... (53/300)\n",
      "Added academic paper: Question Answering System Using Syntactic Informat... (54/300)\n",
      "Added academic paper: One-Level Prosodic Morphology... (55/300)\n",
      "Added academic paper: Resolution of Indirect Anaphora in Japanese Senten... (56/300)\n",
      "Added academic paper: Pronoun Resolution in Japanese Sentences Using Sur... (57/300)\n",
      "Added academic paper: An Estimate of Referent of Noun Phrases in Japanes... (58/300)\n",
      "Added academic paper: Resolution of Verb Ellipsis in Japanese Sentence u... (59/300)\n",
      "Added academic paper: An Example-Based Approach to Japanese-to-English T... (60/300)\n",
      "Added academic paper: Deduction over Mixed-Level Logic Representations f... (61/300)\n",
      "Added academic paper: Mixed-Level Knowledge Representation and Variable-... (62/300)\n",
      "Added academic paper: A Real World Implementation of Answer Extraction... (63/300)\n",
      "Added academic paper: Measures of Distributional Similarity... (64/300)\n",
      "Added academic paper: Exploiting Syntactic Structure for Natural Languag... (65/300)\n",
      "Added academic paper: Refinement of a Structured Language Model... (66/300)\n",
      "Added academic paper: Recognition Performance of a Structured Language M... (67/300)\n",
      "Added academic paper: Structured Language Modeling for Speech Recognitio... (68/300)\n",
      "Added academic paper: Requirements of Text Processing Lexicons... (69/300)\n",
      "Added academic paper: An Usage Measure Based on Psychophysical Relations... (70/300)\n",
      "Added academic paper: TnT - A Statistical Part-of-Speech Tagger... (71/300)\n",
      "Added academic paper: Message Classification in the Call Center... (72/300)\n",
      "Added academic paper: A Finite State and Data-Oriented Method for Graphe... (73/300)\n",
      "Added academic paper: Variable Word Rate N-grams... (74/300)\n",
      "Added academic paper: Advances in domain independent linear text segment... (75/300)\n",
      "Added academic paper: Information Extraction from Broadcast News... (76/300)\n",
      "Added academic paper: Looking at discourse in a corpus: The role of lexi... (77/300)\n",
      "Added academic paper: A Simple Approach to Building Ensembles of Naive B... (78/300)\n",
      "Added academic paper: Noun Phrase Recognition by System Combination... (79/300)\n",
      "Added academic paper: Improving Testsuites via Instrumentation... (80/300)\n",
      "Added academic paper: On the Scalability of the Answer Extraction System... (81/300)\n",
      "Added academic paper: Finite-State Reduplication in One-Level Prosodic M... (82/300)\n",
      "Added academic paper: Ranking suspected answers to natural language ques... (83/300)\n",
      "Added academic paper: Exploiting Diversity in Natural Language Processin... (84/300)\n",
      "Added academic paper: Bagging and Boosting a Treebank Parser... (85/300)\n",
      "Added academic paper: Exploiting Diversity for Natural Language Parsing... (86/300)\n",
      "Added academic paper: Turning Speech Into Scripts... (87/300)\n",
      "Added academic paper: A Compact Architecture for Dialogue Management Bas... (88/300)\n",
      "Added academic paper: A Comparison of the XTAG and CLE Grammars for Engl... (89/300)\n",
      "Added academic paper: Compiling Language Models from a Linguistically Mo... (90/300)\n",
      "Added academic paper: Dialogue Act Modeling for Automatic Tagging and Re... (91/300)\n",
      "Added academic paper: Can Prosody Aid the Automatic Classification of Di... (92/300)\n",
      "Added academic paper: Entropy-based Pruning of Backoff Language Models... (93/300)\n",
      "Added academic paper: Trainable Methods for Surface Natural Language Gen... (94/300)\n",
      "Added academic paper: Prosody-Based Automatic Segmentation of Speech int... (95/300)\n",
      "Added academic paper: Approximation and Exactness in Finite State Optima... (96/300)\n",
      "Added academic paper: Finite-State Non-Concatenative Morphotactics... (97/300)\n",
      "Added academic paper: Incremental construction of minimal acyclic finite... (98/300)\n",
      "Added academic paper: Bootstrapping a Tagged Corpus through Combination ... (99/300)\n",
      "Added academic paper: ATLAS: A flexible and extensible architecture for ... (100/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added academic paper: Many uses, many annotations for large speech corpo... (101/300)\n",
      "Added academic paper: Parameter-free Model of Rank Polysemantic Distribu... (102/300)\n",
      "Added academic paper: Mapping WordNets Using Structural Information... (103/300)\n",
      "Added academic paper: Language identification of controlled systems: Mod... (104/300)\n",
      "Added academic paper: Interfacing Constraint-Based Grammars and Generati... (105/300)\n",
      "Added academic paper: Comparing two trainable grammatical relations find... (106/300)\n",
      "Added academic paper: More accurate tests for the statistical significan... (107/300)\n",
      "Added academic paper: Tagger Evaluation Given Hierarchical Tag Sets... (108/300)\n",
      "Added academic paper: Applying System Combination to Base Noun Phrase Id... (109/300)\n",
      "Added academic paper: Meta-Learning for Phonemic Annotation of Corpora... (110/300)\n",
      "Added academic paper: Aspects of Pattern-Matching in Data-Oriented Parsi... (111/300)\n",
      "Added academic paper: Temiar Reduplication in One-Level Prosodic Morphol... (112/300)\n",
      "Added academic paper: Efficient probabilistic top-down and left-corner p... (113/300)\n",
      "Added academic paper: Compact non-left-recursive grammars using the sele... (114/300)\n",
      "Added academic paper: Selectional Restrictions in HPSG... (115/300)\n",
      "Added academic paper: Estimation of Stochastic Attribute-Value Grammars ... (116/300)\n",
      "Added academic paper: Noun-phrase co-occurrence statistics for semi-auto... (117/300)\n",
      "Added academic paper: Measuring efficiency in high-accuracy, broad-cover... (118/300)\n",
      "Added academic paper: Estimators for Stochastic ``Unification-Based'' Gr... (119/300)\n",
      "Added academic paper: Exploiting auxiliary distributions in stochastic u... (120/300)\n",
      "Added academic paper: Metonymy Interpretation Using X NO Y Examples... (121/300)\n",
      "Added academic paper: Bunsetsu Identification Using Category-Exclusive R... (122/300)\n",
      "Added academic paper: Japanese Probabilistic Information Retrieval Using... (123/300)\n",
      "Added academic paper: Temporal Expressions in Japanese-to-English Machin... (124/300)\n",
      "Added academic paper: Lexicalized Stochastic Modeling of Constraint-Base... (125/300)\n",
      "Added academic paper: Using a Probabilistic Class-Based Lexicon for Lexi... (126/300)\n",
      "Added academic paper: Probabilistic Constraint Logic Programming. Formal... (127/300)\n",
      "Added academic paper: Automatic Extraction of Subcategorization Frames f... (128/300)\n",
      "Added academic paper: Introduction to the CoNLL-2000 Shared Task: Chunki... (129/300)\n",
      "Added academic paper: Anaphora Resolution in Japanese Sentences Using Su... (130/300)\n",
      "Added academic paper: A Tableaux Calculus for Ambiguous Quantification... (131/300)\n",
      "Added academic paper: Parsing with the Shortest Derivation... (132/300)\n",
      "Added academic paper: An improved parser for data-oriented lexical-funct... (133/300)\n",
      "Added academic paper: Finding consensus in speech recognition: word erro... (134/300)\n",
      "Added academic paper: Using existing systems to supplement small amounts... (135/300)\n",
      "Added academic paper: Exploring automatic word sense disambiguation with... (136/300)\n",
      "Added academic paper: Extraction of semantic relations from a Basque mon... (137/300)\n",
      "Added academic paper: Enriching very large ontologies using the WWW... (138/300)\n",
      "Added academic paper: One Sense per Collocation and Genre/Topic Variatio... (139/300)\n",
      "Added academic paper: Reduction of Intermediate Alphabets in Finite-Stat... (140/300)\n",
      "Added academic paper: Utilizing the World Wide Web as an Encyclopedia: E... (141/300)\n",
      "Added academic paper: A Novelty-based Evaluation Method for Information ... (142/300)\n",
      "Added academic paper: Applying Machine Translation to Two-Stage Cross-La... (143/300)\n",
      "Added academic paper: The Use of Instrumentation in Grammar Engineering... (144/300)\n",
      "Added academic paper: Semantic interpretation of temporal information by... (145/300)\n",
      "Added academic paper: Abductive reasoning with temporal information... (146/300)\n",
      "Added academic paper: Do All Fragments Count?... (147/300)\n",
      "Added academic paper: Multi-Syllable Phonotactic Modelling... (148/300)\n",
      "Added academic paper: Taking Primitive Optimality Theory Beyond the Fini... (149/300)\n",
      "Added academic paper: Finite-State Phonology: Proceedings of the 5th Wor... (150/300)\n",
      "Added academic paper: Mathematical Model of Word Length on the Basis of ... (151/300)\n",
      "Added academic paper: Two-parameter Model of Word Length \"Language - Gen... (152/300)\n",
      "Added academic paper: Magical Number Seven Plus or Minus Two: Syntactic ... (153/300)\n",
      "Added academic paper: A Machine-Learning Approach to Estimating the Refe... (154/300)\n",
      "Added academic paper: Meaning Sort - Three examples: dictionary construc... (155/300)\n",
      "Added academic paper: CRL at Ntcir2... (156/300)\n",
      "Added academic paper: A Decision Tree of Bigrams is an Accurate Predicto... (157/300)\n",
      "Added academic paper: Type Arithmetics: Computation based on the theory ... (158/300)\n",
      "Added academic paper: Dynamic Nonlocal Language Modeling via Hierarchica... (159/300)\n",
      "Added academic paper: Microplanning with Communicative Intentions: The S... (160/300)\n",
      "Added academic paper: Correction of Errors in a Modality Corpus Used for... (161/300)\n",
      "Added academic paper: Man [and Woman] vs. Machine: A Case Study in Base ... (162/300)\n",
      "Added academic paper: A Complete WordNet1.5 to WordNet1.6 Mapping... (163/300)\n",
      "Added academic paper: Joint and conditional estimation of tagging and pa... (164/300)\n",
      "Added academic paper: Probabilistic top-down parsing and language modeli... (165/300)\n",
      "Added academic paper: Robust Probabilistic Predictive Syntactic Processi... (166/300)\n",
      "Added academic paper: Generating a 3D Simulation of a Car Accident from ... (167/300)\n",
      "Added academic paper: Historical Dynamics of Lexical System as Random Wa... (168/300)\n",
      "Added academic paper: Integrating Prosodic and Lexical Cues for Automati... (169/300)\n",
      "Added academic paper: Organizing Encyclopedic Knowledge based on the Web... (170/300)\n",
      "Added academic paper: Using the Distribution of Performance for Studying... (171/300)\n",
      "Added academic paper: Modeling informational novelty in a conversational... (172/300)\n",
      "Added academic paper: The Role of Conceptual Relations in Word Sense Dis... (173/300)\n",
      "Added academic paper: Looking Under the Hood : Tools for Diagnosing your... (174/300)\n",
      "Added academic paper: Introduction to the CoNLL-2001 Shared Task: Clause... (175/300)\n",
      "Added academic paper: Learning Computational Grammars... (176/300)\n",
      "Added academic paper: Combining a self-organising map with memory-based ... (177/300)\n",
      "Added academic paper: Applying Natural Language Generation to Indicative... (178/300)\n",
      "Added academic paper: Transformation-Based Learning in the Fast Lane... (179/300)\n",
      "Added academic paper: Multidimensional Transformation-Based Learning... (180/300)\n",
      "Added academic paper: A Bit of Progress in Language Modeling... (181/300)\n",
      "Added academic paper: Classes for Fast Maximum Entropy Training... (182/300)\n",
      "Added academic paper: Portability of Syntactic Structure for Language Mo... (183/300)\n",
      "Added academic paper: Anaphora and Discourse Structure... (184/300)\n",
      "Added academic paper: Boosting Trees for Anti-Spam Email Filtering... (185/300)\n",
      "Added academic paper: Modelling Semantic Association and Conceptual Inhe... (186/300)\n",
      "Added academic paper: Learning class-to-class selectional preferences... (187/300)\n",
      "Added academic paper: Knowledge Sources for Word Sense Disambiguation... (188/300)\n",
      "Added academic paper: Enriching WordNet concepts with topic signatures... (189/300)\n",
      "Added academic paper: Testing for Mathematical Lineation in Jim Crace's ... (190/300)\n",
      "Added academic paper: Richer Syntactic Dependencies for Structured Langu... (191/300)\n",
      "Added academic paper: Part-of-Speech Tagging with Two Sequential Transdu... (192/300)\n",
      "Added academic paper: What is the minimal set of fragments that achieves... (193/300)\n",
      "Added academic paper: Combining semantic and syntactic structure for lan... (194/300)\n",
      "Added academic paper: A procedure for unsupervised lexicon learning... (195/300)\n",
      "Added academic paper: A Statistical Model for Word Discovery in Transcri... (196/300)\n",
      "Added academic paper: Using a Support-Vector Machine for Japanese-to-Eng... (197/300)\n",
      "Added academic paper: Part of Speech Tagging in Thai Language Using Supp... (198/300)\n",
      "Added academic paper: Universal Model for Paraphrasing -- Using Transfor... (199/300)\n",
      "Added academic paper: Blind Normalization of Speech From Different Chann... (200/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added academic paper: An Integrated Framework for Treebanks and Multilay... (201/300)\n",
      "Added academic paper: Annotation Graphs and Servers and Multi-Modal Reso... (202/300)\n",
      "Added academic paper: Computational Phonology... (203/300)\n",
      "Added academic paper: Phonology... (204/300)\n",
      "Added academic paper: Integrating selectional preferences in WordNet... (205/300)\n",
      "Added academic paper: Decision Lists for English and Basque... (206/300)\n",
      "Added academic paper: The Basque task: did systems perform in the upperb... (207/300)\n",
      "Added academic paper: Memory-Based Shallow Parsing... (208/300)\n",
      "Added academic paper: Unsupervised discovery of morphologically related ... (209/300)\n",
      "Added academic paper: Mostly-Unsupervised Statistical Segmentation of Ja... (210/300)\n",
      "Added academic paper: Ellogon: A New Text Engineering Platform... (211/300)\n",
      "Added academic paper: A variable-free dynamic semantics... (212/300)\n",
      "Added academic paper: NLTK: The Natural Language Toolkit... (213/300)\n",
      "Added academic paper: Unsupervised Discovery of Morphemes... (214/300)\n",
      "Added academic paper: Bootstrapping Lexical Choice via Multiple-Sequence... (215/300)\n",
      "Added academic paper: Evaluating the Effectiveness of Ensembles of Decis... (216/300)\n",
      "Added academic paper: Assessing System Agreement and Instance Difficulty... (217/300)\n",
      "Added academic paper: Machine Learning with Lexical Features: The Duluth... (218/300)\n",
      "Added academic paper: A Method for Open-Vocabulary Speech-Driven Text Re... (219/300)\n",
      "Added academic paper: Japanese/English Cross-Language Information Retrie... (220/300)\n",
      "Added academic paper: A Probabilistic Method for Analyzing Japanese Anap... (221/300)\n",
      "Added academic paper: Applying a Hybrid Query Translation Method to Japa... (222/300)\n",
      "Added academic paper: PRIME: A System for Multi-lingual Patent Retrieval... (223/300)\n",
      "Added academic paper: Language Modeling for Multi-Domain Speech-Driven T... (224/300)\n",
      "Added academic paper: Speech-Driven Text Retrieval: Using Target IR Coll... (225/300)\n",
      "Added academic paper: Using eigenvectors of the bigram graph to infer mo... (226/300)\n",
      "Added academic paper: Analysis of Titles and Readers For Title Generatio... (227/300)\n",
      "Added academic paper: Efficient Deep Processing of Japanese... (228/300)\n",
      "Added academic paper: Using the DIFF Command for Natural Language Proces... (229/300)\n",
      "Added academic paper: Evaluation of Coreference Rules on Complex Narrati... (230/300)\n",
      "Added academic paper: Three New Methods for Evaluating Reference Resolut... (231/300)\n",
      "Added academic paper: Cooperation between Pronoun and Reference Resoluti... (232/300)\n",
      "Added academic paper: Reference Resolution Beyond Coreference: a Concept... (233/300)\n",
      "Added academic paper: A Chart-Parsing Algorithm for Efficient Semantic A... (234/300)\n",
      "Added academic paper: Rerendering Semantic Ontologies: Automatic Extensi... (235/300)\n",
      "Added academic paper: Introduction to the CoNLL-2002 Shared Task: Langua... (236/300)\n",
      "Added academic paper: Probabilistic Parsing Strategies... (237/300)\n",
      "Added academic paper: Answering Subcognitive Turing Test Questions: A Re... (238/300)\n",
      "Added academic paper: An Algorithm for Aligning Sentences in Bilingual C... (239/300)\n",
      "Added academic paper: Empirical Methods for Compound Splitting... (240/300)\n",
      "Added academic paper: About compression of vocabulary in computer orient... (241/300)\n",
      "Added academic paper: Glottochronology and problems of protolanguage rec... (242/300)\n",
      "Added academic paper: Learning to Paraphrase: An Unsupervised Approach U... (243/300)\n",
      "Added academic paper: Blind Normalization of Speech From Different Chann... (244/300)\n",
      "Added academic paper: Glottochronologic Retrognostic of Language System... (245/300)\n",
      "Added academic paper: \"I'm sorry Dave, I'm afraid I can't do that\": Ling... (246/300)\n",
      "Added academic paper: An XML based Document Suite... (247/300)\n",
      "Added academic paper: Exploiting Sublanguage and Domain Characteristics ... (248/300)\n",
      "Added academic paper: An Approach for Resource Sharing in Multilingual N... (249/300)\n",
      "Added academic paper: Factorization of Language Models through Backing-O... (250/300)\n",
      "Added academic paper: Introduction to the CoNLL-2003 Shared Task: Langua... (251/300)\n",
      "Added academic paper: Learning to Order Facts for Discourse Planning in ... (252/300)\n",
      "Added academic paper: An Improved k-Nearest Neighbor Algorithm for Text ... (253/300)\n",
      "Added academic paper: Issues in Communication Game... (254/300)\n",
      "Added academic paper: Parsing and Generation with Tabulation and Compila... (255/300)\n",
      "Added academic paper: The Linguistic DS: Linguisitic Description in MPEG... (256/300)\n",
      "Added academic paper: Collaborative Creation of Digital Content in India... (257/300)\n",
      "Added academic paper: Information Revolution... (258/300)\n",
      "Added academic paper: Anusaaraka: Overcoming the Language Barrier in Ind... (259/300)\n",
      "Added academic paper: Language Access: An Information Based Approach... (260/300)\n",
      "Added academic paper: LERIL : Collaborative Effort for Creating Lexical ... (261/300)\n",
      "Added academic paper: Building a Test Collection for Speech-Driven Web R... (262/300)\n",
      "Added academic paper: A Cross-media Retrieval System for Lecture Videos... (263/300)\n",
      "Added academic paper: Effective XML Representation for Spoken Language i... (264/300)\n",
      "Added academic paper: Application Architecture for Spoken Language Resou... (265/300)\n",
      "Added academic paper: The Rank-Frequency Analysis for the Functional Sty... (266/300)\n",
      "Added academic paper: Measuring the Functional Load of Phonological Cont... (267/300)\n",
      "Added academic paper: Lexical Base as a Compressed Language Model of the... (268/300)\n",
      "Added academic paper: Polarity sensitivity and evaluation order in type-... (269/300)\n",
      "Added academic paper: Tabular Parsing... (270/300)\n",
      "Added academic paper: Test Collections for Patent-to-Patent Retrieval an... (271/300)\n",
      "Added academic paper: A Probabilistic Model of Machine Translation... (272/300)\n",
      "Added academic paper: Catching the Drift: Probabilistic Content Models, ... (273/300)\n",
      "Added academic paper: A Public Reference Implementation of the RAP Anaph... (274/300)\n",
      "Added academic paper: Building a linguistic corpus from bee dance data... (275/300)\n",
      "Added academic paper: Annotating Predicate-Argument Structure for a Para... (276/300)\n",
      "Added academic paper: Statistical Machine Translation by Generalized Par... (277/300)\n",
      "Added academic paper: Summarizing Encyclopedic Term Descriptions on the ... (278/300)\n",
      "Added academic paper: Unsupervised Topic Adaptation for Lecture Speech R... (279/300)\n",
      "Added academic paper: Effects of Language Modeling on Speech-driven Ques... (280/300)\n",
      "Added academic paper: A Bimachine Compiler for Ranked Tagging Rules... (281/300)\n",
      "Added academic paper: Application of the Double Metaphone Algorithm to A... (282/300)\n",
      "Added academic paper: Proofing Tools Technology at Neurosoft S.A.... (283/300)\n",
      "Added academic paper: Verbal chunk extraction in French using limited re... (284/300)\n",
      "Added academic paper: An electronic dictionary as a basis for NLP tools:... (285/300)\n",
      "Added academic paper: A Model for Fine-Grained Alignment of Multilingual... (286/300)\n",
      "Added academic paper: A Sentimental Education: Sentiment Analysis Using ... (287/300)\n",
      "Added academic paper: A Tutorial on the Expectation-Maximization Algorit... (288/300)\n",
      "Added academic paper: Inside-Outside Estimation Meets Dynamic EM... (289/300)\n",
      "Added academic paper: State of the Art, Evaluation and Recommendations r... (290/300)\n",
      "Added academic paper: Thematic Annotation: extracting concepts out of do... (291/300)\n",
      "Added academic paper: Multi-document Biography Summarization... (292/300)\n",
      "Added academic paper: A Matter of Opinion: Sentiment Analysis and Busine... (293/300)\n",
      "Added academic paper: Word sense disambiguation criteria: a systematic s... (294/300)\n",
      "Added academic paper: Using phonetic constraints in acoustic-to-articula... (295/300)\n",
      "Added academic paper: An elitist approach for extracting automatically w... (296/300)\n",
      "Added academic paper: Statistical Parameters of the Novel \"Perekhresni s... (297/300)\n",
      "Added academic paper: Analyzing language development from a network appr... (298/300)\n",
      "Added academic paper: Unification of multi-lingual scientific terminolog... (299/300)\n",
      "Added academic paper: Foundations of Modern Language Resource Archives... (300/300)\n",
      "Retrieved 100 papers from API.\n",
      "No more results or API error. Moving to next query.\n",
      "Querying arXiv API with: \"natural language processing\"\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Prompt Engineering for Healthcare: Methodologies a... (1/300)\n",
      "Added industry paper: Natural language processing on customer note data... (2/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: torchdistill Meets Hugging Face Libraries for Repr... (3/300)\n",
      "Added industry paper: A Natural Language Processing Framework for Hotel ... (4/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Application of Sequence Embedding in Protein Seque... (5/300)\n",
      "Added industry paper: Addressing the Selection Bias in Voice Assistance:... (6/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Deployment of a Free-Text Analytics Platform at a ... (7/300)\n",
      "Added industry paper: Review of Design of Speech Recognition and Text An... (8/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Dependency-based Text Graphs for Keyphrase and Sum... (9/300)\n",
      "Added industry paper: COVID-Twitter-BERT: A Natural Language Processing ... (10/300)\n",
      "Added industry paper: NARMADA: Need and Available Resource Managing Assi... (11/300)\n",
      "Added industry paper: TweeNLP: A Twitter Exploration Portal for Natural ... (12/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Types of Approaches, Applications and Challenges i... (13/300)\n",
      "Added industry paper: Gpt-4: A Review on Advancements and Opportunities ... (14/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Convolutional Neural Networks for Sentiment Analys... (15/300)\n",
      "Added industry paper: Energy Estimates Across Layers of Computing: From ... (16/300)\n",
      "Added industry paper: App for Resume-Based Job Matching with Speech Inte... (17/300)\n",
      "Added industry paper: Riveter: Measuring Power and Social Dynamics Betwe... (18/300)\n",
      "Added industry paper: Development of a Human-Robot Interaction Platform ... (19/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Determining the Unithood of Word Sequences using a... (20/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Deep Learning Algorithms with Applications to Vide... (21/300)\n",
      "Added industry paper: A Framework for Extracting and Modeling HIPAA Priv... (22/300)\n",
      "Added industry paper: When silver glitters more than gold: Bootstrapping... (23/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Lessons from Contextual Bandit Learning in a Custo... (24/300)\n",
      "Added industry paper: Exploiting Social Networks. Technological Trends (... (25/300)\n",
      "Querying arXiv API with: \"NLP\" AND \"deep learning\"\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Deep Learning and NLP in Cryptocurrency Forecastin... (26/300)\n",
      "Added industry paper: Sentiment Analysis Based on Deep Learning: A Compa... (27/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Applications of Deep Neural Networks with Keras... (28/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Spatio-temporal Storytelling? Leveraging Generativ... (29/300)\n",
      "Added industry paper: Cross-Cultural Polarity and Emotion Detection Usin... (30/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: The Role of LLMs in Sustainable Smart Cities: Appl... (31/300)\n",
      "Added industry paper: BET: A Backtranslation Approach for Easy Data Augm... (32/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: BERTaú: Itaú BERT for digital customer service... (33/300)\n",
      "Added industry paper: Online Embedding Compression for Text Classificati... (34/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: A large-scale Twitter dataset for drug safety appl... (35/300)\n",
      "Added industry paper: AI Trust in business processes: The need for proce... (36/300)\n",
      "Added industry paper: A Compression-Compilation Framework for On-mobile ... (37/300)\n",
      "Added industry paper: BERT-Defense: A Probabilistic Model Based on BERT ... (38/300)\n",
      "Added industry paper: Exploring Personality and Online Social Engagement... (39/300)\n",
      "Added industry paper: Multi-modal application: Image Memes Generation... (40/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Federated Continual Learning for Text Classificati... (41/300)\n",
      "Added industry paper: Analysis and Detection of Multilingual Hate Speech... (42/300)\n",
      "Added industry paper: Transparent but Powerful: Explainability, Accuracy... (43/300)\n",
      "Added industry paper: Advances in Transformers for Robotic Applications:... (44/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Deep Learning-Based Sentiment Analysis of COVID-19... (45/300)\n",
      "Added industry paper: ProcessGPT: Transforming Business Process Manageme... (46/300)\n",
      "Added industry paper: Efficacy of BERT embeddings on predicting disaster... (47/300)\n",
      "Added industry paper: Sentiment and Emotion Classification of Epidemic R... (48/300)\n",
      "Added industry paper: Stock price prediction using BERT and GAN... (49/300)\n",
      "Added industry paper: DuETT: Dual Event Time Transformer for Electronic ... (50/300)\n",
      "Retrieved 81 papers from API.\n",
      "No more results or API error. Moving to next query.\n",
      "Querying arXiv API with: \"language model\" AND \"transformer\"\n",
      "Retrieved 100 papers from API.\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: LinkTransformer: A Unified Package for Record Link... (51/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: MoEUT: Mixture-of-Experts Universal Transformers... (52/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Memory Transformer... (53/300)\n",
      "Added industry paper: Leveraging Pre-trained Models for Failure Analysis... (54/300)\n",
      "Added industry paper: SwitchHead: Accelerating Transformers with Mixture... (55/300)\n",
      "Retrieved 100 papers from API.\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: A Survey on Large Language Models for Personalized... (56/300)\n",
      "Added industry paper: Understanding Transformers for Bot Detection in Tw... (57/300)\n",
      "No more results or API error. Moving to next query.\n",
      "Querying arXiv API with: \"BERT\" OR \"GPT\" AND \"language\"\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Evaluating Text Summaries Generated by Large Langu... (58/300)\n",
      "Added industry paper: GPT Models in Construction Industry: Opportunities... (59/300)\n",
      "Added industry paper: Few-shot learning for sentence pair classification... (60/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: How well can machine-generated texts be identified... (61/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Automated radiotherapy treatment planning guided b... (62/300)\n",
      "Added industry paper: From Chatbots to PhishBots? -- Preventing Phishing... (63/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Multimodal ChatGPT for Medical Applications: an Ex... (64/300)\n",
      "Added industry paper: PaSa: An LLM Agent for Comprehensive Academic Pape... (65/300)\n",
      "Added industry paper: Towards LLM-based optimization compilers. Can LLMs... (66/300)\n",
      "Added industry paper: Leveraging GPT-4o Efficiency for Detecting Rework ... (67/300)\n",
      "Added industry paper: Integrating Large Language Models with Internet of... (68/300)\n",
      "Added industry paper: A Challenger to GPT-4V? Early Explorations of Gemi... (69/300)\n",
      "Added industry paper: Realizing Visual Question Answering for Education:... (70/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Multi-Agent Reinforcement Learning is a Sequence M... (71/300)\n",
      "Added industry paper: Data Exposure from LLM Apps: An In-depth Investiga... (72/300)\n",
      "Added industry paper: Unleashing GPT on the Metaverse: Savior or Destroy... (73/300)\n",
      "Added industry paper: Can Large Language Models Understand Molecules?... (74/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Multiclass Classification of Policy Documents with... (75/300)\n",
      "Added industry paper: Benchmarking Llama2, Mistral, Gemma and GPT for Fa... (76/300)\n",
      "Added industry paper: Digital Guardians: Can GPT-4, Perspective API, and... (77/300)\n",
      "Added industry paper: The Silicon Ceiling: Auditing GPT's Race and Gende... (78/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Distinguishing ChatGPT(-3.5, -4)-generated and hum... (79/300)\n",
      "Added industry paper: DNA-GPT: Divergent N-Gram Analysis for Training-Fr... (80/300)\n",
      "Added industry paper: Cancer Type, Stage and Prognosis Assessment from P... (81/300)\n",
      "Added industry paper: Named entity recognition using GPT for identifying... (82/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: T2S-GPT: Dynamic Vector Quantization for Autoregre... (83/300)\n",
      "Added industry paper: CulturalBench: a Robust, Diverse and Challenging B... (84/300)\n",
      "Added industry paper: The GitHub Recent Bugs Dataset for Evaluating LLM-... (85/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: The Power of Combining Data and Knowledge: GPT-4o ... (86/300)\n",
      "Added industry paper: Vision-Language Model-based Physical Reasoning for... (87/300)\n",
      "Retrieved 100 papers from API.\n",
      "Added industry paper: Can AI Moderate Online Communities?... (88/300)\n",
      "Added industry paper: Optimizing Performance: How Compact Models Match o... (89/300)\n",
      "Added industry paper: On the Promises and Challenges of Multimodal Found... (90/300)\n",
      "Collected 300 academic papers and 90 industry papers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef1e57de7da41f78ae5eebae9f4f467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading PDFs:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download PDF for 9908001v1, status: 500\n",
      "Failed to download PDF for 0002007v1, status: 500\n",
      "Failed to download PDF for 0102022v2, status: 500\n",
      "Failed to download PDF for 0104010v1, status: 500\n",
      "Successfully downloaded 296 PDFs to nlp_papers/academic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f82e1e97564c0b9895bd7cbc5880c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading PDFs:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 90 PDFs to nlp_papers/industry\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9514d8794db645328f4b81641de4db0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting text from PDFs:   0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from 296 PDFs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d14675060440718dd692b536f82de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting text from PDFs:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text from 90 PDFs\n",
      "Warning: Only 90 papers available for balanced dataset\n",
      "Final academic papers: 296\n",
      "Final industry papers: 90\n",
      "Final balanced dataset: 180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import tarfile\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create necessary directories\"\"\"\n",
    "    os.makedirs('nlp_papers', exist_ok=True)\n",
    "    os.makedirs('nlp_papers/academic', exist_ok=True)\n",
    "    os.makedirs('nlp_papers/industry', exist_ok=True)\n",
    "\n",
    "def download_arxiv_metadata_sample():\n",
    "    \"\"\"\n",
    "    Download a sample of the arXiv metadata instead of the full file\n",
    "    \"\"\"\n",
    "    print(\"Downloading arXiv metadata sample...\")\n",
    "    \n",
    "    # URL for the Kaggle dataset (smaller subset)\n",
    "    # Alternative: use the arXiv API instead\n",
    "    metadata_url = \"https://arxiv.org/help/api/basics\"\n",
    "    \n",
    "    print(f\"Please visit {metadata_url} to learn about the arXiv API usage.\")\n",
    "    print(\"We'll use the arXiv API to download metadata for specific queries.\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def query_arxiv_api(query, start=0, max_results=100):\n",
    "    \"\"\"\n",
    "    Query the arXiv API for papers\n",
    "    \n",
    "    Parameters:\n",
    "    - query: Search query string\n",
    "    - start: Starting index\n",
    "    - max_results: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "    - List of paper metadata\n",
    "    \"\"\"\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    \n",
    "    # Build the query URL\n",
    "    query_url = f\"{base_url}search_query={query}&start={start}&max_results={max_results}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(query_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Parse the XML response\n",
    "            import xml.etree.ElementTree as ET\n",
    "            root = ET.fromstring(response.content)\n",
    "            \n",
    "            # Extract papers\n",
    "            papers = []\n",
    "            ns = {'atom': 'http://www.w3.org/2005/Atom', \n",
    "                  'arxiv': 'http://arxiv.org/schemas/atom'}\n",
    "            \n",
    "            for entry in root.findall('.//atom:entry', ns):\n",
    "                # Extract basic paper information\n",
    "                paper = {}\n",
    "                \n",
    "                # ID (convert from URL to arXiv ID)\n",
    "                id_elem = entry.find('./atom:id', ns)\n",
    "                if id_elem is not None:\n",
    "                    paper['id'] = id_elem.text.split('/')[-1]\n",
    "                \n",
    "                # Title\n",
    "                title_elem = entry.find('./atom:title', ns)\n",
    "                if title_elem is not None:\n",
    "                    paper['title'] = title_elem.text\n",
    "                \n",
    "                # Abstract\n",
    "                summary_elem = entry.find('./atom:summary', ns)\n",
    "                if summary_elem is not None:\n",
    "                    paper['abstract'] = summary_elem.text\n",
    "                \n",
    "                # Authors\n",
    "                authors = []\n",
    "                for author_elem in entry.findall('./atom:author', ns):\n",
    "                    name_elem = author_elem.find('./atom:name', ns)\n",
    "                    if name_elem is not None:\n",
    "                        authors.append(name_elem.text)\n",
    "                paper['authors'] = ', '.join(authors)\n",
    "                \n",
    "                # Categories\n",
    "                categories = []\n",
    "                for cat_elem in entry.findall('./arxiv:primary_category', ns):\n",
    "                    if 'term' in cat_elem.attrib:\n",
    "                        categories.append(cat_elem.attrib['term'])\n",
    "                for cat_elem in entry.findall('./atom:category', ns):\n",
    "                    if 'term' in cat_elem.attrib:\n",
    "                        categories.append(cat_elem.attrib['term'])\n",
    "                paper['categories'] = ', '.join(categories)\n",
    "                \n",
    "                # Publication date\n",
    "                published_elem = entry.find('./atom:published', ns)\n",
    "                if published_elem is not None:\n",
    "                    paper['published'] = published_elem.text[:10]  # YYYY-MM-DD\n",
    "                \n",
    "                # Links\n",
    "                for link_elem in entry.findall('./atom:link', ns):\n",
    "                    if link_elem.attrib.get('title') == 'pdf':\n",
    "                        paper['pdf_url'] = link_elem.attrib.get('href')\n",
    "                    elif link_elem.attrib.get('rel') == 'alternate':\n",
    "                        paper['url'] = link_elem.attrib.get('href')\n",
    "                \n",
    "                papers.append(paper)\n",
    "            \n",
    "            return papers\n",
    "        else:\n",
    "            print(f\"Error: API returned status code {response.status_code}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying arXiv API: {e}\")\n",
    "        return []\n",
    "\n",
    "def classify_paper_affiliation(paper):\n",
    "    \"\"\"\n",
    "    Classify a paper as academic or industry based on metadata\n",
    "    with improved author affiliation extraction\n",
    "    \n",
    "    Parameters:\n",
    "    - paper: Paper metadata\n",
    "    \n",
    "    Returns:\n",
    "    - 'academic', 'industry', or None\n",
    "    \"\"\"\n",
    "    # Companies to identify industry papers - expanded list\n",
    "    companies = [\n",
    "        'google', 'microsoft', 'amazon', 'facebook', 'meta', 'apple', 'ibm', \n",
    "        'deepmind', 'openai', 'anthropic', 'nvidia', 'hugging face', 'tencent',\n",
    "        'baidu', 'salesforce', 'adobe', 'twitter', 'linkedin', 'samsung',\n",
    "        'uber', 'netflix', 'intel', 'oracle', 'sap', 'bloomberg', 'spotify',\n",
    "        'airbnb', 'dropbox', 'ebay', 'snap', 'paypal', 'stripe'\n",
    "    ]\n",
    "    \n",
    "    # Academic institutions keywords\n",
    "    academic_keywords = [\n",
    "        'university', 'college', 'institute of technology', 'polytechnic',\n",
    "        'school of', 'department of', 'faculty of', 'academy of sciences',\n",
    "        'university of', 'ecole', 'universit', 'academic', 'laboratory',\n",
    "        'lab,', 'lab.', 'laboratory,', 'laboratory.'\n",
    "    ]\n",
    "    \n",
    "    # Additional heuristics\n",
    "    email_academic_domains = ['.edu', '.ac.', '.uni-', '.univ']\n",
    "    \n",
    "    # Try to determine if it's industry or academic\n",
    "    is_industry = False\n",
    "    is_academic = False\n",
    "    \n",
    "    # Check authors field for affiliations\n",
    "    authors = paper.get('authors', '')\n",
    "    \n",
    "    # Look for affiliations in different formats\n",
    "    # Common format: \"Author Name (Organization)\"\n",
    "    affiliation_pattern = re.compile(r'\\((.*?)\\)')\n",
    "    affiliations = affiliation_pattern.findall(authors)\n",
    "    \n",
    "    # Common format: \"Author Name, Organization\"\n",
    "    if not affiliations and ',' in authors:\n",
    "        # Try to extract the part after the first comma\n",
    "        first_author_parts = authors.split(',', 1)\n",
    "        if len(first_author_parts) > 1:\n",
    "            affiliations.append(first_author_parts[1].strip())\n",
    "    \n",
    "    # Process found affiliations\n",
    "    for affiliation in affiliations:\n",
    "        affiliation_lower = affiliation.lower()\n",
    "        \n",
    "        # Check for industry affiliations\n",
    "        for company in companies:\n",
    "            if company in affiliation_lower:\n",
    "                is_industry = True\n",
    "                break\n",
    "        \n",
    "        # Check for academic affiliations\n",
    "        for keyword in academic_keywords:\n",
    "            if keyword in affiliation_lower:\n",
    "                is_academic = True\n",
    "                break\n",
    "    \n",
    "    # If no clear affiliation found in authors field, check abstract\n",
    "    if not is_industry and not is_academic:\n",
    "        abstract = paper.get('abstract', '').lower()\n",
    "        \n",
    "        # Look for author affiliations sometimes mentioned in abstract\n",
    "        for company in companies:\n",
    "            if company in abstract:\n",
    "                # Check if it appears as an affiliation mention\n",
    "                if any(marker in abstract for marker in \n",
    "                       [f\"at {company}\", f\"from {company}\", f\"{company} research\", \n",
    "                        f\"{company},\", f\"{company} inc\", f\"{company} corporation\"]):\n",
    "                    is_industry = True\n",
    "                    break\n",
    "        \n",
    "        for keyword in academic_keywords:\n",
    "            if keyword in abstract:\n",
    "                # Check if it appears as an affiliation mention\n",
    "                if any(marker in abstract for marker in \n",
    "                       [f\"at {keyword}\", f\"from {keyword}\", f\"{keyword} research\",\n",
    "                        f\"{keyword},\", f\"the {keyword}\"]):\n",
    "                    is_academic = True\n",
    "                    break\n",
    "    \n",
    "    # Check for email domains if available (sometimes in authors field)\n",
    "    email_pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    emails = email_pattern.findall(authors)\n",
    "    \n",
    "    if emails:\n",
    "        primary_email = emails[0].lower()\n",
    "        \n",
    "        # Check academic email domains\n",
    "        if any(domain in primary_email for domain in email_academic_domains):\n",
    "            is_academic = True\n",
    "        \n",
    "        # Check industry email domains\n",
    "        if any(company in primary_email for company in companies):\n",
    "            is_industry = True\n",
    "    \n",
    "    # Check paper categories for additional clues\n",
    "    categories = paper.get('categories', '').lower()\n",
    "    if 'cs.cl' in categories and not is_industry:\n",
    "        # Computational Linguistics papers without industry affiliation \n",
    "        # are more likely to be academic\n",
    "        is_academic = True\n",
    "    \n",
    "    # Make a decision\n",
    "    if is_industry and is_academic:\n",
    "        # Check which is stronger - prioritize by order in author list\n",
    "        if authors:\n",
    "            first_half = authors[:len(authors)//2].lower()\n",
    "            for company in companies:\n",
    "                if company in first_half:\n",
    "                    return 'industry'\n",
    "            \n",
    "            for keyword in academic_keywords:\n",
    "                if keyword in first_half:\n",
    "                    return 'academic'\n",
    "        \n",
    "        # Default prioritization for mixed affiliations\n",
    "        return 'industry'  # Industry papers are rarer, so prioritize them\n",
    "    elif is_industry:\n",
    "        return 'industry'\n",
    "    elif is_academic:\n",
    "        return 'academic'\n",
    "    else:\n",
    "        # If still unclear, we need additional heuristics\n",
    "        \n",
    "        # Check if title contains common industry terms\n",
    "        title = paper.get('title', '').lower()\n",
    "        industry_title_terms = ['product', 'application', 'platform', 'customer', 'business']\n",
    "        academic_title_terms = ['theoretical', 'framework', 'formal', 'model of', 'approach to']\n",
    "        \n",
    "        if any(term in title for term in industry_title_terms):\n",
    "            return 'industry'\n",
    "        \n",
    "        if any(term in title for term in academic_title_terms):\n",
    "            return 'academic'\n",
    "        \n",
    "        # Default to academic as most papers on arXiv are academic\n",
    "        return 'academic'\n",
    "\n",
    "def download_pdf(paper_id, pdf_url, output_dir):\n",
    "    \"\"\"\n",
    "    Download the PDF for a paper\n",
    "    \n",
    "    Parameters:\n",
    "    - paper_id: ID of the paper\n",
    "    - pdf_url: URL to download the PDF\n",
    "    - output_dir: Directory to save the PDF\n",
    "    \n",
    "    Returns:\n",
    "    - True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Check if we already have this PDF\n",
    "    pdf_path = os.path.join(output_dir, f\"{paper_id}.pdf\")\n",
    "    if os.path.exists(pdf_path):\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        # Add a delay to be polite to the server\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Download the PDF\n",
    "        response = requests.get(pdf_url, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to download PDF for {paper_id}, status: {response.status_code}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading PDF for {paper_id}: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_path: Path to the PDF file\n",
    "    \n",
    "    Returns:\n",
    "    - Extracted text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import PyPDF2\n",
    "        \n",
    "        with open(pdf_path, 'rb') as f:\n",
    "            pdf_reader = PyPDF2.PdfReader(f)\n",
    "            text = \"\"\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for i in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[i]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "            \n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_nlp_papers(num_academic=300, num_industry=300, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Extract NLP papers from arXiv using the API\n",
    "    \n",
    "    Parameters:\n",
    "    - num_academic: Number of academic papers to extract\n",
    "    - num_industry: Number of industry papers to extract\n",
    "    - max_iterations: Maximum number of API calls\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrames for academic and industry papers\n",
    "    \"\"\"\n",
    "    setup_directories()\n",
    "    \n",
    "    # NLP-related search queries\n",
    "    queries = [\n",
    "        \"cat:cs.CL\",  # Computational Linguistics\n",
    "        \"\\\"natural language processing\\\"\",\n",
    "        \"\\\"NLP\\\" AND \\\"deep learning\\\"\",\n",
    "        \"\\\"language model\\\" AND \\\"transformer\\\"\",\n",
    "        \"\\\"BERT\\\" OR \\\"GPT\\\" AND \\\"language\\\"\"\n",
    "    ]\n",
    "    \n",
    "    academic_papers = []\n",
    "    industry_papers = []\n",
    "    \n",
    "    processed_ids = set()  # Track papers we've already processed\n",
    "    \n",
    "    # Try each query until we have enough papers\n",
    "    for query in queries:\n",
    "        if len(academic_papers) >= num_academic and len(industry_papers) >= num_industry:\n",
    "            break\n",
    "            \n",
    "        print(f\"Querying arXiv API with: {query}\")\n",
    "        \n",
    "        # Make multiple API calls with different start indices\n",
    "        for iteration in range(max_iterations):\n",
    "            start_index = iteration * 100\n",
    "            \n",
    "            # Check if we have enough papers\n",
    "            if len(academic_papers) >= num_academic and len(industry_papers) >= num_industry:\n",
    "                break\n",
    "                \n",
    "            # Query the API\n",
    "            results = query_arxiv_api(query, start=start_index, max_results=100)\n",
    "            \n",
    "            if not results:\n",
    "                print(\"No more results or API error. Moving to next query.\")\n",
    "                break\n",
    "                \n",
    "            print(f\"Retrieved {len(results)} papers from API.\")\n",
    "            \n",
    "            # Process the results\n",
    "            for paper in results:\n",
    "                # Skip if we've already processed this paper\n",
    "                if paper['id'] in processed_ids:\n",
    "                    continue\n",
    "                    \n",
    "                processed_ids.add(paper['id'])\n",
    "                \n",
    "                # Classify the paper\n",
    "                paper_type = classify_paper_affiliation(paper)\n",
    "                paper['type'] = paper_type\n",
    "                \n",
    "                # Add to appropriate list if we still need papers of this type\n",
    "                if paper_type == 'academic' and len(academic_papers) < num_academic:\n",
    "                    academic_papers.append(paper)\n",
    "                    print(f\"Added academic paper: {paper['title'][:50]}... ({len(academic_papers)}/{num_academic})\")\n",
    "                    \n",
    "                elif paper_type == 'industry' and len(industry_papers) < num_industry:\n",
    "                    industry_papers.append(paper)\n",
    "                    print(f\"Added industry paper: {paper['title'][:50]}... ({len(industry_papers)}/{num_industry})\")\n",
    "            \n",
    "            # Pause between API calls to be respectful\n",
    "            time.sleep(3)\n",
    "    \n",
    "    # Create DataFrames\n",
    "    academic_df = pd.DataFrame(academic_papers)\n",
    "    industry_df = pd.DataFrame(industry_papers)\n",
    "    \n",
    "    # Save the metadata\n",
    "    academic_df.to_csv('nlp_papers/academic_papers_metadata.csv', index=False)\n",
    "    industry_df.to_csv('nlp_papers/industry_papers_metadata.csv', index=False)\n",
    "    \n",
    "    print(f\"Collected {len(academic_df)} academic papers and {len(industry_df)} industry papers.\")\n",
    "    \n",
    "    return academic_df, industry_df\n",
    "\n",
    "def download_paper_pdfs(papers_df, output_dir, limit=None):\n",
    "    \"\"\"\n",
    "    Download PDFs for papers in the DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    - papers_df: DataFrame containing paper metadata\n",
    "    - output_dir: Directory to save the PDFs\n",
    "    - limit: Maximum number of papers to download (None for all)\n",
    "    \n",
    "    Returns:\n",
    "    - List of successfully downloaded paper IDs\n",
    "    \"\"\"\n",
    "    if limit:\n",
    "        papers_to_download = papers_df.head(limit)\n",
    "    else:\n",
    "        papers_to_download = papers_df\n",
    "    \n",
    "    successful_downloads = []\n",
    "    \n",
    "    for _, paper in tqdm(papers_to_download.iterrows(), total=len(papers_to_download), desc=\"Downloading PDFs\"):\n",
    "        paper_id = paper['id']\n",
    "        pdf_url = paper.get('pdf_url')\n",
    "        \n",
    "        if not pdf_url:\n",
    "            # Construct PDF URL if not available\n",
    "            pdf_url = f\"https://arxiv.org/pdf/{paper_id}.pdf\"\n",
    "        \n",
    "        # Download the PDF\n",
    "        if download_pdf(paper_id, pdf_url, output_dir):\n",
    "            successful_downloads.append(paper_id)\n",
    "    \n",
    "    print(f\"Successfully downloaded {len(successful_downloads)} PDFs to {output_dir}\")\n",
    "    return successful_downloads\n",
    "\n",
    "def extract_text_from_pdfs(paper_ids, input_dir):\n",
    "    \"\"\"\n",
    "    Extract text from downloaded PDFs\n",
    "    \n",
    "    Parameters:\n",
    "    - paper_ids: List of paper IDs\n",
    "    - input_dir: Directory containing the PDFs\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary mapping paper IDs to extracted text\n",
    "    \"\"\"\n",
    "    # Install PyPDF2 if not already installed\n",
    "    try:\n",
    "        import PyPDF2\n",
    "    except ImportError:\n",
    "        !pip install PyPDF2\n",
    "        import PyPDF2\n",
    "    \n",
    "    text_contents = {}\n",
    "    \n",
    "    for paper_id in tqdm(paper_ids, desc=\"Extracting text from PDFs\"):\n",
    "        pdf_path = os.path.join(input_dir, f\"{paper_id}.pdf\")\n",
    "        \n",
    "        if os.path.exists(pdf_path):\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            text_contents[paper_id] = text\n",
    "    \n",
    "    print(f\"Extracted text from {len(text_contents)} PDFs\")\n",
    "    return text_contents\n",
    "\n",
    "def create_final_datasets(academic_df, industry_df, academic_texts, industry_texts):\n",
    "    \"\"\"\n",
    "    Create final datasets with text content\n",
    "    \n",
    "    Parameters:\n",
    "    - academic_df: DataFrame with academic paper metadata\n",
    "    - industry_df: DataFrame with industry paper metadata\n",
    "    - academic_texts: Dictionary of academic paper texts\n",
    "    - industry_texts: Dictionary of industry paper texts\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrames for academic and industry papers with content\n",
    "    \"\"\"\n",
    "    # Add content to dataframes\n",
    "    academic_with_content = academic_df.copy()\n",
    "    academic_with_content['content'] = academic_with_content['id'].apply(\n",
    "        lambda x: academic_texts.get(x, \"\")\n",
    "    )\n",
    "    \n",
    "    industry_with_content = industry_df.copy()\n",
    "    industry_with_content['content'] = industry_with_content['id'].apply(\n",
    "        lambda x: industry_texts.get(x, \"\")\n",
    "    )\n",
    "    \n",
    "    # Filter out papers without content\n",
    "    academic_with_content = academic_with_content[academic_with_content['content'].str.len() > 100]\n",
    "    industry_with_content = industry_with_content[industry_with_content['content'].str.len() > 100]\n",
    "    \n",
    "    # Clean text fields\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove non-printable characters\n",
    "        text = ''.join(c for c in text if c.isprintable() or c in ['\\n', '\\t'])\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    academic_with_content['title'] = academic_with_content['title'].apply(clean_text)\n",
    "    academic_with_content['abstract'] = academic_with_content['abstract'].apply(clean_text)\n",
    "    academic_with_content['content'] = academic_with_content['content'].apply(clean_text)\n",
    "    \n",
    "    industry_with_content['title'] = industry_with_content['title'].apply(clean_text)\n",
    "    industry_with_content['abstract'] = industry_with_content['abstract'].apply(clean_text)\n",
    "    industry_with_content['content'] = industry_with_content['content'].apply(clean_text)\n",
    "    \n",
    "    # Save final datasets\n",
    "    academic_with_content.to_csv('nlp_papers/academic_papers_with_content.csv', index=False)\n",
    "    industry_with_content.to_csv('nlp_papers/industry_papers_with_content.csv', index=False)\n",
    "    \n",
    "    # Create balanced dataset\n",
    "    min_size = min(len(academic_with_content), len(industry_with_content))\n",
    "    \n",
    "    if min_size < 300:\n",
    "        print(f\"Warning: Only {min_size} papers available for balanced dataset\")\n",
    "    \n",
    "    academic_sample = academic_with_content.sample(min(min_size, 300), random_state=42)\n",
    "    industry_sample = industry_with_content.sample(min(min_size, 300), random_state=42)\n",
    "    \n",
    "    balanced_df = pd.concat([academic_sample, industry_sample])\n",
    "    balanced_df.to_csv('nlp_papers/balanced_nlp_papers.csv', index=False)\n",
    "    \n",
    "    return academic_with_content, industry_with_content, balanced_df\n",
    "\n",
    "# Main execution function\n",
    "def extract_nlp_papers_main():\n",
    "    \"\"\"Main function to extract NLP papers\"\"\"\n",
    "    # Step 1: Set up extraction\n",
    "    setup_directories()\n",
    "    \n",
    "    # Step 2: Extract metadata\n",
    "    academic_df, industry_df = extract_nlp_papers(num_academic=300, num_industry=300)\n",
    "    \n",
    "    # Step 3: Download PDFs\n",
    "    academic_downloads = download_paper_pdfs(academic_df, 'nlp_papers/academic')\n",
    "    industry_downloads = download_paper_pdfs(industry_df, 'nlp_papers/industry')\n",
    "    \n",
    "    # Step 4: Extract text from PDFs\n",
    "    academic_texts = extract_text_from_pdfs(academic_downloads, 'nlp_papers/academic')\n",
    "    industry_texts = extract_text_from_pdfs(industry_downloads, 'nlp_papers/industry')\n",
    "    \n",
    "    # Step 5: Create final datasets\n",
    "    academic_final, industry_final, balanced_final = create_final_datasets(\n",
    "        academic_df, industry_df, academic_texts, industry_texts\n",
    "    )\n",
    "    \n",
    "    print(f\"Final academic papers: {len(academic_final)}\")\n",
    "    print(f\"Final industry papers: {len(industry_final)}\")\n",
    "    print(f\"Final balanced dataset: {len(balanced_final)}\")\n",
    "    \n",
    "    return academic_final, industry_final, balanced_final\n",
    "\n",
    "# Run the extraction process\n",
    "academic_papers, industry_papers, balanced_papers = extract_nlp_papers_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      We present a new method for discovering a segm...\n",
       "1      We outline how utterances in dialogs can be in...\n",
       "2      This document describes a sizable grammar of E...\n",
       "3      Language models for speech recognition typical...\n",
       "4      Much of the power of probabilistic methods in ...\n",
       "                             ...                        \n",
       "295    The problem of measuring sentence similarity i...\n",
       "296    Natural Language Processing offers new insight...\n",
       "297    How can a text corpus stored in a customer rel...\n",
       "298    In this study, a natural language processing-b...\n",
       "299    Federated Learning aims to learn machine learn...\n",
       "Name: abstract, Length: 296, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_papers['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>published</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2304.14670v2</td>\n",
       "      <td>Prompt Engineering for Healthcare: Methodologi...</td>\n",
       "      <td>Prompt engineering is a critical technique in ...</td>\n",
       "      <td>Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Cho...</td>\n",
       "      <td>cs.AI, cs.AI</td>\n",
       "      <td>2023-04-28</td>\n",
       "      <td>http://arxiv.org/abs/2304.14670v2</td>\n",
       "      <td>http://arxiv.org/pdf/2304.14670v2</td>\n",
       "      <td>industry</td>\n",
       "      <td>JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2305.02029v1</td>\n",
       "      <td>Natural language processing on customer note data</td>\n",
       "      <td>Automatic analysis of customer data for busine...</td>\n",
       "      <td>Andrew Hilditch, David Webb, Jozef Baca, Tom A...</td>\n",
       "      <td>cs.CL, cs.CL</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>http://arxiv.org/abs/2305.02029v1</td>\n",
       "      <td>http://arxiv.org/pdf/2305.02029v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>Natural language processing on customer note d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2310.17644v1</td>\n",
       "      <td>torchdistill Meets Hugging Face Libraries for ...</td>\n",
       "      <td>Reproducibility in scientific work has been be...</td>\n",
       "      <td>Yoshitomo Matsubara</td>\n",
       "      <td>cs.CL, cs.CL, cs.CV, cs.LG</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>http://arxiv.org/abs/2310.17644v1</td>\n",
       "      <td>http://arxiv.org/pdf/2310.17644v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>torchdistill Meets Hugging Face Libraries for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2408.00716v1</td>\n",
       "      <td>A Natural Language Processing Framework for Ho...</td>\n",
       "      <td>Recently, the application of Artificial Intell...</td>\n",
       "      <td>Lavrentia Aravani, Emmanuel Pintelas, Christos...</td>\n",
       "      <td>cs.LG, cs.LG</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>http://arxiv.org/abs/2408.00716v1</td>\n",
       "      <td>http://arxiv.org/pdf/2408.00716v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>A Natural Language Processing Framework for Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2110.07609v1</td>\n",
       "      <td>Application of Sequence Embedding in Protein S...</td>\n",
       "      <td>In sequence-based predictions, conventionally ...</td>\n",
       "      <td>Nabil Ibtehaz, Daisuke Kihara</td>\n",
       "      <td>q-bio.QM, q-bio.QM</td>\n",
       "      <td>2021-10-14</td>\n",
       "      <td>http://arxiv.org/abs/2110.07609v1</td>\n",
       "      <td>http://arxiv.org/pdf/2110.07609v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>1 Application of Sequence Embedding in Protein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2407.17900v5</td>\n",
       "      <td>The Power of Combining Data and Knowledge: GPT...</td>\n",
       "      <td>Lymph node metastasis (LNM) is a crucial facto...</td>\n",
       "      <td>Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu</td>\n",
       "      <td>cs.CL, cs.CL, cs.LG</td>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>http://arxiv.org/abs/2407.17900v5</td>\n",
       "      <td>http://arxiv.org/pdf/2407.17900v5</td>\n",
       "      <td>industry</td>\n",
       "      <td>THEPOWER OF COMBINING DATA AND KNOWLEDGE : GPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2404.06904v1</td>\n",
       "      <td>Vision-Language Model-based Physical Reasoning...</td>\n",
       "      <td>There is a growing interest in applying large ...</td>\n",
       "      <td>Wenqiang Lai, Yuan Gao, Tin Lun Lam</td>\n",
       "      <td>cs.RO, cs.RO</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>http://arxiv.org/abs/2404.06904v1</td>\n",
       "      <td>http://arxiv.org/pdf/2404.06904v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>This work has been submitted to the IEEE for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2306.05122v1</td>\n",
       "      <td>Can AI Moderate Online Communities?</td>\n",
       "      <td>The task of cultivating healthy communication ...</td>\n",
       "      <td>Henrik Axelsen, Johannes Rude Jensen, Sebastia...</td>\n",
       "      <td>cs.CY, cs.CY</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>http://arxiv.org/abs/2306.05122v1</td>\n",
       "      <td>http://arxiv.org/pdf/2306.05122v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>1 Can AI Moderat e Online Communities ? Henrik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2409.11408v1</td>\n",
       "      <td>Optimizing Performance: How Compact Models Mat...</td>\n",
       "      <td>In this paper, we demonstrate that non-generat...</td>\n",
       "      <td>Baptiste Lefort, Eric Benhamou, Jean-Jacques O...</td>\n",
       "      <td>cs.CL, cs.CL, q-fin.ST</td>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>http://arxiv.org/abs/2409.11408v1</td>\n",
       "      <td>http://arxiv.org/pdf/2409.11408v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>Optimizing Performance: How Compact Models Mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2312.17016v1</td>\n",
       "      <td>On the Promises and Challenges of Multimodal F...</td>\n",
       "      <td>The advent of large language models (LLMs) has...</td>\n",
       "      <td>Chenjiao Tan, Qian Cao, Yiwei Li, Jielu Zhang,...</td>\n",
       "      <td>cs.CV, cs.CV, cs.AI, I.2.7; I.2.10; I.4.6; I.4...</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>http://arxiv.org/abs/2312.17016v1</td>\n",
       "      <td>http://arxiv.org/pdf/2312.17016v1</td>\n",
       "      <td>industry</td>\n",
       "      <td>On the Promises and Challenges of Multimodal F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "0   2304.14670v2  Prompt Engineering for Healthcare: Methodologi...   \n",
       "1   2305.02029v1  Natural language processing on customer note data   \n",
       "2   2310.17644v1  torchdistill Meets Hugging Face Libraries for ...   \n",
       "3   2408.00716v1  A Natural Language Processing Framework for Ho...   \n",
       "4   2110.07609v1  Application of Sequence Embedding in Protein S...   \n",
       "..           ...                                                ...   \n",
       "85  2407.17900v5  The Power of Combining Data and Knowledge: GPT...   \n",
       "86  2404.06904v1  Vision-Language Model-based Physical Reasoning...   \n",
       "87  2306.05122v1                Can AI Moderate Online Communities?   \n",
       "88  2409.11408v1  Optimizing Performance: How Compact Models Mat...   \n",
       "89  2312.17016v1  On the Promises and Challenges of Multimodal F...   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   Prompt engineering is a critical technique in ...   \n",
       "1   Automatic analysis of customer data for busine...   \n",
       "2   Reproducibility in scientific work has been be...   \n",
       "3   Recently, the application of Artificial Intell...   \n",
       "4   In sequence-based predictions, conventionally ...   \n",
       "..                                                ...   \n",
       "85  Lymph node metastasis (LNM) is a crucial facto...   \n",
       "86  There is a growing interest in applying large ...   \n",
       "87  The task of cultivating healthy communication ...   \n",
       "88  In this paper, we demonstrate that non-generat...   \n",
       "89  The advent of large language models (LLMs) has...   \n",
       "\n",
       "                                              authors  \\\n",
       "0   Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Cho...   \n",
       "1   Andrew Hilditch, David Webb, Jozef Baca, Tom A...   \n",
       "2                                 Yoshitomo Matsubara   \n",
       "3   Lavrentia Aravani, Emmanuel Pintelas, Christos...   \n",
       "4                       Nabil Ibtehaz, Daisuke Kihara   \n",
       "..                                                ...   \n",
       "85         Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu   \n",
       "86                Wenqiang Lai, Yuan Gao, Tin Lun Lam   \n",
       "87  Henrik Axelsen, Johannes Rude Jensen, Sebastia...   \n",
       "88  Baptiste Lefort, Eric Benhamou, Jean-Jacques O...   \n",
       "89  Chenjiao Tan, Qian Cao, Yiwei Li, Jielu Zhang,...   \n",
       "\n",
       "                                           categories   published  \\\n",
       "0                                        cs.AI, cs.AI  2023-04-28   \n",
       "1                                        cs.CL, cs.CL  2023-05-03   \n",
       "2                          cs.CL, cs.CL, cs.CV, cs.LG  2023-10-26   \n",
       "3                                        cs.LG, cs.LG  2024-08-01   \n",
       "4                                  q-bio.QM, q-bio.QM  2021-10-14   \n",
       "..                                                ...         ...   \n",
       "85                                cs.CL, cs.CL, cs.LG  2024-07-25   \n",
       "86                                       cs.RO, cs.RO  2024-04-10   \n",
       "87                                       cs.CY, cs.CY  2023-06-08   \n",
       "88                             cs.CL, cs.CL, q-fin.ST  2024-08-22   \n",
       "89  cs.CV, cs.CV, cs.AI, I.2.7; I.2.10; I.4.6; I.4...  2023-12-23   \n",
       "\n",
       "                                  url                            pdf_url  \\\n",
       "0   http://arxiv.org/abs/2304.14670v2  http://arxiv.org/pdf/2304.14670v2   \n",
       "1   http://arxiv.org/abs/2305.02029v1  http://arxiv.org/pdf/2305.02029v1   \n",
       "2   http://arxiv.org/abs/2310.17644v1  http://arxiv.org/pdf/2310.17644v1   \n",
       "3   http://arxiv.org/abs/2408.00716v1  http://arxiv.org/pdf/2408.00716v1   \n",
       "4   http://arxiv.org/abs/2110.07609v1  http://arxiv.org/pdf/2110.07609v1   \n",
       "..                                ...                                ...   \n",
       "85  http://arxiv.org/abs/2407.17900v5  http://arxiv.org/pdf/2407.17900v5   \n",
       "86  http://arxiv.org/abs/2404.06904v1  http://arxiv.org/pdf/2404.06904v1   \n",
       "87  http://arxiv.org/abs/2306.05122v1  http://arxiv.org/pdf/2306.05122v1   \n",
       "88  http://arxiv.org/abs/2409.11408v1  http://arxiv.org/pdf/2409.11408v1   \n",
       "89  http://arxiv.org/abs/2312.17016v1  http://arxiv.org/pdf/2312.17016v1   \n",
       "\n",
       "        type                                            content  \n",
       "0   industry  JOURNAL OF L ATEX CLASS FILES, VOL. 14, NO. 8,...  \n",
       "1   industry  Natural language processing on customer note d...  \n",
       "2   industry  torchdistill Meets Hugging Face Libraries for ...  \n",
       "3   industry  A Natural Language Processing Framework for Ho...  \n",
       "4   industry  1 Application of Sequence Embedding in Protein...  \n",
       "..       ...                                                ...  \n",
       "85  industry  THEPOWER OF COMBINING DATA AND KNOWLEDGE : GPT...  \n",
       "86  industry  This work has been submitted to the IEEE for p...  \n",
       "87  industry  1 Can AI Moderat e Online Communities ? Henrik...  \n",
       "88  industry  Optimizing Performance: How Compact Models Mat...  \n",
       "89  industry  On the Promises and Challenges of Multimodal F...  \n",
       "\n",
       "[90 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industry_papers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfenv_pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
