{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translation_papers = pd.read_parquet('data/translation_papers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_conclusion(text_list):\n",
    "    for i, text in enumerate(text_list):\n",
    "        if 'conclusion' in text[0].lower():\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into title, abstract, and body\n",
    "def split_text(text_list):\n",
    "    index_conclusion = find_index_conclusion(text_list)\n",
    "    title = \" \".join(text_list[0])  # First list, first element\n",
    "    abstract = \" \".join(text_list[1])  # Second list, first element\n",
    "    conclusion = \" \".join(text_list[index_conclusion])\n",
    "\n",
    "    return title, abstract, conclusion\n",
    "\n",
    "\n",
    "# Apply function to create new columns\n",
    "new_translation_df = df_translation_papers.copy()\n",
    "new_translation_df[[\"title\", \"abstract\", \"conclusion\"]] = new_translation_df[\"text\"].apply(\n",
    "    lambda x: pd.Series(split_text(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first 10 characters from the 'abstract' column\n",
    "new_translation_df[\"abstract\"] = new_translation_df[\"abstract\"].apply(\n",
    "    lambda x: x[10:] if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Remove the first 13 characters from the 'body' column\n",
    "new_translation_df[\"conclusion\"] = new_translation_df[\"conclusion\"].apply(\n",
    "    lambda x: x[11:] if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from helper_functions import calculate_results\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['0' '1']\n",
      "24.318397827562798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:16:32.393331: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "To address this inconsistency, and to shed light on the potential role of carabao in the transmission of S. japonicum in the Philippines, we undertook a pilot survey, collecting fecal samples from animals in Western Samar Province and we used a combination of molecular and copro-parasitological techniques to determine the prevalence and intensity of S. japonicum.\n",
      "\n",
      "Length of text: 56\n",
      "\n",
      "Vectorized text:\n",
      "[[   6 1055   16 8624    4    6 4308  405   19    2   99   50    3 1925\n",
      "     5    2  712    3  518 1152    5    2 2602   12 6115    7 4571 2021\n",
      "  9965 5168  371   20  284    5 1230 6863 3235    4   12   64    7  391\n",
      "     3  134    4 2898  958    6  628    2  605    4 1157    3  518]]\n",
      "Number of words in vocabulary: 11218\n",
      "Most common words in the vocabulary: ['', '[UNK]', 'the', 'of', 'and']\n",
      "Least common words in the vocabulary: ['0027', '0021', '001p009', '00174', '0006']\n",
      "Sentence before Vectorization : \n",
      "To address this inconsistency, and to shed light on the potential role of carabao in the transmission of S. japonicum in the Philippines, we undertook a pilot survey, collecting fecal samples from animals in Western Samar Province and we used a combination of molecular and copro-parasitological techniques to determine the prevalence and intensity of S. japonicum.\n",
      "\n",
      "Sentence After vectorization :\n",
      " [[   6 1055   16 8624    4    6 4308  405   19    2   99   50    3 1925\n",
      "     5    2  712    3  518 1152    5    2 2602   12 6115    7 4571 2021\n",
      "  9965 5168  371   20  284    5 1230 6863 3235    4   12   64    7  391\n",
      "     3  134    4 2898  958    6  628    2  605    4 1157    3  518]]\n",
      "\n",
      "Embedding Sentence :\n",
      "[[[-0.01972711 -0.03604001 -0.02243462 ... -0.00029231  0.00385607\n",
      "   -0.03091278]\n",
      "  [ 0.02582349  0.03609154  0.00285799 ...  0.02367562 -0.01355162\n",
      "    0.00220903]\n",
      "  [ 0.04104361  0.01363267  0.04673362 ... -0.00311706  0.02316063\n",
      "   -0.03643116]\n",
      "  ...\n",
      "  [-0.04119555  0.01626636  0.04215344 ... -0.00568017 -0.0370351\n",
      "    0.04118982]\n",
      "  [-0.01127089 -0.01903775 -0.02607268 ... -0.00886811 -0.03194902\n",
      "   -0.00227674]\n",
      "  [ 0.03248019  0.00769486 -0.00061233 ... -0.03120004  0.01041043\n",
      "    0.00214376]]]\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVec  (None, 55)               0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 55, 128)           1435904   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,477,058\n",
      "Trainable params: 1,477,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "9/9 [==============================] - 1s 35ms/step - loss: 1.4187 - accuracy: 0.6806 - val_loss: 1.2405 - val_accuracy: 0.8194\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.1175 - accuracy: 0.8194 - val_loss: 0.9857 - val_accuracy: 0.8194\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.9359 - accuracy: 0.8021 - val_loss: 0.8319 - val_accuracy: 0.8194\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.8360 - accuracy: 0.7847 - val_loss: 0.7273 - val_accuracy: 0.8194\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6875 - accuracy: 0.8229 - val_loss: 0.6498 - val_accuracy: 0.8194\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 0.6741 - accuracy: 0.7847 - val_loss: 0.5934 - val_accuracy: 0.8194\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.5896 - accuracy: 0.8090 - val_loss: 0.5536 - val_accuracy: 0.8194\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5586 - accuracy: 0.7951 - val_loss: 0.5233 - val_accuracy: 0.8194\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.4556 - accuracy: 0.8542 - val_loss: 0.4969 - val_accuracy: 0.8212\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5456 - accuracy: 0.7743 - val_loss: 0.4793 - val_accuracy: 0.8212\n",
      "Epoch 11/15\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 0.5519 - accuracy: 0.6875WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 135 batches). You may need to use the repeat() function when building your dataset.\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4778 - accuracy: 0.7576 - val_loss: 0.4909 - val_accuracy: 0.8368\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "claim_data_dir = \"./Claim-Extraction-dataset/\"\n",
    "claim_filenames = [claim_data_dir + filename for filename in os.listdir(claim_data_dir)]\n",
    "\n",
    "claim_train_data = pd.read_json(claim_filenames[1], lines=True)\n",
    "claim_test_data = pd.read_json(claim_filenames[0], lines=True)\n",
    "claim_val_data = pd.read_json(claim_filenames[2], lines=True)\n",
    "\n",
    "\n",
    "def sentences_label(claim_train_data):\n",
    "    ID = []\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    list_df = []\n",
    "    claim_sentences = claim_train_data[\"sentences\"]\n",
    "    claim_labels = claim_train_data[\"labels\"]\n",
    "    paper_id = claim_train_data[\"paper_id\"]\n",
    "    for i in range(len(claim_sentences)):\n",
    "        for j in range(len(claim_sentences[i])):\n",
    "            sentences.append(claim_sentences[i][j])\n",
    "            labels.append(claim_labels[i][j])\n",
    "            ID.append(paper_id[i])\n",
    "            list_df.append([paper_id[i], claim_labels[i][j], claim_sentences[i][j]])\n",
    "    df = pd.DataFrame(list_df, columns=[\"Paper Ids\", \"Label\", \"Sentences\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "claim_train_sentences_df = sentences_label(claim_train_data)\n",
    "claim_train_sentences = claim_train_sentences_df[\"Sentences\"].tolist()\n",
    "claim_train_labels_one_hot = one_hot_encoder.fit_transform(\n",
    "    claim_train_sentences_df[\"Label\"].to_numpy().reshape(-1, 1)\n",
    ")\n",
    "claim_label_encoder = LabelEncoder()\n",
    "claim_train_labels_encoded = claim_label_encoder.fit_transform(\n",
    "    claim_train_sentences_df[\"Label\"].to_numpy()\n",
    ")\n",
    "\n",
    "claim_test_sentences_df = sentences_label(claim_test_data)\n",
    "claim_test_sentences = claim_test_sentences_df[\"Sentences\"].tolist()\n",
    "claim_test_labels_one_hot = one_hot_encoder.fit_transform(\n",
    "    claim_test_sentences_df[\"Label\"].to_numpy().reshape(-1, 1)\n",
    ")\n",
    "claim_test_labels_encoded = claim_label_encoder.fit_transform(\n",
    "    claim_test_sentences_df[\"Label\"].to_numpy()\n",
    ")\n",
    "\n",
    "claim_val_sentences_df = sentences_label(claim_val_data)\n",
    "claim_val_sentences = claim_val_sentences_df[\"Sentences\"].tolist()\n",
    "claim_val_labels_one_hot = one_hot_encoder.fit_transform(\n",
    "    claim_val_sentences_df[\"Label\"].to_numpy().reshape(-1, 1)\n",
    ")\n",
    "claim_val_labels_encoded = claim_label_encoder.fit_transform(\n",
    "    claim_val_sentences_df[\"Label\"].to_numpy()\n",
    ")\n",
    "\n",
    "\n",
    "# Get class names and number of classes from LabelEncoder instance\n",
    "num_classes = len(claim_label_encoder.classes_)\n",
    "class_names = claim_label_encoder.classes_\n",
    "print(num_classes, class_names)\n",
    "\n",
    "sen_len = [len(sentences.split()) for sentences in claim_train_sentences]\n",
    "avg_sen_len = np.mean(sen_len)\n",
    "print(avg_sen_len)\n",
    "\n",
    "\n",
    "def count_words(claim_train_sentences):\n",
    "    total = []\n",
    "    total_unique = []\n",
    "    for i in range(len(claim_train_sentences)):\n",
    "        text_tokens = word_tokenize(claim_train_sentences[i])\n",
    "        # tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "        total.append(text_tokens)\n",
    "    for i in range(len(total)):\n",
    "        for j in range(len(total[i])):\n",
    "            total_unique.append(total[i][j])\n",
    "    words = list(set((total_unique)))\n",
    "    n_words = len(words)\n",
    "    return n_words\n",
    "\n",
    "\n",
    "claim_max_token = count_words(claim_train_sentences)\n",
    "\n",
    "claim_text_vectorizer = TextVectorization(\n",
    "    max_tokens=claim_max_token,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_sequence_length=55,\n",
    ")\n",
    "# Adapt text vectorizer to training sentences\n",
    "claim_text_vectorizer.adapt(claim_train_sentences)\n",
    "\n",
    "# viewing vectorize training sentences\n",
    "target_sentence = random.choice(claim_train_sentences)\n",
    "print(f\"Text:\\n{target_sentence}\")\n",
    "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
    "print(f\"\\nVectorized text:\\n{claim_text_vectorizer([target_sentence])}\")\n",
    "\n",
    "\n",
    "# Getting the vocabulary and showing most frequent and least frequest words in the vocabulary\n",
    "claim_text_vocab = claim_text_vectorizer.get_vocabulary()\n",
    "most_common = claim_text_vocab[:5]\n",
    "least_common = claim_text_vocab[-5:]\n",
    "print(f\"Number of words in vocabulary: {len(claim_text_vocab)}\"),\n",
    "print(f\"Most common words in the vocabulary: {most_common}\")\n",
    "print(f\"Least common words in the vocabulary: {least_common}\")\n",
    "\n",
    "# Get the config of our text vectorizer\n",
    "claim_text_vectorizer.get_config()\n",
    "\n",
    "token_embed = layers.Embedding(\n",
    "    input_dim=len(claim_text_vocab), output_dim=128, mask_zero=True, input_length=55\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Sentence before Vectorization : \\n{target_sentence}\\n\")\n",
    "vec_sentence = claim_text_vectorizer([target_sentence])\n",
    "print(f\"Sentence After vectorization :\\n {vec_sentence}\\n\")\n",
    "embed_sentence = token_embed(vec_sentence)\n",
    "print(f\"Embedding Sentence :\\n{embed_sentence}\\n\")\n",
    "\n",
    "# Turn our data into TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (claim_train_sentences, claim_train_labels_one_hot)\n",
    ")\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (claim_val_sentences, claim_val_labels_one_hot)\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (claim_test_sentences, claim_test_labels_one_hot)\n",
    ")\n",
    "\n",
    "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vector = claim_text_vectorizer(inputs)\n",
    "embed = token_embed(text_vector)\n",
    "x = layers.Conv1D(\n",
    "    filters=64,\n",
    "    kernel_size=5,\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=tf.keras.regularizers.L2(0.01),\n",
    ")(embed)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_1_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "    epochs=15,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=int(0.1 * len(valid_dataset)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "33/33 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "data = new_translation_df\n",
    "\n",
    "\n",
    "# Function to extract claims from a text block\n",
    "def extract_claims(text):\n",
    "    sentences = text.split(\". \")  # Split into sentences\n",
    "    results = model.predict(sentences)\n",
    "    claims = [sentence for sentence, result in zip(sentences, results) if result[0] > 0.75]\n",
    "    return claims\n",
    "\n",
    "\n",
    "# Process each abstract and body\n",
    "results = []\n",
    "for idx, row in data.iterrows():\n",
    "    id_paper = row[\"id\"]\n",
    "    title = row[\"title\"]\n",
    "    abstract = row[\"abstract\"]\n",
    "    conclusion = row[\"conclusion\"]\n",
    "    # body = row[\"body\"]\n",
    "\n",
    "    # Extract claims\n",
    "    abstract_claims = extract_claims(abstract)\n",
    "    conclusion_claims = extract_claims(conclusion)\n",
    "    # body_claims = extract_claims(body)\n",
    "\n",
    "    results.append({\"id\": id_paper,\"title\": title, \"abstract_claims\": abstract_claims, \"conclusion_claims\": conclusion_claims})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author and insitution extraction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "\n",
    "def get_main_author(arxiv_id):\n",
    "    # Search for the paper using the arXiv ID\n",
    "    search = arxiv.Search(id_list=[arxiv_id])\n",
    "\n",
    "    # Fetch the result\n",
    "    result = next(search.results())\n",
    "\n",
    "    # Get the main author (first author)\n",
    "    main_author = result.authors[0]\n",
    "\n",
    "    return main_author.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/n1zmwvf923q5h9v_4n2k33100000gn/T/ipykernel_91594/3386764335.py:9: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  result = next(search.results())\n"
     ]
    }
   ],
   "source": [
    "results_df[\"main_author\"] = results_df[\"id\"].apply(get_main_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 355/355 [05:00<00:00,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyalex import Works\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_main_author_institutions(df):\n",
    "    \"\"\"Extract first author institution for each paper using OpenAlex\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            # Extract title from nested list structure\n",
    "            title = row[\"title\"]\n",
    "\n",
    "            # Search OpenAlex by title\n",
    "            work = Works().search_filter(title=title).get()\n",
    "\n",
    "            if work and len(work) > 0:\n",
    "                paper = work[0]\n",
    "\n",
    "                # Get first author's institution\n",
    "                if paper['authorships'] and len(paper['authorships']) > 0:\n",
    "                    first_author = paper['authorships'][0]\n",
    "                    institution = (\n",
    "                        first_author['institutions'][0]['display_name']\n",
    "                        if first_author['institutions']\n",
    "                        else \"No institution found\"\n",
    "                    )\n",
    "                    author_name = first_author['author']['display_name']\n",
    "                else:\n",
    "                    institution = \"No authors found\"\n",
    "                    author_name = \"Unknown\"\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"main_author\": author_name,\n",
    "                        \"institution\": institution,\n",
    "                        \"year\": paper['publication_year'],\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"title\": title,\n",
    "                        \"main_author\": \"Not found\",\n",
    "                        \"institution\": \"Paper not found in OpenAlex\",\n",
    "                        \"year\": None,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            time.sleep(0.1)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"title\": title,\n",
    "                    \"main_author\": \"Error\",\n",
    "                    \"institution\": f\"Error: {str(e)}\",\n",
    "                    \"year\": None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Process your results_df\n",
    "institutions_df = get_main_author_institutions(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions_df_cleaned = institutions_df[institutions_df[\"institution\"] != \"No institution found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def academic_or_industry(institution):\n",
    "    if \"university\" in institution.lower() or \"college\" in institution.lower() or \"institute\" in institution.lower():\n",
    "        return \"Academic\"\n",
    "    else:\n",
    "        return \"Industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j0/n1zmwvf923q5h9v_4n2k33100000gn/T/ipykernel_91594/1260278320.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  institutions_df_cleaned[\"institution_type\"] = institutions_df_cleaned[\"institution\"].apply(academic_or_industry)\n"
     ]
    }
   ],
   "source": [
    "institutions_df_cleaned[\"institution_type\"] = institutions_df_cleaned[\"institution\"].apply(academic_or_industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df = institutions_df_cleaned[\n",
    "    (institutions_df_cleaned[\"institution_type\"] == \"Industry\")\n",
    "    & (institutions_df_cleaned[\"year\"].notnull())\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"univ\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"instit\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"eth\"))\n",
    "    & ~(\n",
    "        institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"polytechnique\")\n",
    "    )\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"mit\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"instit\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"national\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"beijing\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"commonwealth\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"bruno\"))\n",
    "    & ~(institutions_df_cleaned[\"institution\"].str.lower().str.contains(\"laboratoire d'\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_df_complete = results_df.merge(industry_df, on=[\"title\",\"main_author\"], how=\"inner\")\n",
    "academic_df_complete = results_df.merge(\n",
    "    institutions_df_cleaned[\n",
    "        (institutions_df_cleaned[\"institution_type\"] == \"Academic\")\n",
    "        & (institutions_df_cleaned[\"year\"].notnull())\n",
    "    ]\n",
    "    .drop_duplicates(subset=[\"title\"]),\n",
    "    on=[\"title\",\"main_author\"],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_industry_really_complete =industry_df_complete.merge(new_translation_df, on=[\"title\",\"id\"], how=\"inner\")\n",
    "df_academic_really_complete =academic_df_complete.merge(new_translation_df, on=[\"title\",\"id\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_academic_really_complete.to_parquet(\"data/academic_really_complete.parquet\")\n",
    "df_industry_really_complete.to_parquet(\"data/industry_really_complete.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in industry titles:\n",
      "neural: 6\n",
      "translation: 5\n",
      "language: 4\n",
      "machine: 3\n",
      "show: 3\n",
      "models: 3\n",
      "pretraining: 2\n",
      "generation: 2\n",
      "fully: 2\n",
      "embedding: 2\n",
      "\n",
      "Top 10 words in academic titles:\n",
      "language: 29\n",
      "neural: 23\n",
      "translation: 17\n",
      "machine: 16\n",
      "natural: 13\n",
      "processing: 11\n",
      "networks: 10\n",
      "word: 9\n",
      "survey: 8\n",
      "learning: 8\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "def get_word_frequencies(titles):\n",
    "    # Combine all titles into one string and convert to lowercase\n",
    "    text = \" \".join([title.lower() for title in titles])\n",
    "\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Get stopwords and add custom ones\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    custom_stops = {\"using\", \"based\", \"via\", \"towards\", \"approach\", \"study\", \"analysis\"}\n",
    "    stop_words.update(custom_stops)\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Count frequencies\n",
    "    return Counter(words).most_common(10)\n",
    "\n",
    "\n",
    "# Get frequencies for both categories\n",
    "industry_freq = get_word_frequencies(df_industry_really_complete[\"title\"])\n",
    "academic_freq = get_word_frequencies(df_academic_really_complete[\"title\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Top 10 words in industry titles:\")\n",
    "for word, count in industry_freq:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in academic titles:\")\n",
    "for word, count in academic_freq:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in industry abstracts:\n",
      "language: 49\n",
      "models: 38\n",
      "translation: 33\n",
      "natural: 32\n",
      "processing: 29\n",
      "model: 28\n",
      "tasks: 27\n",
      "machine: 24\n",
      "show: 18\n",
      "sentence: 18\n",
      "\n",
      "Top 10 words in academic abstracts:\n",
      "language: 301\n",
      "translation: 194\n",
      "models: 186\n",
      "natural: 164\n",
      "model: 149\n",
      "processing: 148\n",
      "tasks: 146\n",
      "machine: 128\n",
      "languages: 109\n",
      "data: 107\n"
     ]
    }
   ],
   "source": [
    "# Get frequencies for both categories\n",
    "industry_freq = get_word_frequencies(df_industry_really_complete[\"abstract\"])\n",
    "academic_freq = get_word_frequencies(df_academic_really_complete[\"abstract\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Top 10 words in industry abstracts:\")\n",
    "for word, count in industry_freq:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in academic abstracts:\")\n",
    "for word, count in academic_freq:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in industry conclusions:\n",
      "model: 33\n",
      "image: 33\n",
      "models: 27\n",
      "translation: 24\n",
      "method: 22\n",
      "results: 20\n",
      "mathcal: 19\n",
      "language: 17\n",
      "languages: 16\n",
      "neural: 16\n",
      "\n",
      "Top 10 words in academic conclusions:\n",
      "models: 156\n",
      "model: 149\n",
      "language: 131\n",
      "tasks: 112\n",
      "translation: 110\n",
      "work: 106\n",
      "future: 105\n",
      "data: 95\n",
      "different: 81\n",
      "languages: 81\n"
     ]
    }
   ],
   "source": [
    "# Get frequencies for both categories\n",
    "industry_freq = get_word_frequencies(df_industry_really_complete[\"conclusion\"])\n",
    "academic_freq = get_word_frequencies(df_academic_really_complete[\"conclusion\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Top 10 words in industry conclusions:\")\n",
    "for word, count in industry_freq:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in academic conclusions:\")\n",
    "for word, count in academic_freq:\n",
    "    print(f\"{word}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streem-wind-prod-forecast-jFLq_jOy-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
